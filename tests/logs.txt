

2024-04-20 22:31:22,118 - INFO - Received chat message: user_id='brian' message='reports'


2024-04-20 22:31:22,120 - INFO - Called the handcrafted conversation flow


2024-04-20 22:31:22,120 - INFO - Received event in the handler


2024-04-20 22:31:22,120 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:31:22,120 - INFO - Sending messages to the model:
	{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'reports'}


2024-04-20 22:31:22,124 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 22:31:22,125 - DEBUG - max_retries: 3


2024-04-20 22:31:22,125 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x106651ab0>


2024-04-20 22:31:22,133 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:31:22,170 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:31:22,204 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107c3de70>


2024-04-20 22:31:22,204 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x107a9c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:31:22,224 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107c3d210>


2024-04-20 22:31:22,224 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:31:22,225 - DEBUG - send_request_headers.complete


2024-04-20 22:31:22,225 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:31:22,225 - DEBUG - send_request_body.complete


2024-04-20 22:31:22,225 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:31:22,364 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 05:31:22 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599698'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_767236afbb48511e8ab805943b65338b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=W.uOQgZqoaeVteyqJj8DulOh0TaXsbETy7reAdVyoUE-1713677482-1.0.1.1-AJTI5Ar9o_PuH2r2P652x9_QptQLhc5D_UiuW4aJIHYSLm_72ciw.HWsC08RMTWUikUF1TzvT3OJeScCL6cn1Q; path=/; expires=Sun, 21-Apr-24 06:01:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=bsP_OZdfQqVuTIXsNkPDOSFfCpxTg3AFXkJ3OVLMaKA-1713677482385-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877afcc82efa7cda-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:31:22,364 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 22:31:22,364 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:31:22,364 - DEBUG - receive_response_body.complete


2024-04-20 22:31:22,364 - DEBUG - response_closed.started


2024-04-20 22:31:22,365 - DEBUG - response_closed.complete


2024-04-20 22:31:22,365 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 22:31:22,365 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 22:31:22,368 - DEBUG - Not retrying


2024-04-20 22:31:22,368 - DEBUG - Re-raising status error


2024-04-20 22:31:22,368 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107aef010>


2024-04-20 22:31:22,372 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:31:22,373 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:31:22,373 - DEBUG - send_request_headers.complete


2024-04-20 22:31:22,373 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:31:22,373 - DEBUG - send_request_body.complete


2024-04-20 22:31:22,373 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:31:22,512 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 05:31:22 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'30'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599698'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_f5907326e83aece4bf398052741001a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877afcc90fb67cda-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:31:22,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 22:31:22,512 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:31:22,512 - DEBUG - receive_response_body.complete


2024-04-20 22:31:22,512 - DEBUG - response_closed.started


2024-04-20 22:31:22,512 - DEBUG - response_closed.complete


2024-04-20 22:31:22,512 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 22:31:22,512 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 22:31:22,513 - DEBUG - Not retrying


2024-04-20 22:31:22,513 - DEBUG - Re-raising status error


2024-04-20 22:31:22,513 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107c71060>


2024-04-20 22:31:22,516 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:31:22,516 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:31:22,517 - DEBUG - send_request_headers.complete


2024-04-20 22:31:22,517 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:31:22,517 - DEBUG - send_request_body.complete


2024-04-20 22:31:22,517 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:31:22,649 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 05:31:22 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'25'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599698'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_6d87780f7679f11d36ff191683f51b33'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877afcc9f8407cda-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:31:22,650 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 22:31:22,650 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:31:22,651 - DEBUG - receive_response_body.complete


2024-04-20 22:31:22,651 - DEBUG - response_closed.started


2024-04-20 22:31:22,651 - DEBUG - response_closed.complete


2024-04-20 22:31:22,651 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 22:31:22,651 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 22:31:22,652 - DEBUG - Not retrying


2024-04-20 22:31:22,652 - DEBUG - Re-raising status error


2024-04-20 22:35:54,557 - INFO - Received chat message: user_id='brian' message='reports please'


2024-04-20 22:35:54,558 - INFO - Called the handcrafted conversation flow


2024-04-20 22:35:54,559 - INFO - Received event in the handler


2024-04-20 22:35:54,559 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:35:54,559 - INFO - Sending messages to the model:
	{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports please'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'reports please'}


2024-04-20 22:35:54,563 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports please'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 22:35:54,564 - DEBUG - max_retries: 3


2024-04-20 22:35:54,564 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x112651b10>


2024-04-20 22:35:54,573 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports please'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:35:54,609 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:35:54,647 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x112e3a050>


2024-04-20 22:35:54,647 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x112a9c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:35:54,668 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x112aecb50>


2024-04-20 22:35:54,668 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:35:54,668 - DEBUG - send_request_headers.complete


2024-04-20 22:35:54,668 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:35:54,669 - DEBUG - send_request_body.complete


2024-04-20 22:35:54,669 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:35:54,801 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 05:35:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599693'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_a7fe2aefa522f8f48dd10df86c939452'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=.Ydt6hFjloBPGzA_yzCVk8s1WwtrFT2aoQaHghDcqWI-1713677754-1.0.1.1-Ho4E_s_hl45A3RvlQ6iL99ygAuwGZvAvKWRGSCGKbVpjd1im_WWNu4W8Ac2rnM85uGeWi25DJAeEeL0uv2ykeg; path=/; expires=Sun, 21-Apr-24 06:05:54 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=xRBU0jAbl_LuVTP7.0gn0mOMTdfqHjclko0sb.zq.YQ-1713677754823-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b036eea49320f-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:35:54,801 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 22:35:54,801 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:35:54,802 - DEBUG - receive_response_body.complete


2024-04-20 22:35:54,802 - DEBUG - response_closed.started


2024-04-20 22:35:54,802 - DEBUG - response_closed.complete


2024-04-20 22:35:54,802 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 22:35:54,802 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 22:35:54,803 - DEBUG - Not retrying


2024-04-20 22:35:54,803 - DEBUG - Re-raising status error


2024-04-20 22:35:54,804 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x112aeee00>


2024-04-20 22:35:54,809 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports please'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:35:54,809 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:35:54,810 - DEBUG - send_request_headers.complete


2024-04-20 22:35:54,810 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:35:54,810 - DEBUG - send_request_body.complete


2024-04-20 22:35:54,810 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:35:54,938 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 05:35:54 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599693'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_c6ce5c1209d98d50afed21a6619dc4f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b036fcaf4320f-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:35:54,938 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 22:35:54,938 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:35:54,938 - DEBUG - receive_response_body.complete


2024-04-20 22:35:54,939 - DEBUG - response_closed.started


2024-04-20 22:35:54,939 - DEBUG - response_closed.complete


2024-04-20 22:35:54,939 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 22:35:54,939 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 22:35:54,939 - DEBUG - Not retrying


2024-04-20 22:35:54,939 - DEBUG - Re-raising status error


2024-04-20 22:35:54,939 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x112e39210>


2024-04-20 22:35:54,943 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports please'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:35:54,943 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:35:54,944 - DEBUG - send_request_headers.complete


2024-04-20 22:35:54,944 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:35:54,944 - DEBUG - send_request_body.complete


2024-04-20 22:35:54,944 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:35:55,092 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 05:35:55 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'32'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599694'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_5907b15cb0b4f0cbb5351939e40eaf39'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b0370abb2320f-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:35:55,093 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 22:35:55,093 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:35:55,094 - DEBUG - receive_response_body.complete


2024-04-20 22:35:55,095 - DEBUG - response_closed.started


2024-04-20 22:35:55,095 - DEBUG - response_closed.complete


2024-04-20 22:35:55,095 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 22:35:55,095 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 22:35:55,096 - DEBUG - Not retrying


2024-04-20 22:35:55,096 - DEBUG - Re-raising status error


2024-04-20 22:37:33,039 - INFO - Received chat message: user_id='brian' message='reports please'


2024-04-20 22:37:33,041 - INFO - Called the handcrafted conversation flow


2024-04-20 22:37:33,042 - INFO - Received event in the handler


2024-04-20 22:37:33,042 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:37:33,042 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports please'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'reports please'}


2024-04-20 22:37:33,051 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports please'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 22:37:33,052 - DEBUG - max_retries: 3


2024-04-20 22:37:33,052 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x109055a50>


2024-04-20 22:37:33,059 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'reports please'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:37:33,091 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:37:33,128 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10d941f00>


2024-04-20 22:37:33,128 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1094950c0> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:37:33,147 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10d9411e0>


2024-04-20 22:37:33,148 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:37:33,148 - DEBUG - send_request_headers.complete


2024-04-20 22:37:33,148 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:37:33,148 - DEBUG - send_request_body.complete


2024-04-20 22:37:33,148 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:37:36,018 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:37:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599693'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'30ms'), (b'x-request-id', b'req_b7381f9861715d3018c053eeee149641'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=_qJ13nBEHwu0qPfkW.DaEWtUpbbROhoMaKtOSzr8zgk-1713677856-1.0.1.1-lPZorP4VkYP564gDwt5p39wruUDmJLl3M0ENsmr1TjpWWWNpyZJI4IFXKdZWzmteyj1dIB6.GZ.6VW.ulZZydw; path=/; expires=Sun, 21-Apr-24 06:07:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=1Pc7uwy1vIWpvEn0Dy_eaLHesPRqA1TrvGyeL3g5Wvw-1713677856007-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b05d66eb06a26-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:37:36,021 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:37:36,022 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:37:36,022 - DEBUG - receive_response_body.complete


2024-04-20 22:37:36,022 - DEBUG - response_closed.started


2024-04-20 22:37:36,023 - DEBUG - response_closed.complete


2024-04-20 22:37:36,023 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:37:36,038 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKBJYK0jNJmmJZ1NPbvpKY3LPuSg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NcXgWE35OBhx8vBF5Nuvpexd', function=Function(arguments='{"filter_prompt":null,"questions":"Could you please provide more details on the type of reports you are looking for? For example, how often do you want the reports to be generated, are there any specific topics, hashtags, or users you are interested in, and do you have any preferences regarding the number of tweets included in each report?"}', name='Stage3'), type='function')]))], created=1713677853, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=70, prompt_tokens=340, total_tokens=410))


2024-04-20 22:37:36,041 - INFO - Received completion from the model:
filter_prompt: None
questions: Could you please provide more details on the type of reports you are looking for? For example, how often do you want the reports to be generated, are there any specific topics, hashtags, or users you are interested in, and do you have any preferences regarding the number of tweets included in each report?


2024-04-20 22:38:34,693 - INFO - Received chat message: user_id='brian' message="Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"


2024-04-20 22:38:34,704 - INFO - Called the handcrafted conversation flow


2024-04-20 22:38:34,705 - INFO - Received event in the handler


2024-04-20 22:38:34,705 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:38:34,705 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports please'}
	{'role': 'assistant', 'content': 'Could you please provide more details on the type of reports you are looking for? For example, how often do you want the reports to be generated, are there any specific topics, hashtags, or users you are interested in, and do you have any preferences regarding the number of tweets included in each report?'}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}


2024-04-20 22:38:34,712 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': 'Could you please provide more details on the type of reports you are looking for? For example, how often do you want the reports to be generated, are there any specific topics, hashtags, or users you are interested in, and do you have any preferences regarding the number of tweets included in each report?'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 22:38:34,712 - DEBUG - max_retries: 3


2024-04-20 22:38:34,712 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10d99a0b0>


2024-04-20 22:38:34,721 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': 'Could you please provide more details on the type of reports you are looking for? For example, how often do you want the reports to be generated, are there any specific topics, hashtags, or users you are interested in, and do you have any preferences regarding the number of tweets included in each report?'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:38:34,722 - DEBUG - close.started


2024-04-20 22:38:34,723 - DEBUG - close.complete


2024-04-20 22:38:34,723 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:38:34,756 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10d9f0fd0>


2024-04-20 22:38:34,756 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1094950c0> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:38:34,776 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10d9f0820>


2024-04-20 22:38:34,776 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:38:34,777 - DEBUG - send_request_headers.complete


2024-04-20 22:38:34,777 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:38:34,777 - DEBUG - send_request_body.complete


2024-04-20 22:38:34,777 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:38:39,915 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:38:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4860'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599270'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_a962729f33bc341498000472fbdaeb76'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b07579aea0904-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:38:39,919 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:38:39,920 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:38:39,921 - DEBUG - receive_response_body.complete


2024-04-20 22:38:39,921 - DEBUG - response_closed.started


2024-04-20 22:38:39,921 - DEBUG - response_closed.complete


2024-04-20 22:38:39,922 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:38:39,923 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKCJ94aYBRfBc0a5eJVmM11O1iwK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_GByDHWmhZlGBgdK7mkz0PkgF', function=Function(arguments='{\n  "filter_prompt": "Looking for tweets about new methods in Retrieval-Augmented Generation (RAG) that address specific problems such as: \\n1. New methods for chunking in RAG\\n2. State-of-the-art vector databases\\n3. Models specifically fine-tuned for RAG\\n4. Methods that utilize metadata or descriptions alongside vector similarity for navigation\\n5. Systems that autonomously organize arbitrary data into a file structure with descriptions and enable LLM-based searching\\n\\nPlease include tweets that provide insights, advancements, or discussions related to these topics. Exclude general content about RAG that does not contribute to these specific areas of interest.",\n  "questions": null\n}', name='Stage3'), type='function')]))], created=1713677915, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=140, prompt_tokens=685, total_tokens=825))


2024-04-20 22:38:39,927 - INFO - Received completion from the model:
filter_prompt: Looking for tweets about new methods in Retrieval-Augmented Generation (RAG) that address specific problems such as: 
1. New methods for chunking in RAG
2. State-of-the-art vector databases
3. Models specifically fine-tuned for RAG
4. Methods that utilize metadata or descriptions alongside vector similarity for navigation
5. Systems that autonomously organize arbitrary data into a file structure with descriptions and enable LLM-based searching

Please include tweets that provide insights, advancements, or discussions related to these topics. Exclude general content about RAG that does not contribute to these specific areas of interest.
questions: None


2024-04-20 22:38:47,820 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 22:38:47,825 - INFO - Called the handcrafted conversation flow


2024-04-20 22:38:47,829 - INFO - Received event in the handler


2024-04-20 22:38:47,830 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:52:36,371 - INFO - Received chat message: user_id='brian' message='reports please'


2024-04-20 22:52:36,375 - INFO - Called the handcrafted conversation flow


2024-04-20 22:52:36,378 - INFO - Received event in the handler


2024-04-20 22:52:36,378 - INFO - Received event in the determine_filter_target function


2024-04-20 22:52:36,378 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}
	{'role': 'user', 'content': 'reports please'}


2024-04-20 22:52:36,390 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage1'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports please'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}}


2024-04-20 22:52:36,391 - DEBUG - max_retries: 3


2024-04-20 22:52:36,391 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x105251ab0>


2024-04-20 22:52:36,396 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports please'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}]}}


2024-04-20 22:52:36,432 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:52:36,468 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109a51960>


2024-04-20 22:52:36,468 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10559c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:52:36,487 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1055ecb20>


2024-04-20 22:52:36,487 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:52:36,488 - DEBUG - send_request_headers.complete


2024-04-20 22:52:36,488 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:52:36,488 - DEBUG - send_request_body.complete


2024-04-20 22:52:36,488 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:52:37,296 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:52:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'683'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599733'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'req_09b4e0a0d31b15b4bdfdfc465d3da6e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=nRCq0iSqV3PXBs4zcDX5kZjfSJvxsU7gTFDHoI0emK0-1713678757-1.0.1.1-7ua5uQMgQAEUB.PWzuoBsDEeFbDxlW0ySadZ9tPGMcnow1mkHeFAUXsEDXGbjTJhDVEHmfT1eNPlH.cLSzRCSQ; path=/; expires=Sun, 21-Apr-24 06:22:37 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OUJ_Obvc8COBDhG70K3mOuB0HrLhWDSUQ.EGkc2NNjI-1713678757332-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b1be46b780ff7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:52:37,300 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:52:37,304 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:52:37,305 - DEBUG - receive_response_body.complete


2024-04-20 22:52:37,305 - DEBUG - response_closed.started


2024-04-20 22:52:37,305 - DEBUG - response_closed.complete


2024-04-20 22:52:37,305 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:52:37,315 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKPsSNY2MNbNcFyfqvE84LbSOGL3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VcS3wTa6x1qh6l1DrL7VTwPz', function=Function(arguments='{"filter_target":"reports","message":""}', name='Stage1'), type='function')]))], created=1713678756, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=9, prompt_tokens=282, total_tokens=291))


2024-04-20 22:52:37,319 - INFO - Received completion from the model:
filter_target: reports
message: 


2024-04-20 22:56:23,502 - INFO - Received chat message: user_id='brian' message="Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"


2024-04-20 22:56:23,504 - INFO - Called the handcrafted conversation flow


2024-04-20 22:56:23,504 - INFO - Received event in the handler


2024-04-20 22:56:23,504 - INFO - Received event in the build_primary_prompt function


2024-04-20 22:56:23,505 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports please'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}


2024-04-20 22:56:23,508 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-20 22:56:23,508 - DEBUG - max_retries: 3


2024-04-20 22:56:23,508 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x109aad3c0>


2024-04-20 22:56:23,515 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 22:56:23,516 - DEBUG - close.started


2024-04-20 22:56:23,516 - DEBUG - close.complete


2024-04-20 22:56:23,516 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:56:23,550 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c444c0>


2024-04-20 22:56:23,551 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10559c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:56:23,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109aafcd0>


2024-04-20 22:56:23,571 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:56:23,572 - DEBUG - send_request_headers.complete


2024-04-20 22:56:23,572 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:56:23,572 - DEBUG - send_request_body.complete


2024-04-20 22:56:23,572 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:56:28,984 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:56:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5298'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599266'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_35e3348e293a4d91888009a816e9c639'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b216fad6b2f76-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:56:28,985 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:56:28,986 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:56:28,987 - DEBUG - receive_response_body.complete


2024-04-20 22:56:28,987 - DEBUG - response_closed.started


2024-04-20 22:56:28,987 - DEBUG - response_closed.complete


2024-04-20 22:56:28,988 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:56:28,990 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKTXek1Ovz4JhCeYJ7CNz82Gp4RC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gs4BbZXTJEcHCBehHGquvKpu', function=Function(arguments='{"rewritten_primary_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content.","questions":null,"name":"RAG Innovation"}', name='Stage2'), type='function')]))], created=1713678983, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=163, prompt_tokens=707, total_tokens=870))


2024-04-20 22:56:28,993 - INFO - Received completion from the model:
rewritten_primary_prompt: I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content.
questions: None


2024-04-20 22:56:35,938 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 22:56:35,947 - INFO - Called the handcrafted conversation flow


2024-04-20 22:56:35,948 - INFO - Received event in the handler


2024-04-20 22:56:35,948 - INFO - Received event in the build_primary_prompt function


2024-04-20 22:56:51,172 - INFO - Received chat message: user_id='brian' message='i just want it to run every 3 days'


2024-04-20 22:56:51,181 - INFO - Called the handcrafted conversation flow


2024-04-20 22:56:51,181 - INFO - Received event in the handler


2024-04-20 22:56:51,181 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:56:51,181 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports please'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content."}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'i just want it to run every 3 days'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'i just want it to run every 3 days'}


2024-04-20 22:56:51,183 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'i just want it to run every 3 days'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'i just want it to run every 3 days'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 22:56:51,183 - DEBUG - max_retries: 3


2024-04-20 22:56:51,183 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x109c45f90>


2024-04-20 22:56:51,195 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'i just want it to run every 3 days'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'i just want it to run every 3 days'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 22:56:51,196 - DEBUG - close.started


2024-04-20 22:56:51,196 - DEBUG - close.complete


2024-04-20 22:56:51,196 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:56:51,232 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c55db0>


2024-04-20 22:56:51,232 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10559c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:56:51,268 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c55600>


2024-04-20 22:56:51,268 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:56:51,268 - DEBUG - send_request_headers.complete


2024-04-20 22:56:51,268 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:56:51,269 - DEBUG - send_request_body.complete


2024-04-20 22:56:51,269 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:56:52,537 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:56:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'992'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599005'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'99ms'), (b'x-request-id', b'req_231f2f750866bef2c7875eedff28512a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b221cc91b0911-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:56:52,539 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:56:52,540 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:56:52,541 - DEBUG - receive_response_body.complete


2024-04-20 22:56:52,543 - DEBUG - response_closed.started


2024-04-20 22:56:52,544 - DEBUG - response_closed.complete


2024-04-20 22:56:52,545 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:56:52,547 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKTzbAusKme2l0wtJm3FZUv08Xgi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gnWcJtmaBm7DGvZx0WCLV21j', function=Function(arguments='{"filter_prompt":"Run every 3 days","questions":null}', name='Stage3'), type='function')]))], created=1713679011, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=14, prompt_tokens=928, total_tokens=942))


2024-04-20 22:56:52,549 - INFO - Received completion from the model:
filter_prompt: Run every 3 days
questions: None


2024-04-20 22:56:59,200 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 22:56:59,207 - INFO - Called the handcrafted conversation flow


2024-04-20 22:56:59,208 - INFO - Received event in the handler


2024-04-20 22:56:59,208 - INFO - Received event in the build_filter_prompt function


2024-04-20 22:57:19,098 - INFO - Received chat message: user_id='brian' message='concise, simple, technical and focused on insights '


2024-04-20 22:57:19,101 - INFO - Called the handcrafted conversation flow


2024-04-20 22:57:19,102 - INFO - Received event in the handler


2024-04-20 22:57:19,102 - INFO - Received event in the build_report_guide function


2024-04-20 22:57:19,102 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports please'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content."}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'i just want it to run every 3 days'}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nRun every 3 days"}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. Please specify the format you prefer for these reports (e.g., text, PDF, spreadsheet). For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}
	{'role': 'user', 'content': 'concise, simple, technical and focused on insights '}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}
	{'role': 'user', 'content': 'concise, simple, technical and focused on insights '}


2024-04-20 22:57:19,109 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage4'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'i just want it to run every 3 days'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nRun every 3 days"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. Please specify the format you prefer for these reports (e.g., text, PDF, spreadsheet). For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'concise, simple, technical and focused on insights '}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'concise, simple, technical and focused on insights '}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}}


2024-04-20 22:57:19,109 - DEBUG - max_retries: 3


2024-04-20 22:57:19,109 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x109c44970>


2024-04-20 22:57:19,127 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports please'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG applications. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata, descriptions, and language models to navigate through a structured hierarchy like folders or trees. A particular area of interest is the development of systems capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling a language model to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'i just want it to run every 3 days'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nRun every 3 days"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. Please specify the format you prefer for these reports (e.g., text, PDF, spreadsheet). For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'concise, simple, technical and focused on insights '}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'concise, simple, technical and focused on insights '}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}]}}


2024-04-20 22:57:19,128 - DEBUG - close.started


2024-04-20 22:57:19,128 - DEBUG - close.complete


2024-04-20 22:57:19,128 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:57:19,144 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c63e20>


2024-04-20 22:57:19,144 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10559c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:57:19,164 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c63f10>


2024-04-20 22:57:19,164 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:57:19,164 - DEBUG - send_request_headers.complete


2024-04-20 22:57:19,164 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:57:19,165 - DEBUG - send_request_body.complete


2024-04-20 22:57:19,165 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:57:24,691 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:57:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5366'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598820'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'118ms'), (b'x-request-id', b'req_8ed969da21ecc57f4189f8076ebaf265'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b22cb1ec0102d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:57:24,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:57:24,694 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:57:24,695 - DEBUG - receive_response_body.complete


2024-04-20 22:57:24,695 - DEBUG - response_closed.started


2024-04-20 22:57:24,695 - DEBUG - response_closed.complete


2024-04-20 22:57:24,696 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:57:24,697 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKURzTfyajjzvS8Pu1bixy1V50hl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3QrKImM7miOABmsARr6LSgaG', function=Function(arguments='{"report_guide":"The report will be concise, simple, and technical, focusing primarily on insights related to innovative methods in Retrieval-Augmented Generation (RAG). It will include information on new techniques for chunking in RAG, the latest state-of-the-art vector databases, and models fine-tuned for RAG applications. The report will also highlight novel approaches that utilize metadata, descriptions, and language models to navigate structured hierarchies, as well as systems that autonomously organize data into a file structure for LLM search capabilities. The tone will be technical, presenting the most relevant and insightful findings from the tweets.","questions":null}', name='Stage4'), type='function')]))], created=1713679039, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=129, prompt_tokens=1077, total_tokens=1206))


2024-04-20 22:57:24,699 - INFO - Received completion from the model:
report_guide: The report will be concise, simple, and technical, focusing primarily on insights related to innovative methods in Retrieval-Augmented Generation (RAG). It will include information on new techniques for chunking in RAG, the latest state-of-the-art vector databases, and models fine-tuned for RAG applications. The report will also highlight novel approaches that utilize metadata, descriptions, and language models to navigate structured hierarchies, as well as systems that autonomously organize data into a file structure for LLM search capabilities. The tone will be technical, presenting the most relevant and insightful findings from the tweets.
questions: None


2024-04-20 22:57:34,231 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 22:57:34,236 - INFO - Called the handcrafted conversation flow


2024-04-20 22:57:34,237 - INFO - Received event in the handler


2024-04-20 22:57:34,237 - INFO - Received event in the build_report_guide function


2024-04-20 22:57:34,248 - INFO - Building filter


2024-04-20 22:57:34,248 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}
	{'role': 'user', 'content': 'Run every 3 days'}


2024-04-20 22:57:34,254 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.ExtractedFilters'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'Run every 3 days'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fil in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report?', 'title': 'Return Cap'}}, 'type': 'object', 'required': []}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}}


2024-04-20 22:57:34,254 - DEBUG - max_retries: 3


2024-04-20 22:57:34,254 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x109c55870>


2024-04-20 22:57:34,258 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'Run every 3 days'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fil in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report?', 'title': 'Return Cap'}}, 'type': 'object', 'required': []}}}]}}


2024-04-20 22:57:34,259 - DEBUG - close.started


2024-04-20 22:57:34,259 - DEBUG - close.complete


2024-04-20 22:57:34,259 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 22:57:34,292 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c67610>


2024-04-20 22:57:34,292 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10559c540> server_hostname='api.openai.com' timeout=5.0


2024-04-20 22:57:34,311 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x109c66e60>


2024-04-20 22:57:34,311 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 22:57:34,311 - DEBUG - send_request_headers.complete


2024-04-20 22:57:34,311 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 22:57:34,311 - DEBUG - send_request_body.complete


2024-04-20 22:57:34,311 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 22:57:36,162 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 05:57:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1673'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599941'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_6dd1f0f4808fe425e2049fafe43b1705'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b2329cd482ab9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 22:57:36,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 22:57:36,164 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 22:57:36,165 - DEBUG - receive_response_body.complete


2024-04-20 22:57:36,166 - DEBUG - response_closed.started


2024-04-20 22:57:36,166 - DEBUG - response_closed.complete


2024-04-20 22:57:36,167 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 22:57:36,169 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GKUg2wlbktFqMJTabVUIwP7vFmKl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Y8l6RDJSWj2MY3kEYkMzKvin', function=Function(arguments='{"filter_period":3}', name='ExtractedFilters'), type='function')]))], created=1713679054, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=6, prompt_tokens=297, total_tokens=303))


2024-04-20 22:57:36,174 - INFO - Received completion from the model:
filter_period: 3, usernames: None, only_search_specified_usernames: None, only_search_followers: None, return_cap: None


2024-04-20 23:12:19,204 - INFO - Token: eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJ1c2VyX2lkIjoiYnJpYW4iLCJleHAiOjE3MTYyMzYxNTUsImlhdCI6MTcxMzY0NDE1NX0.DUKYoY2KyxJr48LUsF1c8km7xqulxCHa0eLo9w2sZso   first


2024-04-20 23:12:19,206 - INFO - Payload: {'user_id': 'brian', 'exp': 1716236155, 'iat': 1713644155}   second


2024-04-20 23:40:35,164 - INFO - Received chat message: user_id='brian' message='reports'


2024-04-20 23:40:35,165 - INFO - Called the handcrafted conversation flow


2024-04-20 23:40:35,165 - INFO - Received event in the handler


2024-04-20 23:40:35,166 - INFO - Received event in the determine_filter_target function


2024-04-20 23:40:35,166 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}
	{'role': 'user', 'content': 'reports'}


2024-04-20 23:40:35,171 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage1'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}}


2024-04-20 23:40:35,171 - DEBUG - max_retries: 8


2024-04-20 23:40:35,171 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e51a80>


2024-04-20 23:40:35,175 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}]}}


2024-04-20 23:40:35,202 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:40:35,238 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1045462c0>


2024-04-20 23:40:35,239 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10419c640> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:40:35,257 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1041edb40>


2024-04-20 23:40:35,258 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:35,259 - DEBUG - send_request_headers.complete


2024-04-20 23:40:35,259 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:35,259 - DEBUG - send_request_body.complete


2024-04-20 23:40:35,259 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:36,337 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:40:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'935'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599735'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'req_26ef0ae8499d806dbd1b7b0a64e8687d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=aana1i_a7Tcuihkf5wBIW4aLe5JuW9Y_rGWtkMTwnfM-1713681636-1.0.1.1-NOvEe4TbW__JOMacsyG6MaN39ihrnsZmI33.etHt4YzuheJJbo.x_j3PhRUyLncw_VMqmn.HNsPRkpbNFApE3A; path=/; expires=Sun, 21-Apr-24 07:10:36 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=P6e5aK9WcDCoRKW4kzm.wMZMXGQmXOvMRb4Nn232Dqc-1713681636364-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b622cdd227bd3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:36,338 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:40:36,338 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:36,339 - DEBUG - receive_response_body.complete


2024-04-20 23:40:36,339 - DEBUG - response_closed.started


2024-04-20 23:40:36,339 - DEBUG - response_closed.complete


2024-04-20 23:40:36,339 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:40:36,344 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLAJ0fsz5RbAIwMQZDR44B1PxBKd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HDSJgWzhjQJEjJnM8sAwSsHg', function=Function(arguments='{"filter_target":"reports","message":""}', name='Stage1'), type='function')]))], created=1713681635, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=9, prompt_tokens=281, total_tokens=290))


2024-04-20 23:40:36,346 - INFO - Received completion from the model:
filter_target: reports
message: 


2024-04-20 23:40:47,986 - INFO - Received chat message: user_id='brian' message="Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"


2024-04-20 23:40:47,988 - INFO - Called the handcrafted conversation flow


2024-04-20 23:40:47,988 - INFO - Received event in the handler


2024-04-20 23:40:47,988 - INFO - Received event in the build_primary_prompt function


2024-04-20 23:40:47,988 - INFO - Sending messages to the model:
	{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}


2024-04-20 23:40:47,990 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-20 23:40:47,990 - DEBUG - max_retries: 8


2024-04-20 23:40:47,990 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10459de70>


2024-04-20 23:40:47,996 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:47,997 - DEBUG - close.started


2024-04-20 23:40:47,998 - DEBUG - close.complete


2024-04-20 23:40:47,998 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:40:48,012 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10470ce50>


2024-04-20 23:40:48,013 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x10419c640> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:40:48,031 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10470c970>


2024-04-20 23:40:48,032 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,032 - DEBUG - send_request_headers.complete


2024-04-20 23:40:48,032 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,032 - DEBUG - send_request_body.complete


2024-04-20 23:40:48,032 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,179 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_dc343703986bfc8d273d32f716f53175'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b627caace7d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:48,179 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:48,179 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,179 - DEBUG - receive_response_body.complete


2024-04-20 23:40:48,180 - DEBUG - response_closed.started


2024-04-20 23:40:48,180 - DEBUG - response_closed.complete


2024-04-20 23:40:48,180 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:48,180 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:48,182 - DEBUG - Not retrying


2024-04-20 23:40:48,182 - DEBUG - Re-raising status error


2024-04-20 23:40:48,182 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10459e290>


2024-04-20 23:40:48,188 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:48,189 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,189 - DEBUG - send_request_headers.complete


2024-04-20 23:40:48,189 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,189 - DEBUG - send_request_body.complete


2024-04-20 23:40:48,189 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,504 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'26'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_faa8bb67f809d3c6abaa708d1ff7c90c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b627dabb67d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:48,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:48,504 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,504 - DEBUG - receive_response_body.complete


2024-04-20 23:40:48,504 - DEBUG - response_closed.started


2024-04-20 23:40:48,504 - DEBUG - response_closed.complete


2024-04-20 23:40:48,504 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:48,504 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:48,505 - DEBUG - Not retrying


2024-04-20 23:40:48,505 - DEBUG - Re-raising status error


2024-04-20 23:40:48,505 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10459e2c0>


2024-04-20 23:40:48,510 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:48,511 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,511 - DEBUG - send_request_headers.complete


2024-04-20 23:40:48,511 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,511 - DEBUG - send_request_body.complete


2024-04-20 23:40:48,512 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,756 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'24'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_de1dab35a2567c7a736a3738c171f579'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b627faddb7d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:48,757 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:48,758 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,758 - DEBUG - receive_response_body.complete


2024-04-20 23:40:48,758 - DEBUG - response_closed.started


2024-04-20 23:40:48,759 - DEBUG - response_closed.complete


2024-04-20 23:40:48,759 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:48,759 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:48,760 - DEBUG - Not retrying


2024-04-20 23:40:48,760 - DEBUG - Re-raising status error


2024-04-20 23:40:48,761 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x104758c40>


2024-04-20 23:40:48,780 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:48,782 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,783 - DEBUG - send_request_headers.complete


2024-04-20 23:40:48,783 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,783 - DEBUG - send_request_body.complete


2024-04-20 23:40:48,783 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,908 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:48 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_0f1f3ac735f2b166e9da16e52a1286d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b62815f577d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:48,909 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:48,910 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,910 - DEBUG - receive_response_body.complete


2024-04-20 23:40:48,910 - DEBUG - response_closed.started


2024-04-20 23:40:48,911 - DEBUG - response_closed.complete


2024-04-20 23:40:48,911 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:48,911 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:48,912 - DEBUG - Not retrying


2024-04-20 23:40:48,912 - DEBUG - Re-raising status error


2024-04-20 23:40:48,913 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10475be20>


2024-04-20 23:40:48,932 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:48,933 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:48,933 - DEBUG - send_request_headers.complete


2024-04-20 23:40:48,933 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:48,934 - DEBUG - send_request_body.complete


2024-04-20 23:40:48,934 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,221 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'27'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_dd52186df8f91622486a5205a443cc38'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b6282485a7d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:49,221 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:49,221 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,221 - DEBUG - receive_response_body.complete


2024-04-20 23:40:49,222 - DEBUG - response_closed.started


2024-04-20 23:40:49,222 - DEBUG - response_closed.complete


2024-04-20 23:40:49,222 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:49,222 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:49,222 - DEBUG - Not retrying


2024-04-20 23:40:49,222 - DEBUG - Re-raising status error


2024-04-20 23:40:49,222 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x104761ae0>


2024-04-20 23:40:49,230 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:49,231 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,232 - DEBUG - send_request_headers.complete


2024-04-20 23:40:49,232 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,232 - DEBUG - send_request_body.complete


2024-04-20 23:40:49,232 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,430 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_29b257ab693aea24658755e59af080e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b62842a017d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:49,432 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:49,432 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,432 - DEBUG - receive_response_body.complete


2024-04-20 23:40:49,433 - DEBUG - response_closed.started


2024-04-20 23:40:49,433 - DEBUG - response_closed.complete


2024-04-20 23:40:49,434 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:49,434 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:49,436 - DEBUG - Not retrying


2024-04-20 23:40:49,438 - DEBUG - Re-raising status error


2024-04-20 23:40:49,439 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x104761c90>


2024-04-20 23:40:49,453 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:49,454 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,454 - DEBUG - send_request_headers.complete


2024-04-20 23:40:49,455 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,455 - DEBUG - send_request_body.complete


2024-04-20 23:40:49,455 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,734 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_7e5e3f9e464e97874ab1bff774410609'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b62858b547d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:49,736 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:49,736 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,737 - DEBUG - receive_response_body.complete


2024-04-20 23:40:49,737 - DEBUG - response_closed.started


2024-04-20 23:40:49,738 - DEBUG - response_closed.complete


2024-04-20 23:40:49,738 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:49,738 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:49,739 - DEBUG - Not retrying


2024-04-20 23:40:49,739 - DEBUG - Re-raising status error


2024-04-20 23:40:49,741 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10476e2f0>


2024-04-20 23:40:49,758 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:40:49,760 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,761 - DEBUG - send_request_headers.complete


2024-04-20 23:40:49,761 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,761 - DEBUG - send_request_body.complete


2024-04-20 23:40:49,761 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:40:49,889 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:40:49 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_73be34c3f070bd29f5f4e63f698b9ec4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b62877ce97d27-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:40:49,891 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:40:49,891 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:40:49,893 - DEBUG - receive_response_body.complete


2024-04-20 23:40:49,893 - DEBUG - response_closed.started


2024-04-20 23:40:49,893 - DEBUG - response_closed.complete


2024-04-20 23:40:49,894 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:40:49,894 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:40:49,895 - DEBUG - Not retrying


2024-04-20 23:40:49,898 - DEBUG - Re-raising status error


2024-04-20 23:42:04,668 - INFO - Received chat message: user_id='brian' message="Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."


2024-04-20 23:42:04,670 - INFO - Called the handcrafted conversation flow


2024-04-20 23:42:04,670 - INFO - Received event in the handler


2024-04-20 23:42:04,670 - INFO - Received event in the build_primary_prompt function


2024-04-20 23:42:04,670 - INFO - Sending messages to the model:
	{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}


2024-04-20 23:42:04,674 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-20 23:42:04,675 - DEBUG - max_retries: 8


2024-04-20 23:42:04,675 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x119755960>


2024-04-20 23:42:04,683 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:04,720 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:42:04,759 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b02bd30>


2024-04-20 23:42:04,759 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:42:04,781 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b02a620>


2024-04-20 23:42:04,781 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:04,781 - DEBUG - send_request_headers.complete


2024-04-20 23:42:04,781 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:04,782 - DEBUG - send_request_body.complete


2024-04-20 23:42:04,782 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:05,325 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599093'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_6c9f9dddb4026fac90b15f77d1326f9c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=NZcWhcu_4my1g_BKQIbFCzUuTwT6mwibfLYTc1E2Zss-1713681725-1.0.1.1-hFxBjEe_ul9Pf.RS7rWXDHgAkDQYisi6e0xtwrfmHFBYrJHpyUi8D6tJNPvPsWxpTGSUxKECveyiQ64wva.Z2w; path=/; expires=Sun, 21-Apr-24 07:12:05 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=cORtUTq12BXWr7gB9VzdJoJyuupyRddHSnAKFaBRu4s-1713681725385-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b645c5ee6db6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:05,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:05,327 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:05,327 - DEBUG - receive_response_body.complete


2024-04-20 23:42:05,327 - DEBUG - response_closed.started


2024-04-20 23:42:05,327 - DEBUG - response_closed.complete


2024-04-20 23:42:05,328 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:05,328 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:05,330 - DEBUG - Not retrying


2024-04-20 23:42:05,330 - DEBUG - Re-raising status error


2024-04-20 23:42:05,331 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x119beda50>


2024-04-20 23:42:05,339 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:05,341 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:05,341 - DEBUG - send_request_headers.complete


2024-04-20 23:42:05,341 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:05,341 - DEBUG - send_request_body.complete


2024-04-20 23:42:05,341 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:05,586 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599093'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_b952a01ff1102f727afeb93573d4bf2a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b645fda6ddb6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:05,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:05,591 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:05,592 - DEBUG - receive_response_body.complete


2024-04-20 23:42:05,592 - DEBUG - response_closed.started


2024-04-20 23:42:05,593 - DEBUG - response_closed.complete


2024-04-20 23:42:05,593 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:05,594 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:05,594 - DEBUG - Not retrying


2024-04-20 23:42:05,595 - DEBUG - Re-raising status error


2024-04-20 23:42:05,597 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b072590>


2024-04-20 23:42:05,620 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:05,622 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:05,622 - DEBUG - send_request_headers.complete


2024-04-20 23:42:05,622 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:05,623 - DEBUG - send_request_body.complete


2024-04-20 23:42:05,623 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:05,920 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:05 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'17'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599094'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_5bb6892548ccc633ae34d271b3fdd9df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b64619bfedb6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:05,921 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:05,921 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:05,921 - DEBUG - receive_response_body.complete


2024-04-20 23:42:05,921 - DEBUG - response_closed.started


2024-04-20 23:42:05,922 - DEBUG - response_closed.complete


2024-04-20 23:42:05,922 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:05,922 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:05,922 - DEBUG - Not retrying


2024-04-20 23:42:05,922 - DEBUG - Re-raising status error


2024-04-20 23:42:05,923 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b10f640>


2024-04-20 23:42:05,932 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:05,933 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:05,934 - DEBUG - send_request_headers.complete


2024-04-20 23:42:05,934 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:05,934 - DEBUG - send_request_body.complete


2024-04-20 23:42:05,934 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:06,084 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:06 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'29'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599093'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_3793cbacab607c124b9ec7043b3239a5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b64638da7db6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:06,085 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:06,086 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:06,089 - DEBUG - receive_response_body.complete


2024-04-20 23:42:06,090 - DEBUG - response_closed.started


2024-04-20 23:42:06,091 - DEBUG - response_closed.complete


2024-04-20 23:42:06,091 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:06,091 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:06,092 - DEBUG - Not retrying


2024-04-20 23:42:06,092 - DEBUG - Re-raising status error


2024-04-20 23:42:06,093 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b116cb0>


2024-04-20 23:42:06,119 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:06,121 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:06,121 - DEBUG - send_request_headers.complete


2024-04-20 23:42:06,122 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:06,122 - DEBUG - send_request_body.complete


2024-04-20 23:42:06,122 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:06,382 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:06 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599093'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_03b2e30d430b43399177eba49d00b2ad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b6464be9fdb6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:06,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:06,384 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:06,384 - DEBUG - receive_response_body.complete


2024-04-20 23:42:06,385 - DEBUG - response_closed.started


2024-04-20 23:42:06,385 - DEBUG - response_closed.complete


2024-04-20 23:42:06,386 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:06,386 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:06,389 - DEBUG - Not retrying


2024-04-20 23:42:06,389 - DEBUG - Re-raising status error


2024-04-20 23:42:06,390 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b10f430>


2024-04-20 23:42:06,414 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:06,416 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:06,416 - DEBUG - send_request_headers.complete


2024-04-20 23:42:06,416 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:06,417 - DEBUG - send_request_body.complete


2024-04-20 23:42:06,417 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:06,849 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:06 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599093'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_5afce9ca4a0ee52c1f1859161b3f74c8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b6466984edb6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:06,851 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:06,851 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:06,851 - DEBUG - receive_response_body.complete


2024-04-20 23:42:06,852 - DEBUG - response_closed.started


2024-04-20 23:42:06,852 - DEBUG - response_closed.complete


2024-04-20 23:42:06,853 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:06,853 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:06,854 - DEBUG - Not retrying


2024-04-20 23:42:06,854 - DEBUG - Re-raising status error


2024-04-20 23:42:06,855 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b11e6b0>


2024-04-20 23:42:06,876 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:06,877 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:06,877 - DEBUG - send_request_headers.complete


2024-04-20 23:42:06,877 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:06,878 - DEBUG - send_request_body.complete


2024-04-20 23:42:06,878 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:07,156 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:07 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'41'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599093'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_0467ae065365c4fe6297f4f024252ce9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b64699ba9db6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:07,157 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:07,157 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:07,157 - DEBUG - receive_response_body.complete


2024-04-20 23:42:07,157 - DEBUG - response_closed.started


2024-04-20 23:42:07,158 - DEBUG - response_closed.complete


2024-04-20 23:42:07,158 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:07,158 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:07,159 - DEBUG - Not retrying


2024-04-20 23:42:07,159 - DEBUG - Re-raising status error


2024-04-20 23:42:07,159 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b12d360>


2024-04-20 23:42:07,182 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'ai', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:42:07,184 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:42:07,184 - DEBUG - send_request_headers.complete


2024-04-20 23:42:07,184 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:42:07,184 - DEBUG - send_request_body.complete


2024-04-20 23:42:07,184 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:42:07,405 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 400, b'Bad Request', [(b'Date', b'Sun, 21 Apr 2024 06:42:07 GMT'), (b'Content-Type', b'application/json'), (b'Content-Length', b'195'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599094'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'90ms'), (b'x-request-id', b'req_05d807a9264e8b4df6603dcd86abd068'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b646b5d75db6e-LAX'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:42:07,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 400 Bad Request"


2024-04-20 23:42:07,407 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:42:07,407 - DEBUG - receive_response_body.complete


2024-04-20 23:42:07,408 - DEBUG - response_closed.started


2024-04-20 23:42:07,408 - DEBUG - response_closed.complete


2024-04-20 23:42:07,408 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "400 Bad Request"


2024-04-20 23:42:07,409 - DEBUG - Encountered httpx.HTTPStatusError
Traceback (most recent call last):
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/openai/_base_client.py", line 1555, in _request
    response.raise_for_status()
  File "/Users/brianprzezdziecki/Library/Caches/pypoetry/virtualenvs/x-filter-Wtad7ql5-py3.10/lib/python3.10/site-packages/httpx/_models.py", line 761, in raise_for_status
    raise HTTPStatusError(message, request=request, response=self)
httpx.HTTPStatusError: Client error '400 Bad Request' for url 'https://api.openai.com/v1/chat/completions'
For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400


2024-04-20 23:42:07,409 - DEBUG - Not retrying


2024-04-20 23:42:07,409 - DEBUG - Re-raising status error


2024-04-20 23:43:06,060 - INFO - Received chat message: user_id='brian' message='reports'


2024-04-20 23:43:06,063 - INFO - Called the handcrafted conversation flow


2024-04-20 23:43:06,064 - INFO - Received event in the handler


2024-04-20 23:43:06,065 - INFO - Received event in the determine_filter_target function


2024-04-20 23:43:06,065 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}
	{'role': 'user', 'content': 'reports'}


2024-04-20 23:43:06,077 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage1'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}}


2024-04-20 23:43:06,077 - DEBUG - max_retries: 8


2024-04-20 23:43:06,077 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b132a10>


2024-04-20 23:43:06,086 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}]}}


2024-04-20 23:43:06,087 - DEBUG - close.started


2024-04-20 23:43:06,088 - DEBUG - close.complete


2024-04-20 23:43:06,088 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:43:06,110 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b133940>


2024-04-20 23:43:06,110 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:43:06,150 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b1334c0>


2024-04-20 23:43:06,150 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:43:06,151 - DEBUG - send_request_headers.complete


2024-04-20 23:43:06,151 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:43:06,151 - DEBUG - send_request_body.complete


2024-04-20 23:43:06,151 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:43:07,084 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:43:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'782'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599736'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'req_08dfb0cc3aaa1d98543684646841dbff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b65dc0d217c43-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:43:07,086 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:43:07,086 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:43:07,087 - DEBUG - receive_response_body.complete


2024-04-20 23:43:07,087 - DEBUG - response_closed.started


2024-04-20 23:43:07,088 - DEBUG - response_closed.complete


2024-04-20 23:43:07,088 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:43:07,099 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLCkEpF3wc6z5HJbBonpAlHwzsjA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CDk65lQFwYDGlECgZyh2b7pd', function=Function(arguments='{"filter_target":"reports","message":""}', name='Stage1'), type='function')]))], created=1713681786, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=9, prompt_tokens=281, total_tokens=290))


2024-04-20 23:43:07,102 - INFO - Received completion from the model:
filter_target: reports
message: 


2024-04-20 23:43:34,290 - INFO - Received chat message: user_id='brian' message="Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"


2024-04-20 23:43:34,293 - INFO - Called the handcrafted conversation flow


2024-04-20 23:43:34,293 - INFO - Received event in the handler


2024-04-20 23:43:34,293 - INFO - Received event in the build_primary_prompt function


2024-04-20 23:43:34,293 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}


2024-04-20 23:43:34,295 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-20 23:43:34,295 - DEBUG - max_retries: 8


2024-04-20 23:43:34,295 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b29ca00>


2024-04-20 23:43:34,302 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:43:34,303 - DEBUG - close.started


2024-04-20 23:43:34,303 - DEBUG - close.complete


2024-04-20 23:43:34,303 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:43:34,337 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b29d660>


2024-04-20 23:43:34,337 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:43:34,356 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b29d1b0>


2024-04-20 23:43:34,356 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:43:34,356 - DEBUG - send_request_headers.complete


2024-04-20 23:43:34,356 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:43:34,356 - DEBUG - send_request_body.complete


2024-04-20 23:43:34,356 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:43:42,691 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:43:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'8116'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_3f491d7ac702f105e348d071f515322a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b668c3bb308a6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:43:42,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:43:42,694 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:43:42,695 - DEBUG - receive_response_body.complete


2024-04-20 23:43:42,695 - DEBUG - response_closed.started


2024-04-20 23:43:42,695 - DEBUG - response_closed.complete


2024-04-20 23:43:42,696 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:43:42,700 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLDCKD36ZPhKJNmacqaNpEh1v2l3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5UREMQpOLJ6J3re0GBxRuDHA', function=Function(arguments='{"rewritten_primary_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","name":"RAG Innovation"}', name='Stage2'), type='function')]))], created=1713681814, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=162, prompt_tokens=706, total_tokens=868))


2024-04-20 23:43:42,728 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b29df90>


2024-04-20 23:43:42,740 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': '', 'tool_calls': [{'id': 'call_5UREMQpOLJ6J3re0GBxRuDHA', 'function': {'arguments': '{"rewritten_primary_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","name":"RAG Innovation"}', 'name': 'Stage2'}, 'type': 'function'}]}, {'role': 'tool', 'tool_call_id': 'call_5UREMQpOLJ6J3re0GBxRuDHA', 'name': 'Stage2', 'content': "Validation Error found:\n1 validation error for Stage2\nquestions\n  Field required [type=missing, input_value={'rewritten_primary_promp...name': 'RAG Innovation'}, input_type=dict]\n    For further information visit https://errors.pydantic.dev/2.7/v/missing\nRecall the function correctly, fix the errors"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:43:42,742 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:43:42,743 - DEBUG - send_request_headers.complete


2024-04-20 23:43:42,743 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:43:42,744 - DEBUG - send_request_body.complete


2024-04-20 23:43:42,744 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:43:49,619 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:43:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'6750'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599191'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'80ms'), (b'x-request-id', b'req_6b2e03106c52e24abd8f3a639abb8437'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b66c09c0808a6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:43:49,620 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:43:49,620 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:43:49,620 - DEBUG - receive_response_body.complete


2024-04-20 23:43:49,620 - DEBUG - response_closed.started


2024-04-20 23:43:49,620 - DEBUG - response_closed.complete


2024-04-20 23:43:49,621 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:43:49,621 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLDK0sLbvUvGZc51e73DiYrdkdX6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PgxThUbNI1IxNY53WOYq1ISB', function=Function(arguments='{"rewritten_primary_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","questions":null,"name":"RAG Innovation"}', name='Stage2'), type='function')]))], created=1713681822, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=328, prompt_tokens=1661, total_tokens=1989))


2024-04-20 23:43:49,621 - INFO - Received completion from the model:
rewritten_primary_prompt: I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.
questions: None


2024-04-20 23:45:00,436 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 23:45:00,437 - INFO - Called the handcrafted conversation flow


2024-04-20 23:45:00,437 - INFO - Received event in the handler


2024-04-20 23:45:00,437 - INFO - Received event in the build_primary_prompt function


2024-04-20 23:45:34,112 - INFO - Received chat message: user_id='brian' message='search every 3 days. Id like to see 10 tweets per report'


2024-04-20 23:45:34,114 - INFO - Called the handcrafted conversation flow


2024-04-20 23:45:34,115 - INFO - Received event in the handler


2024-04-20 23:45:34,115 - INFO - Received event in the build_filter_prompt function


2024-04-20 23:45:34,115 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}


2024-04-20 23:45:34,122 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 23:45:34,122 - DEBUG - max_retries: 8


2024-04-20 23:45:34,122 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b29d8a0>


2024-04-20 23:45:34,143 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 23:45:34,144 - DEBUG - close.started


2024-04-20 23:45:34,144 - DEBUG - close.complete


2024-04-20 23:45:34,144 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:45:34,179 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b1316c0>


2024-04-20 23:45:34,179 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:45:34,198 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b133b50>


2024-04-20 23:45:34,198 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:45:34,198 - DEBUG - send_request_headers.complete


2024-04-20 23:45:34,198 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:45:34,198 - DEBUG - send_request_body.complete


2024-04-20 23:45:34,198 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:45:42,293 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:45:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'7442'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599001'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'99ms'), (b'x-request-id', b'req_43de8e7d76ce4a10d9b4209e1b5dbb3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b69793a222eba-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:45:42,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:45:42,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:45:42,300 - DEBUG - receive_response_body.complete


2024-04-20 23:45:42,300 - DEBUG - response_closed.started


2024-04-20 23:45:42,301 - DEBUG - response_closed.complete


2024-04-20 23:45:42,301 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:45:42,304 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLF9kuru9b9Kq0KIuBaq2t4zhnM9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lxzC7rvSKcWNRTmO1wAG6iaS', function=Function(arguments='{"filter_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","questions":"search every 3 days. Id like to see 10 tweets per report"}', name='Stage3'), type='function')]))], created=1713681935, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=172, prompt_tokens=940, total_tokens=1112))


2024-04-20 23:45:42,309 - INFO - Received completion from the model:
filter_prompt: I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.
questions: search every 3 days. Id like to see 10 tweets per report


2024-04-20 23:46:27,368 - INFO - Received chat message: user_id='brian' message='what?'


2024-04-20 23:46:27,373 - INFO - Called the handcrafted conversation flow


2024-04-20 23:46:27,373 - INFO - Received event in the handler


2024-04-20 23:46:27,373 - INFO - Received event in the build_filter_prompt function


2024-04-20 23:46:27,373 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'user', 'content': 'what?'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'what?'}


2024-04-20 23:46:27,375 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'user', 'content': 'what?'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'what?'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 23:46:27,375 - DEBUG - max_retries: 8


2024-04-20 23:46:27,376 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b29c940>


2024-04-20 23:46:27,387 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'user', 'content': 'what?'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'what?'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 23:46:27,388 - DEBUG - close.started


2024-04-20 23:46:27,388 - DEBUG - close.complete


2024-04-20 23:46:27,389 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:46:27,405 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b130dc0>


2024-04-20 23:46:27,405 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:46:27,424 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b130d60>


2024-04-20 23:46:27,425 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:46:27,425 - DEBUG - send_request_headers.complete


2024-04-20 23:46:27,425 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:46:27,425 - DEBUG - send_request_body.complete


2024-04-20 23:46:27,425 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:46:36,548 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:46:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'8976'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598996'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'100ms'), (b'x-request-id', b'req_34c4a2e981893c19a67b60cfaade29b4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b6ac5ed632a98-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:46:36,550 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:46:36,550 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:46:36,551 - DEBUG - receive_response_body.complete


2024-04-20 23:46:36,551 - DEBUG - response_closed.started


2024-04-20 23:46:36,552 - DEBUG - response_closed.complete


2024-04-20 23:46:36,552 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:46:36,554 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLFz1sMj0VDUkYd1LueEEAm2sqHM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FsaLLzofITB7oaaecBPKVArR', function=Function(arguments='{"filter_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","questions":"How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you\'re interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}', name='Stage3'), type='function')]))], created=1713681987, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=233, prompt_tokens=952, total_tokens=1185))


2024-04-20 23:46:36,556 - INFO - Received completion from the model:
filter_prompt: I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.
questions: How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?


2024-04-20 23:46:54,105 - INFO - Received chat message: user_id='brian' message='Id like this to run every 3 days and i want to see 10 tweets per report'


2024-04-20 23:46:54,107 - INFO - Called the handcrafted conversation flow


2024-04-20 23:46:54,108 - INFO - Received event in the handler


2024-04-20 23:46:54,108 - INFO - Received event in the build_filter_prompt function


2024-04-20 23:46:54,108 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'user', 'content': 'what?'}
	{'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}
	{'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}


2024-04-20 23:46:54,114 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'user', 'content': 'what?'}, {'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}, {'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 23:46:54,115 - DEBUG - max_retries: 8


2024-04-20 23:46:54,115 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b1333a0>


2024-04-20 23:46:54,138 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'user', 'content': 'what?'}, {'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}, {'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 23:46:54,139 - DEBUG - close.started


2024-04-20 23:46:54,139 - DEBUG - close.complete


2024-04-20 23:46:54,139 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:46:54,173 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x119a66290>


2024-04-20 23:46:54,173 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:46:54,193 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x119a66050>


2024-04-20 23:46:54,193 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:46:54,194 - DEBUG - send_request_headers.complete


2024-04-20 23:46:54,194 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:46:54,194 - DEBUG - send_request_body.complete


2024-04-20 23:46:54,194 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:47:02,459 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:47:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'8052'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598870'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_d3b3b12427757abcd0e423d22b8a72f4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b6b6d3e822a95-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:47:02,461 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:47:02,462 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:47:02,463 - DEBUG - receive_response_body.complete


2024-04-20 23:47:02,463 - DEBUG - response_closed.started


2024-04-20 23:47:02,464 - DEBUG - response_closed.complete


2024-04-20 23:47:02,464 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:47:02,467 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLGQGeSqlLWW434Qg0qiYCbtFjvw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_I6G6EQIcH6MCom5We9HUQJ9B', function=Function(arguments='{"filter_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","questions":"How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you\'re interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}', name='Stage3'), type='function')]))], created=1713682014, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=233, prompt_tokens=1072, total_tokens=1305))


2024-04-20 23:47:02,471 - INFO - Received completion from the model:
filter_prompt: I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.
questions: How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?


2024-04-20 23:50:03,875 - INFO - Received chat message: user_id='brian' message='Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'


2024-04-20 23:50:03,877 - INFO - Called the handcrafted conversation flow


2024-04-20 23:50:03,878 - INFO - Received event in the handler


2024-04-20 23:50:03,878 - INFO - Received event in the build_filter_prompt function


2024-04-20 23:50:03,879 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}
	{'role': 'user', 'content': 'reports'}
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}
	{'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}
	{'role': 'user', 'content': 'yes'}
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}
	{'role': 'user', 'content': 'what?'}
	{'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}
	{'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}
	{'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}
	{'role': 'user', 'content': 'Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'}


2024-04-20 23:50:03,884 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'user', 'content': 'what?'}, {'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}, {'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}, {'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}, {'role': 'user', 'content': 'Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 23:50:03,884 - DEBUG - max_retries: 8


2024-04-20 23:50:03,885 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11b29c940>


2024-04-20 23:50:03,911 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'reports'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nI am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everythingjust share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- How many tweets/users would you like to see in each report? We can set a maximum number of tweets/users to display.\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'assistant', 'content': 'search every 3 days. Id like to see 10 tweets per report'}, {'role': 'user', 'content': 'what?'}, {'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}, {'role': 'user', 'content': 'Id like this to run every 3 days and i want to see 10 tweets per report'}, {'role': 'assistant', 'content': "How often would you like this filter to run? How many tweets/users would you like to see in each report? Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? Are there any keywords or specific combinations of keywords you think will be useful to search by?"}, {'role': 'user', 'content': 'Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'Look listen. i want the filter to run every 3 days, and see 10 tweets as return cap. now move on, stop asking questions'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 23:50:03,912 - DEBUG - close.started


2024-04-20 23:50:03,912 - DEBUG - close.complete


2024-04-20 23:50:03,913 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:50:03,949 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b1318d0>


2024-04-20 23:50:03,950 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x119b9c440> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:50:03,970 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11b130dc0>


2024-04-20 23:50:03,970 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:50:03,971 - DEBUG - send_request_headers.complete


2024-04-20 23:50:03,971 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:50:03,971 - DEBUG - send_request_body.complete


2024-04-20 23:50:03,971 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:50:11,300 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:50:11 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'7027'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'598735'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'126ms'), (b'x-request-id', b'req_cc5db9c123ec6b69f9c67e870e7eb364'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b700f4c0fdba2-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:50:11,303 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:50:11,303 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:50:11,304 - DEBUG - receive_response_body.complete


2024-04-20 23:50:11,304 - DEBUG - response_closed.started


2024-04-20 23:50:11,305 - DEBUG - response_closed.complete


2024-04-20 23:50:11,305 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:50:11,308 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLJUgDBjuIwkxARdxAxFrFOffSmi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yT9Vy3PThq9s4nddr1kOS1xy', function=Function(arguments='{"filter_prompt":"I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.","questions":null}', name='Stage3'), type='function')]))], created=1713682204, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=158, prompt_tokens=1197, total_tokens=1355))


2024-04-20 23:50:11,314 - INFO - Received completion from the model:
filter_prompt: I am looking for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG) that address new challenges. Specifically, I am interested in: 1. New techniques for chunking in RAG. 2. The latest state-of-the-art vector databases. 3. Models that are fine-tuned specifically for RAG. Additionally, I am seeking information on novel approaches that go beyond vector similarity, such as using metadata or descriptions, and leveraging a Language Model (LLM) to navigate through a structured system like folders or trees. A particular area of interest is a system capable of autonomously organizing arbitrary data into a file structure, complete with descriptive labels, and enabling an LLM to search through this organized content.
questions: None


2024-04-20 23:51:38,256 - INFO - Received chat message: user_id='brian' message='reports'


2024-04-20 23:51:38,257 - INFO - Called the handcrafted conversation flow


2024-04-20 23:51:38,258 - INFO - Received event in the handler


2024-04-20 23:51:38,258 - INFO - Received event in the determine_filter_target function


2024-04-20 23:51:38,258 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}
	{'role': 'user', 'content': 'reports'}


2024-04-20 23:51:38,269 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage1'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}}


2024-04-20 23:51:38,270 - DEBUG - max_retries: 8


2024-04-20 23:51:38,270 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108759990>


2024-04-20 23:51:38,276 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'reports'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}]}}


2024-04-20 23:51:38,314 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:51:38,351 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108d462c0>


2024-04-20 23:51:38,352 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b95040> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:51:38,372 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108bedb40>


2024-04-20 23:51:38,372 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:51:38,373 - DEBUG - send_request_headers.complete


2024-04-20 23:51:38,373 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:51:38,373 - DEBUG - send_request_body.complete


2024-04-20 23:51:38,373 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:51:39,362 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:51:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'665'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599735'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'req_b67eb1b3fc3f177f5f6516888fc10ea1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=jzbFCcAwc4t2ZLTldHIODwMC1zmroJu6DpRNLD7Oyqw-1713682299-1.0.1.1-J_BhQP_bUQ3lX3MrtNiMdHLBuIxaFjC0OQuGWLSx7E74ZjC5H.V8MVwNqgYniGvIWtr4X59mK3gs5M0iIgwwlg; path=/; expires=Sun, 21-Apr-24 07:21:39 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=OGJGbVqdpEYB84pI389_YH3V1ZAdACuiDQnIWvLonPQ-1713682299317-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b725d5a4c69b7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:51:39,367 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:51:39,368 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:51:39,370 - DEBUG - receive_response_body.complete


2024-04-20 23:51:39,371 - DEBUG - response_closed.started


2024-04-20 23:51:39,371 - DEBUG - response_closed.complete


2024-04-20 23:51:39,372 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:51:39,389 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLL08e195LhbW67ZYe0unlnWzUwE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UMSQ9HWgEed6c6GbSMvnXCYF', function=Function(arguments='{"filter_target":"reports","message":""}', name='Stage1'), type='function')]))], created=1713682298, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=9, prompt_tokens=281, total_tokens=290))


2024-04-20 23:51:39,390 - INFO - Received completion from the model:
filter_target: reports
message: 


2024-04-20 23:51:53,443 - INFO - Received chat message: user_id='brian' message="Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"


2024-04-20 23:51:53,451 - INFO - Called the handcrafted conversation flow


2024-04-20 23:51:53,452 - INFO - Received event in the handler


2024-04-20 23:51:53,452 - INFO - Received event in the build_primary_prompt function


2024-04-20 23:51:53,452 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}


2024-04-20 23:51:53,455 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-20 23:51:53,456 - DEBUG - max_retries: 8


2024-04-20 23:51:53,456 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108daa890>


2024-04-20 23:51:53,463 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': "Im specifically looking for tweets that deliver insights into new methods in RAG, that solve new problems. Specific problems im interested include new methods for chunking in RAG, the best state of the art vector databases and models specifically finetuned for RAG. I'm also particularly interested in new methods where we dont just use vector similarity but use metadata, or descriptions and an LLM to navigate sections, a folder structure or tree. Id be particularly fascinated to see someone working on a system that takes an arbitrary data, and organizes it into a file structure autonomously, labeling folders with descripitons organizing it etc, and then to be able to have an LLM search it. \n"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-20 23:51:53,465 - DEBUG - close.started


2024-04-20 23:51:53,465 - DEBUG - close.complete


2024-04-20 23:51:53,465 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:51:53,482 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108dab850>


2024-04-20 23:51:53,482 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b95040> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:51:53,502 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108da9f30>


2024-04-20 23:51:53,502 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:51:53,503 - DEBUG - send_request_headers.complete


2024-04-20 23:51:53,503 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:51:53,503 - DEBUG - send_request_body.complete


2024-04-20 23:51:53,503 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:51:59,226 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:51:59 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5490'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599556'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'44ms'), (b'x-request-id', b'req_a8144f9c199db7fb08f7fff6d974f085'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b72bbe98e2b6f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:51:59,227 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:51:59,228 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:51:59,230 - DEBUG - receive_response_body.complete


2024-04-20 23:51:59,230 - DEBUG - response_closed.started


2024-04-20 23:51:59,230 - DEBUG - response_closed.complete


2024-04-20 23:51:59,231 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:51:59,233 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLLFbS7RUhw7DwDyd3hy6YAHdf85', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_61Dk570cRPxBoUVVJmexTYHw', function=Function(arguments='{\n  "rewritten_primary_prompt": "Search for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG), focusing on: 1. New techniques for chunking in RAG, 2. Leading-edge vector databases, 3. Models specifically fine-tuned for RAG applications, 4. Methods that incorporate metadata or descriptions along with vector similarity for navigating sections, folders, or tree structures, 5. Systems that autonomously organize arbitrary data into a file structure with descriptive labels, and 6. The use of Language Models like LLMs to search within such organized structures.",\n  "questions": null,\n  "name": "RAG Innovation"\n}', name='Stage2'), type='function')]))], created=1713682313, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=141, prompt_tokens=450, total_tokens=591))


2024-04-20 23:51:59,235 - INFO - Received completion from the model:
rewritten_primary_prompt: Search for tweets that provide insights into innovative methods in Retrieval-Augmented Generation (RAG), focusing on: 1. New techniques for chunking in RAG, 2. Leading-edge vector databases, 3. Models specifically fine-tuned for RAG applications, 4. Methods that incorporate metadata or descriptions along with vector similarity for navigating sections, folders, or tree structures, 5. Systems that autonomously organize arbitrary data into a file structure with descriptive labels, and 6. The use of Language Models like LLMs to search within such organized structures.
questions: None


2024-04-20 23:52:04,973 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 23:52:04,977 - INFO - Called the handcrafted conversation flow


2024-04-20 23:52:04,977 - INFO - Received event in the handler


2024-04-20 23:52:04,977 - INFO - Received event in the build_primary_prompt function


2024-04-20 23:52:26,147 - INFO - Received chat message: user_id='brian' message='i want this to run every 3 days and return 10 tweets'


2024-04-20 23:52:26,149 - INFO - Called the handcrafted conversation flow


2024-04-20 23:52:26,149 - INFO - Received event in the handler


2024-04-20 23:52:26,149 - INFO - Received event in the build_filter_prompt function


2024-04-20 23:52:26,149 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'i want this to run every 3 days and return 10 tweets'}


2024-04-20 23:52:26,151 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'i want this to run every 3 days and return 10 tweets'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-20 23:52:26,151 - DEBUG - max_retries: 8


2024-04-20 23:52:26,151 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10e010e20>


2024-04-20 23:52:26,157 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'i want this to run every 3 days and return 10 tweets'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-20 23:52:26,159 - DEBUG - close.started


2024-04-20 23:52:26,159 - DEBUG - close.complete


2024-04-20 23:52:26,159 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:52:26,195 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108da9930>


2024-04-20 23:52:26,195 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b95040> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:52:26,216 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108dabb80>


2024-04-20 23:52:26,217 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:52:26,217 - DEBUG - send_request_headers.complete


2024-04-20 23:52:26,217 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:52:26,217 - DEBUG - send_request_body.complete


2024-04-20 23:52:26,217 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:52:27,692 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:52:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1257'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599746'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'25ms'), (b'x-request-id', b'req_2e4364519106c1a5292dfa1a78f36a1e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b73885e6e1506-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:52:27,693 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:52:27,693 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:52:27,693 - DEBUG - receive_response_body.complete


2024-04-20 23:52:27,694 - DEBUG - response_closed.started


2024-04-20 23:52:27,694 - DEBUG - response_closed.complete


2024-04-20 23:52:27,694 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:52:27,695 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLLmmsZBUMPNyueAWz9rQqEgoVml', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_oUQvyeOzVxZ0ZPP9xjBleQmR', function=Function(arguments='{"filter_prompt":"Run every 3 days, maximum of 10 tweets per report.","questions":null}', name='Stage3'), type='function')]))], created=1713682346, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=22, prompt_tokens=287, total_tokens=309))


2024-04-20 23:52:27,696 - INFO - Received completion from the model:
filter_prompt: Run every 3 days, maximum of 10 tweets per report.
questions: None


2024-04-20 23:52:32,164 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 23:52:32,168 - INFO - Called the handcrafted conversation flow


2024-04-20 23:52:32,169 - INFO - Received event in the handler


2024-04-20 23:52:32,169 - INFO - Received event in the build_filter_prompt function


2024-04-20 23:53:06,967 - INFO - Received chat message: user_id='brian' message='concise, simple, technical. no analysis, just report back to me the facts and raw stuff compressed'


2024-04-20 23:53:06,972 - INFO - Called the handcrafted conversation flow


2024-04-20 23:53:06,973 - INFO - Received event in the handler


2024-04-20 23:53:06,973 - INFO - Received event in the build_report_guide function


2024-04-20 23:53:06,973 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}
	{'role': 'user', 'content': 'concise, simple, technical. no analysis, just report back to me the facts and raw stuff compressed'}


2024-04-20 23:53:06,980 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage4'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'concise, simple, technical. no analysis, just report back to me the facts and raw stuff compressed'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}}


2024-04-20 23:53:06,980 - DEBUG - max_retries: 8


2024-04-20 23:53:06,980 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10e0124a0>


2024-04-20 23:53:06,984 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'concise, simple, technical. no analysis, just report back to me the facts and raw stuff compressed'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}]}}


2024-04-20 23:53:06,986 - DEBUG - close.started


2024-04-20 23:53:06,987 - DEBUG - close.complete


2024-04-20 23:53:06,987 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:53:07,021 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108bed930>


2024-04-20 23:53:07,022 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b95040> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:53:07,040 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108bed7e0>


2024-04-20 23:53:07,040 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:53:07,040 - DEBUG - send_request_headers.complete


2024-04-20 23:53:07,040 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:53:07,040 - DEBUG - send_request_body.complete


2024-04-20 23:53:07,040 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:53:08,903 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:53:08 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1675'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599823'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_ba032820e26eaa9280029083cf7463b7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b74873de77c24-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:53:08,907 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:53:08,908 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:53:08,909 - DEBUG - receive_response_body.complete


2024-04-20 23:53:08,909 - DEBUG - response_closed.started


2024-04-20 23:53:08,910 - DEBUG - response_closed.complete


2024-04-20 23:53:08,910 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:53:08,912 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLMRY1XBaHvtxsfy2zd3xzt1sXHb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Tb9CmmsqbtePWU0TiAmwTWi5', function=Function(arguments='{"report_guide":"concise, simple, technical. no analysis, just report back the facts and raw stuff compressed","questions":null}', name='Stage4'), type='function')]))], created=1713682387, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=28, prompt_tokens=214, total_tokens=242))


2024-04-20 23:53:08,919 - INFO - Received completion from the model:
report_guide: concise, simple, technical. no analysis, just report back the facts and raw stuff compressed
questions: None


2024-04-20 23:53:14,859 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-20 23:53:14,861 - INFO - Called the handcrafted conversation flow


2024-04-20 23:53:14,861 - INFO - Received event in the handler


2024-04-20 23:53:14,861 - INFO - Received event in the build_report_guide function


2024-04-20 23:53:14,876 - INFO - Building filter


2024-04-20 23:53:14,876 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}
	{'role': 'user', 'content': 'Run every 3 days, maximum of 10 tweets per report.'}


2024-04-20 23:53:14,884 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.ExtractedFilters'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'Run every 3 days, maximum of 10 tweets per report.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fill in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report?', 'title': 'Return Cap'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}}, 'type': 'object', 'required': []}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}}


2024-04-20 23:53:14,884 - DEBUG - max_retries: 8


2024-04-20 23:53:14,884 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108da9a80>


2024-04-20 23:53:14,889 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'Run every 3 days, maximum of 10 tweets per report.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fill in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report?', 'title': 'Return Cap'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}}, 'type': 'object', 'required': []}}}]}}


2024-04-20 23:53:14,890 - DEBUG - close.started


2024-04-20 23:53:14,890 - DEBUG - close.complete


2024-04-20 23:53:14,890 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-20 23:53:14,906 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10e021150>


2024-04-20 23:53:14,906 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x108b95040> server_hostname='api.openai.com' timeout=5.0


2024-04-20 23:53:14,929 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10e020100>


2024-04-20 23:53:14,929 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-20 23:53:14,930 - DEBUG - send_request_headers.complete


2024-04-20 23:53:14,930 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-20 23:53:14,930 - DEBUG - send_request_body.complete


2024-04-20 23:53:14,930 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-20 23:53:16,377 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 06:53:16 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1237'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599933'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_19150e4aaf9639b2860398f23bcc87a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877b74b88812316f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-20 23:53:16,382 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-20 23:53:16,382 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-20 23:53:16,383 - DEBUG - receive_response_body.complete


2024-04-20 23:53:16,383 - DEBUG - response_closed.started


2024-04-20 23:53:16,383 - DEBUG - response_closed.complete


2024-04-20 23:53:16,384 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-20 23:53:16,385 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GLMZrOojuzG9MMEPndBW8ok9RmR4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AteqSwYuh2mfvkVPOv6pEtIP', function=Function(arguments='{\n  "filter_period": 3,\n  "return_cap": 10\n}', name='ExtractedFilters'), type='function')]))], created=1713682395, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=18, prompt_tokens=306, total_tokens=324))


2024-04-20 23:53:16,392 - INFO - Received completion from the model:
filter_period: 3, usernames: None, only_search_specified_usernames: None, only_search_followers: None, return_cap: 10
