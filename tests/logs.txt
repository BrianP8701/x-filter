

2024-04-21 10:59:21,212 - INFO - Received chat message: user_id='brian' message='hi id like to search for reports\n'


2024-04-21 10:59:21,214 - INFO - Called the handcrafted conversation flow


2024-04-21 10:59:21,214 - INFO - Received event in the handler


2024-04-21 10:59:21,215 - INFO - Received event in the determine_filter_target function


2024-04-21 10:59:21,215 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}
	{'role': 'user', 'content': 'hi id like to search for reports\n'}


2024-04-21 10:59:21,223 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage1'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'hi id like to search for reports\n'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}}


2024-04-21 10:59:21,224 - DEBUG - max_retries: 8


2024-04-21 10:59:21,224 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107057d60>


2024-04-21 10:59:21,228 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'hi id like to search for reports\n'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}]}}


2024-04-21 10:59:21,275 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 10:59:21,313 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1079813f0>


2024-04-21 10:59:21,313 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 10:59:21,337 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1079801f0>


2024-04-21 10:59:21,338 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 10:59:21,338 - DEBUG - send_request_headers.complete


2024-04-21 10:59:21,339 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 10:59:21,339 - DEBUG - send_request_body.complete


2024-04-21 10:59:21,339 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 10:59:22,506 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 17:59:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'884'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599730'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'req_bb1685d86a0095628417021dc6435adb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=v4__lxUOfBTgbqf.N_.P_gluOXQ7Lj4rrOlUhe8L1vc-1713722362-1.0.1.1-qj1QCplSJjw8fsQWfK0Fb3VVsLTgVToBeWLxWSX40EyQQ5MRRsybbruuLlPZTX.JGSGy0A3r0KpROzxNSfZfsA; path=/; expires=Sun, 21-Apr-24 18:29:22 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=IXreDrlhw5hfKU27JZ_u2D5CDB535ezQu9MK_Q5krd4-1713722362429-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f447678927be6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 10:59:22,509 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 10:59:22,510 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 10:59:22,511 - DEBUG - receive_response_body.complete


2024-04-21 10:59:22,511 - DEBUG - response_closed.started


2024-04-21 10:59:22,511 - DEBUG - response_closed.complete


2024-04-21 10:59:22,512 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 10:59:22,531 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVlBVvTXv7nsEagcMrzdAlZAaQjJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9zeuD3j5BY6E0XW8grseFngw', function=Function(arguments='{"filter_target":"reports","message":""}', name='Stage1'), type='function')]))], created=1713722361, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=9, prompt_tokens=288, total_tokens=297))


2024-04-21 10:59:22,534 - INFO - Received completion from the model:
filter_target: reports
message: 


2024-04-21 10:59:49,839 - INFO - Received chat message: user_id='brian' message='can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'


2024-04-21 10:59:49,844 - INFO - Called the handcrafted conversation flow


2024-04-21 10:59:49,845 - INFO - Received event in the handler


2024-04-21 10:59:49,846 - INFO - Received event in the build_primary_prompt function


2024-04-21 10:59:49,846 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}


2024-04-21 10:59:49,849 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-21 10:59:49,849 - DEBUG - max_retries: 8


2024-04-21 10:59:49,849 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1079ed360>


2024-04-21 10:59:49,854 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-21 10:59:49,855 - DEBUG - close.started


2024-04-21 10:59:49,855 - DEBUG - close.complete


2024-04-21 10:59:49,855 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 10:59:49,890 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1079ef640>


2024-04-21 10:59:49,890 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 10:59:49,908 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1079ef220>


2024-04-21 10:59:49,908 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 10:59:49,908 - DEBUG - send_request_headers.complete


2024-04-21 10:59:49,908 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 10:59:49,908 - DEBUG - send_request_body.complete


2024-04-21 10:59:49,908 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 10:59:53,531 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 17:59:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599625'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'37ms'), (b'x-request-id', b'req_84a9d87413c5fed852856c8f21788615'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f45290d5f6a2c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 10:59:53,532 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 10:59:53,532 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 10:59:53,533 - DEBUG - receive_response_body.complete


2024-04-21 10:59:53,533 - DEBUG - response_closed.started


2024-04-21 10:59:53,534 - DEBUG - response_closed.complete


2024-04-21 10:59:53,534 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 10:59:53,536 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVleGhXD5EMepqjLKrnp5ticI2uD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_1FDOFpD4hjwNRlZJsKoKhVxc', function=Function(arguments='{"rewritten_primary_prompt":"Search for tweets providing updates on the X Dev Challenge, including information on the event\'s progress, announcements, participant experiences, and any significant occurrences since it started yesterday.","name":"XDevChallengeUpdate","questions":null}', name='Stage2'), type='function')]))], created=1713722390, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=50, prompt_tokens=412, total_tokens=462))


2024-04-21 10:59:53,538 - INFO - Received completion from the model:
rewritten_primary_prompt: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.
questions: None


2024-04-21 10:59:59,761 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-21 10:59:59,763 - INFO - Called the handcrafted conversation flow


2024-04-21 10:59:59,765 - INFO - Received event in the handler


2024-04-21 10:59:59,769 - INFO - Received event in the build_primary_prompt function


2024-04-21 11:00:09,199 - INFO - Received chat message: user_id='brian' message='x dev challenge\n'


2024-04-21 11:00:09,203 - INFO - Called the handcrafted conversation flow


2024-04-21 11:00:09,204 - INFO - Received event in the handler


2024-04-21 11:00:09,206 - INFO - Received event in the build_filter_prompt function


2024-04-21 11:00:09,206 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'x dev challenge\n'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the minimum and maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'x dev challenge\n'}


2024-04-21 11:00:09,208 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'x dev challenge\n'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the minimum and maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'x dev challenge\n'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-21 11:00:09,208 - DEBUG - max_retries: 8


2024-04-21 11:00:09,208 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d68700>


2024-04-21 11:00:09,214 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'x dev challenge\n'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the minimum and maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'x dev challenge\n'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-21 11:00:09,215 - DEBUG - close.started


2024-04-21 11:00:09,215 - DEBUG - close.complete


2024-04-21 11:00:09,215 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:00:09,230 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d68160>


2024-04-21 11:00:09,230 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:00:09,250 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d69c90>


2024-04-21 11:00:09,250 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:09,251 - DEBUG - send_request_headers.complete


2024-04-21 11:00:09,251 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:09,251 - DEBUG - send_request_body.complete


2024-04-21 11:00:09,251 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:10,161 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'778'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599535'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'46ms'), (b'x-request-id', b'req_4977238ee69587fe70db32d9847be066'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f45a1ec02092c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:10,163 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:10,164 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:10,164 - DEBUG - receive_response_body.complete


2024-04-21 11:00:10,165 - DEBUG - response_closed.started


2024-04-21 11:00:10,165 - DEBUG - response_closed.complete


2024-04-21 11:00:10,166 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:10,167 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVlxcO7lOl2G9K1xONGFl45JhavK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7TgLqRkjf29lHqkHlQ73bk9B', function=Function(arguments='{"filter_prompt":"x dev challenge","questions":null}', name='Stage3'), type='function')]))], created=1713722409, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=12, prompt_tokens=473, total_tokens=485))


2024-04-21 11:00:10,169 - INFO - Received completion from the model:
filter_prompt: x dev challenge
questions: None


2024-04-21 11:00:14,606 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-21 11:00:14,609 - INFO - Called the handcrafted conversation flow


2024-04-21 11:00:14,610 - INFO - Received event in the handler


2024-04-21 11:00:14,611 - INFO - Received event in the build_filter_prompt function


2024-04-21 11:00:30,767 - INFO - Received chat message: user_id='brian' message='simple, concise'


2024-04-21 11:00:30,769 - INFO - Called the handcrafted conversation flow


2024-04-21 11:00:30,769 - INFO - Received event in the handler


2024-04-21 11:00:30,771 - INFO - Received event in the build_report_guide function


2024-04-21 11:00:30,771 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}
	{'role': 'user', 'content': 'simple, concise'}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}
	{'role': 'user', 'content': 'simple, concise'}


2024-04-21 11:00:30,777 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage4'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'simple, concise'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'simple, concise'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}}


2024-04-21 11:00:30,777 - DEBUG - max_retries: 8


2024-04-21 11:00:30,777 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d68700>


2024-04-21 11:00:30,785 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'simple, concise'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'simple, concise'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}]}}


2024-04-21 11:00:30,786 - DEBUG - close.started


2024-04-21 11:00:30,787 - DEBUG - close.complete


2024-04-21 11:00:30,787 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:00:30,820 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d6a080>


2024-04-21 11:00:30,821 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:00:30,840 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d6a560>


2024-04-21 11:00:30,840 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:30,841 - DEBUG - send_request_headers.complete


2024-04-21 11:00:30,841 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:30,841 - DEBUG - send_request_body.complete


2024-04-21 11:00:30,841 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:32,142 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'992'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599638'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'36ms'), (b'x-request-id', b'req_0b4ae0cb8c1bf5b6aed8ed73e1d22cd0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4628de8e1009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:32,143 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:32,143 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:32,144 - DEBUG - receive_response_body.complete


2024-04-21 11:00:32,144 - DEBUG - response_closed.started


2024-04-21 11:00:32,144 - DEBUG - response_closed.complete


2024-04-21 11:00:32,144 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:32,144 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmIQqZPsSyRNWsuDuh79VaXcviX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uRQ78aVbEqxctfTcFCgDaUAB', function=Function(arguments='{"report_guide":"simple, concise","questions":null}', name='Stage4'), type='function')]))], created=1713722430, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=12, prompt_tokens=362, total_tokens=374))


2024-04-21 11:00:32,145 - INFO - Received completion from the model:
report_guide: simple, concise
questions: None


2024-04-21 11:00:36,372 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-21 11:00:36,382 - INFO - Called the handcrafted conversation flow


2024-04-21 11:00:36,384 - INFO - Received event in the handler


2024-04-21 11:00:36,392 - INFO - Received event in the build_report_guide function


2024-04-21 11:00:36,399 - INFO - Building filter


2024-04-21 11:00:36,399 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}
	{'role': 'user', 'content': 'x dev challenge'}


2024-04-21 11:00:36,405 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.ExtractedFilters'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'x dev challenge'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fill in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'return_min': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask for a minimum number of tweets/users to return? If so fill in this field', 'title': 'Return Min'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report? If so fill in this field.', 'title': 'Return Cap'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}}, 'type': 'object', 'required': []}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}}


2024-04-21 11:00:36,405 - DEBUG - max_retries: 8


2024-04-21 11:00:36,405 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d6a170>


2024-04-21 11:00:36,408 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'x dev challenge'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fill in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'return_min': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask for a minimum number of tweets/users to return? If so fill in this field', 'title': 'Return Min'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report? If so fill in this field.', 'title': 'Return Cap'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}}, 'type': 'object', 'required': []}}}]}}


2024-04-21 11:00:36,409 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:36,410 - DEBUG - send_request_headers.complete


2024-04-21 11:00:36,410 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:36,410 - DEBUG - send_request_body.complete


2024-04-21 11:00:36,410 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:41,969 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5348'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599943'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'5ms'), (b'x-request-id', b'req_c7d16fda88fb6fc9aeff27a1729c9e12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f464baf351009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:41,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:41,971 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:41,972 - DEBUG - receive_response_body.complete


2024-04-21 11:00:41,972 - DEBUG - response_closed.started


2024-04-21 11:00:41,973 - DEBUG - response_closed.complete


2024-04-21 11:00:41,973 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:41,975 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmOWOwIDxdI0caEIh1jPefaLYkI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UxVH0sn46Et3d5CioambkasB', function=Function(arguments='{"filter_prompt":"I want a filter that runs every 7 days. It should look for tweets from the people I follow, specifically those mentioning \'x dev challenge\'. I don\'t want tweets from anyone else. Please make sure I get at least 10 results but no more than 50 in each report."}', name='ExtractedFilters'), type='function')]))], created=1713722436, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=64, prompt_tokens=341, total_tokens=405))


2024-04-21 11:00:41,979 - INFO - Received completion from the model:
filter_period: None, usernames: None, only_search_specified_usernames: None, only_search_followers: None, return_cap: None


2024-04-21 11:00:41,982 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}
	{'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:00:41,987 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.GenerateKeywordGroups'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}}


2024-04-21 11:00:41,988 - DEBUG - max_retries: 8


2024-04-21 11:00:41,988 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d79fc0>


2024-04-21 11:00:41,995 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:00:41,997 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:41,997 - DEBUG - send_request_headers.complete


2024-04-21 11:00:41,998 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:41,998 - DEBUG - send_request_body.complete


2024-04-21 11:00:41,998 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:45,454 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:45 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3161'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599449'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'55ms'), (b'x-request-id', b'req_88eb52b502a110123e63ccefa41e3eb7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f466e9ef71009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:45,457 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:45,458 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:45,458 - DEBUG - receive_response_body.complete


2024-04-21 11:00:45,459 - DEBUG - response_closed.started


2024-04-21 11:00:45,459 - DEBUG - response_closed.complete


2024-04-21 11:00:45,459 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:45,461 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmUVWREK0mF1dZAun2xVeFFvznJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wlJktKUBP0zlmGRvpIiNK0MN', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "participant experiences"],\n    ["X Dev Challenge", "significant occurrences"]\n  ]\n}', name='GenerateKeywordGroups'), type='function')]))], created=1713722442, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=58, prompt_tokens=530, total_tokens=588))


2024-04-21 11:00:45,463 - INFO - Received completion from the model:
keyword_groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences']]


2024-04-21 11:00:45,467 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences") -is:reply


2024-04-21 11:00:45,467 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:00:45Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:00:45,480 - DEBUG - Starting new HTTPS connection (1): api.twitter.com:443


2024-04-21 11:00:45,671 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A00%3A45Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+%22participant+experiences%22%29+OR+%28%22X+Dev+Challenge%22+%22significant+occurrences%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:00:45,677 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:00:45 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'set-cookie': 'guest_id_marketing=v1%3A171372244560483251; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:00:45 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id_ads=v1%3A171372244560483251; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:00:45 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, personalization_id="v1_KGYgumam7bw64ncVAzcykQ=="; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:00:45 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id=v1%3A171372244560483251; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:00:45 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '6df7ff0116412f38', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713722678', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '447', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '69', 'x-connection-hash': '8f7a91b08188775033741d8e6f543ac780140b0fff2061d6f39d37a783832925'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:00:45,678 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences']]\n\nPlease provide a new keyword group."}


2024-04-21 11:00:45,688 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:00:45,688 - DEBUG - max_retries: 8


2024-04-21 11:00:45,688 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d79570>


2024-04-21 11:00:45,704 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:00:45,706 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:45,707 - DEBUG - send_request_headers.complete


2024-04-21 11:00:45,707 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:45,707 - DEBUG - send_request_body.complete


2024-04-21 11:00:45,707 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:49,035 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3091'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599726'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'req_8ece898b6d5c5d521419dbc251af5425'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4685c9781009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:49,037 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:49,037 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:49,038 - DEBUG - receive_response_body.complete


2024-04-21 11:00:49,038 - DEBUG - response_closed.started


2024-04-21 11:00:49,039 - DEBUG - response_closed.complete


2024-04-21 11:00:49,040 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:49,043 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmXTkjHnQMyHPt49X3GvVBAfrK2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fZD8dEmtFRyzEuZL5wbn6lS8', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "experiences"],\n    ["X Dev Challenge", "occurrences"],\n    ["X Dev Challenge"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722445, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=64, prompt_tokens=301, total_tokens=365))


2024-04-21 11:00:49,045 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge']]


2024-04-21 11:00:49,050 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" experiences) OR ("X Dev Challenge" occurrences) OR ("X Dev Challenge") -is:reply


2024-04-21 11:00:49,050 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:00:49Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" experiences) OR ("X Dev Challenge" occurrences) OR ("X Dev Challenge") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:00:49,269 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A00%3A49Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+experiences%29+OR+%28%22X+Dev+Challenge%22+occurrences%29+OR+%28%22X+Dev+Challenge%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:00:49,271 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:00:49 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'dcdcf19a8f368b0a', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713722678', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '446', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '179', 'x-connection-hash': '8f7a91b08188775033741d8e6f543ac780140b0fff2061d6f39d37a783832925'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:00:49,273 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}


2024-04-21 11:00:49,284 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:00:49,284 - DEBUG - max_retries: 8


2024-04-21 11:00:49,284 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d7a3b0>


2024-04-21 11:00:49,295 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:00:49,297 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:49,298 - DEBUG - send_request_headers.complete


2024-04-21 11:00:49,298 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:49,298 - DEBUG - send_request_body.complete


2024-04-21 11:00:49,298 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:54,080 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:54 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599726'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'req_a498d6528ddc285934945a15803c149d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f469c3d6d1009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:54,081 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:54,081 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:54,081 - DEBUG - receive_response_body.complete


2024-04-21 11:00:54,081 - DEBUG - response_closed.started


2024-04-21 11:00:54,081 - DEBUG - response_closed.complete


2024-04-21 11:00:54,081 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:54,082 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmb3ykJ0uCIPwSdlZ6IjJLGbUfy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UT7vuRPBG2q8RDdlGcDUsGPG', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "participant experiences"],\n    ["X Dev Challenge", "significant occurrences"],\n    ["X Dev Challenge", "event"],\n    ["X Dev Challenge"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722449, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=73, prompt_tokens=306, total_tokens=379))


2024-04-21 11:00:54,082 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]


2024-04-21 11:00:54,083 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences") OR ("X Dev Challenge" event) OR ("X Dev Challenge") -is:reply


2024-04-21 11:00:54,083 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:00:54Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences") OR ("X Dev Challenge" event) OR ("X Dev Challenge") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:00:54,190 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A00%3A54Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+%22participant+experiences%22%29+OR+%28%22X+Dev+Challenge%22+%22significant+occurrences%22%29+OR+%28%22X+Dev+Challenge%22+event%29+OR+%28%22X+Dev+Challenge%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:00:54,191 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:00:54 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'ac91f090c903b639', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713722678', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '445', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '75', 'x-connection-hash': '8f7a91b08188775033741d8e6f543ac780140b0fff2061d6f39d37a783832925'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:00:54,191 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}


2024-04-21 11:00:54,192 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:00:54,192 - DEBUG - max_retries: 8


2024-04-21 11:00:54,192 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107983160>


2024-04-21 11:00:54,195 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:00:54,195 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:54,196 - DEBUG - send_request_headers.complete


2024-04-21 11:00:54,196 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:54,196 - DEBUG - send_request_body.complete


2024-04-21 11:00:54,196 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:00:58,249 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:00:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3749'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599713'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_a9f662c5f58e6ae95b3a02c332a5fedd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46bacb701009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:00:58,249 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:00:58,249 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:00:58,250 - DEBUG - receive_response_body.complete


2024-04-21 11:00:58,250 - DEBUG - response_closed.started


2024-04-21 11:00:58,250 - DEBUG - response_closed.complete


2024-04-21 11:00:58,250 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:00:58,250 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmgttnu5RptbFGF92LJUO2AKh1k', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HLZORyyeMXcjyV3MCakfey95', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "experiences"],\n    ["X Dev Challenge", "occurrences"],\n    ["X Dev Challenge", "event"],\n    ["X Dev Challenge"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722454, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=73, prompt_tokens=314, total_tokens=387))


2024-04-21 11:00:58,251 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]


2024-04-21 11:00:58,252 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" experiences) OR ("X Dev Challenge" occurrences) OR ("X Dev Challenge" event) OR ("X Dev Challenge") -is:reply


2024-04-21 11:00:58,252 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:00:58Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" experiences) OR ("X Dev Challenge" occurrences) OR ("X Dev Challenge" event) OR ("X Dev Challenge") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:00:58,354 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A00%3A58Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+experiences%29+OR+%28%22X+Dev+Challenge%22+occurrences%29+OR+%28%22X+Dev+Challenge%22+event%29+OR+%28%22X+Dev+Challenge%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:00:58,354 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:00:58 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '693373cc04789770', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713722678', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '444', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '70', 'x-connection-hash': '8f7a91b08188775033741d8e6f543ac780140b0fff2061d6f39d37a783832925'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:00:58,355 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}


2024-04-21 11:00:58,357 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:00:58,361 - DEBUG - max_retries: 8


2024-04-21 11:00:58,362 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d8a650>


2024-04-21 11:00:58,364 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'experiences'], ['X Dev Challenge', 'occurrences'], ['X Dev Challenge', 'event'], ['X Dev Challenge']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:00:58,365 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:00:58,365 - DEBUG - send_request_headers.complete


2024-04-21 11:00:58,365 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:00:58,365 - DEBUG - send_request_body.complete


2024-04-21 11:00:58,365 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:01,116 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2599'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599718'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_acecde2a552e58cba0dcb79d48945085'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46d4eb5c1009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:01,116 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:01,117 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:01,117 - DEBUG - receive_response_body.complete


2024-04-21 11:01:01,117 - DEBUG - response_closed.started


2024-04-21 11:01:01,117 - DEBUG - response_closed.complete


2024-04-21 11:01:01,117 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:01,118 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmkwKkcVfiZcC1AZuIQfhCAifpL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_d67so1s8ZooWLlYjcMJQ3zcD', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["participant experiences"],\n    ["significant occurrences"],\n    ["event started yesterday"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722458, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=54, prompt_tokens=314, total_tokens=368))


2024-04-21 11:01:01,118 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['participant experiences'], ['significant occurrences'], ['event started yesterday']]


2024-04-21 11:01:01,119 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("event started yesterday") -is:reply


2024-04-21 11:01:01,119 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:01:01Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("event started yesterday") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:01:01,834 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A01%3A01Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22participant+experiences%22%29+OR+%28%22significant+occurrences%22%29+OR+%28%22event+started+yesterday%22%29+-is%3Areply HTTP/1.1" 200 6305


2024-04-21 11:01:01,835 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:01:01 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '6305', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '33d9bbc26e62a2a8', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713722678', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '443', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '634', 'x-connection-hash': '8f7a91b08188775033741d8e6f543ac780140b0fff2061d6f39d37a783832925'}
Content: b'{"data":[{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1782062925496340840","edit_history_tweet_ids":["1782062925496340840"],"author_id":"630487521"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1782051841125069237","edit_history_tweet_ids":["1782051841125069237"],"author_id":"32403564"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1782047601782632564","edit_history_tweet_ids":["1782047601782632564"],"author_id":"1676164223301451776"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781884776393196010","edit_history_tweet_ids":["1781884776393196010"],"author_id":"1521962734233210880"},{"text":"April 11, 1954, was recorded as the most boring day in the world. \\nStatistics show that no significant occurrences took place in the world.\\n\\uD83C\\uDF0D \\uD83E\\uDD71 #Boring #Bored #April #World #Statistics #FunFacts","id":"1781875026913796185","edit_history_tweet_ids":["1781875026913796185"],"author_id":"1777442846406037504"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781806594390671662","edit_history_tweet_ids":["1781806594390671662"],"author_id":"935994980165861377"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781796029014094318","edit_history_tweet_ids":["1781796029014094318"],"author_id":"1460191675138117634"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781781547839898099","edit_history_tweet_ids":["1781781547839898099"],"author_id":"1657415515898515458"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781710792515051990","edit_history_tweet_ids":["1781710792515051990"],"author_id":"1025075253494595584"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781676961569370154","edit_history_tweet_ids":["1781676961569370154"],"author_id":"1767360627423444992"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781672117735399727","edit_history_tweet_ids":["1781672117735399727"],"author_id":"1118642208083783681"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781661787194085680","edit_history_tweet_ids":["1781661787194085680"],"author_id":"1409267824531476482"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781657936328093882","edit_history_tweet_ids":["1781657936328093882"],"author_id":"1644747499343695874"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781650777737732188","edit_history_tweet_ids":["1781650777737732188"],"author_id":"912116847826186240"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781648026697707573","edit_history_tweet_ids":["1781648026697707573"],"author_id":"1385240529051521027"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781636664823316944","edit_history_tweet_ids":["1781636664823316944"],"author_id":"1513204379574468609"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781621917889298554","edit_history_tweet_ids":["1781621917889298554"],"author_id":"29790817"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781606749889540333","edit_history_tweet_ids":["1781606749889540333"],"author_id":"181889520"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781599730629329214","edit_history_tweet_ids":["1781599730629329214"],"author_id":"749615852807413760"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781590783096729915","edit_history_tweet_ids":["1781590783096729915"],"author_id":"1685321640907804672"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781582531709546683","edit_history_tweet_ids":["1781582531709546683"],"author_id":"1701201303043489792"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781581443644436711","edit_history_tweet_ids":["1781581443644436711"],"author_id":"1415665060274266112"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781576523948126666","edit_history_tweet_ids":["1781576523948126666"],"author_id":"1074232447292780545"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781576080291197046","edit_history_tweet_ids":["1781576080291197046"],"author_id":"3029824326"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781575173558222856","edit_history_tweet_ids":["1781575173558222856"],"author_id":"50949539"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781573468862976377","edit_history_tweet_ids":["1781573468862976377"],"author_id":"1619028953133465612"},{"text":"like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel","id":"1781566302714577399","edit_history_tweet_ids":["1781566302714577399"],"author_id":"1486361576332742658"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781562231282663512","edit_history_tweet_ids":["1781562231282663512"],"author_id":"1438501174269775887"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781556464059809871","edit_history_tweet_ids":["1781556464059809871"],"author_id":"1395171663755497472"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781529327412093238","edit_history_tweet_ids":["1781529327412093238"],"author_id":"1371282159915429889"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781525367439622383","edit_history_tweet_ids":["1781525367439622383"],"author_id":"1514839082731548676"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781523566254809436","edit_history_tweet_ids":["1781523566254809436"],"author_id":"1571575059697012736"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781519682585198892","edit_history_tweet_ids":["1781519682585198892"],"author_id":"1522529601557303297"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781507795499548841","edit_history_tweet_ids":["1781507795499548841"],"author_id":"96475174"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781486248479375798","edit_history_tweet_ids":["1781486248479375798"],"author_id":"1358780273769422849"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781485268819746826","edit_history_tweet_ids":["1781485268819746826"],"author_id":"1741786039662813184"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781469870544077114","edit_history_tweet_ids":["1781469870544077114"],"author_id":"368512817"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781460777766948889","edit_history_tweet_ids":["1781460777766948889"],"author_id":"3327232431"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781459230165471654","edit_history_tweet_ids":["1781459230165471654"],"author_id":"1379669673206185990"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781457357068718338","edit_history_tweet_ids":["1781457357068718338"],"author_id":"1732000012597395456"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781449025335525874","edit_history_tweet_ids":["1781449025335525874"],"author_id":"1471144474629787656"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781446414356173236","edit_history_tweet_ids":["1781446414356173236"],"author_id":"1444726992323104775"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781440779627684278","edit_history_tweet_ids":["1781440779627684278"],"author_id":"1388842780970024968"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781436743742619776","edit_history_tweet_ids":["1781436743742619776"],"author_id":"1481542542546333698"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781435062921126074","edit_history_tweet_ids":["1781435062921126074"],"author_id":"1436160020748570630"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781433028524581141","edit_history_tweet_ids":["1781433028524581141"],"author_id":"1453220233343287300"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781430512050954449","edit_history_tweet_ids":["1781430512050954449"],"author_id":"1610469503241945088"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781430073796505622","edit_history_tweet_ids":["1781430073796505622"],"author_id":"1624083715780497410"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781424758409568721","edit_history_tweet_ids":["1781424758409568721"],"author_id":"1524483921114800128"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781424620043682274","edit_history_tweet_ids":["1781424620043682274"],"author_id":"1577313385615708160"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781419640402370957","edit_history_tweet_ids":["1781419640402370957"],"author_id":"1462798510433177601"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781417305974698357","edit_history_tweet_ids":["1781417305974698357"],"author_id":"1421021188730523651"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781410442142974417","edit_history_tweet_ids":["1781410442142974417"],"author_id":"1452857026229403650"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781408145295769689","edit_history_tweet_ids":["1781408145295769689"],"author_id":"452384298"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781403660632653955","edit_history_tweet_ids":["1781403660632653955"],"author_id":"150178720"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781397354299453772","edit_history_tweet_ids":["1781397354299453772"],"author_id":"794412655146516480"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781395883696824496","edit_history_tweet_ids":["1781395883696824496"],"author_id":"25153589"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781391803289137328","edit_history_tweet_ids":["1781391803289137328"],"author_id":"246220698"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781390931289342463","edit_history_tweet_ids":["1781390931289342463"],"author_id":"4286792165"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781390180596723831","edit_history_tweet_ids":["1781390180596723831"],"author_id":"1244047263137218560"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781388714054222033","edit_history_tweet_ids":["1781388714054222033"],"author_id":"1492628666739830795"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781388093490176348","edit_history_tweet_ids":["1781388093490176348"],"author_id":"14172125"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781387817727205517","edit_history_tweet_ids":["1781387817727205517"],"author_id":"1774529585675194368"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781387335696846962","edit_history_tweet_ids":["1781387335696846962"],"author_id":"3385290333"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781386371900330099","edit_history_tweet_ids":["1781386371900330099"],"author_id":"1363422527066931200"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781383164419575890","edit_history_tweet_ids":["1781383164419575890"],"author_id":"1656931309820715008"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781382500520005910","edit_history_tweet_ids":["1781382500520005910"],"author_id":"1331678427523522560"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781381818039824732","edit_history_tweet_ids":["1781381818039824732"],"author_id":"1515899384478720009"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781381561679552851","edit_history_tweet_ids":["1781381561679552851"],"author_id":"1452027939759996928"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781381241331175882","edit_history_tweet_ids":["1781381241331175882"],"author_id":"1603773806342033409"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781380371583566181","edit_history_tweet_ids":["1781380371583566181"],"author_id":"32970280"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781378973269958759","edit_history_tweet_ids":["1781378973269958759"],"author_id":"1573257117125025792"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781378396821332273","edit_history_tweet_ids":["1781378396821332273"],"author_id":"1368365171236872193"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781378062283624876","edit_history_tweet_ids":["1781378062283624876"],"author_id":"48564581"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781377914790920594","edit_history_tweet_ids":["1781377914790920594"],"author_id":"1235700080847486977"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781377628731031680","edit_history_tweet_ids":["1781377628731031680"],"author_id":"1536757259476295681"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781375019760623873","edit_history_tweet_ids":["1781375019760623873"],"author_id":"1662665145003245571"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781374506516262987","edit_history_tweet_ids":["1781374506516262987"],"author_id":"1440041286778511360"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781372725178581361","edit_history_tweet_ids":["1781372725178581361"],"author_id":"63150251"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781371360700211340","edit_history_tweet_ids":["1781371360700211340"],"author_id":"1175848670467678208"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781371354677137838","edit_history_tweet_ids":["1781371354677137838"],"author_id":"1065140892"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781368185683357819","edit_history_tweet_ids":["1781368185683357819"],"author_id":"1512880203185414154"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781365502402523475","edit_history_tweet_ids":["1781365502402523475"],"author_id":"1372177405683597319"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781363159955046619","edit_history_tweet_ids":["1781363159955046619"],"author_id":"1189656610945286150"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781362859156672663","edit_history_tweet_ids":["1781362859156672663"],"author_id":"1430220863505272837"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781362832006635680","edit_history_tweet_ids":["1781362832006635680"],"author_id":"1474205982490349568"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781361952507240579","edit_history_tweet_ids":["1781361952507240579"],"author_id":"1169760066"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781361304902775115","edit_history_tweet_ids":["1781361304902775115"],"author_id":"64583"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781360878988009928","edit_history_tweet_ids":["1781360878988009928"],"author_id":"1720735649396133888"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781359616862920945","edit_history_tweet_ids":["1781359616862920945"],"author_id":"462850404"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781358681096892432","edit_history_tweet_ids":["1781358681096892432"],"author_id":"1431642439094312961"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781354702636228670","edit_history_tweet_ids":["1781354702636228670"],"author_id":"62240213"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781354241791082952","edit_history_tweet_ids":["1781354241791082952"],"author_id":"1089491150"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781353746468921713","edit_history_tweet_ids":["1781353746468921713"],"author_id":"1500093887410495489"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781353700193079377","edit_history_tweet_ids":["1781353700193079377"],"author_id":"822043263196680193"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781352812162531557","edit_history_tweet_ids":["1781352812162531557"],"author_id":"2332439312"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781350514359456036","edit_history_tweet_ids":["1781350514359456036"],"author_id":"202125279"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781348139561062472","edit_history_tweet_ids":["1781348139561062472"],"author_id":"1436768213417840641"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781347685792190908","edit_history_tweet_ids":["1781347685792190908"],"author_id":"907522967831117824"},{"text":"RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \\n\\nWe were very impressed by the pieces we discovered and highlighted mo\xe2\x80\xa6","id":"1781346210751590563","edit_history_tweet_ids":["1781346210751590563"],"author_id":"1397160357970460678"}],"includes":{"users":[{"id":"630487521","name":"metaperson","username":"meta_person"},{"id":"32403564","name":"akiradice \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f","username":"AkiraD"},{"id":"1676164223301451776","name":"thatbitch.tez","username":"ArtsieRosey"},{"id":"1521962734233210880","name":"MarsCitizen \\uD83D\\uDC7D","username":"Alien_Designer"},{"id":"1777442846406037504","name":"AnalyticAvenue","username":"AnalyticAvenue"},{"id":"935994980165861377","name":"NFT ART MAGAZINE TOKYO","username":"nftmag_tokyo"},{"id":"1460191675138117634","name":"MisterTW.eth \\uD83E\\uDD54\\uD83D\\uDC51 | \\uD83D\\uDCCCOBJKT4OBJKT\\uD83D\\uDCCC","username":"MisterTW_Art"},{"id":"1657415515898515458","name":"Black Loop Lab","username":"BlackLoopLab"},{"id":"1025075253494595584","name":"citezenb | citezenb.tez","username":"CitezenB"},{"id":"1767360627423444992","name":"Ongridpixels","username":"ongridpixels"},{"id":"1118642208083783681","name":"U\xcc\xb7\xcd\x80\xcc\xa0\xcc\xaf\xcd\x9a\xcc\xa0\xc5\xbe\xcc\xb7\xcd\x81\xcd\x80\xcc\x8b\xcd\x97\xcd\x84\xcc\x98u\xcc\xb6\xcc\x87\xcc\x93\xcd\x86\xcc\x99\xcc\xba\xcc\xa3p\xcc\xb8\xcd\x84\xcd\x97\xcd\x81\xcc\x91\xcc\xbe\xcc\x8a\xcd\x8e\xcd\x99\xcc\xa2\xcc\xb2\xcc\xa1i\xcc\xb5\xcc\x86\xcc\x9f\xcc\xb2\xcc\x99\xcc\x98\xcc\xb0s\xcc\xb7\xcd\x9b\xcd\xa0\xcc\x90\xcc\x84","username":"UzupisMUC"},{"id":"1409267824531476482","name":"John Bezold","username":"JohnBezold"},{"id":"1644747499343695874","name":"Negar\\uD83D\\uDD79\xef\xb8\x8f$RCADE","username":"Artnegar"},{"id":"912116847826186240","name":"FrederickSchultz.tez\\uD83C\\uDFF4\xe2\x80\x8d\xe2\x98\xa0\xef\xb8\x8f \\uD83C\\uDDE6\\uD83C\\uDDFA","username":"AustraliaShultz"},{"id":"1385240529051521027","name":"SV3ZR","username":"SV3ZR"},{"id":"1513204379574468609","name":"RexManusAdamas","username":"AdamasRex"},{"id":"29790817","name":"Tobias Hartmann \xe2\x80\x93 hamato.tez/.eth \\uD83D\\uDCF7","username":"h4m4t0"},{"id":"181889520","name":"tjhinoz","username":"riocino"},{"id":"749615852807413760","name":"Hana","username":"avelivnft"},{"id":"1685321640907804672","name":"tesserart","username":"tesserart_xyz"},{"id":"1701201303043489792","name":"somayeh.haypernfts.NFTNYC2024","username":"yasaminft"},{"id":"1415665060274266112","name":"_paperspace","username":"_paperspace"},{"id":"1074232447292780545","name":"~*\xe2\x98\x86\xe2\x9c\xa8\\uD835\\uDCEE\\uD835\\uDCF7\\uD835\\uDCEC\\uD835\\uDCF1\\uD835\\uDCEA\\uD835\\uDCF7\\uD835\\uDCFD\\uD835\\uDCEE\\uD835\\uDCED_\\uD835\\uDCEF\\uD835\\uDCEA\\uD835\\uDCF2\\uD835\\uDCFB\\uD835\\uDD02\xe2\x9c\xa8\xe2\x98\x86*~","username":"BlytheLoveStory"},{"id":"3029824326","name":"marksmcneill","username":"marksmcneill"},{"id":"50949539","name":"Nad-NFTs","username":"nad_nfts"},{"id":"1619028953133465612","name":"#OBJKT4OBJKT","username":"OBJKT4OBJKT"},{"id":"1486361576332742658","name":"peter in punk \xe2\x98\x85","username":"bootlegwentz"},{"id":"1438501174269775887","name":"Arm Suwittawat R.","username":"SuwittawatR"},{"id":"1395171663755497472","name":"Dreams&Schemes.eth","username":"BebesBotanica"},{"id":"1371282159915429889","name":"AD_AD","username":"adam_disbrow"},{"id":"1514839082731548676","name":"Mina","username":"_iaM_Mina"},{"id":"1571575059697012736","name":"\xe2\x9a\xa1\xef\xb8\x8f\xe2\x9a\xa1\xef\xb8\x8fG.\\uD83D\\uDC80Dir.Bj","username":"BJs_Pits"},{"id":"1522529601557303297","name":"\xe2\x9d\xa4\xef\xb8\x8f\xe2\x80\x8d\\uD83D\\uDD25 1/1 on Tezos - A Showcase of Rare Art","username":"1of1xtz"},{"id":"96475174","name":"MykNash","username":"myknash"},{"id":"1358780273769422849","name":"kelborhal78\\uD83C\\uDDFE\\uD83C\\uDDEA","username":"plaguemarine87"},{"id":"1741786039662813184","name":"Niniola`Art 4 u","username":"Niniola4u"},{"id":"368512817","name":"\xe1\xb5\x89\xe1\xb5\x8f\xe1\xb5\x89\xe1\xb5\x8f\xe1\xb5\x92","username":"ekeko_mtdc"},{"id":"3327232431","name":"badOdds","username":"b4dodds"},{"id":"1379669673206185990","name":"SIFT | \xe1\x9c\x83\xe1\x9c\x92\xe1\x9c\x87\xe1\x9c\x94\xe1\x9c\x8e\xe1\x9c\x86\xe1\x9c\x94","username":"siftcroix"},{"id":"1732000012597395456","name":"braindead.gif","username":"rightclickdead"},{"id":"1471144474629787656","name":"treeskulltown.tez/eth","username":"treeskulltown2"},{"id":"1444726992323104775","name":"SoulplayClayNFTs","username":"SoulplayClayNFT"},{"id":"1388842780970024968","name":"bonce","username":"bonabonce"},{"id":"1481542542546333698","name":"Green Ginger | \\uD83D\\uDFE2\\uD83E\\uDEDA\\uD83D\\uDCCC","username":"greenisginger"},{"id":"1436160020748570630","name":"unrealB0X","username":"unrealb0x"},{"id":"1453220233343287300","name":"B-exter","username":"B_DWIL"},{"id":"1610469503241945088","name":"Cryptol3mon_nft","username":"cryptol3mon_nft"},{"id":"1624083715780497410","name":"Lena Ekert \\uD83C\\uDF31","username":"BreathlesssAsh"},{"id":"1524483921114800128","name":"Xart_limonnft","username":"limonnft_art"},{"id":"1577313385615708160","name":"QR","username":"qr4gallery"},{"id":"1462798510433177601","name":"V\xc3\xadctor Arce \xe2\x9c\xb7 \\uD835\\uDCF5\\uD835\\uDD01\\uD835\\uDCFD\\uD835\\uDD01\\uD835\\uDCEC\\uD835\\uDD01 \\uD83C\\uDF10","username":"lxtxcx"},{"id":"1421021188730523651","name":"Ariuw \xd8\xa2\xd8\xb2\xd8\xa7\xd8\xaf\xdb\x8c","username":"AriuAzadi"},{"id":"1452857026229403650","name":"\\uD835\\uDFD9\\uD835\\uDFD8\\uD835\\uDFD8\\uD835\\uDFD8\\uD835\\uDD43\\uD835\\uDD52\\uD835\\uDD5F\\uD835\\uDD55\\uD835\\uDD6B \\uD83C\\uDFF4\xe2\x80\x8d\xe2\x98\xa0\xef\xb8\x8f\\uD83D\\uDC8E","username":"1000Landz"},{"id":"452384298","name":"warpcast is better - He/Him","username":"WhichWitchWasIt"},{"id":"150178720","name":"Martin Vanek","username":"Martinvanek"},{"id":"794412655146516480","name":"TULSI SH. KUMBHAR||tulsishankar.eth|| NFT.NYC2024","username":"TULSISHANKAR1"},{"id":"25153589","name":"Jundaboom","username":"Jundaboom"},{"id":"246220698","name":"Erdem Kuybulu","username":"ErdemKuybulu"},{"id":"4286792165","name":"Datura","username":"daturascore"},{"id":"1244047263137218560","name":"\\uD835\\uDCD3\\uD835\\uDCEA\\uD835\\uDCF2\\uD835\\uDCEA\\uD835\\uDCF7\\uD835\\uDCEA \\uD835\\uDCDB\\uD835\\uDCEA\\uD835\\uDD03\\uD835\\uDD03\\uD835\\uDCEA\\uD835\\uDCFB\\uD835\\uDCF2\\uD835\\uDCF7 #objkt4objkt","username":"daiana_lazzarin"},{"id":"1492628666739830795","name":"\\uD83C\\uDFAC 00:00:00:01","username":"OsipenkovNFTs"},{"id":"14172125","name":"\\uD83C\\uDD7E\\uD83C\\uDD7B\\uD83C\\uDD73\\uD83C\\uDD7E","username":"oldo"},{"id":"1774529585675194368","name":"Failure001","username":"001failure"},{"id":"3385290333","name":"Gaurav Rai | gauravrai.tez","username":"rai_nef"},{"id":"1363422527066931200","name":"Kx_","username":"Kx________"},{"id":"1656931309820715008","name":"Mrraval NFTs","username":"mrraval6677"},{"id":"1331678427523522560","name":"don\'t be so vasya \\uD83E\\uDEE0","username":"dontbesovasya"},{"id":"1515899384478720009","name":"Ermac Kiyani","username":"ErmacKiyani"},{"id":"1452027939759996928","name":"Rodicqart","username":"rodicqart"},{"id":"1603773806342033409","name":"AlenaArt_40","username":"AlenaArt_40"},{"id":"32970280","name":"Kika Nicolela","username":"kikanicolela"},{"id":"1573257117125025792","name":"GCakes | Joy City, Beijing OC 2023 NFT","username":"Cakes6G"},{"id":"1368365171236872193","name":"theurbanita\\uD83D\\uDCAB","username":"theurbanita"},{"id":"48564581","name":"Von Doyle","username":"VonDoyl"},{"id":"1235700080847486977","name":"Cindy","username":"CindyApples1984"},{"id":"1536757259476295681","name":"DTheLetterD","username":"DtheletterD"},{"id":"1662665145003245571","name":"Huemans of the Universe","username":"HuemansUniverse"},{"id":"1440041286778511360","name":"wwwombats","username":"wwwombats"},{"id":"63150251","name":"Andressa Furletti #TezQuakeAid","username":"a_tchuca"},{"id":"1175848670467678208","name":"Moonzi\\uD83C\\uDF19","username":"mo0n_zi"},{"id":"1065140892","name":"B.D.Vision","username":"behroozdaavari"},{"id":"1512880203185414154","name":"brasiltezos","username":"brasiltezos"},{"id":"1372177405683597319","name":"historicalive.tez","username":"historicalive"},{"id":"1189656610945286150","name":"Nihat Bay\xc4\xb1r","username":"Nhtbyr"},{"id":"1430220863505272837","name":"Skitchism","username":"skitchism"},{"id":"1474205982490349568","name":"Buctown MMA \\uD83E\\uDD4B\\uD83E\\uDD4A\\uD83E\\uDDE0\xe2\x9c\xa8\xef\xb8\x8f buctown.eth","username":"BuctownMMA"},{"id":"1169760066","name":"Nicole Ruggiero \\uD83D\\uDC69\xe2\x80\x8d\\uD83D\\uDCBB\\uD83C\\uDFA8","username":"_NicoleRuggiero"},{"id":"64583","name":"PixelSushiRobot \\uD83D\\uDCAB","username":"PixelSushiRobot"},{"id":"1720735649396133888","name":"Ophelia Karina - TEZ","username":"opheliart_Tez"},{"id":"462850404","name":"Fabrice","username":"aladwani13"},{"id":"1431642439094312961","name":"Arkain","username":"ArkainArt"},{"id":"62240213","name":"Ade Santora","username":"adesantora"},{"id":"1089491150","name":"L\'Inquisiteur","username":"BurnZeWitch"},{"id":"1500093887410495489","name":"p.i.x.e.l.l.a.r.e. \\uD83C\\uDF49","username":"_pixellare"},{"id":"822043263196680193","name":"Javier Montero","username":"javiermonttero"},{"id":"2332439312","name":"Ferdoropeza.eth/tez","username":"Ferdoropeza"},{"id":"202125279","name":"ssshihtung","username":"seeingsun"},{"id":"1436768213417840641","name":"\\uD835\\uDC0D\\uD835\\uDC08\\uD835\\uDC03\\uD835\\uDC19\\uD835\\uDC00\\uD835\\uDC11\\uD835\\uDC13","username":"nidzartt"},{"id":"907522967831117824","name":"\\uD83C\\uDF2EAkashi\\uD83C\\uDF2E","username":"akashitez"},{"id":"1397160357970460678","name":"Brian McAlister","username":"brianmca_"}]},"meta":{"newest_id":"1782062925496340840","oldest_id":"1781346210751590563","result_count":100,"next_token":"b26v89c19zqg8o3fr5zcinjwvxcuhfoyyzl6clgk01lkt"}}'


2024-04-21 11:01:01,836 - DEBUG - Making API request: GET https://api.twitter.com/2/users
Parameters: {'ids': '630487521,32403564,1676164223301451776,1521962734233210880,1777442846406037504,935994980165861377,1460191675138117634,1657415515898515458,1025075253494595584,1767360627423444992,1118642208083783681,1409267824531476482,1644747499343695874,912116847826186240,1385240529051521027,1513204379574468609,29790817,181889520,749615852807413760,1685321640907804672,1701201303043489792,1415665060274266112,1074232447292780545,3029824326,50949539,1619028953133465612,1486361576332742658,1438501174269775887,1395171663755497472,1371282159915429889,1514839082731548676,1571575059697012736,1522529601557303297,96475174,1358780273769422849,1741786039662813184,368512817,3327232431,1379669673206185990,1732000012597395456,1471144474629787656,1444726992323104775,1388842780970024968,1481542542546333698,1436160020748570630,1453220233343287300,1610469503241945088,1624083715780497410,1524483921114800128,1577313385615708160,1462798510433177601,1421021188730523651,1452857026229403650,452384298,150178720,794412655146516480,25153589,246220698,4286792165,1244047263137218560,1492628666739830795,14172125,1774529585675194368,3385290333,1363422527066931200,1656931309820715008,1331678427523522560,1515899384478720009,1452027939759996928,1603773806342033409,32970280,1573257117125025792,1368365171236872193,48564581,1235700080847486977,1536757259476295681,1662665145003245571,1440041286778511360,63150251,1175848670467678208,1065140892,1512880203185414154,1372177405683597319,1189656610945286150,1430220863505272837,1474205982490349568,1169760066,64583,1720735649396133888,462850404,1431642439094312961,62240213,1089491150,1500093887410495489,822043263196680193,2332439312,202125279,1436768213417840641,907522967831117824,1397160357970460678'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:01:02,145 - DEBUG - https://api.twitter.com:443 "GET /2/users?ids=630487521%2C32403564%2C1676164223301451776%2C1521962734233210880%2C1777442846406037504%2C935994980165861377%2C1460191675138117634%2C1657415515898515458%2C1025075253494595584%2C1767360627423444992%2C1118642208083783681%2C1409267824531476482%2C1644747499343695874%2C912116847826186240%2C1385240529051521027%2C1513204379574468609%2C29790817%2C181889520%2C749615852807413760%2C1685321640907804672%2C1701201303043489792%2C1415665060274266112%2C1074232447292780545%2C3029824326%2C50949539%2C1619028953133465612%2C1486361576332742658%2C1438501174269775887%2C1395171663755497472%2C1371282159915429889%2C1514839082731548676%2C1571575059697012736%2C1522529601557303297%2C96475174%2C1358780273769422849%2C1741786039662813184%2C368512817%2C3327232431%2C1379669673206185990%2C1732000012597395456%2C1471144474629787656%2C1444726992323104775%2C1388842780970024968%2C1481542542546333698%2C1436160020748570630%2C1453220233343287300%2C1610469503241945088%2C1624083715780497410%2C1524483921114800128%2C1577313385615708160%2C1462798510433177601%2C1421021188730523651%2C1452857026229403650%2C452384298%2C150178720%2C794412655146516480%2C25153589%2C246220698%2C4286792165%2C1244047263137218560%2C1492628666739830795%2C14172125%2C1774529585675194368%2C3385290333%2C1363422527066931200%2C1656931309820715008%2C1331678427523522560%2C1515899384478720009%2C1452027939759996928%2C1603773806342033409%2C32970280%2C1573257117125025792%2C1368365171236872193%2C48564581%2C1235700080847486977%2C1536757259476295681%2C1662665145003245571%2C1440041286778511360%2C63150251%2C1175848670467678208%2C1065140892%2C1512880203185414154%2C1372177405683597319%2C1189656610945286150%2C1430220863505272837%2C1474205982490349568%2C1169760066%2C64583%2C1720735649396133888%2C462850404%2C1431642439094312961%2C62240213%2C1089491150%2C1500093887410495489%2C822043263196680193%2C2332439312%2C202125279%2C1436768213417840641%2C907522967831117824%2C1397160357970460678 HTTP/1.1" 200 3578


2024-04-21 11:01:02,147 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:01:02 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '3578', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'cd7ee6119add42db', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713723361', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '299', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '210', 'x-connection-hash': '8f7a91b08188775033741d8e6f543ac780140b0fff2061d6f39d37a783832925'}
Content: b'{"data":[{"id":"630487521","name":"metaperson","username":"meta_person"},{"id":"32403564","name":"akiradice \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f","username":"AkiraD"},{"id":"1676164223301451776","name":"thatbitch.tez","username":"ArtsieRosey"},{"id":"1521962734233210880","name":"MarsCitizen \\uD83D\\uDC7D","username":"Alien_Designer"},{"id":"1777442846406037504","name":"AnalyticAvenue","username":"AnalyticAvenue"},{"id":"935994980165861377","name":"NFT ART MAGAZINE TOKYO","username":"nftmag_tokyo"},{"id":"1460191675138117634","name":"MisterTW.eth \\uD83E\\uDD54\\uD83D\\uDC51 | \\uD83D\\uDCCCOBJKT4OBJKT\\uD83D\\uDCCC","username":"MisterTW_Art"},{"id":"1657415515898515458","name":"Black Loop Lab","username":"BlackLoopLab"},{"id":"1025075253494595584","name":"citezenb | citezenb.tez","username":"CitezenB"},{"id":"1767360627423444992","name":"Ongridpixels","username":"ongridpixels"},{"id":"1118642208083783681","name":"U\xcc\xb7\xcd\x80\xcc\xa0\xcc\xaf\xcd\x9a\xcc\xa0\xc5\xbe\xcc\xb7\xcd\x81\xcd\x80\xcc\x8b\xcd\x97\xcd\x84\xcc\x98u\xcc\xb6\xcc\x87\xcc\x93\xcd\x86\xcc\x99\xcc\xba\xcc\xa3p\xcc\xb8\xcd\x84\xcd\x97\xcd\x81\xcc\x91\xcc\xbe\xcc\x8a\xcd\x8e\xcd\x99\xcc\xa2\xcc\xb2\xcc\xa1i\xcc\xb5\xcc\x86\xcc\x9f\xcc\xb2\xcc\x99\xcc\x98\xcc\xb0s\xcc\xb7\xcd\x9b\xcd\xa0\xcc\x90\xcc\x84","username":"UzupisMUC"},{"id":"1409267824531476482","name":"John Bezold","username":"JohnBezold"},{"id":"1644747499343695874","name":"Negar\\uD83D\\uDD79\xef\xb8\x8f$RCADE","username":"Artnegar"},{"id":"912116847826186240","name":"FrederickSchultz.tez\\uD83C\\uDFF4\xe2\x80\x8d\xe2\x98\xa0\xef\xb8\x8f \\uD83C\\uDDE6\\uD83C\\uDDFA","username":"AustraliaShultz"},{"id":"1385240529051521027","name":"SV3ZR","username":"SV3ZR"},{"id":"1513204379574468609","name":"RexManusAdamas","username":"AdamasRex"},{"id":"29790817","name":"Tobias Hartmann \xe2\x80\x93 hamato.tez/.eth \\uD83D\\uDCF7","username":"h4m4t0"},{"id":"181889520","name":"tjhinoz","username":"riocino"},{"id":"749615852807413760","name":"Hana","username":"avelivnft"},{"id":"1685321640907804672","name":"tesserart","username":"tesserart_xyz"},{"id":"1701201303043489792","name":"somayeh.haypernfts.NFTNYC2024","username":"yasaminft"},{"id":"1415665060274266112","name":"_paperspace","username":"_paperspace"},{"id":"1074232447292780545","name":"~*\xe2\x98\x86\xe2\x9c\xa8\\uD835\\uDCEE\\uD835\\uDCF7\\uD835\\uDCEC\\uD835\\uDCF1\\uD835\\uDCEA\\uD835\\uDCF7\\uD835\\uDCFD\\uD835\\uDCEE\\uD835\\uDCED_\\uD835\\uDCEF\\uD835\\uDCEA\\uD835\\uDCF2\\uD835\\uDCFB\\uD835\\uDD02\xe2\x9c\xa8\xe2\x98\x86*~","username":"BlytheLoveStory"},{"id":"3029824326","name":"marksmcneill","username":"marksmcneill"},{"id":"50949539","name":"Nad-NFTs","username":"nad_nfts"},{"id":"1619028953133465612","name":"#OBJKT4OBJKT","username":"OBJKT4OBJKT"},{"id":"1486361576332742658","name":"peter in punk \xe2\x98\x85","username":"bootlegwentz"},{"id":"1438501174269775887","name":"Arm Suwittawat R.","username":"SuwittawatR"},{"id":"1395171663755497472","name":"Dreams&Schemes.eth","username":"BebesBotanica"},{"id":"1371282159915429889","name":"AD_AD","username":"adam_disbrow"},{"id":"1514839082731548676","name":"Mina","username":"_iaM_Mina"},{"id":"1571575059697012736","name":"\xe2\x9a\xa1\xef\xb8\x8f\xe2\x9a\xa1\xef\xb8\x8fG.\\uD83D\\uDC80Dir.Bj","username":"BJs_Pits"},{"id":"1522529601557303297","name":"\xe2\x9d\xa4\xef\xb8\x8f\xe2\x80\x8d\\uD83D\\uDD25 1/1 on Tezos - A Showcase of Rare Art","username":"1of1xtz"},{"id":"96475174","name":"MykNash","username":"myknash"},{"id":"1358780273769422849","name":"kelborhal78\\uD83C\\uDDFE\\uD83C\\uDDEA","username":"plaguemarine87"},{"id":"1741786039662813184","name":"Niniola`Art 4 u","username":"Niniola4u"},{"id":"368512817","name":"\xe1\xb5\x89\xe1\xb5\x8f\xe1\xb5\x89\xe1\xb5\x8f\xe1\xb5\x92","username":"ekeko_mtdc"},{"id":"3327232431","name":"badOdds","username":"b4dodds"},{"id":"1379669673206185990","name":"SIFT | \xe1\x9c\x83\xe1\x9c\x92\xe1\x9c\x87\xe1\x9c\x94\xe1\x9c\x8e\xe1\x9c\x86\xe1\x9c\x94","username":"siftcroix"},{"id":"1732000012597395456","name":"braindead.gif","username":"rightclickdead"},{"id":"1471144474629787656","name":"treeskulltown.tez/eth","username":"treeskulltown2"},{"id":"1444726992323104775","name":"SoulplayClayNFTs","username":"SoulplayClayNFT"},{"id":"1388842780970024968","name":"bonce","username":"bonabonce"},{"id":"1481542542546333698","name":"Green Ginger | \\uD83D\\uDFE2\\uD83E\\uDEDA\\uD83D\\uDCCC","username":"greenisginger"},{"id":"1436160020748570630","name":"unrealB0X","username":"unrealb0x"},{"id":"1453220233343287300","name":"B-exter","username":"B_DWIL"},{"id":"1610469503241945088","name":"Cryptol3mon_nft","username":"cryptol3mon_nft"},{"id":"1624083715780497410","name":"Lena Ekert \\uD83C\\uDF31","username":"BreathlesssAsh"},{"id":"1524483921114800128","name":"Xart_limonnft","username":"limonnft_art"},{"id":"1577313385615708160","name":"QR","username":"qr4gallery"},{"id":"1462798510433177601","name":"V\xc3\xadctor Arce \xe2\x9c\xb7 \\uD835\\uDCF5\\uD835\\uDD01\\uD835\\uDCFD\\uD835\\uDD01\\uD835\\uDCEC\\uD835\\uDD01 \\uD83C\\uDF10","username":"lxtxcx"},{"id":"1421021188730523651","name":"Ariuw \xd8\xa2\xd8\xb2\xd8\xa7\xd8\xaf\xdb\x8c","username":"AriuAzadi"},{"id":"1452857026229403650","name":"\\uD835\\uDFD9\\uD835\\uDFD8\\uD835\\uDFD8\\uD835\\uDFD8\\uD835\\uDD43\\uD835\\uDD52\\uD835\\uDD5F\\uD835\\uDD55\\uD835\\uDD6B \\uD83C\\uDFF4\xe2\x80\x8d\xe2\x98\xa0\xef\xb8\x8f\\uD83D\\uDC8E","username":"1000Landz"},{"id":"452384298","name":"warpcast is better - He/Him","username":"WhichWitchWasIt"},{"id":"150178720","name":"Martin Vanek","username":"Martinvanek"},{"id":"794412655146516480","name":"TULSI SH. KUMBHAR||tulsishankar.eth|| NFT.NYC2024","username":"TULSISHANKAR1"},{"id":"25153589","name":"Jundaboom","username":"Jundaboom"},{"id":"246220698","name":"Erdem Kuybulu","username":"ErdemKuybulu"},{"id":"4286792165","name":"Datura","username":"daturascore"},{"id":"1244047263137218560","name":"\\uD835\\uDCD3\\uD835\\uDCEA\\uD835\\uDCF2\\uD835\\uDCEA\\uD835\\uDCF7\\uD835\\uDCEA \\uD835\\uDCDB\\uD835\\uDCEA\\uD835\\uDD03\\uD835\\uDD03\\uD835\\uDCEA\\uD835\\uDCFB\\uD835\\uDCF2\\uD835\\uDCF7 #objkt4objkt","username":"daiana_lazzarin"},{"id":"1492628666739830795","name":"\\uD83C\\uDFAC 00:00:00:01","username":"OsipenkovNFTs"},{"id":"14172125","name":"\\uD83C\\uDD7E\\uD83C\\uDD7B\\uD83C\\uDD73\\uD83C\\uDD7E","username":"oldo"},{"id":"1774529585675194368","name":"Failure001","username":"001failure"},{"id":"3385290333","name":"Gaurav Rai | gauravrai.tez","username":"rai_nef"},{"id":"1363422527066931200","name":"Kx_","username":"Kx________"},{"id":"1656931309820715008","name":"Mrraval NFTs","username":"mrraval6677"},{"id":"1331678427523522560","name":"don\'t be so vasya \\uD83E\\uDEE0","username":"dontbesovasya"},{"id":"1515899384478720009","name":"Ermac Kiyani","username":"ErmacKiyani"},{"id":"1452027939759996928","name":"Rodicqart","username":"rodicqart"},{"id":"1603773806342033409","name":"AlenaArt_40","username":"AlenaArt_40"},{"id":"32970280","name":"Kika Nicolela","username":"kikanicolela"},{"id":"1573257117125025792","name":"GCakes | Joy City, Beijing OC 2023 NFT","username":"Cakes6G"},{"id":"1368365171236872193","name":"theurbanita\\uD83D\\uDCAB","username":"theurbanita"},{"id":"48564581","name":"Von Doyle","username":"VonDoyl"},{"id":"1235700080847486977","name":"Cindy","username":"CindyApples1984"},{"id":"1536757259476295681","name":"DTheLetterD","username":"DtheletterD"},{"id":"1662665145003245571","name":"Huemans of the Universe","username":"HuemansUniverse"},{"id":"1440041286778511360","name":"wwwombats","username":"wwwombats"},{"id":"63150251","name":"Andressa Furletti #TezQuakeAid","username":"a_tchuca"},{"id":"1175848670467678208","name":"Moonzi\\uD83C\\uDF19","username":"mo0n_zi"},{"id":"1065140892","name":"B.D.Vision","username":"behroozdaavari"},{"id":"1512880203185414154","name":"brasiltezos","username":"brasiltezos"},{"id":"1372177405683597319","name":"historicalive.tez","username":"historicalive"},{"id":"1189656610945286150","name":"Nihat Bay\xc4\xb1r","username":"Nhtbyr"},{"id":"1430220863505272837","name":"Skitchism","username":"skitchism"},{"id":"1474205982490349568","name":"Buctown MMA \\uD83E\\uDD4B\\uD83E\\uDD4A\\uD83E\\uDDE0\xe2\x9c\xa8\xef\xb8\x8f buctown.eth","username":"BuctownMMA"},{"id":"1169760066","name":"Nicole Ruggiero \\uD83D\\uDC69\xe2\x80\x8d\\uD83D\\uDCBB\\uD83C\\uDFA8","username":"_NicoleRuggiero"},{"id":"64583","name":"PixelSushiRobot \\uD83D\\uDCAB","username":"PixelSushiRobot"},{"id":"1720735649396133888","name":"Ophelia Karina - TEZ","username":"opheliart_Tez"},{"id":"462850404","name":"Fabrice","username":"aladwani13"},{"id":"1431642439094312961","name":"Arkain","username":"ArkainArt"},{"id":"62240213","name":"Ade Santora","username":"adesantora"},{"id":"1089491150","name":"L\'Inquisiteur","username":"BurnZeWitch"},{"id":"1500093887410495489","name":"p.i.x.e.l.l.a.r.e. \\uD83C\\uDF49","username":"_pixellare"},{"id":"822043263196680193","name":"Javier Montero","username":"javiermonttero"},{"id":"2332439312","name":"Ferdoropeza.eth/tez","username":"Ferdoropeza"},{"id":"202125279","name":"ssshihtung","username":"seeingsun"},{"id":"1436768213417840641","name":"\\uD835\\uDC0D\\uD835\\uDC08\\uD835\\uDC03\\uD835\\uDC19\\uD835\\uDC00\\uD835\\uDC11\\uD835\\uDC13","username":"nidzartt"},{"id":"907522967831117824","name":"\\uD83C\\uDF2EAkashi\\uD83C\\uDF2E","username":"akashitez"},{"id":"1397160357970460678","name":"Brian McAlister","username":"brianmca_"}]}'


2024-04-21 11:01:02,150 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,153 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,153 - DEBUG - max_retries: 8


2024-04-21 11:01:02,153 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107dc4a90>


2024-04-21 11:01:02,159 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,160 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,162 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,162 - DEBUG - max_retries: 8


2024-04-21 11:01:02,162 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107dc7640>


2024-04-21 11:01:02,166 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,167 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,169 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,169 - DEBUG - max_retries: 8


2024-04-21 11:01:02,169 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107df1a20>


2024-04-21 11:01:02,173 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,174 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,176 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,176 - DEBUG - max_retries: 8


2024-04-21 11:01:02,176 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107df35e0>


2024-04-21 11:01:02,179 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,180 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: April 11, 1954, was recorded as the most boring day in the world. \nStatistics show that no significant occurrences took place in the world.\n🌍 🥱 #Boring #Bored #April #World #Statistics #FunFacts\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,181 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: April 11, 1954, was recorded as the most boring day in the world. \nStatistics show that no significant occurrences took place in the world.\n🌍 🥱 #Boring #Bored #April #World #Statistics #FunFacts\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,181 - DEBUG - max_retries: 8


2024-04-21 11:01:02,181 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107df97e0>


2024-04-21 11:01:02,184 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: April 11, 1954, was recorded as the most boring day in the world. \nStatistics show that no significant occurrences took place in the world.\n🌍 🥱 #Boring #Bored #April #World #Statistics #FunFacts\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,184 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,185 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,185 - DEBUG - max_retries: 8


2024-04-21 11:01:02,186 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107df9210>


2024-04-21 11:01:02,188 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,189 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,190 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,190 - DEBUG - max_retries: 8


2024-04-21 11:01:02,190 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107df9630>


2024-04-21 11:01:02,193 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,193 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,194 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,194 - DEBUG - max_retries: 8


2024-04-21 11:01:02,194 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e30070>


2024-04-21 11:01:02,197 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,197 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,198 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,198 - DEBUG - max_retries: 8


2024-04-21 11:01:02,198 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e315a0>


2024-04-21 11:01:02,200 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,201 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,201 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,201 - DEBUG - max_retries: 8


2024-04-21 11:01:02,202 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e32740>


2024-04-21 11:01:02,204 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,204 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,205 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,205 - DEBUG - max_retries: 8


2024-04-21 11:01:02,205 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e33490>


2024-04-21 11:01:02,207 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,208 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,209 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,209 - DEBUG - max_retries: 8


2024-04-21 11:01:02,209 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e32ef0>


2024-04-21 11:01:02,212 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,212 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,213 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,213 - DEBUG - max_retries: 8


2024-04-21 11:01:02,213 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e33010>


2024-04-21 11:01:02,215 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,215 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,216 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,216 - DEBUG - max_retries: 8


2024-04-21 11:01:02,216 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e65780>


2024-04-21 11:01:02,218 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,219 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,219 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,219 - DEBUG - max_retries: 8


2024-04-21 11:01:02,219 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e65150>


2024-04-21 11:01:02,221 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,222 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,222 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,222 - DEBUG - max_retries: 8


2024-04-21 11:01:02,222 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e67820>


2024-04-21 11:01:02,225 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,225 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,226 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,226 - DEBUG - max_retries: 8


2024-04-21 11:01:02,226 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e88070>


2024-04-21 11:01:02,228 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,228 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,229 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,229 - DEBUG - max_retries: 8


2024-04-21 11:01:02,229 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e65060>


2024-04-21 11:01:02,231 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,231 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,232 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,232 - DEBUG - max_retries: 8


2024-04-21 11:01:02,232 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e89ed0>


2024-04-21 11:01:02,234 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,234 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,235 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,235 - DEBUG - max_retries: 8


2024-04-21 11:01:02,235 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e89b40>


2024-04-21 11:01:02,237 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,237 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,238 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,238 - DEBUG - max_retries: 8


2024-04-21 11:01:02,238 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e8be80>


2024-04-21 11:01:02,240 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,240 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,241 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,241 - DEBUG - max_retries: 8


2024-04-21 11:01:02,241 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ea4790>


2024-04-21 11:01:02,243 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,243 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,244 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,244 - DEBUG - max_retries: 8


2024-04-21 11:01:02,244 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ea4310>


2024-04-21 11:01:02,246 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,246 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,247 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,247 - DEBUG - max_retries: 8


2024-04-21 11:01:02,247 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ea6890>


2024-04-21 11:01:02,249 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,249 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,249 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,249 - DEBUG - max_retries: 8


2024-04-21 11:01:02,249 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ea7040>


2024-04-21 11:01:02,251 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,252 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,252 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,252 - DEBUG - max_retries: 8


2024-04-21 11:01:02,252 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ea5570>


2024-04-21 11:01:02,254 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,255 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,255 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,255 - DEBUG - max_retries: 8


2024-04-21 11:01:02,255 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ed0f40>


2024-04-21 11:01:02,257 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,258 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,258 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,258 - DEBUG - max_retries: 8


2024-04-21 11:01:02,258 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ed0bb0>


2024-04-21 11:01:02,260 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,260 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,261 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,261 - DEBUG - max_retries: 8


2024-04-21 11:01:02,261 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ed2ec0>


2024-04-21 11:01:02,263 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,263 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,264 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,264 - DEBUG - max_retries: 8


2024-04-21 11:01:02,264 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ed3790>


2024-04-21 11:01:02,266 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,266 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,267 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,267 - DEBUG - max_retries: 8


2024-04-21 11:01:02,267 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ea4160>


2024-04-21 11:01:02,269 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,270 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,270 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,270 - DEBUG - max_retries: 8


2024-04-21 11:01:02,270 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f093c0>


2024-04-21 11:01:02,272 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,273 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,273 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,273 - DEBUG - max_retries: 8


2024-04-21 11:01:02,273 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f09b70>


2024-04-21 11:01:02,275 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,276 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,276 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,276 - DEBUG - max_retries: 8


2024-04-21 11:01:02,276 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f0af20>


2024-04-21 11:01:02,278 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,279 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,279 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,279 - DEBUG - max_retries: 8


2024-04-21 11:01:02,279 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f0ba30>


2024-04-21 11:01:02,281 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,281 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,282 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,282 - DEBUG - max_retries: 8


2024-04-21 11:01:02,282 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f0aa40>


2024-04-21 11:01:02,284 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,284 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,285 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,285 - DEBUG - max_retries: 8


2024-04-21 11:01:02,285 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2d960>


2024-04-21 11:01:02,287 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,287 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,288 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,288 - DEBUG - max_retries: 8


2024-04-21 11:01:02,288 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2e110>


2024-04-21 11:01:02,290 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,290 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,291 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,291 - DEBUG - max_retries: 8


2024-04-21 11:01:02,291 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2f4c0>


2024-04-21 11:01:02,293 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,293 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,294 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,294 - DEBUG - max_retries: 8


2024-04-21 11:01:02,294 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121810070>


2024-04-21 11:01:02,296 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,296 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,297 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,297 - DEBUG - max_retries: 8


2024-04-21 11:01:02,297 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2f010>


2024-04-21 11:01:02,299 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,299 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,300 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,300 - DEBUG - max_retries: 8


2024-04-21 11:01:02,300 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121811f00>


2024-04-21 11:01:02,302 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,302 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,303 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,303 - DEBUG - max_retries: 8


2024-04-21 11:01:02,303 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218126b0>


2024-04-21 11:01:02,305 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,305 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,305 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,305 - DEBUG - max_retries: 8


2024-04-21 11:01:02,306 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121813a60>


2024-04-21 11:01:02,307 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,308 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,308 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,308 - DEBUG - max_retries: 8


2024-04-21 11:01:02,308 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12183c5b0>


2024-04-21 11:01:02,310 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,311 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,311 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,311 - DEBUG - max_retries: 8


2024-04-21 11:01:02,311 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12183c040>


2024-04-21 11:01:02,313 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,314 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,314 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,314 - DEBUG - max_retries: 8


2024-04-21 11:01:02,314 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12183e4a0>


2024-04-21 11:01:02,316 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,317 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,317 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,317 - DEBUG - max_retries: 8


2024-04-21 11:01:02,317 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12183ec50>


2024-04-21 11:01:02,319 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,319 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,320 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,320 - DEBUG - max_retries: 8


2024-04-21 11:01:02,320 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12183fcd0>


2024-04-21 11:01:02,322 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,322 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,323 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,323 - DEBUG - max_retries: 8


2024-04-21 11:01:02,323 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121870b80>


2024-04-21 11:01:02,325 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,325 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,326 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,326 - DEBUG - max_retries: 8


2024-04-21 11:01:02,326 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121871540>


2024-04-21 11:01:02,328 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,328 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,329 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,329 - DEBUG - max_retries: 8


2024-04-21 11:01:02,329 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218726b0>


2024-04-21 11:01:02,331 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,331 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,332 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,332 - DEBUG - max_retries: 8


2024-04-21 11:01:02,332 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121872e60>


2024-04-21 11:01:02,334 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,334 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,335 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,335 - DEBUG - max_retries: 8


2024-04-21 11:01:02,335 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121873eb0>


2024-04-21 11:01:02,337 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,337 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,338 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,338 - DEBUG - max_retries: 8


2024-04-21 11:01:02,338 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121898d60>


2024-04-21 11:01:02,340 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,340 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,341 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,341 - DEBUG - max_retries: 8


2024-04-21 11:01:02,341 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121898730>


2024-04-21 11:01:02,343 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,343 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,344 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,344 - DEBUG - max_retries: 8


2024-04-21 11:01:02,344 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12189ac50>


2024-04-21 11:01:02,346 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,346 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,347 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,347 - DEBUG - max_retries: 8


2024-04-21 11:01:02,347 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12189b400>


2024-04-21 11:01:02,349 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,349 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,350 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,350 - DEBUG - max_retries: 8


2024-04-21 11:01:02,350 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121898790>


2024-04-21 11:01:02,352 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,352 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,352 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,352 - DEBUG - max_retries: 8


2024-04-21 11:01:02,352 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bd300>


2024-04-21 11:01:02,354 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,355 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,355 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,355 - DEBUG - max_retries: 8


2024-04-21 11:01:02,355 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bcd30>


2024-04-21 11:01:02,357 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,358 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,358 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,358 - DEBUG - max_retries: 8


2024-04-21 11:01:02,358 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bf1f0>


2024-04-21 11:01:02,360 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,361 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,362 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,362 - DEBUG - max_retries: 8


2024-04-21 11:01:02,362 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bf9a0>


2024-04-21 11:01:02,364 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,364 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,365 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,365 - DEBUG - max_retries: 8


2024-04-21 11:01:02,365 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bcca0>


2024-04-21 11:01:02,367 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,367 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,368 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,368 - DEBUG - max_retries: 8


2024-04-21 11:01:02,368 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218e98a0>


2024-04-21 11:01:02,370 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,371 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,371 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,371 - DEBUG - max_retries: 8


2024-04-21 11:01:02,371 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218e92d0>


2024-04-21 11:01:02,373 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,374 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,374 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,374 - DEBUG - max_retries: 8


2024-04-21 11:01:02,374 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218eb790>


2024-04-21 11:01:02,377 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,377 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,378 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,378 - DEBUG - max_retries: 8


2024-04-21 11:01:02,378 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121918040>


2024-04-21 11:01:02,380 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,380 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,381 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,381 - DEBUG - max_retries: 8


2024-04-21 11:01:02,381 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218e9240>


2024-04-21 11:01:02,383 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,383 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,384 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,384 - DEBUG - max_retries: 8


2024-04-21 11:01:02,384 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121919e40>


2024-04-21 11:01:02,386 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,387 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,388 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,388 - DEBUG - max_retries: 8


2024-04-21 11:01:02,388 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12191ac20>


2024-04-21 11:01:02,390 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,391 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,391 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,392 - DEBUG - max_retries: 8


2024-04-21 11:01:02,392 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12191b970>


2024-04-21 11:01:02,394 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,394 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,395 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,395 - DEBUG - max_retries: 8


2024-04-21 11:01:02,395 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193c160>


2024-04-21 11:01:02,397 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,398 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,398 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,398 - DEBUG - max_retries: 8


2024-04-21 11:01:02,398 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12191bfd0>


2024-04-21 11:01:02,400 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,401 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,402 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,402 - DEBUG - max_retries: 8


2024-04-21 11:01:02,402 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193e020>


2024-04-21 11:01:02,404 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,404 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,405 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,405 - DEBUG - max_retries: 8


2024-04-21 11:01:02,405 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193d9f0>


2024-04-21 11:01:02,407 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,407 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,408 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,408 - DEBUG - max_retries: 8


2024-04-21 11:01:02,408 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196c070>


2024-04-21 11:01:02,410 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,411 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,412 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,412 - DEBUG - max_retries: 8


2024-04-21 11:01:02,412 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196c700>


2024-04-21 11:01:02,414 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,414 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,415 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,415 - DEBUG - max_retries: 8


2024-04-21 11:01:02,415 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196dae0>


2024-04-21 11:01:02,417 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,417 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,418 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,418 - DEBUG - max_retries: 8


2024-04-21 11:01:02,418 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196e5c0>


2024-04-21 11:01:02,420 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,421 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,421 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,421 - DEBUG - max_retries: 8


2024-04-21 11:01:02,421 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196e260>


2024-04-21 11:01:02,423 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,424 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,424 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,424 - DEBUG - max_retries: 8


2024-04-21 11:01:02,424 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219944f0>


2024-04-21 11:01:02,427 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,427 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,428 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,428 - DEBUG - max_retries: 8


2024-04-21 11:01:02,428 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121994ca0>


2024-04-21 11:01:02,430 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,430 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,431 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,431 - DEBUG - max_retries: 8


2024-04-21 11:01:02,431 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121996080>


2024-04-21 11:01:02,433 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,434 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,434 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,434 - DEBUG - max_retries: 8


2024-04-21 11:01:02,434 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121996b60>


2024-04-21 11:01:02,437 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,437 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,438 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,438 - DEBUG - max_retries: 8


2024-04-21 11:01:02,438 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121996800>


2024-04-21 11:01:02,440 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,440 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,441 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,441 - DEBUG - max_retries: 8


2024-04-21 11:01:02,441 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c0a90>


2024-04-21 11:01:02,443 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,443 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,444 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,444 - DEBUG - max_retries: 8


2024-04-21 11:01:02,444 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c1240>


2024-04-21 11:01:02,446 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,446 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,447 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,447 - DEBUG - max_retries: 8


2024-04-21 11:01:02,447 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c25f0>


2024-04-21 11:01:02,449 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,449 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,450 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,450 - DEBUG - max_retries: 8


2024-04-21 11:01:02,450 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c3100>


2024-04-21 11:01:02,452 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,452 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,453 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,453 - DEBUG - max_retries: 8


2024-04-21 11:01:02,453 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c2bf0>


2024-04-21 11:01:02,455 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,455 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,456 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,456 - DEBUG - max_retries: 8


2024-04-21 11:01:02,456 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219f8c70>


2024-04-21 11:01:02,458 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,459 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,460 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,460 - DEBUG - max_retries: 8


2024-04-21 11:01:02,460 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219f9420>


2024-04-21 11:01:02,462 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,462 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,463 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,463 - DEBUG - max_retries: 8


2024-04-21 11:01:02,463 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219fa7d0>


2024-04-21 11:01:02,466 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,466 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,467 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,467 - DEBUG - max_retries: 8


2024-04-21 11:01:02,467 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219fb2e0>


2024-04-21 11:01:02,469 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,469 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,470 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,470 - DEBUG - max_retries: 8


2024-04-21 11:01:02,470 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219fa8c0>


2024-04-21 11:01:02,472 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,473 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,473 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,473 - DEBUG - max_retries: 8


2024-04-21 11:01:02,473 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121b11210>


2024-04-21 11:01:02,476 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,476 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,477 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,477 - DEBUG - max_retries: 8


2024-04-21 11:01:02,477 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121b119c0>


2024-04-21 11:01:02,479 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,480 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,480 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,480 - DEBUG - max_retries: 8


2024-04-21 11:01:02,480 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121b12d70>


2024-04-21 11:01:02,482 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,483 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:02,484 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:02,484 - DEBUG - max_retries: 8


2024-04-21 11:01:02,484 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121b13880>


2024-04-21 11:01:02,486 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:02,486 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,486 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,486 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,487 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,487 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,487 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,487 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,487 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,487 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,487 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,488 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,489 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,489 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,489 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,489 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,490 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,490 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,490 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,490 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,490 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,490 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,491 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,491 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,491 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,491 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,491 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,491 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,492 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,492 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,492 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,492 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,493 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,493 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,493 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,493 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,493 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,493 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,494 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,494 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,494 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,494 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,495 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,495 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,495 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,495 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,495 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,495 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,496 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,496 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,496 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,496 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,497 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,497 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,497 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,498 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,498 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,498 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,498 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,499 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,499 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,499 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,499 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,499 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,500 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,500 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,500 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,501 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,501 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,501 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,501 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,501 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,502 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,502 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,502 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,502 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,502 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,502 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,503 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,504 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,504 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,504 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,504 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,504 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,505 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,505 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,505 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,505 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,505 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,506 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,506 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,506 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,506 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,507 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:02,510 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b132e0>


2024-04-21 11:01:02,511 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,511 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35510>


2024-04-21 11:01:02,511 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,511 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b13850>


2024-04-21 11:01:02,511 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,513 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b13340>


2024-04-21 11:01:02,513 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,514 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e30160>


2024-04-21 11:01:02,514 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,514 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b349a0>


2024-04-21 11:01:02,514 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,514 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b34c70>


2024-04-21 11:01:02,514 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35240>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121812170>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35210>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35ab0>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b13220>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb01f0>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,515 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb03d0>


2024-04-21 11:01:02,515 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,516 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb13f0>


2024-04-21 11:01:02,516 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,516 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1480>


2024-04-21 11:01:02,516 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,516 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b36050>


2024-04-21 11:01:02,516 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,516 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b36320>


2024-04-21 11:01:02,516 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,516 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b37010>


2024-04-21 11:01:02,516 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb0610>


2024-04-21 11:01:02,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb2650>


2024-04-21 11:01:02,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ea7910>


2024-04-21 11:01:02,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb3520>


2024-04-21 11:01:02,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb36a0>


2024-04-21 11:01:02,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,518 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193fb80>


2024-04-21 11:01:02,518 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,518 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5d0f0>


2024-04-21 11:01:02,518 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,519 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b105b0>


2024-04-21 11:01:02,519 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5d900>


2024-04-21 11:01:02,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,523 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5d420>


2024-04-21 11:01:02,523 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,524 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf9f60>


2024-04-21 11:01:02,524 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,524 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf9cc0>


2024-04-21 11:01:02,524 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,524 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf9a20>


2024-04-21 11:01:02,524 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,524 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bfa4a0>


2024-04-21 11:01:02,524 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,525 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5e6b0>


2024-04-21 11:01:02,525 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,525 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5ef20>


2024-04-21 11:01:02,525 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,525 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35a80>


2024-04-21 11:01:02,525 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5f1f0>


2024-04-21 11:01:02,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5f790>


2024-04-21 11:01:02,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121812f80>


2024-04-21 11:01:02,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b5f4c0>


2024-04-21 11:01:02,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,527 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35d50>


2024-04-21 11:01:02,527 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,543 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df2800>


2024-04-21 11:01:02,544 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e33be0>


2024-04-21 11:01:02,544 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df8b80>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e1f220>


2024-04-21 11:01:02,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e32320>


2024-04-21 11:01:02,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dfb2e0>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,545 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,545 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,545 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,545 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,546 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,546 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,546 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,546 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,546 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,546 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,546 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b8ccd0>


2024-04-21 11:01:02,546 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,546 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,546 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,547 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,547 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,547 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,547 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e1fac0>


2024-04-21 11:01:02,571 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e893f0>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e1f430>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e329b0>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e8b130>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e312d0>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e66500>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ea4ee0>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e88eb0>


2024-04-21 11:01:02,571 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e89a80>


2024-04-21 11:01:02,572 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ea5bd0>


2024-04-21 11:01:02,572 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df28c0>


2024-04-21 11:01:02,572 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e678e0>


2024-04-21 11:01:02,572 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ea7220>


2024-04-21 11:01:02,577 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,577 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ed0220>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e671c0>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ea6fe0>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ed2170>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e66d40>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e64e80>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ea7790>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ed3e80>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ed2a70>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2c1c0>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121810760>


2024-04-21 11:01:02,579 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f08f10>


2024-04-21 11:01:02,580 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ed2da0>


2024-04-21 11:01:02,580 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f0a2c0>


2024-04-21 11:01:02,580 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f08790>


2024-04-21 11:01:02,582 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,582 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,582 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,583 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,583 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,583 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,583 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,583 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,583 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,583 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,584 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,585 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,585 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2e800>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2dae0>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121812890>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2d7b0>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2cd00>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218112a0>


2024-04-21 11:01:02,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121811ae0>


2024-04-21 11:01:02,585 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b8d4e0>


2024-04-21 11:01:02,585 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,585 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b8e380>


2024-04-21 11:01:02,585 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,586 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c54d90>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b37a30>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,586 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b37160>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,586 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b37f40>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,586 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c555d0>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,586 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107982b30>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,586 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf86a0>


2024-04-21 11:01:02,586 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf8790>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb09a0>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c21570>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bfbbb0>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1660>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf86d0>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb0130>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,587 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,587 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,587 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb0640>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,587 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b37ac0>


2024-04-21 11:01:02,587 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,588 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,588 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb19c0>


2024-04-21 11:01:02,588 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,588 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,588 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,588 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1f60>


2024-04-21 11:01:02,588 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,588 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,588 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb2710>


2024-04-21 11:01:02,588 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,588 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,588 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,588 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b12830>


2024-04-21 11:01:02,588 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,588 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,588 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,589 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,589 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,590 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bdbd0>


2024-04-21 11:01:02,591 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,591 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,591 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,591 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,591 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,591 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,591 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1c90>


2024-04-21 11:01:02,591 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,591 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,591 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,591 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191bd90>


2024-04-21 11:01:02,591 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,591 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b12950>


2024-04-21 11:01:02,591 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb2230>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb3790>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb3070>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,592 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,592 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,592 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcc0d0>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193f430>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcc040>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b34c40>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,592 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b34970>


2024-04-21 11:01:02,592 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcc3a0>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c0d0>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c970>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2cf10>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,593 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c070>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b36a40>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c8b0>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,593 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2cd90>


2024-04-21 11:01:02,593 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,594 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,594 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c940>


2024-04-21 11:01:02,594 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,594 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2df90>


2024-04-21 11:01:02,594 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,594 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,594 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2cdc0>


2024-04-21 11:01:02,594 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,594 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2cee0>


2024-04-21 11:01:02,594 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,594 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d2a0>


2024-04-21 11:01:02,594 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,594 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2dc00>


2024-04-21 11:01:02,594 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,595 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,595 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2dab0>


2024-04-21 11:01:02,595 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d5d0>


2024-04-21 11:01:02,595 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b11420>


2024-04-21 11:01:02,595 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,595 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,595 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d720>


2024-04-21 11:01:02,595 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,595 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,595 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e830>


2024-04-21 11:01:02,595 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e6e0>


2024-04-21 11:01:02,595 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,595 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,595 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,595 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,596 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,596 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,596 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,596 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,596 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,596 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,596 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,596 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,596 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,596 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,596 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,596 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,597 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,597 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b34f10>


2024-04-21 11:01:02,597 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,597 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,597 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,597 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,597 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2ebc0>


2024-04-21 11:01:02,597 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,597 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2ed10>


2024-04-21 11:01:02,597 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:02,598 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,598 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,598 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,598 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,598 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,598 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12183d7e0>


2024-04-21 11:01:02,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218712d0>


2024-04-21 11:01:02,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,609 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,609 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,609 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,609 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,609 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,609 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,614 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121899f90>


2024-04-21 11:01:02,615 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,616 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218eaad0>


2024-04-21 11:01:02,616 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218be530>


2024-04-21 11:01:02,616 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219186d0>


2024-04-21 11:01:02,617 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,617 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,617 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,617 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,617 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,617 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e8070>


2024-04-21 11:01:02,617 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12183f340>


2024-04-21 11:01:02,620 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,620 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,620 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,620 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,620 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,620 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,620 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,620 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,620 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,620 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121812da0>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121872260>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bd8a0>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12183e9e0>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121870dc0>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121873550>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12183cd00>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bf520>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218994b0>


2024-04-21 11:01:02,621 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121870850>


2024-04-21 11:01:02,623 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,623 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,623 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,623 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,623 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,623 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,623 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,624 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,624 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,624 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,624 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189b040>


2024-04-21 11:01:02,624 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12183e920>


2024-04-21 11:01:02,624 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191bcd0>


2024-04-21 11:01:02,624 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191a530>


2024-04-21 11:01:02,624 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189baf0>


2024-04-21 11:01:02,624 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bda50>


2024-04-21 11:01:02,625 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,625 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,625 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,625 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,625 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,626 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,626 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,626 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e8ee0>


2024-04-21 11:01:02,626 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,626 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,627 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,627 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,627 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,627 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,627 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,627 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,627 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,627 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,628 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,628 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,628 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,631 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,631 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,631 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e9ff0>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193dc30>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193d780>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121919480>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196ee90>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c1990>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193df90>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121997250>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218ebb80>


2024-04-21 11:01:02,632 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196c5b0>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,638 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193da50>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191bb50>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b12290>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121994040>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193c8b0>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196dff0>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b11870>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c30a0>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196ecb0>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121996740>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121997d90>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219953f0>


2024-04-21 11:01:02,639 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b113f0>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c2170>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c37f0>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196f7f0>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219fb9d0>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219f9b70>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c0670>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b343d0>


2024-04-21 11:01:02,640 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b10df0>


2024-04-21 11:01:02,640 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,640 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,641 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,641 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,642 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,643 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,643 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,643 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,643 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,643 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219f8640>


2024-04-21 11:01:02,643 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,643 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,644 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,644 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,644 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,645 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,645 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,645 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,645 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,646 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,646 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,647 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,647 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:02,647 - DEBUG - send_request_headers.complete


2024-04-21 11:01:02,647 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:02,647 - DEBUG - send_request_body.complete


2024-04-21 11:01:02,647 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:03,163 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4977'), (b'x-ratelimit-remaining-tokens', b'596186'), (b'x-ratelimit-reset-requests', b'267ms'), (b'x-ratelimit-reset-tokens', b'381ms'), (b'x-request-id', b'req_de7920301b52e7b40f3eb884f406f2a8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4bdf7d5c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,164 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,164 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,164 - DEBUG - response_closed.started


2024-04-21 11:01:03,164 - DEBUG - response_closed.complete


2024-04-21 11:01:03,164 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,165 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoc42VXJhpmXtoVSrTwuiwBM3F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_j2Iis23lC3KEk7110WSwsHPn', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,165 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,166 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'598933'), (b'x-ratelimit-reset-requests', b'82ms'), (b'x-ratelimit-reset-tokens', b'106ms'), (b'x-request-id', b'req_b215ebfe7787bac889b0c8a46084fa19'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef0d4f8400-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,166 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,166 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,166 - DEBUG - response_closed.started


2024-04-21 11:01:03,166 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4997'), (b'x-ratelimit-remaining-tokens', b'599544'), (b'x-ratelimit-reset-requests', b'32ms'), (b'x-ratelimit-reset-tokens', b'45ms'), (b'x-request-id', b'req_a51b81d8ba876ab632cafda4e280faa9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef0f615251-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,166 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,167 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,167 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,167 - DEBUG - response_closed.started


2024-04-21 11:01:03,167 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'442'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'598829'), (b'x-ratelimit-reset-requests', b'75ms'), (b'x-ratelimit-reset-tokens', b'117ms'), (b'x-request-id', b'req_4db7d7093799c615f6e6034dd73a99a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3c7628fc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,167 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,167 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,167 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,167 - DEBUG - response_closed.started


2024-04-21 11:01:03,167 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'441'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4976'), (b'x-ratelimit-remaining-tokens', b'595889'), (b'x-ratelimit-reset-requests', b'284ms'), (b'x-ratelimit-reset-tokens', b'411ms'), (b'x-request-id', b'req_d178245f42af8e00df71ca91d14ead92'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4f75100b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,167 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,168 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,168 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,168 - DEBUG - response_closed.started


2024-04-21 11:01:03,168 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'460'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4978'), (b'x-ratelimit-remaining-tokens', b'596435'), (b'x-ratelimit-reset-requests', b'255ms'), (b'x-ratelimit-reset-tokens', b'356ms'), (b'x-request-id', b'req_87f96e618185a4495d1de852f229bc6f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4ff97c89-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,168 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,168 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,168 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,168 - DEBUG - response_closed.started


2024-04-21 11:01:03,168 - DEBUG - response_closed.complete


2024-04-21 11:01:03,169 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,169 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmodyszrFAaUht0y1D6uVAjLiin', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bUNThCv3liZbqyGSL81dHDB1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,169 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,169 - DEBUG - response_closed.complete


2024-04-21 11:01:03,169 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,170 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo4PaxEdm2hi1ldYzHyZqOm0b1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_oHQB4FYW3e7qqB37vXXW1uNq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,170 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,170 - DEBUG - response_closed.complete


2024-04-21 11:01:03,170 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,170 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo3mai9X3iFf64VzQRb0uHpHSf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BZovyLRDFG0edqEN3luq7dvv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,171 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,171 - DEBUG - response_closed.complete


2024-04-21 11:01:03,171 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,171 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoXIdrUHixE6GQMxyPdrVvQWzC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0oW71aLB2HqMeA7p3WgN6v7e', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=224, total_tokens=229))


2024-04-21 11:01:03,171 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,171 - DEBUG - response_closed.complete


2024-04-21 11:01:03,172 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,172 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoeORD75EiyywRvqAyCpeEPsVs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lrYRoaiGAiRBi0yQeX0Mcif6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,172 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,172 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4953'), (b'x-ratelimit-remaining-tokens', b'591983'), (b'x-ratelimit-reset-requests', b'563ms'), (b'x-ratelimit-reset-tokens', b'801ms'), (b'x-request-id', b'req_bb482b3a2ceab4af881805540597df7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8fb92aa6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,173 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,173 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,173 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,173 - DEBUG - response_closed.started


2024-04-21 11:01:03,173 - DEBUG - response_closed.complete


2024-04-21 11:01:03,173 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,173 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmojlmTAswZInVuNybRvjsq8uyz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_tf0Ocpso1k4M7IA37yPkuySa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,174 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,174 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'464'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4965'), (b'x-ratelimit-remaining-tokens', b'594154'), (b'x-ratelimit-reset-requests', b'408ms'), (b'x-ratelimit-reset-tokens', b'584ms'), (b'x-request-id', b'req_2004e058aa45cacf506b2cdcd4fa2ca7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4e8108d3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,174 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,174 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,174 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,174 - DEBUG - response_closed.started


2024-04-21 11:01:03,174 - DEBUG - response_closed.complete


2024-04-21 11:01:03,175 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,175 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo1RzplpR9auRwbabky66ev8SB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_p164XIsi89SNxwnovePRsdiT', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,175 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,175 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4933'), (b'x-ratelimit-remaining-tokens', b'588664'), (b'x-ratelimit-reset-requests', b'795ms'), (b'x-ratelimit-reset-tokens', b'1.133s'), (b'x-request-id', b'req_aea31cdd56174d2802aa7e1b726f1655'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9bcf5361-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,175 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,175 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,175 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,176 - DEBUG - response_closed.started


2024-04-21 11:01:03,176 - DEBUG - response_closed.complete


2024-04-21 11:01:03,176 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,176 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmos99yfyilL5CsAhE2xfKca2xy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_WrFKDD36U4NXucqjBbR7ZQMD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,176 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,194 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'491'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4970'), (b'x-ratelimit-remaining-tokens', b'594879'), (b'x-ratelimit-reset-requests', b'354ms'), (b'x-ratelimit-reset-tokens', b'512ms'), (b'x-request-id', b'req_37fd9952be299f5467db4d65fa1881ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef5b480fdb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,194 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,195 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,195 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,195 - DEBUG - response_closed.started


2024-04-21 11:01:03,195 - DEBUG - response_closed.complete


2024-04-21 11:01:03,195 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,196 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmokmyt83bUipzk0KWBuRBavkhe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wz5Y7bBp0A2TQZbkhc94GTLq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,196 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,206 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'465'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4950'), (b'x-ratelimit-remaining-tokens', b'591491'), (b'x-ratelimit-reset-requests', b'594ms'), (b'x-ratelimit-reset-tokens', b'850ms'), (b'x-request-id', b'req_fc2e630b0400d5d31e412e8140689629'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8bf3db59-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,206 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,206 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,206 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,206 - DEBUG - response_closed.started


2024-04-21 11:01:03,206 - DEBUG - response_closed.complete


2024-04-21 11:01:03,207 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,207 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoEJlUST9peQtlqVoEfiHBBDhR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UxVH0sn46Et3d5CioambkasB', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,207 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,212 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'451'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4912'), (b'x-ratelimit-remaining-tokens', b'585144'), (b'x-ratelimit-reset-requests', b'1.048s'), (b'x-ratelimit-reset-tokens', b'1.485s'), (b'x-request-id', b'req_e59f5671e79fcb4b106b21257fdd92a6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef99bb318b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,212 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,212 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,212 - DEBUG - response_closed.started


2024-04-21 11:01:03,212 - DEBUG - response_closed.complete


2024-04-21 11:01:03,213 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,213 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoomte6Qp3yixyve4M7RbZYXuE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_2QAR5oZYmzjBRdIMXEKWr7cs', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,213 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,214 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'435'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599268'), (b'x-ratelimit-reset-requests', b'44ms'), (b'x-ratelimit-reset-tokens', b'73ms'), (b'x-request-id', b'req_a759419cd638c9f28a00891dd1904dfe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef0b4a0fb8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,215 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,215 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,215 - DEBUG - response_closed.started


2024-04-21 11:01:03,215 - DEBUG - response_closed.complete


2024-04-21 11:01:03,216 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,216 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoWzVqV2YlWS2exQNNP8USPIAi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_SRXS8fV5YS8RLt6zOnSlUsIg', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,216 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,218 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'473'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4941'), (b'x-ratelimit-remaining-tokens', b'589938'), (b'x-ratelimit-reset-requests', b'704ms'), (b'x-ratelimit-reset-tokens', b'1.006s'), (b'x-request-id', b'req_813a9358b8ded41714d1deeb7fdfc011'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9e747c59-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,218 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,218 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,218 - DEBUG - response_closed.started


2024-04-21 11:01:03,218 - DEBUG - response_closed.complete


2024-04-21 11:01:03,219 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,219 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoKi7FNKEsGqNDX6whtxncBraR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_iCnls6VPhNXW7UC3MkQWUbsp', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,219 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,219 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'456'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4926'), (b'x-ratelimit-remaining-tokens', b'587388'), (b'x-ratelimit-reset-requests', b'887ms'), (b'x-ratelimit-reset-tokens', b'1.261s'), (b'x-request-id', b'req_846a75812b7fa1c33b3b4af2fa23fe0d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9d352f26-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,219 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,219 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,220 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,220 - DEBUG - response_closed.started


2024-04-21 11:01:03,220 - DEBUG - response_closed.complete


2024-04-21 11:01:03,220 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,221 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmohGROvlDqbXva1cBf469noiqm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kolxqcU3Iu2fh1AITAduTUyV', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,221 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,223 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'431'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598574'), (b'x-ratelimit-reset-requests', b'91ms'), (b'x-ratelimit-reset-tokens', b'142ms'), (b'x-request-id', b'req_90da39d1d80365cbb81a37bb8b18eced'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3c331031-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,223 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,223 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,223 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,223 - DEBUG - response_closed.started


2024-04-21 11:01:03,223 - DEBUG - response_closed.complete


2024-04-21 11:01:03,224 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,224 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo5FBblkGbgEyxTfxrrIh3QHej', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UOCpd353cIl2sRUbjiEkdmvx', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,224 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,224 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'472'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4939'), (b'x-ratelimit-remaining-tokens', b'589571'), (b'x-ratelimit-reset-requests', b'727ms'), (b'x-ratelimit-reset-tokens', b'1.042s'), (b'x-request-id', b'req_bfc2cc68118d3d8c832b8f3d038b3430'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef98c90ffb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,225 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,225 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,225 - DEBUG - response_closed.started


2024-04-21 11:01:03,225 - DEBUG - response_closed.complete


2024-04-21 11:01:03,226 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,226 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoC2YgHXO3jcZUxvl69uDFUoe4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_2bVWeFQSBQrLR7v583JygURH', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,226 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,228 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4940'), (b'x-ratelimit-remaining-tokens', b'589770'), (b'x-ratelimit-reset-requests', b'716ms'), (b'x-ratelimit-reset-tokens', b'1.022s'), (b'x-request-id', b'req_d149833eda54396e8db3df567eb62ff6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9def52bf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,228 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,228 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,229 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,229 - DEBUG - response_closed.started


2024-04-21 11:01:03,229 - DEBUG - response_closed.complete


2024-04-21 11:01:03,230 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,230 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo7TVVb6zoJe6VxOCRTVG13AFC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3cGqI8XAgDPEgmtUQcxSzYUY', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,230 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,230 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'462'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4915'), (b'x-ratelimit-remaining-tokens', b'585722'), (b'x-ratelimit-reset-requests', b'1.013s'), (b'x-ratelimit-reset-tokens', b'1.427s'), (b'x-request-id', b'req_a574b98e13e3cde4657f3c15d707dda2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efa9d82f7b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,230 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,231 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,231 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,231 - DEBUG - response_closed.started


2024-04-21 11:01:03,231 - DEBUG - response_closed.complete


2024-04-21 11:01:03,232 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,232 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmopvN2sZ8xpR79cYTeRNcq0zxR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zXUAiv8zuznFGcOOIERmOCtZ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,232 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,233 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'468'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4918'), (b'x-ratelimit-remaining-tokens', b'586081'), (b'x-ratelimit-reset-requests', b'982ms'), (b'x-ratelimit-reset-tokens', b'1.391s'), (b'x-request-id', b'req_168f17f26637d5968fc032a88ef5c57b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efaeef2a97-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,233 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,233 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,234 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,234 - DEBUG - response_closed.started


2024-04-21 11:01:03,234 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4943'), (b'x-ratelimit-remaining-tokens', b'590273'), (b'x-ratelimit-reset-requests', b'680ms'), (b'x-ratelimit-reset-tokens', b'972ms'), (b'x-request-id', b'req_af735f3f2c6503d123c3332144d15cbc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9e277e8e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,234 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,234 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,234 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,234 - DEBUG - response_closed.started


2024-04-21 11:01:03,234 - DEBUG - response_closed.complete


2024-04-21 11:01:03,235 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,236 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoLDHRiOSLTwTD7pFbqSxsc5Gc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_j9W9TNKppDmyxorPlPPICtMP', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,236 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,236 - DEBUG - response_closed.complete


2024-04-21 11:01:03,237 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,237 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoJtZjMpMbK6bW2vLJMF4tLspm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_C7gL719zLP4JLnzEnOze4ThS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,237 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,241 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'432'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4984'), (b'x-ratelimit-remaining-tokens', b'597347'), (b'x-ratelimit-reset-requests', b'182ms'), (b'x-ratelimit-reset-tokens', b'265ms'), (b'x-request-id', b'req_2c3aa3a1cb6023f22457ee8c6d7b52b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4cc60fbe-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,241 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,241 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,241 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,241 - DEBUG - response_closed.started


2024-04-21 11:01:03,241 - DEBUG - response_closed.complete


2024-04-21 11:01:03,242 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,242 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmorsuHbjW34hOOpo2WAszrJOK1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_auevcPpNS7otYcI6T4p5jmaq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,243 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,243 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'540'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'598933'), (b'x-ratelimit-reset-requests', b'69ms'), (b'x-ratelimit-reset-tokens', b'106ms'), (b'x-request-id', b'req_22d01af4172c2309b61fb229cf307e42'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3c6e7d6a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,243 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,243 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,243 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,243 - DEBUG - response_closed.started


2024-04-21 11:01:03,243 - DEBUG - response_closed.complete


2024-04-21 11:01:03,244 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,244 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmod5HQZWe9STWVODNGhtsn6eak', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CDk65lQFwYDGlECgZyh2b7pd', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,245 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,264 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4966'), (b'x-ratelimit-remaining-tokens', b'594126'), (b'x-ratelimit-reset-requests', b'407ms'), (b'x-ratelimit-reset-tokens', b'587ms'), (b'x-request-id', b'req_674c6fb09de71e19d1ada07a3dd17761'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4a932b61-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,264 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,264 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,264 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,264 - DEBUG - response_closed.started


2024-04-21 11:01:03,264 - DEBUG - response_closed.complete


2024-04-21 11:01:03,266 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,266 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoB2KnOvdOOxDp0AkJ1G5H3DoJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3LAme8J21m2tkJOaEHdHETR5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,266 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,276 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4984'), (b'x-ratelimit-remaining-tokens', b'597215'), (b'x-ratelimit-reset-requests', b'191ms'), (b'x-ratelimit-reset-tokens', b'278ms'), (b'x-request-id', b'req_e3fc21bb6ae4e0f74f627b1244f78cb9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4e057c9e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,276 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,276 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,276 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,277 - DEBUG - response_closed.started


2024-04-21 11:01:03,277 - DEBUG - response_closed.complete


2024-04-21 11:01:03,278 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,278 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoCafcgAUQUY49JqVTKH72ZT5P', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_42gKob7vHBWwkN333FMJJQ9B', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,278 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,278 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'514'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4936'), (b'x-ratelimit-remaining-tokens', b'589142'), (b'x-ratelimit-reset-requests', b'761ms'), (b'x-ratelimit-reset-tokens', b'1.085s'), (b'x-request-id', b'req_73082ba1fc4f6d16043b3615425026e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9f9d7ebf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,279 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,279 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,279 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,279 - DEBUG - response_closed.started


2024-04-21 11:01:03,279 - DEBUG - response_closed.complete


2024-04-21 11:01:03,280 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,280 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoptyBBUbVn8vx1SljvnnZxMZN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_koCQTbyGzmJhtnFhFFceFylv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,280 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,281 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'585'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4990'), (b'x-ratelimit-remaining-tokens', b'598304'), (b'x-ratelimit-reset-requests', b'114ms'), (b'x-ratelimit-reset-tokens', b'169ms'), (b'x-request-id', b'req_8b04859b6b27b03f00582ecf49ed7197'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3d4f2a91-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,281 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,281 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,281 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,281 - DEBUG - response_closed.started


2024-04-21 11:01:03,281 - DEBUG - response_closed.complete


2024-04-21 11:01:03,282 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,282 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoFrbvT4FKhM7uoS22yDVl4glz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Camfo6GeDwIWurCgXZJPVYJb', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,283 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,284 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'453'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4964'), (b'x-ratelimit-remaining-tokens', b'593861'), (b'x-ratelimit-reset-requests', b'429ms'), (b'x-ratelimit-reset-tokens', b'613ms'), (b'x-request-id', b'req_5f1f70bed35d3ba0124f557acd7f21f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef38d52f70-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,284 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,284 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,285 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,285 - DEBUG - response_closed.started


2024-04-21 11:01:03,285 - DEBUG - response_closed.complete


2024-04-21 11:01:03,286 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,286 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoBRtcTKsNbFomDvPS7gY9EOXA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UHWl2ql1BYFY7lBvtoXlspGh', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,286 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,286 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'511'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599368'), (b'x-ratelimit-reset-requests', b'43ms'), (b'x-ratelimit-reset-tokens', b'63ms'), (b'x-request-id', b'req_6379d6640a00b698ff29eac56b01e773'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef0d122b85-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,287 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,287 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,287 - DEBUG - response_closed.started


2024-04-21 11:01:03,287 - DEBUG - response_closed.complete


2024-04-21 11:01:03,288 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,288 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoYYNWstn4hJ5i0DN2Y57pEMiV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bcB16DwEhHyATZwiNYCpqU2B', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=224, total_tokens=229))


2024-04-21 11:01:03,289 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,311 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'438'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4947'), (b'x-ratelimit-remaining-tokens', b'591015'), (b'x-ratelimit-reset-requests', b'628ms'), (b'x-ratelimit-reset-tokens', b'898ms'), (b'x-request-id', b'req_1c42822079c215d6fdd5ec078df6d7e0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef7e0a7c6e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,311 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,311 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,311 - DEBUG - response_closed.started


2024-04-21 11:01:03,311 - DEBUG - response_closed.complete


2024-04-21 11:01:03,313 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,313 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmotTcXfs8PBSG6heE4KbTGRb4G', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_V3n3D8blmUWuHS9lTLrVUnx0', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,313 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,314 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4963'), (b'x-ratelimit-remaining-tokens', b'593750'), (b'x-ratelimit-reset-requests', b'435ms'), (b'x-ratelimit-reset-tokens', b'624ms'), (b'x-request-id', b'req_6ba2ce74876bf01e5cc3a80649d6135e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef5cf70fdd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,314 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,314 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,315 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,315 - DEBUG - response_closed.started


2024-04-21 11:01:03,315 - DEBUG - response_closed.complete


2024-04-21 11:01:03,316 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,316 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoFvaLxWbwvnohp1CPBdUdZHqb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0j6NsLwAUINYuJVsbOJJBukF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,316 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,318 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4930'), (b'x-ratelimit-remaining-tokens', b'588179'), (b'x-ratelimit-reset-requests', b'830ms'), (b'x-ratelimit-reset-tokens', b'1.182s'), (b'x-request-id', b'req_98d517b98670f4bea0cd21f0f9e2d3bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef99897d59-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,319 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,319 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,319 - DEBUG - response_closed.started


2024-04-21 11:01:03,319 - DEBUG - response_closed.complete


2024-04-21 11:01:03,320 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,321 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoNr8PIfNJdIuqyf8nrfoGeRd9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fNRvnZ6rfnfuLeqsltId3CRo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,321 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,321 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'534'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'597995'), (b'x-ratelimit-reset-requests', b'135ms'), (b'x-ratelimit-reset-tokens', b'200ms'), (b'x-request-id', b'req_d2464e30d40c017447eefd5750d46aad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef390f08f8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,321 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,321 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,321 - DEBUG - response_closed.started


2024-04-21 11:01:03,321 - DEBUG - response_closed.complete


2024-04-21 11:01:03,323 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,323 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmotzsA4e1qkhHfBQs9TYA4wCVA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_hfKsQRR5wVk88WVldMkfWRp1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,323 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,330 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'660'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599835'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'16ms'), (b'x-request-id', b'req_ca515eb235c2f7c6bbee4a2b3463631b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef0f78102d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,330 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,330 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,330 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,330 - DEBUG - response_closed.started


2024-04-21 11:01:03,330 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'504'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4960'), (b'x-ratelimit-remaining-tokens', b'593254'), (b'x-ratelimit-reset-requests', b'471ms'), (b'x-ratelimit-reset-tokens', b'674ms'), (b'x-request-id', b'req_ec8998fcdbd409c0dbb3c7ca0463f4b7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef7f827ce5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,331 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,331 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,331 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,331 - DEBUG - response_closed.started


2024-04-21 11:01:03,331 - DEBUG - response_closed.complete


2024-04-21 11:01:03,332 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,333 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo5VmvD0ksTAklbtNZB6hGLzxt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NZVw3ZqxFYcxYRmCbG1KpO5C', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,333 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,333 - DEBUG - response_closed.complete


2024-04-21 11:01:03,334 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,335 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmovB5iTiHgoFmqCwzV8QoNsZsG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_XFfYF1YkKY6BrXLBaOasBslK', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,335 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,335 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'624'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4979'), (b'x-ratelimit-remaining-tokens', b'596597'), (b'x-ratelimit-reset-requests', b'244ms'), (b'x-ratelimit-reset-tokens', b'340ms'), (b'x-request-id', b'req_15ef7efadeaf68ba4c00876cf541cdd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4b260d0c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,335 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,335 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,335 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,335 - DEBUG - response_closed.started


2024-04-21 11:01:03,335 - DEBUG - response_closed.complete


2024-04-21 11:01:03,337 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,337 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo8sME2TEX1zCxleS3dMTWfXfR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VTmcATYNIbMnQJb26J5NiCeu', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,337 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,349 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'543'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4966'), (b'x-ratelimit-remaining-tokens', b'594294'), (b'x-ratelimit-reset-requests', b'399ms'), (b'x-ratelimit-reset-tokens', b'570ms'), (b'x-request-id', b'req_0fe1e379c79ff91d8906063b062bd13d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef5ec569aa-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,349 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,349 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,349 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,349 - DEBUG - response_closed.started


2024-04-21 11:01:03,349 - DEBUG - response_closed.complete


2024-04-21 11:01:03,351 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,351 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmobEIh1e31jAJwG6z3E5Qg59mC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fPN6TuaD0CAdNvJxWk5IlsAX', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,351 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,355 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'641'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4980'), (b'x-ratelimit-remaining-tokens', b'596570'), (b'x-ratelimit-reset-requests', b'237ms'), (b'x-ratelimit-reset-tokens', b'342ms'), (b'x-request-id', b'req_69bc3dd115b0e739225b4970eb9ea53d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4ac57cf7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,355 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,355 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,355 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,355 - DEBUG - response_closed.started


2024-04-21 11:01:03,355 - DEBUG - response_closed.complete


2024-04-21 11:01:03,357 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,357 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmov8zpF0rgRSPxrEui6vNvgVmT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OzDSwdetJjNoFi7zoKUOAdu5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,357 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,357 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'640'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4978'), (b'x-ratelimit-remaining-tokens', b'596342'), (b'x-ratelimit-reset-requests', b'256ms'), (b'x-ratelimit-reset-tokens', b'365ms'), (b'x-request-id', b'req_f34354f5b7987be803954a8a96ba192d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4b092ec6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,357 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,357 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,357 - DEBUG - response_closed.started


2024-04-21 11:01:03,358 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'491'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'585471'), (b'x-ratelimit-reset-requests', b'1.029s'), (b'x-ratelimit-reset-tokens', b'1.452s'), (b'x-request-id', b'req_5c119e698fcfffd80c7cd728c31ea521'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef98d30ffd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,358 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,358 - DEBUG - response_closed.started


2024-04-21 11:01:03,358 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'636'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4967'), (b'x-ratelimit-remaining-tokens', b'594486'), (b'x-ratelimit-reset-requests', b'384ms'), (b'x-ratelimit-reset-tokens', b'551ms'), (b'x-request-id', b'req_d20109dbd182b90ae7799fea26e1e1dd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef5b56dbd1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,358 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,358 - DEBUG - response_closed.started


2024-04-21 11:01:03,358 - DEBUG - response_closed.complete


2024-04-21 11:01:03,360 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,360 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoEC2xc9dih3CR31XzdptG1Gjp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aALlYzLKLiWkGvgzZ4Rjpjqa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,361 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,361 - DEBUG - response_closed.complete


2024-04-21 11:01:03,362 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,363 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmopQ1FE8G8U6EzU9miwxpaSQTn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_WJA4Oyw3XWALbibGceQdMetF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,363 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,363 - DEBUG - response_closed.complete


2024-04-21 11:01:03,365 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,365 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoXMeS1UKCWdpjkNiLjaIi3FHu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jPfu6q8OI7WCwpMJIUTgoBLo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,365 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,366 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'557'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4974'), (b'x-ratelimit-remaining-tokens', b'595578'), (b'x-ratelimit-reset-requests', b'307ms'), (b'x-ratelimit-reset-tokens', b'442ms'), (b'x-request-id', b'req_671841b080bb3e9746771da7b27f9041'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4f5c0fe9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,366 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,366 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,366 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,366 - DEBUG - response_closed.started


2024-04-21 11:01:03,366 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'564'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4973'), (b'x-ratelimit-remaining-tokens', b'595416'), (b'x-ratelimit-reset-requests', b'318ms'), (b'x-ratelimit-reset-tokens', b'458ms'), (b'x-request-id', b'req_307468cc1da1491d11b5f38ffe3cd686'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4c3c1031-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,366 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,366 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,367 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,367 - DEBUG - response_closed.started


2024-04-21 11:01:03,367 - DEBUG - response_closed.complete


2024-04-21 11:01:03,369 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,370 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmowTyh06K1Tl4sOQCdmpQbQw6J', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_s61BP3MZOg6tWCXYtau5Q1D1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,370 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,370 - DEBUG - response_closed.complete


2024-04-21 11:01:03,372 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,372 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmof9U1ajtwvXIeR1ylRVItWKmw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dNzOSQvkHAqUnQDkXeD8sYaU', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,372 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,373 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'505'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4934'), (b'x-ratelimit-remaining-tokens', b'588826'), (b'x-ratelimit-reset-requests', b'784ms'), (b'x-ratelimit-reset-tokens', b'1.117s'), (b'x-request-id', b'req_4a32bac669f778c6641d292ceca5e602'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efae7b7c3d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,373 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,373 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,373 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,373 - DEBUG - response_closed.started


2024-04-21 11:01:03,373 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4944'), (b'x-ratelimit-remaining-tokens', b'590432'), (b'x-ratelimit-reset-requests', b'668ms'), (b'x-ratelimit-reset-tokens', b'956ms'), (b'x-request-id', b'req_32a3c5677d24155928bfce4815f7555d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9bae7ee9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,373 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,373 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,373 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,373 - DEBUG - response_closed.started


2024-04-21 11:01:03,374 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'500'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4916'), (b'x-ratelimit-remaining-tokens', b'585764'), (b'x-ratelimit-reset-requests', b'1.004s'), (b'x-ratelimit-reset-tokens', b'1.423s'), (b'x-request-id', b'req_f5010d5aca5fa681e2ceb72a2479b308'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efabd27c6b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,374 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,374 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,374 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,374 - DEBUG - response_closed.started


2024-04-21 11:01:03,374 - DEBUG - response_closed.complete


2024-04-21 11:01:03,376 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,376 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo1VbD8b9Yy7KN6WGQUZcMf35g', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fnjDZHHHkkiZi88CZL5cmu6V', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,376 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,376 - DEBUG - response_closed.complete


2024-04-21 11:01:03,378 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,378 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoMgqV4sJ4nLFiAqUkEiTLtOTW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_XRMTIFjdeaj9wOLRAYYAK0k7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,378 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,378 - DEBUG - response_closed.complete


2024-04-21 11:01:03,380 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,380 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoEB5jjpxsHaUoo0MA5egWJEuD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_sJWP7Ql3RNg8OMOZ9DxjWuWZ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,381 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,381 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'679'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4989'), (b'x-ratelimit-remaining-tokens', b'598154'), (b'x-ratelimit-reset-requests', b'124ms'), (b'x-ratelimit-reset-tokens', b'184ms'), (b'x-request-id', b'req_eaa7bf991809d205d76b37bdda46f343'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3f57dbb6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,381 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,381 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,381 - DEBUG - response_closed.started


2024-04-21 11:01:03,381 - DEBUG - response_closed.complete


2024-04-21 11:01:03,383 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,383 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmozU8ya3RBXWrgR1Fb4pmrQsJ3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ulNIcyLYW5r6CN9tFn38GAxa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,383 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,383 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'686'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597499'), (b'x-ratelimit-reset-requests', b'172ms'), (b'x-ratelimit-reset-tokens', b'250ms'), (b'x-request-id', b'req_977b73205efe859ad890c6f4ce84de77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3f9b0fb7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,384 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,384 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,384 - DEBUG - response_closed.started


2024-04-21 11:01:03,384 - DEBUG - response_closed.complete


2024-04-21 11:01:03,386 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,386 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoNFg2Glm1KR2akDKNcGFdEZkx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BX5F0cNOPrcuNwwszVGYqN6e', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,386 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,411 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'535'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'586823'), (b'x-ratelimit-reset-requests', b'930ms'), (b'x-ratelimit-reset-tokens', b'1.317s'), (b'x-request-id', b'req_119780a40e1ae2689130dc3a861df6ba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efab8b2f7a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,412 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,412 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,412 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,412 - DEBUG - response_closed.started


2024-04-21 11:01:03,412 - DEBUG - response_closed.complete


2024-04-21 11:01:03,414 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,414 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmovrKpp6RckVRrHTfjhGi3ohVq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lCRXvSu4TOjYRuQOScSTiyrz', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,414 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,422 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'585387'), (b'x-ratelimit-reset-requests', b'1.029s'), (b'x-ratelimit-reset-tokens', b'1.461s'), (b'x-request-id', b'req_c5ad83de68c762f6518ebcca268b6005'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efaf922b6d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,422 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,422 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,422 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,422 - DEBUG - response_closed.started


2024-04-21 11:01:03,422 - DEBUG - response_closed.complete


2024-04-21 11:01:03,425 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,425 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmos3RGLlRSMHlLCjXXBTEE3iXX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Ik6hh1Badsyeqtxn3YoaFhkS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,425 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,425 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'543'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4956'), (b'x-ratelimit-remaining-tokens', b'592480'), (b'x-ratelimit-reset-requests', b'526ms'), (b'x-ratelimit-reset-tokens', b'751ms'), (b'x-request-id', b'req_279c39b5a00a76c8431b6c87f40b6078'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8ae27ec3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,425 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,425 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,425 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,426 - DEBUG - response_closed.started


2024-04-21 11:01:03,426 - DEBUG - response_closed.complete


2024-04-21 11:01:03,428 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,428 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmouBLCXcNlmY5uXNuQylMLGzjz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pGfYT5SMWN7fsdIKyDwWII1R', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,428 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,429 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'594'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4955'), (b'x-ratelimit-remaining-tokens', b'592324'), (b'x-ratelimit-reset-requests', b'533ms'), (b'x-ratelimit-reset-tokens', b'767ms'), (b'x-request-id', b'req_00b52a69337e7a7a9e510647896f694a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef892908a8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,429 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,429 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,429 - DEBUG - response_closed.started


2024-04-21 11:01:03,430 - DEBUG - response_closed.complete


2024-04-21 11:01:03,432 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,432 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoygQkVOjej6OX4aIAPnoIsGal', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VUzrAMTxrkjWngezKykJiy6o', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,432 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,432 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'508'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'585186'), (b'x-ratelimit-reset-requests', b'1.031s'), (b'x-ratelimit-reset-tokens', b'1.481s'), (b'x-request-id', b'req_4e8d91cb2ff39a9a5f83ceff452ba99d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9bde08c8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,432 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,433 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,433 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,433 - DEBUG - response_closed.started


2024-04-21 11:01:03,433 - DEBUG - response_closed.complete


2024-04-21 11:01:03,435 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,435 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoZ9EZ63DZM8KFXih8jn8T1qVm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z6aud8LjL7LcuvFNNUt6XTSF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,435 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,435 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'590'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4942'), (b'x-ratelimit-remaining-tokens', b'590104'), (b'x-ratelimit-reset-requests', b'692ms'), (b'x-ratelimit-reset-tokens', b'989ms'), (b'x-request-id', b'req_7c36d909729c6106e497cb4ba3ec26ee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9ff108de-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,435 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,436 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,436 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,436 - DEBUG - response_closed.started


2024-04-21 11:01:03,436 - DEBUG - response_closed.complete


2024-04-21 11:01:03,438 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,438 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoIuM7tvR3wp56ZM8YrtkeoTqM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_KomH2BIJW3pj64csgDaXv16H', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,438 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,438 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'602'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4950'), (b'x-ratelimit-remaining-tokens', b'591581'), (b'x-ratelimit-reset-requests', b'589ms'), (b'x-ratelimit-reset-tokens', b'841ms'), (b'x-request-id', b'req_106c9629a58e118dbf4eb56230dbfee4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef882652f5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,439 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,439 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,439 - DEBUG - response_closed.started


2024-04-21 11:01:03,439 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'604'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4961'), (b'x-ratelimit-remaining-tokens', b'593273'), (b'x-ratelimit-reset-requests', b'465ms'), (b'x-ratelimit-reset-tokens', b'672ms'), (b'x-request-id', b'req_38c1ffd6a82197454a401345432432ea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef7fe4323a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,439 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,439 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,439 - DEBUG - response_closed.started


2024-04-21 11:01:03,439 - DEBUG - response_closed.complete


2024-04-21 11:01:03,441 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,442 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmou9rBXqFGeekzjcjXFlInBDXS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eovkawXZtnoMFGdfY99TRmRt', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,442 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,442 - DEBUG - response_closed.complete


2024-04-21 11:01:03,444 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,444 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo0aQoZAbhga9zfyTGr37fhipn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fMGgJDnl14shZuWclyL2SzTJ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,444 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,450 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'588'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'585449'), (b'x-ratelimit-reset-requests', b'1.027s'), (b'x-ratelimit-reset-tokens', b'1.455s'), (b'x-request-id', b'req_1af980f6ae96a42bc678dc84713cc9df'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efab2a5208-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,450 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,450 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,450 - DEBUG - response_closed.started


2024-04-21 11:01:03,450 - DEBUG - response_closed.complete


2024-04-21 11:01:03,453 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,453 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmooEBqYiF85JnRbp0PsEuuV49X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NJVN9CSJ93ghUhHoQclGSap2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,453 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,456 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4956'), (b'x-ratelimit-remaining-tokens', b'592468'), (b'x-ratelimit-reset-requests', b'523ms'), (b'x-ratelimit-reset-tokens', b'753ms'), (b'x-request-id', b'req_a6673106f32261f0ba957da068e27340'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8f47521a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,456 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,456 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,456 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,456 - DEBUG - response_closed.started


2024-04-21 11:01:03,456 - DEBUG - response_closed.complete


2024-04-21 11:01:03,458 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,459 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo0TOStorOUTaI9sAmJEvFBMWS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_otmprEGpfq1ZSzoyC0KkWYmK', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,459 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,462 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'606'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4931'), (b'x-ratelimit-remaining-tokens', b'588317'), (b'x-ratelimit-reset-requests', b'821ms'), (b'x-ratelimit-reset-tokens', b'1.168s'), (b'x-request-id', b'req_be1271cf0cf74165231e7e9edea98b5c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9bfc840c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,462 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,462 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,462 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,462 - DEBUG - response_closed.started


2024-04-21 11:01:03,462 - DEBUG - response_closed.complete


2024-04-21 11:01:03,465 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,465 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoT5BifETe2JvzIAKtLzxDZKmZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7KoHL7MiaZgQK1jHAAO4B2Wr', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,465 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,467 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'772'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598655'), (b'x-ratelimit-reset-requests', b'87ms'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_373d03eae3730cbe08b2947e93b83dac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3ab07ead-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,467 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,467 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,467 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,467 - DEBUG - response_closed.started


2024-04-21 11:01:03,467 - DEBUG - response_closed.complete


2024-04-21 11:01:03,469 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,470 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoU1Zn6aS764ZBwGkDyNmMW20K', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_cjtj5GIXLW03BpedN5imZ5aj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,470 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,470 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'706'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599483'), (b'x-ratelimit-reset-requests', b'42ms'), (b'x-ratelimit-reset-tokens', b'51ms'), (b'x-request-id', b'req_ae0f9ee19860f2e0ab3039d6bd9146a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef0bb552ad-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,470 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,470 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,470 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,470 - DEBUG - response_closed.started


2024-04-21 11:01:03,470 - DEBUG - response_closed.complete


2024-04-21 11:01:03,473 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,473 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmolWgedzXHuPFC46uKlt1ZBNWk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eYpBLyocVGhkvYYNXbc4Ezqj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,473 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,476 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'627'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'591150'), (b'x-ratelimit-reset-requests', b'619ms'), (b'x-ratelimit-reset-tokens', b'884ms'), (b'x-request-id', b'req_4f5f4d848818dc4f2f6bb2c144236f06'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8e4b7bf5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,476 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,477 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,477 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,477 - DEBUG - response_closed.started


2024-04-21 11:01:03,477 - DEBUG - response_closed.complete


2024-04-21 11:01:03,479 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,479 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmowqkEpfY4ewMIRwOrHWWv56IS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9vD5N8G5p3LGNP9Ta7mmjvKz', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,480 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,480 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'611'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4926'), (b'x-ratelimit-remaining-tokens', b'587535'), (b'x-ratelimit-reset-requests', b'877ms'), (b'x-ratelimit-reset-tokens', b'1.246s'), (b'x-request-id', b'req_9a6a30ed5d3dda6403210357d8023d54'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9d3c08b0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,480 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,480 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,480 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,480 - DEBUG - response_closed.started


2024-04-21 11:01:03,480 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'626'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4958'), (b'x-ratelimit-remaining-tokens', b'592809'), (b'x-ratelimit-reset-requests', b'498ms'), (b'x-ratelimit-reset-tokens', b'719ms'), (b'x-request-id', b'req_7b855552da4600817bbc1ee43dac5033'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8a015239-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,480 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,480 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,480 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,480 - DEBUG - response_closed.started


2024-04-21 11:01:03,480 - DEBUG - response_closed.complete


2024-04-21 11:01:03,483 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,483 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo25LRK1eT6Fa7tumiU07vxeJ4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OPSgvryV16Y7RkIzUzENY54O', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,483 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,483 - DEBUG - response_closed.complete


2024-04-21 11:01:03,486 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,486 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoXfBrTHqqcI91dSxV07dBxGi6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z6aud8LjL7LcuvFNNUt6XTSF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,486 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,486 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'607'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4919'), (b'x-ratelimit-remaining-tokens', b'586339'), (b'x-ratelimit-reset-requests', b'960ms'), (b'x-ratelimit-reset-tokens', b'1.366s'), (b'x-request-id', b'req_363949c9750182111833052193f9b2f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9bb9dbd9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,486 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,486 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,487 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,487 - DEBUG - response_closed.started


2024-04-21 11:01:03,487 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4933'), (b'x-ratelimit-remaining-tokens', b'588615'), (b'x-ratelimit-reset-requests', b'796ms'), (b'x-ratelimit-reset-tokens', b'1.138s'), (b'x-request-id', b'req_9ee31713168585bed97e90ead0039ee4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef997c0912-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,487 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,487 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,487 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,487 - DEBUG - response_closed.started


2024-04-21 11:01:03,487 - DEBUG - response_closed.complete


2024-04-21 11:01:03,489 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,490 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoZncUFgGoBlIHgLIJKnUqD4kK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_K2hGYWqR8DN9MQHjLo1xLpBp', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,490 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,490 - DEBUG - response_closed.complete


2024-04-21 11:01:03,492 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,493 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoCkmyzcroMGPTiVXgz9e5k1n1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_SRXS8fV5YS8RLt6zOnSlUsIg', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,493 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,493 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'637'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4944'), (b'x-ratelimit-remaining-tokens', b'590584'), (b'x-ratelimit-reset-requests', b'662ms'), (b'x-ratelimit-reset-tokens', b'941ms'), (b'x-request-id', b'req_9d18d10a155c3aea53f7a74f6e8b4b13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8f8f2f5c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,493 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,493 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,493 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,493 - DEBUG - response_closed.started


2024-04-21 11:01:03,493 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'638'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'590862'), (b'x-ratelimit-reset-requests', b'639ms'), (b'x-ratelimit-reset-tokens', b'913ms'), (b'x-request-id', b'req_c9ee9a7631df2ffe5442e5c1aad1f08f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8e0f2eef-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,493 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,493 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,493 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,493 - DEBUG - response_closed.started


2024-04-21 11:01:03,493 - DEBUG - response_closed.complete


2024-04-21 11:01:03,496 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,496 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoBW3BZ13kercJEB6COIZ3pnaq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ytWT2xMfIEdlGCZPaenqIy9d', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,496 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,496 - DEBUG - response_closed.complete


2024-04-21 11:01:03,499 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,499 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmosNf2ZTyqr8OLAW9GK9GaVubS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_WH0Aogj4YaUyxgVYC8ZrRP83', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,499 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,499 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4944'), (b'x-ratelimit-remaining-tokens', b'590504'), (b'x-ratelimit-reset-requests', b'665ms'), (b'x-ratelimit-reset-tokens', b'949ms'), (b'x-request-id', b'req_417aa183ee274ebbe96ab84bfec5176d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8d760faf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,499 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,499 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,499 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,499 - DEBUG - response_closed.started


2024-04-21 11:01:03,499 - DEBUG - response_closed.complete


2024-04-21 11:01:03,502 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,502 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoV3zByGqjgQe1ztHF1KQPvft2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_2wnSRMqXCW3haf6ILdlegFE5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,502 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,502 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'686'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4972'), (b'x-ratelimit-remaining-tokens', b'595249'), (b'x-ratelimit-reset-requests', b'330ms'), (b'x-ratelimit-reset-tokens', b'475ms'), (b'x-request-id', b'req_8596cab873798f58d7504ed499b6d0d2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef487b0ffb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,503 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,503 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,503 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,503 - DEBUG - response_closed.started


2024-04-21 11:01:03,503 - DEBUG - response_closed.complete


2024-04-21 11:01:03,505 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,505 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoKLQsuh7lth1866iTS75buEbR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_FnGqPeTDC5k3HVNUgaOQIfdW', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,506 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,515 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4924'), (b'x-ratelimit-remaining-tokens', b'587150'), (b'x-ratelimit-reset-requests', b'906ms'), (b'x-ratelimit-reset-tokens', b'1.284s'), (b'x-request-id', b'req_06ec4260403cc88181b985405ab8c2c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efa97b2aa1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,515 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,516 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,516 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,516 - DEBUG - response_closed.started


2024-04-21 11:01:03,516 - DEBUG - response_closed.complete


2024-04-21 11:01:03,518 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,519 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo0W4QxjtBuQRpf8PA25c8G49s', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Pqkq3vmCx495sP59c3u74UIj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,519 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,536 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'834'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4995'), (b'x-ratelimit-remaining-tokens', b'599088'), (b'x-ratelimit-reset-requests', b'58ms'), (b'x-ratelimit-reset-tokens', b'91ms'), (b'x-request-id', b'req_b3523362c83217d67db67ba5ae7364d2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3c372f1d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,537 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,537 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,537 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,537 - DEBUG - response_closed.started


2024-04-21 11:01:03,537 - DEBUG - response_closed.complete


2024-04-21 11:01:03,540 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,540 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmohq30MFDXGaD9KEjLpzb6VgdP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Kx1BJ9ixOok8vpKebGRHe2ke', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,540 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,542 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'817'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4976'), (b'x-ratelimit-remaining-tokens', b'595985'), (b'x-ratelimit-reset-requests', b'282ms'), (b'x-ratelimit-reset-tokens', b'401ms'), (b'x-request-id', b'req_3daa46e5e62788e00cc32534fc8c66b6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3ef72ab8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,542 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,542 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,542 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,542 - DEBUG - response_closed.started


2024-04-21 11:01:03,542 - DEBUG - response_closed.complete


2024-04-21 11:01:03,545 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,545 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmomgrQ0gUiCpszi0E8FbrB6EsS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YazhfGlBW02mroJjthoukTpO', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,545 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,545 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'592'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4915'), (b'x-ratelimit-remaining-tokens', b'585496'), (b'x-ratelimit-reset-requests', b'1.009s'), (b'x-ratelimit-reset-tokens', b'1.45s'), (b'x-request-id', b'req_48e3458ce509bf9846badb27f48652c7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8d342f74-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,546 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,546 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,546 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,546 - DEBUG - response_closed.started


2024-04-21 11:01:03,546 - DEBUG - response_closed.complete


2024-04-21 11:01:03,549 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,549 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmotfiV2HxZCUXQIkYurR5D8xjJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ncR66ltr1QRdbnf0yAJN14Ze', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,549 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,581 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'763'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4913'), (b'x-ratelimit-remaining-tokens', b'585174'), (b'x-ratelimit-reset-requests', b'1.036s'), (b'x-ratelimit-reset-tokens', b'1.482s'), (b'x-request-id', b'req_189868acc1c0c9d8ba67797669aa6aed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef88a56a2d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,581 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,581 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,581 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,581 - DEBUG - response_closed.started


2024-04-21 11:01:03,581 - DEBUG - response_closed.complete


2024-04-21 11:01:03,585 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,585 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoLt41UkjOC9ikk5diswkau6CQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HVyxUCa9OrArIK6Ns5o30y2W', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,585 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,881 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'929'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'586615'), (b'x-ratelimit-reset-requests', b'942ms'), (b'x-ratelimit-reset-tokens', b'1.338s'), (b'x-request-id', b'req_c6797e16300968807e3473cfa76eb9d2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef99bc0fed-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,882 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,882 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,882 - DEBUG - response_closed.started


2024-04-21 11:01:03,882 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'955'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'591209'), (b'x-ratelimit-reset-requests', b'617ms'), (b'x-ratelimit-reset-tokens', b'879ms'), (b'x-request-id', b'req_5626d833c278794cd38b8d99588d9b51'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8aeb1032-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,882 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,882 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,882 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,883 - DEBUG - response_closed.started


2024-04-21 11:01:03,883 - DEBUG - response_closed.complete


2024-04-21 11:01:03,886 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,887 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmou7IGCUdayPk9X7dJRNIbKkry', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8I9qSbJn4sp69AkS0jojHEMU', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,887 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,887 - DEBUG - response_closed.complete


2024-04-21 11:01:03,891 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,892 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoqkPSB3m7fvpSQnvjHAAgEm1G', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_g1RijtIztikvKsW3Otgcq1sm', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,892 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:03,930 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1033'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4920'), (b'x-ratelimit-remaining-tokens', b'586411'), (b'x-ratelimit-reset-requests', b'958ms'), (b'x-ratelimit-reset-tokens', b'1.358s'), (b'x-request-id', b'req_8657e02911762dec6f70c09a4b9d52f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef88967ea8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:03,930 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:03,930 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:03,930 - DEBUG - receive_response_body.complete


2024-04-21 11:01:03,931 - DEBUG - response_closed.started


2024-04-21 11:01:03,931 - DEBUG - response_closed.complete


2024-04-21 11:01:03,935 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:03,935 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoEZnZJIVJec1qId9VA3SV51ZA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AVVq9WKRptF4FWQtBMjPLGPX', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:03,936 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,009 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1396'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599835'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'16ms'), (b'x-request-id', b'req_29888e002132ec623c86eaf26e27c710'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46eebc541009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,010 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,010 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,010 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,010 - DEBUG - response_closed.started


2024-04-21 11:01:04,010 - DEBUG - response_closed.complete


2024-04-21 11:01:04,014 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,014 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoOQqEkz1fQsRsRjlO9h23eP1h', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PHRAgxJflWe0gwHxncjvdKYo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,015 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,017 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1215'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4975'), (b'x-ratelimit-remaining-tokens', b'595783'), (b'x-ratelimit-reset-requests', b'291ms'), (b'x-ratelimit-reset-tokens', b'421ms'), (b'x-request-id', b'req_b0ded7e3fe8a4aa3d83c92eb24288238'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef49f52b77-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,018 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,018 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,018 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,018 - DEBUG - response_closed.started


2024-04-21 11:01:04,018 - DEBUG - response_closed.complete


2024-04-21 11:01:04,022 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,023 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmod125XiDYxUAlPwoCvsw2eCcG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8QnfxZchuULjzlK8WrGqNmJv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,023 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,050 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1339'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4986'), (b'x-ratelimit-remaining-tokens', b'597682'), (b'x-ratelimit-reset-requests', b'158ms'), (b'x-ratelimit-reset-tokens', b'231ms'), (b'x-request-id', b'req_c0d1d242a824eef52e3c854302663702'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3c4e2eb4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,050 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,050 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,051 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,051 - DEBUG - response_closed.started


2024-04-21 11:01:04,051 - DEBUG - response_closed.complete


2024-04-21 11:01:04,055 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,056 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoijxuV7sFTD7TfhVoC4Ivuc15', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PHRAgxJflWe0gwHxncjvdKYo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,056 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,077 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1375'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4971'), (b'x-ratelimit-remaining-tokens', b'595083'), (b'x-ratelimit-reset-requests', b'343ms'), (b'x-ratelimit-reset-tokens', b'491ms'), (b'x-request-id', b'req_085d865fd8bee75ca9c372abccc681eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef5f9a0ca7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,077 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,078 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,078 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,078 - DEBUG - response_closed.started


2024-04-21 11:01:04,079 - DEBUG - response_closed.complete


2024-04-21 11:01:04,082 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,082 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmpqVvPIYnynzfZUmtjqYDtaJil', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HvCbsJD7pzHndr6cYQHT93X5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722463, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,083 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,179 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1472'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4970'), (b'x-ratelimit-remaining-tokens', b'594945'), (b'x-ratelimit-reset-requests', b'352ms'), (b'x-ratelimit-reset-tokens', b'505ms'), (b'x-request-id', b'req_40b1222b55a5f7e56452372e58594cf7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef58e208a8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,179 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,179 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,180 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,180 - DEBUG - response_closed.started


2024-04-21 11:01:04,180 - DEBUG - response_closed.complete


2024-04-21 11:01:04,184 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,184 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmpH8lOtfutcM3E4lLVFtwR7EYZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zBITqnuepEz9A0C8pgvrL6hJ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722463, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,185 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,336 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1595'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4960'), (b'x-ratelimit-remaining-tokens', b'593110'), (b'x-ratelimit-reset-requests', b'477ms'), (b'x-ratelimit-reset-tokens', b'688ms'), (b'x-request-id', b'req_41d26907a94a688022f2b41b3cca6511'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef88a67bd1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,336 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,336 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,336 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,337 - DEBUG - response_closed.started


2024-04-21 11:01:04,337 - DEBUG - response_closed.complete


2024-04-21 11:01:04,341 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,342 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmogkcQhBgtFkPNcf88m6TUUvgW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PjccJNcSCwVew1XM18KEVri7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,342 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,402 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1663'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4961'), (b'x-ratelimit-remaining-tokens', b'593455'), (b'x-ratelimit-reset-requests', b'456ms'), (b'x-ratelimit-reset-tokens', b'654ms'), (b'x-request-id', b'req_e90bcb8afda17217eaa38a953f650274'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef7d4a1029-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,402 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,402 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,402 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,402 - DEBUG - response_closed.started


2024-04-21 11:01:04,402 - DEBUG - response_closed.complete


2024-04-21 11:01:04,406 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,406 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmomTpH4JDpZA1NPndpUmfMPDrH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lEjo4hV7UR5Td9HTcNtpzKNm', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,406 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,407 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1643'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4929'), (b'x-ratelimit-remaining-tokens', b'588006'), (b'x-ratelimit-reset-requests', b'843ms'), (b'x-ratelimit-reset-tokens', b'1.199s'), (b'x-request-id', b'req_7555451e0125f30f529afa022a546be8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efaa967be6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,408 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,408 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,408 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,408 - DEBUG - response_closed.started


2024-04-21 11:01:04,408 - DEBUG - response_closed.complete


2024-04-21 11:01:04,412 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,412 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoshGVi9inuCuiTEtRYlLuIkjR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_GsQde5KJXu03okHvweAIRMWU', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,413 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,413 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1647'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4927'), (b'x-ratelimit-remaining-tokens', b'587685'), (b'x-ratelimit-reset-requests', b'866ms'), (b'x-ratelimit-reset-tokens', b'1.231s'), (b'x-request-id', b'req_262c6c66e9f17ac46e1190260b849c80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efae4f6a29-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,413 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,413 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,413 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,413 - DEBUG - response_closed.started


2024-04-21 11:01:04,413 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1665'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4952'), (b'x-ratelimit-remaining-tokens', b'591806'), (b'x-ratelimit-reset-requests', b'571ms'), (b'x-ratelimit-reset-tokens', b'819ms'), (b'x-request-id', b'req_caac8b7e7b316e3df190d202e2d93bb6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef78cc7bbf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,414 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,414 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,414 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,414 - DEBUG - response_closed.started


2024-04-21 11:01:04,414 - DEBUG - response_closed.complete


2024-04-21 11:01:04,419 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,419 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo3973cy9uRQuBilmeNrewuIH4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7TgLqRkjf29lHqkHlQ73bk9B', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,419 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,419 - DEBUG - response_closed.complete


2024-04-21 11:01:04,423 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,423 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmofP4aXPNV9uVkk6VMOvAKVyt1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PWs73fbCtjGE5L7s9AyE1TUP', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,424 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,431 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1666'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4937'), (b'x-ratelimit-remaining-tokens', b'589301'), (b'x-ratelimit-reset-requests', b'750ms'), (b'x-ratelimit-reset-tokens', b'1.069s'), (b'x-request-id', b'req_8fc008dff3a36f868c2fa7992728d172'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8c8669cf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,431 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,431 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,431 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,431 - DEBUG - response_closed.started


2024-04-21 11:01:04,431 - DEBUG - response_closed.complete


2024-04-21 11:01:04,436 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,436 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoMAL1wWHBw9g1rQcavXDLbPmW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_peIHZEv3MJZ86WngPoBZFP4H', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,437 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,439 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1668'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'586730'), (b'x-ratelimit-reset-requests', b'935ms'), (b'x-ratelimit-reset-tokens', b'1.326s'), (b'x-request-id', b'req_397d100177fa418de2fae5b99036ff69'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef39822aaf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,440 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,440 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,440 - DEBUG - response_closed.started


2024-04-21 11:01:04,440 - DEBUG - response_closed.complete


2024-04-21 11:01:04,444 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,445 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo01w2845XZaOhPgdg3HOoM2kt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lEjo4hV7UR5Td9HTcNtpzKNm', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,445 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,487 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1632'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4928'), (b'x-ratelimit-remaining-tokens', b'587850'), (b'x-ratelimit-reset-requests', b'854ms'), (b'x-ratelimit-reset-tokens', b'1.214s'), (b'x-request-id', b'req_a9e40a2c0e0a25efaedf75608e2340e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efa8612f5f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,488 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,488 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,488 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,488 - DEBUG - response_closed.started


2024-04-21 11:01:04,488 - DEBUG - response_closed.complete


2024-04-21 11:01:04,493 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,493 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo6nv9TBS1FNKDxWKIL7f46Eyf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_42gKob7vHBWwkN333FMJJQ9B', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,493 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,497 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1744'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'592995'), (b'x-ratelimit-reset-requests', b'484ms'), (b'x-ratelimit-reset-tokens', b'700ms'), (b'x-request-id', b'req_81de4f0201cc5bea871c38112e08a03a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8e917edb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,497 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,497 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,497 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,497 - DEBUG - response_closed.started


2024-04-21 11:01:04,497 - DEBUG - response_closed.complete


2024-04-21 11:01:04,503 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,503 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmotCGiKRjSDKd4kKTKfSIBy9BS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dXHGmD5xkvLXxKivF5eCbLgb', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,503 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,803 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2043'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4969'), (b'x-ratelimit-remaining-tokens', b'594715'), (b'x-ratelimit-reset-requests', b'366ms'), (b'x-ratelimit-reset-tokens', b'528ms'), (b'x-request-id', b'req_508ff27400ab9dff39a4e6a75ea7da97'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef5a292acc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,803 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,803 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,803 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,803 - DEBUG - response_closed.started


2024-04-21 11:01:04,803 - DEBUG - response_closed.complete


2024-04-21 11:01:04,807 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,807 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmojQ9XICTqFwlMar1BQq6CiVXc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8linX4JbgDfzmlamBr6mJggx', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,808 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:04,808 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2017'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4963'), (b'x-ratelimit-remaining-tokens', b'593698'), (b'x-ratelimit-reset-requests', b'436ms'), (b'x-ratelimit-reset-tokens', b'630ms'), (b'x-request-id', b'req_6891b623790002c58727c9caaa169025'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef7da169b8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:04,808 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:04,808 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:04,809 - DEBUG - receive_response_body.complete


2024-04-21 11:01:04,809 - DEBUG - response_closed.started


2024-04-21 11:01:04,809 - DEBUG - response_closed.complete


2024-04-21 11:01:04,813 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:04,813 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmowfDoVSt2cXzxlW1p9IJ2KXnj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_MvOhPosCYaglfpkPmRsPTZRv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:04,813 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:05,212 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2398'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'586817'), (b'x-ratelimit-reset-requests', b'935ms'), (b'x-ratelimit-reset-tokens', b'1.318s'), (b'x-request-id', b'req_dd09cae067c9f914e82894febfdaf6fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46efaeff1039-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:05,214 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:05,214 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:05,214 - DEBUG - receive_response_body.complete


2024-04-21 11:01:05,215 - DEBUG - response_closed.started


2024-04-21 11:01:05,215 - DEBUG - response_closed.complete


2024-04-21 11:01:05,233 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:05,234 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoqhqRMrytroC5AG8KwYzxNwkZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_18VOIyNFshVopA7enssggtRE', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:05,235 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:05,519 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2738'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4935'), (b'x-ratelimit-remaining-tokens', b'588987'), (b'x-ratelimit-reset-requests', b'772ms'), (b'x-ratelimit-reset-tokens', b'1.101s'), (b'x-request-id', b'req_a9121ee99c0135f8608b4b34b7aef9c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9de4092d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:05,520 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:05,520 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:05,520 - DEBUG - receive_response_body.complete


2024-04-21 11:01:05,520 - DEBUG - response_closed.started


2024-04-21 11:01:05,521 - DEBUG - response_closed.complete


2024-04-21 11:01:05,533 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:05,533 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoVNcy7zaMuDyfbtZka5210Z4V', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_18VOIyNFshVopA7enssggtRE', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:05,534 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:06,545 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3710'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'597949'), (b'x-ratelimit-reset-requests', b'136ms'), (b'x-ratelimit-reset-tokens', b'205ms'), (b'x-request-id', b'req_34d10faf837bca9fd546bfa5ea95fcbf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef3ec17d12-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:06,545 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:06,545 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:06,546 - DEBUG - receive_response_body.complete


2024-04-21 11:01:06,546 - DEBUG - response_closed.started


2024-04-21 11:01:06,546 - DEBUG - response_closed.complete


2024-04-21 11:01:06,557 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:06,558 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmo7BAu1maY1nOSoWnebboXzeOK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Cs91bTAXn0159CRfN8m5wQSk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:06,558 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:06,578 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3802'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4982'), (b'x-ratelimit-remaining-tokens', b'596943'), (b'x-ratelimit-reset-requests', b'214ms'), (b'x-ratelimit-reset-tokens', b'305ms'), (b'x-request-id', b'req_8cf4503e3191aa872d0e899c5cd08272'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef4cf314fc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:06,579 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:06,580 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:06,580 - DEBUG - receive_response_body.complete


2024-04-21 11:01:06,580 - DEBUG - response_closed.started


2024-04-21 11:01:06,581 - DEBUG - response_closed.complete


2024-04-21 11:01:06,597 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:06,597 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoF0wKzjWd5qNsUSq861n3MghC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PgiWUp76a36ryiUEQFMX7TR4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:06,598 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:06,615 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3800'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4953'), (b'x-ratelimit-remaining-tokens', b'591979'), (b'x-ratelimit-reset-requests', b'558ms'), (b'x-ratelimit-reset-tokens', b'802ms'), (b'x-request-id', b'req_c1a524c1816861b419d1a04fbb1b8b46'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef8a587bcd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:06,615 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:06,616 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:06,616 - DEBUG - receive_response_body.complete


2024-04-21 11:01:06,616 - DEBUG - response_closed.started


2024-04-21 11:01:06,616 - DEBUG - response_closed.complete


2024-04-21 11:01:06,628 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:06,629 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmoR3VjKRyg7gjbKi5MD7ibB3tq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NzggrmferBzlBODTiKdTHJue', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722462, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:06,629 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:07,059 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:07 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4205'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4939'), (b'x-ratelimit-remaining-tokens', b'589622'), (b'x-ratelimit-reset-requests', b'727ms'), (b'x-ratelimit-reset-tokens', b'1.037s'), (b'x-request-id', b'req_ba4e6a22a0ee29a5d233ddcc45026869'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f46ef9b197bc7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:07,061 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:07,062 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:07,062 - DEBUG - receive_response_body.complete


2024-04-21 11:01:07,062 - DEBUG - response_closed.started


2024-04-21 11:01:07,063 - DEBUG - response_closed.complete


2024-04-21 11:01:07,080 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:07,082 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmp5ScGZfZM42mKMSoes1eUIOnB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yy3RG79ezJEXvIAKFeyfyj7x', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722463, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=201, total_tokens=206))


2024-04-21 11:01:07,083 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:07,086 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'The current primary prompt is not returning enough results. Please provide a new primary prompt that is more general.'}
	{'role': 'user', 'content': "Current primary prompt: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}


2024-04-21 11:01:07,094 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewPrimaryPrompt'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'The current primary prompt is not returning enough results. Please provide a new primary prompt that is more general.'}, {'role': 'user', 'content': "Current primary prompt: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt', 'description': 'Correctly extracted `MakeNewPrimaryPrompt` with all the required parameters with correct types', 'parameters': {'properties': {'primary_prompt': {'description': 'Enter a new primary prompt.', 'title': 'Primary Prompt', 'type': 'string'}}, 'required': ['primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt'}}}


2024-04-21 11:01:07,094 - DEBUG - max_retries: 8


2024-04-21 11:01:07,094 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e2fb80>


2024-04-21 11:01:07,099 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'The current primary prompt is not returning enough results. Please provide a new primary prompt that is more general.'}, {'role': 'user', 'content': "Current primary prompt: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt', 'description': 'Correctly extracted `MakeNewPrimaryPrompt` with all the required parameters with correct types', 'parameters': {'properties': {'primary_prompt': {'description': 'Enter a new primary prompt.', 'title': 'Primary Prompt', 'type': 'string'}}, 'required': ['primary_prompt'], 'type': 'object'}}}]}}


2024-04-21 11:01:07,108 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:07,108 - DEBUG - send_request_headers.complete


2024-04-21 11:01:07,108 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:07,108 - DEBUG - send_request_body.complete


2024-04-21 11:01:07,108 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,044 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1690'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599895'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'10ms'), (b'x-request-id', b'req_eda8414576041ad76f723f11d48e5091'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f470b8db91009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:09,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:09,047 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,047 - DEBUG - receive_response_body.complete


2024-04-21 11:01:09,050 - DEBUG - response_closed.started


2024-04-21 11:01:09,051 - DEBUG - response_closed.complete


2024-04-21 11:01:09,061 - DEBUG - close.started


2024-04-21 11:01:09,062 - DEBUG - close.complete


2024-04-21 11:01:09,062 - DEBUG - close.started


2024-04-21 11:01:09,062 - DEBUG - close.complete


2024-04-21 11:01:09,062 - DEBUG - close.started


2024-04-21 11:01:09,062 - DEBUG - close.complete


2024-04-21 11:01:09,062 - DEBUG - close.started


2024-04-21 11:01:09,063 - DEBUG - close.complete


2024-04-21 11:01:09,063 - DEBUG - close.started


2024-04-21 11:01:09,063 - DEBUG - close.complete


2024-04-21 11:01:09,063 - DEBUG - close.started


2024-04-21 11:01:09,063 - DEBUG - close.complete


2024-04-21 11:01:09,063 - DEBUG - close.started


2024-04-21 11:01:09,063 - DEBUG - close.complete


2024-04-21 11:01:09,064 - DEBUG - close.started


2024-04-21 11:01:09,064 - DEBUG - close.complete


2024-04-21 11:01:09,064 - DEBUG - close.started


2024-04-21 11:01:09,064 - DEBUG - close.complete


2024-04-21 11:01:09,064 - DEBUG - close.started


2024-04-21 11:01:09,065 - DEBUG - close.complete


2024-04-21 11:01:09,066 - DEBUG - close.started


2024-04-21 11:01:09,066 - DEBUG - close.complete


2024-04-21 11:01:09,066 - DEBUG - close.started


2024-04-21 11:01:09,066 - DEBUG - close.complete


2024-04-21 11:01:09,066 - DEBUG - close.started


2024-04-21 11:01:09,066 - DEBUG - close.complete


2024-04-21 11:01:09,066 - DEBUG - close.started


2024-04-21 11:01:09,066 - DEBUG - close.complete


2024-04-21 11:01:09,066 - DEBUG - close.started


2024-04-21 11:01:09,067 - DEBUG - close.complete


2024-04-21 11:01:09,067 - DEBUG - close.started


2024-04-21 11:01:09,067 - DEBUG - close.complete


2024-04-21 11:01:09,067 - DEBUG - close.started


2024-04-21 11:01:09,067 - DEBUG - close.complete


2024-04-21 11:01:09,067 - DEBUG - close.started


2024-04-21 11:01:09,067 - DEBUG - close.complete


2024-04-21 11:01:09,067 - DEBUG - close.started


2024-04-21 11:01:09,067 - DEBUG - close.complete


2024-04-21 11:01:09,067 - DEBUG - close.started


2024-04-21 11:01:09,067 - DEBUG - close.complete


2024-04-21 11:01:09,067 - DEBUG - close.started


2024-04-21 11:01:09,068 - DEBUG - close.complete


2024-04-21 11:01:09,068 - DEBUG - close.started


2024-04-21 11:01:09,068 - DEBUG - close.complete


2024-04-21 11:01:09,068 - DEBUG - close.started


2024-04-21 11:01:09,068 - DEBUG - close.complete


2024-04-21 11:01:09,068 - DEBUG - close.started


2024-04-21 11:01:09,068 - DEBUG - close.complete


2024-04-21 11:01:09,068 - DEBUG - close.started


2024-04-21 11:01:09,068 - DEBUG - close.complete


2024-04-21 11:01:09,068 - DEBUG - close.started


2024-04-21 11:01:09,069 - DEBUG - close.complete


2024-04-21 11:01:09,069 - DEBUG - close.started


2024-04-21 11:01:09,069 - DEBUG - close.complete


2024-04-21 11:01:09,069 - DEBUG - close.started


2024-04-21 11:01:09,069 - DEBUG - close.complete


2024-04-21 11:01:09,069 - DEBUG - close.started


2024-04-21 11:01:09,069 - DEBUG - close.complete


2024-04-21 11:01:09,069 - DEBUG - close.started


2024-04-21 11:01:09,069 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,070 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,070 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,070 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,070 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,070 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,070 - DEBUG - close.complete


2024-04-21 11:01:09,070 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,071 - DEBUG - close.complete


2024-04-21 11:01:09,071 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,072 - DEBUG - close.complete


2024-04-21 11:01:09,072 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,073 - DEBUG - close.started


2024-04-21 11:01:09,073 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,074 - DEBUG - close.complete


2024-04-21 11:01:09,074 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,075 - DEBUG - close.complete


2024-04-21 11:01:09,075 - DEBUG - close.started


2024-04-21 11:01:09,076 - DEBUG - close.complete


2024-04-21 11:01:09,076 - DEBUG - close.started


2024-04-21 11:01:09,076 - DEBUG - close.complete


2024-04-21 11:01:09,076 - DEBUG - close.started


2024-04-21 11:01:09,076 - DEBUG - close.complete


2024-04-21 11:01:09,076 - DEBUG - close.started


2024-04-21 11:01:09,076 - DEBUG - close.complete


2024-04-21 11:01:09,076 - DEBUG - close.started


2024-04-21 11:01:09,076 - DEBUG - close.complete


2024-04-21 11:01:09,082 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:09,083 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmtaSy2d66ioaN0xXEoHaooiPZ7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kk0Sv48U5gFHUpijn6PysefV', function=Function(arguments='{"primary_prompt":"Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events."}', name='MakeNewPrimaryPrompt'), type='function')]))], created=1713722467, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=30, prompt_tokens=141, total_tokens=171))


2024-04-21 11:01:09,084 - INFO - Received completion from the model:
primary_prompt='Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'


2024-04-21 11:01:09,087 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,089 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,089 - DEBUG - max_retries: 8


2024-04-21 11:01:09,089 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e2cd00>


2024-04-21 11:01:09,093 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,095 - DEBUG - close.started


2024-04-21 11:01:09,095 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,096 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,096 - DEBUG - max_retries: 8


2024-04-21 11:01:09,097 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e2ea40>


2024-04-21 11:01:09,101 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,102 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,104 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,104 - DEBUG - max_retries: 8


2024-04-21 11:01:09,104 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e2c310>


2024-04-21 11:01:09,107 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,108 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,109 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,109 - DEBUG - max_retries: 8


2024-04-21 11:01:09,109 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f3acb0>


2024-04-21 11:01:09,112 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,113 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: April 11, 1954, was recorded as the most boring day in the world. \nStatistics show that no significant occurrences took place in the world.\n🌍 🥱 #Boring #Bored #April #World #Statistics #FunFacts\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,115 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: April 11, 1954, was recorded as the most boring day in the world. \nStatistics show that no significant occurrences took place in the world.\n🌍 🥱 #Boring #Bored #April #World #Statistics #FunFacts\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,115 - DEBUG - max_retries: 8


2024-04-21 11:01:09,115 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f39b40>


2024-04-21 11:01:09,117 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: April 11, 1954, was recorded as the most boring day in the world. \nStatistics show that no significant occurrences took place in the world.\n🌍 🥱 #Boring #Bored #April #World #Statistics #FunFacts\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,118 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,119 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,119 - DEBUG - max_retries: 8


2024-04-21 11:01:09,119 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f395d0>


2024-04-21 11:01:09,122 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,123 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,146 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,146 - DEBUG - max_retries: 8


2024-04-21 11:01:09,146 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d68eb0>


2024-04-21 11:01:09,148 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,149 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,149 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,149 - DEBUG - max_retries: 8


2024-04-21 11:01:09,149 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107d6bee0>


2024-04-21 11:01:09,151 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,152 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,153 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,153 - DEBUG - max_retries: 8


2024-04-21 11:01:09,153 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1079edff0>


2024-04-21 11:01:09,155 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,155 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,156 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,156 - DEBUG - max_retries: 8


2024-04-21 11:01:09,156 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1079eee60>


2024-04-21 11:01:09,158 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,159 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,159 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,159 - DEBUG - max_retries: 8


2024-04-21 11:01:09,159 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10790a770>


2024-04-21 11:01:09,161 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,162 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,163 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,163 - DEBUG - max_retries: 8


2024-04-21 11:01:09,163 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1079efeb0>


2024-04-21 11:01:09,165 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,165 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,166 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,166 - DEBUG - max_retries: 8


2024-04-21 11:01:09,166 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121ce85b0>


2024-04-21 11:01:09,168 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,169 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,169 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,169 - DEBUG - max_retries: 8


2024-04-21 11:01:09,169 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c3a3e0>


2024-04-21 11:01:09,171 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,172 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,172 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,172 - DEBUG - max_retries: 8


2024-04-21 11:01:09,172 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121cc3a60>


2024-04-21 11:01:09,174 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,175 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,176 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,176 - DEBUG - max_retries: 8


2024-04-21 11:01:09,176 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121cc1ed0>


2024-04-21 11:01:09,178 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,179 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,180 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,180 - DEBUG - max_retries: 8


2024-04-21 11:01:09,180 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c38ac0>


2024-04-21 11:01:09,182 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,182 - DEBUG - close.started


2024-04-21 11:01:09,182 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,183 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,183 - DEBUG - max_retries: 8


2024-04-21 11:01:09,183 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121872020>


2024-04-21 11:01:09,185 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,186 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,186 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,186 - DEBUG - max_retries: 8


2024-04-21 11:01:09,186 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107983cd0>


2024-04-21 11:01:09,188 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,189 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,189 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,189 - DEBUG - max_retries: 8


2024-04-21 11:01:09,189 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12183c070>


2024-04-21 11:01:09,191 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,192 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,193 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,193 - DEBUG - max_retries: 8


2024-04-21 11:01:09,193 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107982e60>


2024-04-21 11:01:09,195 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,195 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,196 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,196 - DEBUG - max_retries: 8


2024-04-21 11:01:09,196 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c91db0>


2024-04-21 11:01:09,198 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,199 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,199 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,199 - DEBUG - max_retries: 8


2024-04-21 11:01:09,199 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c906a0>


2024-04-21 11:01:09,201 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,202 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,202 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,202 - DEBUG - max_retries: 8


2024-04-21 11:01:09,203 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121996b00>


2024-04-21 11:01:09,204 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,205 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,206 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,206 - DEBUG - max_retries: 8


2024-04-21 11:01:09,206 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c41bd0>


2024-04-21 11:01:09,208 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,208 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,209 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,209 - DEBUG - max_retries: 8


2024-04-21 11:01:09,209 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121995120>


2024-04-21 11:01:09,211 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,212 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,212 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,212 - DEBUG - max_retries: 8


2024-04-21 11:01:09,212 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c43d00>


2024-04-21 11:01:09,214 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: like i fucking love it so bad when people come up to me at shows and ask about my stuff or express interest or how they wanna write more bc of smth i did like i literally log the significant occurrences of almost every show ive played and it genuinely makes me feel\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,215 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,216 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,216 - DEBUG - max_retries: 8


2024-04-21 11:01:09,216 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c09d0>


2024-04-21 11:01:09,218 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,218 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,219 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,219 - DEBUG - max_retries: 8


2024-04-21 11:01:09,219 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c1630>


2024-04-21 11:01:09,221 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,222 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,222 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,222 - DEBUG - max_retries: 8


2024-04-21 11:01:09,222 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c1030>


2024-04-21 11:01:09,224 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,225 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,225 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,225 - DEBUG - max_retries: 8


2024-04-21 11:01:09,225 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c3790>


2024-04-21 11:01:09,227 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,228 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,228 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,228 - DEBUG - max_retries: 8


2024-04-21 11:01:09,228 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219fa260>


2024-04-21 11:01:09,230 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,231 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,232 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,232 - DEBUG - max_retries: 8


2024-04-21 11:01:09,232 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219f8b80>


2024-04-21 11:01:09,234 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,234 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,235 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,235 - DEBUG - max_retries: 8


2024-04-21 11:01:09,235 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219c2bc0>


2024-04-21 11:01:09,237 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,238 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,238 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,238 - DEBUG - max_retries: 8


2024-04-21 11:01:09,238 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219fae60>


2024-04-21 11:01:09,240 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,241 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,241 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,241 - DEBUG - max_retries: 8


2024-04-21 11:01:09,241 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219fbd60>


2024-04-21 11:01:09,243 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,244 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,245 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,245 - DEBUG - max_retries: 8


2024-04-21 11:01:09,245 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e8a620>


2024-04-21 11:01:09,247 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,247 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,248 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,248 - DEBUG - max_retries: 8


2024-04-21 11:01:09,248 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e89210>


2024-04-21 11:01:09,250 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,251 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,251 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,251 - DEBUG - max_retries: 8


2024-04-21 11:01:09,251 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e882e0>


2024-04-21 11:01:09,253 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,254 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,254 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,254 - DEBUG - max_retries: 8


2024-04-21 11:01:09,254 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e8b7c0>


2024-04-21 11:01:09,256 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,257 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,258 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,258 - DEBUG - max_retries: 8


2024-04-21 11:01:09,258 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e88070>


2024-04-21 11:01:09,260 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,260 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,261 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,261 - DEBUG - max_retries: 8


2024-04-21 11:01:09,261 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e881c0>


2024-04-21 11:01:09,263 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,264 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,264 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,264 - DEBUG - max_retries: 8


2024-04-21 11:01:09,264 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e65210>


2024-04-21 11:01:09,266 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,267 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,267 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,267 - DEBUG - max_retries: 8


2024-04-21 11:01:09,267 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e67c10>


2024-04-21 11:01:09,269 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,270 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,271 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,271 - DEBUG - max_retries: 8


2024-04-21 11:01:09,271 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e66440>


2024-04-21 11:01:09,273 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,273 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,274 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,274 - DEBUG - max_retries: 8


2024-04-21 11:01:09,274 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e30640>


2024-04-21 11:01:09,276 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,276 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,277 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,277 - DEBUG - max_retries: 8


2024-04-21 11:01:09,277 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e66c50>


2024-04-21 11:01:09,279 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,280 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,280 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,280 - DEBUG - max_retries: 8


2024-04-21 11:01:09,280 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e339a0>


2024-04-21 11:01:09,282 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,283 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,283 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,283 - DEBUG - max_retries: 8


2024-04-21 11:01:09,283 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e32ce0>


2024-04-21 11:01:09,285 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,286 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,287 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,287 - DEBUG - max_retries: 8


2024-04-21 11:01:09,287 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107e33e20>


2024-04-21 11:01:09,289 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,289 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,290 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,290 - DEBUG - max_retries: 8


2024-04-21 11:01:09,290 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196d090>


2024-04-21 11:01:09,292 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,292 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,293 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,293 - DEBUG - max_retries: 8


2024-04-21 11:01:09,293 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196dba0>


2024-04-21 11:01:09,295 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,296 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,296 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,296 - DEBUG - max_retries: 8


2024-04-21 11:01:09,296 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196e680>


2024-04-21 11:01:09,298 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,299 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,300 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,300 - DEBUG - max_retries: 8


2024-04-21 11:01:09,300 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196c400>


2024-04-21 11:01:09,302 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,302 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,303 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,303 - DEBUG - max_retries: 8


2024-04-21 11:01:09,303 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12196f9a0>


2024-04-21 11:01:09,305 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,305 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,306 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,306 - DEBUG - max_retries: 8


2024-04-21 11:01:09,306 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193d810>


2024-04-21 11:01:09,308 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,309 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,309 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,309 - DEBUG - max_retries: 8


2024-04-21 11:01:09,309 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193e260>


2024-04-21 11:01:09,311 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,312 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,312 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,312 - DEBUG - max_retries: 8


2024-04-21 11:01:09,313 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193c550>


2024-04-21 11:01:09,315 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,316 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,316 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,316 - DEBUG - max_retries: 8


2024-04-21 11:01:09,316 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193faf0>


2024-04-21 11:01:09,318 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,319 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,320 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,320 - DEBUG - max_retries: 8


2024-04-21 11:01:09,320 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12193c490>


2024-04-21 11:01:09,322 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,323 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,324 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,324 - DEBUG - max_retries: 8


2024-04-21 11:01:09,324 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121899510>


2024-04-21 11:01:09,326 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,327 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,327 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,327 - DEBUG - max_retries: 8


2024-04-21 11:01:09,327 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121899e70>


2024-04-21 11:01:09,329 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,330 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,331 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,331 - DEBUG - max_retries: 8


2024-04-21 11:01:09,331 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12189b9d0>


2024-04-21 11:01:09,333 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,334 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,334 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,334 - DEBUG - max_retries: 8


2024-04-21 11:01:09,334 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bfa9e0>


2024-04-21 11:01:09,336 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,337 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,337 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,337 - DEBUG - max_retries: 8


2024-04-21 11:01:09,337 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bfb8e0>


2024-04-21 11:01:09,339 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,340 - DEBUG - close.started


2024-04-21 11:01:09,340 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,341 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,341 - DEBUG - max_retries: 8


2024-04-21 11:01:09,341 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12189afe0>


2024-04-21 11:01:09,343 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,343 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,344 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,344 - DEBUG - max_retries: 8


2024-04-21 11:01:09,344 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bf94e0>


2024-04-21 11:01:09,346 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,347 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,347 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,347 - DEBUG - max_retries: 8


2024-04-21 11:01:09,347 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bf100>


2024-04-21 11:01:09,349 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,350 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,350 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,350 - DEBUG - max_retries: 8


2024-04-21 11:01:09,351 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bcbe0>


2024-04-21 11:01:09,353 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,353 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,354 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,354 - DEBUG - max_retries: 8


2024-04-21 11:01:09,354 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218beec0>


2024-04-21 11:01:09,356 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,356 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,357 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,357 - DEBUG - max_retries: 8


2024-04-21 11:01:09,357 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218be5f0>


2024-04-21 11:01:09,359 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,360 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,360 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,360 - DEBUG - max_retries: 8


2024-04-21 11:01:09,360 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218bd750>


2024-04-21 11:01:09,362 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,363 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,363 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,363 - DEBUG - max_retries: 8


2024-04-21 11:01:09,363 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218be9b0>


2024-04-21 11:01:09,365 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,366 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,367 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,367 - DEBUG - max_retries: 8


2024-04-21 11:01:09,367 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x12191aef0>


2024-04-21 11:01:09,369 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,369 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,370 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,370 - DEBUG - max_retries: 8


2024-04-21 11:01:09,370 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121919ea0>


2024-04-21 11:01:09,372 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,373 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,373 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,373 - DEBUG - max_retries: 8


2024-04-21 11:01:09,373 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1219192a0>


2024-04-21 11:01:09,375 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,376 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,377 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,377 - DEBUG - max_retries: 8


2024-04-21 11:01:09,377 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bb0940>


2024-04-21 11:01:09,379 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,379 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,380 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,380 - DEBUG - max_retries: 8


2024-04-21 11:01:09,380 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bb13f0>


2024-04-21 11:01:09,382 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,382 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,383 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,383 - DEBUG - max_retries: 8


2024-04-21 11:01:09,383 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bb3220>


2024-04-21 11:01:09,385 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,386 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,387 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,387 - DEBUG - max_retries: 8


2024-04-21 11:01:09,387 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bb28f0>


2024-04-21 11:01:09,389 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,389 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,390 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,390 - DEBUG - max_retries: 8


2024-04-21 11:01:09,390 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121bb27d0>


2024-04-21 11:01:09,392 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,392 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,393 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,393 - DEBUG - max_retries: 8


2024-04-21 11:01:09,393 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218ea4d0>


2024-04-21 11:01:09,395 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,396 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,396 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,396 - DEBUG - max_retries: 8


2024-04-21 11:01:09,396 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218eaaa0>


2024-04-21 11:01:09,398 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,399 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,399 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,400 - DEBUG - max_retries: 8


2024-04-21 11:01:09,400 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218ebf10>


2024-04-21 11:01:09,402 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,403 - DEBUG - close.started


2024-04-21 11:01:09,403 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,403 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,403 - DEBUG - max_retries: 8


2024-04-21 11:01:09,403 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218eb3a0>


2024-04-21 11:01:09,406 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,406 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,407 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,407 - DEBUG - max_retries: 8


2024-04-21 11:01:09,407 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1218e8c40>


2024-04-21 11:01:09,409 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,410 - DEBUG - close.started


2024-04-21 11:01:09,410 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,411 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,411 - DEBUG - max_retries: 8


2024-04-21 11:01:09,411 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121813df0>


2024-04-21 11:01:09,413 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,413 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,414 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,414 - DEBUG - max_retries: 8


2024-04-21 11:01:09,414 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121813f10>


2024-04-21 11:01:09,416 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,416 - DEBUG - close.started


2024-04-21 11:01:09,417 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,417 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,417 - DEBUG - max_retries: 8


2024-04-21 11:01:09,417 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121812ef0>


2024-04-21 11:01:09,419 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,420 - DEBUG - close.started


2024-04-21 11:01:09,420 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,420 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,420 - DEBUG - max_retries: 8


2024-04-21 11:01:09,420 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2ddb0>


2024-04-21 11:01:09,422 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,423 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,423 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,423 - DEBUG - max_retries: 8


2024-04-21 11:01:09,423 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2fa30>


2024-04-21 11:01:09,425 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,426 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,426 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,426 - DEBUG - max_retries: 8


2024-04-21 11:01:09,426 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2e1d0>


2024-04-21 11:01:09,428 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,429 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,430 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,430 - DEBUG - max_retries: 8


2024-04-21 11:01:09,430 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f2f130>


2024-04-21 11:01:09,432 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,432 - DEBUG - close.started


2024-04-21 11:01:09,432 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,433 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,433 - DEBUG - max_retries: 8


2024-04-21 11:01:09,433 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f084c0>


2024-04-21 11:01:09,435 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,435 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,436 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,436 - DEBUG - max_retries: 8


2024-04-21 11:01:09,436 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f0a1d0>


2024-04-21 11:01:09,438 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,438 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,439 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,439 - DEBUG - max_retries: 8


2024-04-21 11:01:09,439 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f0bc40>


2024-04-21 11:01:09,441 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,442 - DEBUG - close.started


2024-04-21 11:01:09,442 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,443 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,443 - DEBUG - max_retries: 8


2024-04-21 11:01:09,443 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f08400>


2024-04-21 11:01:09,445 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,446 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,446 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,446 - DEBUG - max_retries: 8


2024-04-21 11:01:09,446 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f09210>


2024-04-21 11:01:09,448 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,449 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,450 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,450 - DEBUG - max_retries: 8


2024-04-21 11:01:09,450 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c68a90>


2024-04-21 11:01:09,452 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,453 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}


2024-04-21 11:01:09,453 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:01:09,453 - DEBUG - max_retries: 8


2024-04-21 11:01:09,454 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x121c68730>


2024-04-21 11:01:09,455 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @objktcom: The #OBJKT4OBJKT community event started yesterday!   \n\nWe were very impressed by the pieces we discovered and highlighted mo…\n\nFilter: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,456 - DEBUG - close.complete


2024-04-21 11:01:09,457 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,457 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,457 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,457 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,457 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,458 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,458 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,458 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,459 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,459 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,459 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,460 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,460 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,460 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,460 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,461 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,461 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,461 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,462 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,462 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,462 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,463 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,463 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,463 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,463 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,463 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,464 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,464 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,465 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,465 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,465 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,466 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,466 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,466 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,467 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,467 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,467 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,467 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,468 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,468 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,468 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,468 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,468 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,469 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,469 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,469 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,469 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,469 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,470 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,470 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,470 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,470 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,470 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,470 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,470 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,470 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,471 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,472 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,473 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,473 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,473 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,473 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,473 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,473 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,474 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,475 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,476 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,477 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,477 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,477 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,477 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,477 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,477 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,478 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,478 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,478 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,478 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,478 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,478 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,479 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,479 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,479 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,479 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,479 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,480 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,480 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,480 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,480 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,480 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,480 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,481 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,481 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,481 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,481 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,481 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,481 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,482 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,482 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,482 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,482 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,482 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,483 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:01:09,485 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c90e20>


2024-04-21 11:01:09,486 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,486 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f3b610>


2024-04-21 11:01:09,486 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,491 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c68f40>


2024-04-21 11:01:09,491 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,491 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c25c0>


2024-04-21 11:01:09,491 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,491 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f39a50>


2024-04-21 11:01:09,491 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,492 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e8070>


2024-04-21 11:01:09,492 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,493 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1150>


2024-04-21 11:01:09,493 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,493 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c685b0>


2024-04-21 11:01:09,493 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,493 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c1cc0>


2024-04-21 11:01:09,493 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,494 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c693f0>


2024-04-21 11:01:09,494 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,497 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6a9b0>


2024-04-21 11:01:09,497 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,497 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e67430>


2024-04-21 11:01:09,497 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,502 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc5ff0>


2024-04-21 11:01:09,502 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,502 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219f8400>


2024-04-21 11:01:09,502 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,502 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121cc04c0>


2024-04-21 11:01:09,502 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,502 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121ce8e50>


2024-04-21 11:01:09,502 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,504 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f3b790>


2024-04-21 11:01:09,505 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,505 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,505 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,505 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,505 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,505 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc4940>


2024-04-21 11:01:09,505 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,506 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c3b160>


2024-04-21 11:01:09,506 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,507 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,507 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,507 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,507 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,507 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc5120>


2024-04-21 11:01:09,507 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,507 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc6020>


2024-04-21 11:01:09,507 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,511 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c43850>


2024-04-21 11:01:09,511 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c1870>


2024-04-21 11:01:09,511 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121ce86d0>


2024-04-21 11:01:09,511 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,511 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,511 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,512 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,512 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,512 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,512 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,512 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,512 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,512 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc4370>


2024-04-21 11:01:09,512 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,513 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcfc10>


2024-04-21 11:01:09,513 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,514 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6abc0>


2024-04-21 11:01:09,514 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c0c40>


2024-04-21 11:01:09,514 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c437c0>


2024-04-21 11:01:09,514 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121996860>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,515 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,515 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,515 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,515 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,516 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,516 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,517 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,517 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc7cd0>


2024-04-21 11:01:09,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc6440>


2024-04-21 11:01:09,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,517 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,517 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,517 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,517 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,517 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,517 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,517 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219fae30>


2024-04-21 11:01:09,517 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,518 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c40fd0>


2024-04-21 11:01:09,518 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc7100>


2024-04-21 11:01:09,518 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,518 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e64b20>


2024-04-21 11:01:09,518 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,518 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc7970>


2024-04-21 11:01:09,518 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,518 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,519 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c2830>


2024-04-21 11:01:09,519 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,519 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,519 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,519 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c42ec0>


2024-04-21 11:01:09,519 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc6fe0>


2024-04-21 11:01:09,519 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218be110>


2024-04-21 11:01:09,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,520 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,520 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121b35b10>


2024-04-21 11:01:09,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df04f0>


2024-04-21 11:01:09,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df00d0>


2024-04-21 11:01:09,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,520 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df07f0>


2024-04-21 11:01:09,520 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,520 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,520 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,520 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,521 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,521 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df0280>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df3e80>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df2200>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df3880>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df2500>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df1d20>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df3a60>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,521 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218115a0>


2024-04-21 11:01:09,521 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,522 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,522 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,522 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc58a0>


2024-04-21 11:01:09,522 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,522 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,522 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,522 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df28c0>


2024-04-21 11:01:09,522 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,522 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2d690>


2024-04-21 11:01:09,522 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,522 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107dc4130>


2024-04-21 11:01:09,523 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,523 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df17b0>


2024-04-21 11:01:09,523 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,523 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf82b0>


2024-04-21 11:01:09,523 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,523 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121996740>


2024-04-21 11:01:09,523 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,524 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,524 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,524 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219fbcd0>


2024-04-21 11:01:09,524 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c90820>


2024-04-21 11:01:09,524 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f3bee0>


2024-04-21 11:01:09,524 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,524 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,524 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2ff10>


2024-04-21 11:01:09,524 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,525 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2fc70>


2024-04-21 11:01:09,525 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,525 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,525 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,525 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,525 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,525 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,525 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df2d10>


2024-04-21 11:01:09,525 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,526 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2f7c0>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c400>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,526 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df1c00>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e4d0>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107df00a0>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c3a0>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2c310>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d2d0>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2cf10>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,526 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d360>


2024-04-21 11:01:09,526 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,527 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e680>


2024-04-21 11:01:09,527 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,527 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e290>


2024-04-21 11:01:09,527 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,528 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219f84f0>


2024-04-21 11:01:09,528 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1079833a0>


2024-04-21 11:01:09,528 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d6c0>


2024-04-21 11:01:09,528 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,528 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2d240>


2024-04-21 11:01:09,528 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,528 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e9150>


2024-04-21 11:01:09,528 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,528 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e9e0>


2024-04-21 11:01:09,529 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,529 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218eaec0>


2024-04-21 11:01:09,529 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,529 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,529 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,529 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219f8e20>


2024-04-21 11:01:09,529 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,529 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,529 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,529 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,529 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,530 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,530 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcdc30>


2024-04-21 11:01:09,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcce20>


2024-04-21 11:01:09,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcdd80>


2024-04-21 11:01:09,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcf790>


2024-04-21 11:01:09,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,530 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,530 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,530 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,530 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcda80>


2024-04-21 11:01:09,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcc730>


2024-04-21 11:01:09,530 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,530 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcea10>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcf490>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcd9c0>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bcd240>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bccb50>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,531 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bce950>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1060>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6a290>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,531 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c426e0>


2024-04-21 11:01:09,531 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6a440>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c2e080>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c01f0>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121997b50>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121899870>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c42b90>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,532 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219fac20>


2024-04-21 11:01:09,532 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1066efd40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:01:09,534 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219f9ff0>


2024-04-21 11:01:09,534 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,534 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219fa140>


2024-04-21 11:01:09,534 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,534 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,534 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,534 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,534 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,534 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,535 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,535 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,535 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,537 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219c1180>


2024-04-21 11:01:09,537 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,537 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e89e40>


2024-04-21 11:01:09,537 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,537 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,537 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,538 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,538 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,538 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,538 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,538 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,538 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,539 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e88310>


2024-04-21 11:01:09,539 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c90b50>


2024-04-21 11:01:09,539 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121ceb010>


2024-04-21 11:01:09,539 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,539 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,539 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,539 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,539 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,539 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,539 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,539 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,539 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,540 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219fa470>


2024-04-21 11:01:09,540 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,540 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,540 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,540 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,540 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,540 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,540 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,540 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,540 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,541 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,541 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,541 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e64880>


2024-04-21 11:01:09,541 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e66b60>


2024-04-21 11:01:09,541 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e30ee0>


2024-04-21 11:01:09,542 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e66410>


2024-04-21 11:01:09,542 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e67850>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,542 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,542 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,542 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,542 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,542 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,542 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,544 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,544 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,544 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,544 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,545 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,545 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,545 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,545 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,545 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,545 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e65cc0>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e33f40>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193d1e0>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196f940>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196eef0>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e338b0>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196e770>


2024-04-21 11:01:09,545 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193fd90>


2024-04-21 11:01:09,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,546 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,547 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,547 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,547 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e33220>


2024-04-21 11:01:09,547 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196ca00>


2024-04-21 11:01:09,547 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107e67130>


2024-04-21 11:01:09,548 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,548 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,548 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,548 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,548 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,548 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,548 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,548 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,548 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,548 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,549 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,549 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,549 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,549 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189a680>


2024-04-21 11:01:09,549 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12196d600>


2024-04-21 11:01:09,549 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193f610>


2024-04-21 11:01:09,549 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bfc40>


2024-04-21 11:01:09,549 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf9210>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,552 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,552 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,552 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,552 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,552 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,553 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,553 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,553 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12193f8b0>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bf9a0>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bc340>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191abc0>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121898520>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121918430>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189ab90>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189b700>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bf85e0>


2024-04-21 11:01:09,553 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2f310>


2024-04-21 11:01:09,556 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,556 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,556 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,556 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,556 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,556 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,556 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,556 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,556 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,556 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,557 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,557 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,557 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,557 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1219181f0>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2f430>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218bf040>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191b160>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1390>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb38e0>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121811de0>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e9090>


2024-04-21 11:01:09,557 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121919c00>


2024-04-21 11:01:09,558 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,558 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,558 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,558 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,558 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,558 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,558 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,558 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,558 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,558 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,559 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,559 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,560 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,560 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,560 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12191b3a0>


2024-04-21 11:01:09,560 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1f90>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,565 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,565 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,565 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,565 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,565 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f095d0>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218ea7d0>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f0af80>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121cea980>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6af20>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f3b370>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f0bb20>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2f0a0>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c68bb0>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f2f3a0>


2024-04-21 11:01:09,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1218e9660>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1d50>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189a590>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb2710>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6b9a0>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121bb1780>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c686d0>


2024-04-21 11:01:09,567 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121810b80>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,567 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,568 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,568 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,568 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,568 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,568 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,568 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x121c6a320>


2024-04-21 11:01:09,569 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,569 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,569 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,569 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,569 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,569 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,569 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,569 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,570 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,570 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,570 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,570 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,571 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,571 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,847 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x12189b9a0>


2024-04-21 11:01:09,848 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:09,849 - DEBUG - send_request_headers.complete


2024-04-21 11:01:09,849 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:09,849 - DEBUG - send_request_body.complete


2024-04-21 11:01:09,849 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:10,046 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'365'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4923'), (b'x-ratelimit-remaining-tokens', b'588221'), (b'x-ratelimit-reset-requests', b'915ms'), (b'x-ratelimit-reset-tokens', b'1.177s'), (b'x-request-id', b'req_9ddad25fe2458f39ada48a2a2e4bb3b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeb3a0d18-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,047 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,047 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,048 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,048 - DEBUG - response_closed.started


2024-04-21 11:01:10,049 - DEBUG - response_closed.complete


2024-04-21 11:01:10,051 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,052 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvDNQDRrX0Jy4csEwEfdp4WirY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_re4jiiCPBK97fZCpvXTKzlnS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,054 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,055 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'483'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4998'), (b'x-ratelimit-remaining-tokens', b'599718'), (b'x-ratelimit-reset-requests', b'20ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_75552df145f60c57452757459b67b243'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3ad07bcd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,055 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,056 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,056 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,056 - DEBUG - response_closed.started


2024-04-21 11:01:10,057 - DEBUG - response_closed.complete


2024-04-21 11:01:10,058 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,059 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvSyzYKOLFqfEyoJDjQ64RoUaR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PnY0WS2b6E0uim0nPwqgwcA9', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=216, total_tokens=221))


2024-04-21 11:01:10,060 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,060 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'472'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4995'), (b'x-ratelimit-remaining-tokens', b'599301'), (b'x-ratelimit-reset-requests', b'53ms'), (b'x-ratelimit-reset-tokens', b'69ms'), (b'x-request-id', b'req_335c6c7e36e52b547431ae33cc29df19'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3a427edb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,061 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,061 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,062 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,062 - DEBUG - response_closed.started


2024-04-21 11:01:10,062 - DEBUG - response_closed.complete


2024-04-21 11:01:10,063 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,064 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv1Qg1eesH71msgnagPzfYqwR7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_oCc9NkC8taGcmUStVYxXUS22', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,065 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,066 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599850'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'15ms'), (b'x-request-id', b'req_13fca822064e170e76dadb498a1b84e5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3f447d12-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,067 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,067 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,067 - DEBUG - response_closed.started


2024-04-21 11:01:10,067 - DEBUG - response_closed.complete


2024-04-21 11:01:10,068 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,069 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv4zf4bzoMqAD4zdWW6ZRLbJkO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_SyG3LvJgPit9bPYFfWEJqeFp', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,070 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,079 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4942'), (b'x-ratelimit-remaining-tokens', b'591043'), (b'x-ratelimit-reset-requests', b'693ms'), (b'x-ratelimit-reset-tokens', b'895ms'), (b'x-request-id', b'req_ac4e802f915841c5ba8f73916fef1bed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ad9172b90-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,080 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,080 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,080 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,080 - DEBUG - response_closed.started


2024-04-21 11:01:10,080 - DEBUG - response_closed.complete


2024-04-21 11:01:10,081 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,082 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvGJiinXO3WfSDxtd9XHT8WLPh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_EgS2gOP2bWE4Ul4ePVgTC4SX', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,082 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,084 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'398'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4930'), (b'x-ratelimit-remaining-tokens', b'589246'), (b'x-ratelimit-reset-requests', b'833ms'), (b'x-ratelimit-reset-tokens', b'1.075s'), (b'x-request-id', b'req_db095750cc375ca6fe4145c0b616f620'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeec469d1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,084 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,085 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,085 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,085 - DEBUG - response_closed.started


2024-04-21 11:01:10,086 - DEBUG - response_closed.complete


2024-04-21 11:01:10,087 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,087 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvrQlqOgzo0bNq5DV5oscAT4pO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3idiDnLVMzdyKCMwquklAaiH', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,088 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,088 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'403'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4951'), (b'x-ratelimit-remaining-tokens', b'592415'), (b'x-ratelimit-reset-requests', b'580ms'), (b'x-ratelimit-reset-tokens', b'758ms'), (b'x-request-id', b'req_68447dd97cca4049fb8c0c2011cb8c8f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471add492ee5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,089 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,089 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,089 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,089 - DEBUG - response_closed.started


2024-04-21 11:01:10,090 - DEBUG - response_closed.complete


2024-04-21 11:01:10,090 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,091 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvqnH19QiluljOW91rxfB2KGw4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_2wnSRMqXCW3haf6ILdlegFE5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,091 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,097 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'419'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4927'), (b'x-ratelimit-remaining-tokens', b'588866'), (b'x-ratelimit-reset-requests', b'868ms'), (b'x-ratelimit-reset-tokens', b'1.113s'), (b'x-request-id', b'req_a016676a88414285ae5c222568e486da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeb717bd4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,098 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,098 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,098 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,098 - DEBUG - response_closed.started


2024-04-21 11:01:10,098 - DEBUG - response_closed.complete


2024-04-21 11:01:10,099 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,100 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvTbMBdkDDiKc6yk44uUoYCc3O', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PjccJNcSCwVew1XM18KEVri7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,100 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,106 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'368'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4916'), (b'x-ratelimit-remaining-tokens', b'586908'), (b'x-ratelimit-reset-requests', b'1.007s'), (b'x-ratelimit-reset-tokens', b'1.309s'), (b'x-request-id', b'req_c78dc4ba1b71f7f4ce4ffc4fa09c7a3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ac90c2f03-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,106 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,106 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,106 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,107 - DEBUG - response_closed.started


2024-04-21 11:01:10,107 - DEBUG - response_closed.complete


2024-04-21 11:01:10,108 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,108 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvNL8LnhAZxhLc60gH3uSjgScX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wz5Y7bBp0A2TQZbkhc94GTLq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,109 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,109 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'479'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4983'), (b'x-ratelimit-remaining-tokens', b'597321'), (b'x-ratelimit-reset-requests', b'197ms'), (b'x-ratelimit-reset-tokens', b'267ms'), (b'x-request-id', b'req_04d923e75813eab7da094832cf97feb9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9d902b89-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,109 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,109 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,112 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,112 - DEBUG - response_closed.started


2024-04-21 11:01:10,113 - DEBUG - response_closed.complete


2024-04-21 11:01:10,114 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,114 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvQ6n7OTzGW6K5SzuhfMOrGVIC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rS7fUOJYSm4xcwUwKYBsS3C1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,115 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,123 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4925'), (b'x-ratelimit-remaining-tokens', b'588533'), (b'x-ratelimit-reset-requests', b'890ms'), (b'x-ratelimit-reset-tokens', b'1.146s'), (b'x-request-id', b'req_0350ab8eb75424050e4775da7f7243d4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aed6a2aab-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,123 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,123 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,123 - DEBUG - response_closed.started


2024-04-21 11:01:10,124 - DEBUG - response_closed.complete


2024-04-21 11:01:10,125 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,125 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv35wxIaWPVVlXG2JLclTKCT0e', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i7UwYONmjEt0IzAvlmdyKDCk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,126 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,127 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'473'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4975'), (b'x-ratelimit-remaining-tokens', b'596113'), (b'x-ratelimit-reset-requests', b'291ms'), (b'x-ratelimit-reset-tokens', b'388ms'), (b'x-request-id', b'req_16d305381251ba2d9fe7bca525a53783'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ab9117bc1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,127 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,127 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,127 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,127 - DEBUG - response_closed.started


2024-04-21 11:01:10,128 - DEBUG - response_closed.complete


2024-04-21 11:01:10,129 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,129 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvdLtRACc8EvHc28ZdIFEX8mfu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_seYsqiBWhxucy9VmGxe7qQpD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,130 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,130 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'455'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4950'), (b'x-ratelimit-remaining-tokens', b'592270'), (b'x-ratelimit-reset-requests', b'597ms'), (b'x-ratelimit-reset-tokens', b'772ms'), (b'x-request-id', b'req_e674d3f8a0ebeb04b139dbd808483158'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471adcf22ad8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,131 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,131 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,131 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,131 - DEBUG - response_closed.started


2024-04-21 11:01:10,132 - DEBUG - response_closed.complete


2024-04-21 11:01:10,133 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,133 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvPvWiHLN69RBAtCOVnuRGdRJd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NNWiAkzfxyHuAbO2D1dJLWwg', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,134 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,134 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'507'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'598134'), (b'x-ratelimit-reset-requests', b'134ms'), (b'x-ratelimit-reset-tokens', b'186ms'), (b'x-request-id', b'req_87ffabb3ba25f19c46e60dfaaeef7b51'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9c9a7c97-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,135 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,135 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,135 - DEBUG - response_closed.started


2024-04-21 11:01:10,135 - DEBUG - response_closed.complete


2024-04-21 11:01:10,136 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,137 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvI01TG4EEvCvMUMZfUbPEFFph', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7GIZH4fO5eloqAcIuCy5uESu', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,137 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,138 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'518'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598650'), (b'x-ratelimit-reset-requests', b'94ms'), (b'x-ratelimit-reset-tokens', b'134ms'), (b'x-request-id', b'req_4c69dc1df73fe306396624338afad8a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a8f810fed-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,138 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,138 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,138 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,138 - DEBUG - response_closed.started


2024-04-21 11:01:10,138 - DEBUG - response_closed.complete


2024-04-21 11:01:10,140 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,140 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv5W8yC3NajqCwdmS7y5y7gRfi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_K5vldmMSsIP2s5HGaG7BmfSy', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,140 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,141 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'464'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'591730'), (b'x-ratelimit-reset-requests', b'642ms'), (b'x-ratelimit-reset-tokens', b'826ms'), (b'x-request-id', b'req_cbaf8b3242b57807253c06b8ca62b78e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ad9fd2ee7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,141 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,141 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,141 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,141 - DEBUG - response_closed.started


2024-04-21 11:01:10,141 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'506'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4981'), (b'x-ratelimit-remaining-tokens', b'597039'), (b'x-ratelimit-reset-requests', b'219ms'), (b'x-ratelimit-reset-tokens', b'296ms'), (b'x-request-id', b'req_4b0323c0ad51eff6f7b7277f23c89483'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9b790fcd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,142 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,142 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,142 - DEBUG - response_closed.started


2024-04-21 11:01:10,142 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'477'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'593713'), (b'x-ratelimit-reset-requests', b'480ms'), (b'x-ratelimit-reset-tokens', b'628ms'), (b'x-request-id', b'req_9ffd5a82e361a5d1af7bc69302e6d8fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471acc2c1025-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,143 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,143 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,143 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,143 - DEBUG - response_closed.started


2024-04-21 11:01:10,143 - DEBUG - response_closed.complete


2024-04-21 11:01:10,144 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,145 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvDxMUihbGWis2zd6o2Oii5PcE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jgeaDbl3czq2oQjR3Use9POi', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,145 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,145 - DEBUG - response_closed.complete


2024-04-21 11:01:10,146 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,147 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvWvJZtRdgEtDahaB2Pet0zxhX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jqH7izcPFZbmHrWfia6eeA2K', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,147 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,147 - DEBUG - response_closed.complete


2024-04-21 11:01:10,148 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,149 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvU0MBSX3W4fhSbNlMm4zQKH6c', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_DQYPWbWTKY3GfxEDDgcLFQL3', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,149 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,149 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'408'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4987'), (b'x-ratelimit-remaining-tokens', b'597922'), (b'x-ratelimit-reset-requests', b'152ms'), (b'x-ratelimit-reset-tokens', b'207ms'), (b'x-request-id', b'req_e0a9b4a8a12fda68068471bdde7ad473'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a8c6a0ff3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,149 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,150 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,150 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,150 - DEBUG - response_closed.started


2024-04-21 11:01:10,151 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4972'), (b'x-ratelimit-remaining-tokens', b'595558'), (b'x-ratelimit-reset-requests', b'334ms'), (b'x-ratelimit-reset-tokens', b'444ms'), (b'x-request-id', b'req_cc9dbf182ea6ff95469643ebe709bc25'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ab8332f08-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,151 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,151 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,151 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,151 - DEBUG - response_closed.started


2024-04-21 11:01:10,151 - DEBUG - response_closed.complete


2024-04-21 11:01:10,153 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,153 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvoRYfdgsVWvOsTBE0WfZpJKEQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fZD8dEmtFRyzEuZL5wbn6lS8', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,153 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,153 - DEBUG - response_closed.complete


2024-04-21 11:01:10,154 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,155 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvQzj3yYMGtcdepl9HfHL8Fj64', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8QnfxZchuULjzlK8WrGqNmJv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,155 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,155 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'458'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4924'), (b'x-ratelimit-remaining-tokens', b'588380'), (b'x-ratelimit-reset-requests', b'902ms'), (b'x-ratelimit-reset-tokens', b'1.161s'), (b'x-request-id', b'req_c7b621577cde4cf0f5a1cba7ca7a6e99'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aebc62ad0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,156 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,156 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,156 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,156 - DEBUG - response_closed.started


2024-04-21 11:01:10,156 - DEBUG - response_closed.complete


2024-04-21 11:01:10,158 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,158 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmve4gqKrOp9bIN5dh2WyD3LOOF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_sOluup3ikObvtbQAZcq9dj7i', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,158 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,158 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'599168'), (b'x-ratelimit-reset-requests', b'63ms'), (b'x-ratelimit-reset-tokens', b'83ms'), (b'x-request-id', b'req_8abcd991dbf82957b2c66d5411893e18'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3bf069b8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,159 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,159 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,159 - DEBUG - response_closed.started


2024-04-21 11:01:10,159 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'424'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597719'), (b'x-ratelimit-reset-requests', b'169ms'), (b'x-ratelimit-reset-tokens', b'228ms'), (b'x-request-id', b'req_02701f5763cdf764b527a6a58a7e9435'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9c337ba7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,159 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,159 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,160 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,160 - DEBUG - response_closed.started


2024-04-21 11:01:10,160 - DEBUG - response_closed.complete


2024-04-21 11:01:10,161 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,161 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv2g8e8fRvNEAjgp2Eb3LzKlpm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_hD4HF1lMM6nxMsPvkpOrt8y5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,162 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,162 - DEBUG - response_closed.complete


2024-04-21 11:01:10,163 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,163 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvWUruVx7aUz6nMwhlKN2z0Bt4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UmdQGGwaHiYS0s6G7i6sjbQD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,163 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,164 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'484'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4934'), (b'x-ratelimit-remaining-tokens', b'589855'), (b'x-ratelimit-reset-requests', b'785ms'), (b'x-ratelimit-reset-tokens', b'1.014s'), (b'x-request-id', b'req_e35ba8fbf1c9197358abdbfe88173d33'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ad9b77bc5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,164 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,164 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,164 - DEBUG - response_closed.started


2024-04-21 11:01:10,164 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'407'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4965'), (b'x-ratelimit-remaining-tokens', b'594528'), (b'x-ratelimit-reset-requests', b'416ms'), (b'x-ratelimit-reset-tokens', b'547ms'), (b'x-request-id', b'req_9a1fa2f8e741842a22ea3cdd44b79afe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aabe52f04-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,164 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,164 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,165 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,165 - DEBUG - response_closed.started


2024-04-21 11:01:10,165 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'444'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4989'), (b'x-ratelimit-remaining-tokens', b'598300'), (b'x-ratelimit-reset-requests', b'120ms'), (b'x-ratelimit-reset-tokens', b'169ms'), (b'x-request-id', b'req_8c06ec9a67568050401f3a7430037db8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a8ad469b5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,165 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,165 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,165 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,165 - DEBUG - response_closed.started


2024-04-21 11:01:10,165 - DEBUG - response_closed.complete


2024-04-21 11:01:10,167 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,167 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvnSLCAg7UAgSghjSEAxiLZavs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i7UwYONmjEt0IzAvlmdyKDCk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,167 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,167 - DEBUG - response_closed.complete


2024-04-21 11:01:10,169 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,169 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvRjreOQU1O1gLOkBsExZDK77R', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3DsSZw0pqXAuKovwZkvdiI43', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,169 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,169 - DEBUG - response_closed.complete


2024-04-21 11:01:10,170 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,171 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvqCSZjVhQMaF06524NmMhFFtD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eYpBLyocVGhkvYYNXbc4Ezqj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,171 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,171 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'396'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'588088'), (b'x-ratelimit-reset-requests', b'925ms'), (b'x-ratelimit-reset-tokens', b'1.191s'), (b'x-request-id', b'req_016ea8880e200bf9ba5741c052bfb215'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeb912b55-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,171 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,171 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,171 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,171 - DEBUG - response_closed.started


2024-04-21 11:01:10,172 - DEBUG - response_closed.complete


2024-04-21 11:01:10,173 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,173 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvZ3q1DzhBB2jY9R3r2mNqRC2X', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Fn6lJJO3IIw44nESR6pLwEyx', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,173 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,187 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'515'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4997'), (b'x-ratelimit-remaining-tokens', b'599582'), (b'x-ratelimit-reset-requests', b'31ms'), (b'x-ratelimit-reset-tokens', b'41ms'), (b'x-request-id', b'req_22b32ee9120fb515892717427cc0492e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3d3b2acc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,187 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,187 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,187 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,187 - DEBUG - response_closed.started


2024-04-21 11:01:10,187 - DEBUG - response_closed.complete


2024-04-21 11:01:10,189 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,189 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvCnvTeXxwX5jUV2kRL6IbWwR8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8QnfxZchuULjzlK8WrGqNmJv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,189 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,196 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'428'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4952'), (b'x-ratelimit-remaining-tokens', b'592580'), (b'x-ratelimit-reset-requests', b'569ms'), (b'x-ratelimit-reset-tokens', b'741ms'), (b'x-request-id', b'req_1bb96875f9f48d48aaf275eb4bb8fc7a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ade1c83f7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,196 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,196 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,196 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,196 - DEBUG - response_closed.started


2024-04-21 11:01:10,196 - DEBUG - response_closed.complete


2024-04-21 11:01:10,198 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,198 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvM00E4sKIWM3nspcXiFj1NacA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0TPtdFyCYBq0d88ppPm2fFm6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,198 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,199 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4941'), (b'x-ratelimit-remaining-tokens', b'590833'), (b'x-ratelimit-reset-requests', b'705ms'), (b'x-ratelimit-reset-tokens', b'916ms'), (b'x-request-id', b'req_b7e49e1672cf87dc359a4e8a0d79ddd7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeddf2ad5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,199 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,199 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,199 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,199 - DEBUG - response_closed.started


2024-04-21 11:01:10,199 - DEBUG - response_closed.complete


2024-04-21 11:01:10,201 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,201 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvzEgrlSqO5XNNR8pLsWYy3mRj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yQxmicVOLam4FEs25hrYiejh', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,201 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,208 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'528'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598713'), (b'x-ratelimit-reset-requests', b'91ms'), (b'x-ratelimit-reset-tokens', b'128ms'), (b'x-request-id', b'req_b35446325d456e0c5b2412bd31320ea4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a4d28092d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,208 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,208 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,208 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,208 - DEBUG - response_closed.started


2024-04-21 11:01:10,209 - DEBUG - response_closed.complete


2024-04-21 11:01:10,210 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,210 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvvSOHKyWlFKSCK5584I2ueVmF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YVajdyd3pbKO81ATpnUwjCSP', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,211 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,212 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'429'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4927'), (b'x-ratelimit-remaining-tokens', b'588712'), (b'x-ratelimit-reset-requests', b'875ms'), (b'x-ratelimit-reset-tokens', b'1.128s'), (b'x-request-id', b'req_3e40bfc1fa658cf9a00ab708a6f873fd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aea322b57-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,212 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,212 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,212 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,212 - DEBUG - response_closed.started


2024-04-21 11:01:10,212 - DEBUG - response_closed.complete


2024-04-21 11:01:10,214 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,214 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvvCijhizzpsmftw8CvpRdGJy7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_USqujvfN9yue2W5z1n9ekKS1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,215 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,215 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'449'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4954'), (b'x-ratelimit-remaining-tokens', b'592848'), (b'x-ratelimit-reset-requests', b'548ms'), (b'x-ratelimit-reset-tokens', b'715ms'), (b'x-request-id', b'req_c98d0ae2656e965eab22202cb5a34f50'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471acef93215-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,215 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,215 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,215 - DEBUG - response_closed.started


2024-04-21 11:01:10,215 - DEBUG - response_closed.complete


2024-04-21 11:01:10,217 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,217 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvJoXtAQTTxYCgepRDR3fEHjsN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3LAme8J21m2tkJOaEHdHETR5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,218 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,218 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'542'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598742'), (b'x-ratelimit-reset-requests', b'94ms'), (b'x-ratelimit-reset-tokens', b'125ms'), (b'x-request-id', b'req_ed18b7e66724e978a10079c4139cafb8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a4e192f5f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,218 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,218 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,218 - DEBUG - response_closed.started


2024-04-21 11:01:10,218 - DEBUG - response_closed.complete


2024-04-21 11:01:10,220 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,220 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvHvE0g3FOHrGCgCZNRQy8uxXg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4q7qFzRO2IpdjNgkj0zl04jt', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=216, total_tokens=221))


2024-04-21 11:01:10,220 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,221 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'477'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4973'), (b'x-ratelimit-remaining-tokens', b'595805'), (b'x-ratelimit-reset-requests', b'316ms'), (b'x-ratelimit-reset-tokens', b'419ms'), (b'x-request-id', b'req_65e3c93fcf6552164a9aa0cf8492bc09'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471abf5f2f2f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,221 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,221 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,221 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,221 - DEBUG - response_closed.started


2024-04-21 11:01:10,221 - DEBUG - response_closed.complete


2024-04-21 11:01:10,223 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,223 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvhThpaNLmLkKaJ4ptVa4HDre0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_6NTpLCyzGB1PueWvcCPJAwvc', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,223 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,224 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4932'), (b'x-ratelimit-remaining-tokens', b'589526'), (b'x-ratelimit-reset-requests', b'811ms'), (b'x-ratelimit-reset-tokens', b'1.047s'), (b'x-request-id', b'req_9057471e2e2aac730275c3188b9fe9a5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aed980fbd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,224 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,224 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,224 - DEBUG - response_closed.started


2024-04-21 11:01:10,224 - DEBUG - response_closed.complete


2024-04-21 11:01:10,226 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,226 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvS45ueCp8YNeup7Ph401V5kA1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i1NGoFx3O1Nbk4tamqSNkQX4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,226 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,234 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'541'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4990'), (b'x-ratelimit-remaining-tokens', b'598479'), (b'x-ratelimit-reset-requests', b'117ms'), (b'x-ratelimit-reset-tokens', b'152ms'), (b'x-request-id', b'req_35664506ab9d452d76644eb4daa2b957'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a4f941039-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,235 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,235 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,235 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,235 - DEBUG - response_closed.started


2024-04-21 11:01:10,235 - DEBUG - response_closed.complete


2024-04-21 11:01:10,237 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,237 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvd3pvUw2xqtbDf3x4jD3nAunc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ow4iLkzsVmPEF3HabZG9NW8U', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,237 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,237 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'589'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599425'), (b'x-ratelimit-reset-requests', b'44ms'), (b'x-ratelimit-reset-tokens', b'57ms'), (b'x-request-id', b'req_ab0caca368b045557d0498b6726344b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3d1d14fc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,237 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,237 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,237 - DEBUG - response_closed.started


2024-04-21 11:01:10,238 - DEBUG - response_closed.complete


2024-04-21 11:01:10,239 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,240 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvTILl2NwphLLnwbk3sthBi64H', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_LGASOpRrcE8fVvowjx2oY8NN', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,240 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,242 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'468'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4942'), (b'x-ratelimit-remaining-tokens', b'591024'), (b'x-ratelimit-reset-requests', b'692ms'), (b'x-ratelimit-reset-tokens', b'897ms'), (b'x-request-id', b'req_a69cc3aa9e1c159e178f137e99930eda'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aed0e7be9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,242 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,242 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,242 - DEBUG - response_closed.started


2024-04-21 11:01:10,242 - DEBUG - response_closed.complete


2024-04-21 11:01:10,244 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,245 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvjUgRYPwN1pCuX60mY8HVG90e', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_auevcPpNS7otYcI6T4p5jmaq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,245 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,250 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'605'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4979'), (b'x-ratelimit-remaining-tokens', b'596654'), (b'x-ratelimit-reset-requests', b'249ms'), (b'x-ratelimit-reset-tokens', b'334ms'), (b'x-request-id', b'req_1f7b480e8c30d44a1b905f655e2f8210'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aaf122f10-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,250 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,250 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,251 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,251 - DEBUG - response_closed.started


2024-04-21 11:01:10,251 - DEBUG - response_closed.complete


2024-04-21 11:01:10,253 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,253 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvPhuu7Af5AIDNAFVurKBNDiia', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3idiDnLVMzdyKCMwquklAaiH', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,253 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,254 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'476'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4933'), (b'x-ratelimit-remaining-tokens', b'589788'), (b'x-ratelimit-reset-requests', b'794ms'), (b'x-ratelimit-reset-tokens', b'1.021s'), (b'x-request-id', b'req_ab6280b655d9b834b0f5b4dfc839c5a8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ae87f7c86-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,254 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,254 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,254 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,254 - DEBUG - response_closed.started


2024-04-21 11:01:10,254 - DEBUG - response_closed.complete


2024-04-21 11:01:10,256 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,256 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvzXhhmY7zuDTwbZXML6xkzrjh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9HQMgdnZEOx6cK26T0re8ftD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,256 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,258 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4953'), (b'x-ratelimit-remaining-tokens', b'592742'), (b'x-ratelimit-reset-requests', b'556ms'), (b'x-ratelimit-reset-tokens', b'725ms'), (b'x-request-id', b'req_44670bef98c1377ce85c400dc5635678'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471acdc3092d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,258 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,258 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,258 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,258 - DEBUG - response_closed.started


2024-04-21 11:01:10,258 - DEBUG - response_closed.complete


2024-04-21 11:01:10,260 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,260 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvl3BduBWPFYZ6tXF6E8lDtO3u', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_c0e5BOayxxclsiInWBhKKg0k', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,260 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,261 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'467'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4920'), (b'x-ratelimit-remaining-tokens', b'587794'), (b'x-ratelimit-reset-requests', b'949ms'), (b'x-ratelimit-reset-tokens', b'1.22s'), (b'x-request-id', b'req_f18d668a1d109ea09db6c82c489d03d7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeec47ecf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,261 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,261 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,261 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,261 - DEBUG - response_closed.started


2024-04-21 11:01:10,261 - DEBUG - response_closed.complete


2024-04-21 11:01:10,263 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,263 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvPRyZSvv5SJayZM2Eh2sZstFP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OPSgvryV16Y7RkIzUzENY54O', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,264 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,270 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'626'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4980'), (b'x-ratelimit-remaining-tokens', b'596799'), (b'x-ratelimit-reset-requests', b'237ms'), (b'x-ratelimit-reset-tokens', b'320ms'), (b'x-request-id', b'req_02582209ccba8863265b3e79ffc80729'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aa98ddbd9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,270 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,271 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,271 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,271 - DEBUG - response_closed.started


2024-04-21 11:01:10,271 - DEBUG - response_closed.complete


2024-04-21 11:01:10,273 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,273 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvGRtlOMBWcNiQlI1ilkkVUqur', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zBd6VkhJxucbm6gh3sgrfckq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,273 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,273 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'541'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4918'), (b'x-ratelimit-remaining-tokens', b'587500'), (b'x-ratelimit-reset-requests', b'975ms'), (b'x-ratelimit-reset-tokens', b'1.249s'), (b'x-request-id', b'req_fecc1b631eef84ecfc9cd5ebba41bf77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aea885257-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,274 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,274 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,274 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,274 - DEBUG - response_closed.started


2024-04-21 11:01:10,274 - DEBUG - response_closed.complete


2024-04-21 11:01:10,276 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,276 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv5Edetvc0GIxc1PDZdMQfXc3f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8Ae8y0NrtnXLEYy9IrUUgMKc', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,276 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,277 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'586785'), (b'x-ratelimit-reset-requests', b'1.029s'), (b'x-ratelimit-reset-tokens', b'1.321s'), (b'x-request-id', b'req_248c813f9023e47c53c00cab81421ad5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471adb022f3e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,277 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,277 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,277 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,277 - DEBUG - response_closed.started


2024-04-21 11:01:10,277 - DEBUG - response_closed.complete


2024-04-21 11:01:10,279 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,279 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvRJCQly3JItlIk4TC68c1c9sz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zFYSC1wLTjF272o7bvGePBwv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,280 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,280 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'589'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'591726'), (b'x-ratelimit-reset-requests', b'636ms'), (b'x-ratelimit-reset-tokens', b'827ms'), (b'x-request-id', b'req_4682a4cd7cc5c825e46d2f5cc2e6d439'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ade082b7c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,280 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,280 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,280 - DEBUG - response_closed.started


2024-04-21 11:01:10,280 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'591'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4991'), (b'x-ratelimit-remaining-tokens', b'598510'), (b'x-ratelimit-reset-requests', b'105ms'), (b'x-ratelimit-reset-tokens', b'148ms'), (b'x-request-id', b'req_f6b40e10c8e8196520b1740469b53fb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a8dc21008-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,281 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,281 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,281 - DEBUG - response_closed.started


2024-04-21 11:01:10,281 - DEBUG - response_closed.complete


2024-04-21 11:01:10,283 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,283 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv3Atq2MB6pbHQrcoMohhjfR8E', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_U9lCe4S2N62KiNTqqBFwX98T', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,283 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,283 - DEBUG - response_closed.complete


2024-04-21 11:01:10,285 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,286 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvrYCU3uS3zxhQzjFUG9ZfEQw1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_LKYKOFfH3yiSgtMouVhzTZ8P', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,286 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,286 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'631'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4972'), (b'x-ratelimit-remaining-tokens', b'595688'), (b'x-ratelimit-reset-requests', b'324ms'), (b'x-ratelimit-reset-tokens', b'431ms'), (b'x-request-id', b'req_6a1948a4ef0672a25d70d940e40857aa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ab82d31fd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,286 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,286 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,286 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,286 - DEBUG - response_closed.started


2024-04-21 11:01:10,286 - DEBUG - response_closed.complete


2024-04-21 11:01:10,289 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,289 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvxrrmM81GLl7OlTZGaEUveMc1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i7UwYONmjEt0IzAvlmdyKDCk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,289 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,289 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'508'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4928'), (b'x-ratelimit-remaining-tokens', b'588954'), (b'x-ratelimit-reset-requests', b'857ms'), (b'x-ratelimit-reset-tokens', b'1.104s'), (b'x-request-id', b'req_b907971e5363cfff2a2fec21b5e67b37'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aef02db86-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,289 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,289 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,289 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,289 - DEBUG - response_closed.started


2024-04-21 11:01:10,289 - DEBUG - response_closed.complete


2024-04-21 11:01:10,292 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,292 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvpNltH0BLUFYJNZBcDcl6DqfZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Y2FX9OeKIVOJ2nuymLkuXaPE', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,292 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,292 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'520'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4938'), (b'x-ratelimit-remaining-tokens', b'590429'), (b'x-ratelimit-reset-requests', b'739ms'), (b'x-ratelimit-reset-tokens', b'957ms'), (b'x-request-id', b'req_780db795d40dabf741046d1ab19f30d3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ae9457d80-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,292 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,292 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,292 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,292 - DEBUG - response_closed.started


2024-04-21 11:01:10,292 - DEBUG - response_closed.complete


2024-04-21 11:01:10,294 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,295 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvJtO7PcPCAKqPsROL13MOeZMV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_DJHlcK162BZpkqQzdBY1Dxn9', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,295 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,296 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'496'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'586779'), (b'x-ratelimit-reset-requests', b'1.026s'), (b'x-ratelimit-reset-tokens', b'1.322s'), (b'x-request-id', b'req_c79086b578840bfafd11748a414999a6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aefab52e9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,296 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,296 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,296 - DEBUG - response_closed.started


2024-04-21 11:01:10,296 - DEBUG - response_closed.complete


2024-04-21 11:01:10,298 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,298 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvkiqd3ILj2EfKnCqUF7sUFrFS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9vD5N8G5p3LGNP9Ta7mmjvKz', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,298 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,298 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'513'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'591594'), (b'x-ratelimit-reset-requests', b'647ms'), (b'x-ratelimit-reset-tokens', b'840ms'), (b'x-request-id', b'req_8769693a99f817d7b65707cd942597ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471addcd7e9c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,299 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,299 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,299 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,299 - DEBUG - response_closed.started


2024-04-21 11:01:10,299 - DEBUG - response_closed.complete


2024-04-21 11:01:10,301 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,301 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv0bzuOODhhyKVMFWonNLlb7Dj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9HQMgdnZEOx6cK26T0re8ftD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,301 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,302 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'608'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4917'), (b'x-ratelimit-remaining-tokens', b'587304'), (b'x-ratelimit-reset-requests', b'989ms'), (b'x-ratelimit-reset-tokens', b'1.269s'), (b'x-request-id', b'req_e0a5ed1271bba1d70d375ce66213c031'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ae9a37c29-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,302 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,302 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,302 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,302 - DEBUG - response_closed.started


2024-04-21 11:01:10,302 - DEBUG - response_closed.complete


2024-04-21 11:01:10,304 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,305 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvn2zVEkULhbpiziL5BxVXJwTL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YazhfGlBW02mroJjthoukTpO', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,305 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,305 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'544'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'587919'), (b'x-ratelimit-reset-requests', b'939ms'), (b'x-ratelimit-reset-tokens', b'1.208s'), (b'x-request-id', b'req_2a79033bf02013b2e8e21fa9c25d5397'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471add532aab-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,305 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,305 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,305 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,305 - DEBUG - response_closed.started


2024-04-21 11:01:10,305 - DEBUG - response_closed.complete


2024-04-21 11:01:10,307 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,307 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvenGNBZ0gaOh4qMPLhFNq7YdT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PgiWUp76a36ryiUEQFMX7TR4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,308 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,308 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'646'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4969'), (b'x-ratelimit-remaining-tokens', b'595115'), (b'x-ratelimit-reset-requests', b'370ms'), (b'x-ratelimit-reset-tokens', b'488ms'), (b'x-request-id', b'req_ff57bd59c5d9562c8a6202d11c137826'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471abe4d28f2-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,308 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,308 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,308 - DEBUG - response_closed.started


2024-04-21 11:01:10,308 - DEBUG - response_closed.complete


2024-04-21 11:01:10,310 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,311 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvTYT5tZ9C6Xl3FlahE3e6Qkem', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_rFTv2vih2u8Q6FGr7oiuyf8R', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,311 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,317 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'533'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4936'), (b'x-ratelimit-remaining-tokens', b'590116'), (b'x-ratelimit-reset-requests', b'764ms'), (b'x-ratelimit-reset-tokens', b'988ms'), (b'x-request-id', b'req_b6d1476dd8c8258aea1f99787f36d628'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aefef090e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,317 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,317 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,317 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,317 - DEBUG - response_closed.started


2024-04-21 11:01:10,317 - DEBUG - response_closed.complete


2024-04-21 11:01:10,320 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,320 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvQyaZ5GvtyiiIh6RDfIFqD2JK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9HQMgdnZEOx6cK26T0re8ftD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,320 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,320 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4917'), (b'x-ratelimit-remaining-tokens', b'587338'), (b'x-ratelimit-reset-requests', b'988ms'), (b'x-ratelimit-reset-tokens', b'1.266s'), (b'x-request-id', b'req_7684111cc48de1306016bfec1b5d63f3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ada967eba-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,320 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,320 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,320 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,320 - DEBUG - response_closed.started


2024-04-21 11:01:10,321 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'626'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4939'), (b'x-ratelimit-remaining-tokens', b'590582'), (b'x-ratelimit-reset-requests', b'727ms'), (b'x-ratelimit-reset-tokens', b'941ms'), (b'x-request-id', b'req_b2c7b774a317a7dde1dee5b2123198c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ae9b70cdf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,321 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,321 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,321 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,321 - DEBUG - response_closed.started


2024-04-21 11:01:10,321 - DEBUG - response_closed.complete


2024-04-21 11:01:10,323 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,323 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvfRG0rUTV5VTlbiUgWO3SquWw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_26C5FLuR2tKHECzaHtImK0zt', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,323 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,323 - DEBUG - response_closed.complete


2024-04-21 11:01:10,326 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,326 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmveLHDBxKiFU854rBCLf5sASx9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Oh1nydCyFOV3ISjL2LWit998', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,326 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,326 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4937'), (b'x-ratelimit-remaining-tokens', b'590265'), (b'x-ratelimit-reset-requests', b'753ms'), (b'x-ratelimit-reset-tokens', b'973ms'), (b'x-request-id', b'req_5b837e24d47bacfacbd6907c0457d808'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aed060fd3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,326 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,326 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,326 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,326 - DEBUG - response_closed.started


2024-04-21 11:01:10,326 - DEBUG - response_closed.complete


2024-04-21 11:01:10,328 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,329 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvvmwRYruxOH4eINVwI3alkR33', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7xtQgVWgxGpA40DWDK9B25LT', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,329 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,331 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'625'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4916'), (b'x-ratelimit-remaining-tokens', b'587079'), (b'x-ratelimit-reset-requests', b'1.005s'), (b'x-ratelimit-reset-tokens', b'1.292s'), (b'x-request-id', b'req_32beb9751556ce59d0a393cce4c00312'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aebe40d58-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,331 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,331 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,331 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,331 - DEBUG - response_closed.started


2024-04-21 11:01:10,331 - DEBUG - response_closed.complete


2024-04-21 11:01:10,334 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,334 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvTiBBeSVvpD6ZMIbBqtB6vF7n', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yVrt7Pyi5KOt8EnGFSF085in', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,334 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,334 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'539'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4967'), (b'x-ratelimit-remaining-tokens', b'594850'), (b'x-ratelimit-reset-requests', b'390ms'), (b'x-ratelimit-reset-tokens', b'514ms'), (b'x-request-id', b'req_c1273b5a54af944c60668b5477958c1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471abdf45355-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,334 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,334 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,334 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,334 - DEBUG - response_closed.started


2024-04-21 11:01:10,334 - DEBUG - response_closed.complete


2024-04-21 11:01:10,337 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,337 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvid6E4cTx65FP6W7rwz9wFh0Z', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_KpEmXRzqX1qji2lzarlxsQRS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,337 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,344 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'577'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4982'), (b'x-ratelimit-remaining-tokens', b'597190'), (b'x-ratelimit-reset-requests', b'207ms'), (b'x-ratelimit-reset-tokens', b'280ms'), (b'x-request-id', b'req_e7b5b4069ae363ca00d2d3e2691f27a4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9a200908-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,344 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,344 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,344 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,344 - DEBUG - response_closed.started


2024-04-21 11:01:10,344 - DEBUG - response_closed.complete


2024-04-21 11:01:10,346 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,347 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvDgXfHr3qWI7hUEvaIjjcQBl7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_tfzJPq8RKrtFvK4SGZ9nP2yo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,347 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,348 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'547'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4956'), (b'x-ratelimit-remaining-tokens', b'593136'), (b'x-ratelimit-reset-requests', b'525ms'), (b'x-ratelimit-reset-tokens', b'686ms'), (b'x-request-id', b'req_00692206a86334635ba9bb0850c0b394'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471adaa614e2-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,349 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,349 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,349 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,349 - DEBUG - response_closed.started


2024-04-21 11:01:10,349 - DEBUG - response_closed.complete


2024-04-21 11:01:10,351 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,351 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvCccxArVQpgz1H29EdjA0VA5h', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QXWv0EaYsVxVlKhtdKLFeKat', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,352 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,354 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'585'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4950'), (b'x-ratelimit-remaining-tokens', b'592269'), (b'x-ratelimit-reset-requests', b'591ms'), (b'x-ratelimit-reset-tokens', b'773ms'), (b'x-request-id', b'req_cf9cda57c8643a13368a32a6bd97d95f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aded42b5b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,355 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,355 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,355 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,355 - DEBUG - response_closed.started


2024-04-21 11:01:10,355 - DEBUG - response_closed.complete


2024-04-21 11:01:10,357 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,357 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv2knbJHGAKqIPwB2Euv32l86r', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_K52yEEqtlobICQWQYF6pp5DL', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,358 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,358 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'656'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4915'), (b'x-ratelimit-remaining-tokens', b'586941'), (b'x-ratelimit-reset-requests', b'1.016s'), (b'x-ratelimit-reset-tokens', b'1.305s'), (b'x-request-id', b'req_26bcea92ff220b18b30a6eaff42ccb1c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aec2052a7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,358 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,358 - DEBUG - response_closed.started


2024-04-21 11:01:10,358 - DEBUG - response_closed.complete


2024-04-21 11:01:10,361 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,361 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvBkntVZXQSW5dQ0Gg02u3TrdT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_K81Ofc0WbjEhqsBzxmyQeA42', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,361 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,368 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'707'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4978'), (b'x-ratelimit-remaining-tokens', b'596555'), (b'x-ratelimit-reset-requests', b'256ms'), (b'x-ratelimit-reset-tokens', b'344ms'), (b'x-request-id', b'req_164813d74491fdde98126db508fc27a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aad620920-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,368 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,368 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,369 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,369 - DEBUG - response_closed.started


2024-04-21 11:01:10,369 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'620'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'591567'), (b'x-ratelimit-reset-requests', b'646ms'), (b'x-ratelimit-reset-tokens', b'843ms'), (b'x-request-id', b'req_56b828459f74a47e930bb429f54f1d04'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ad9a72b95-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,369 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,369 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,369 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,369 - DEBUG - response_closed.started


2024-04-21 11:01:10,369 - DEBUG - response_closed.complete


2024-04-21 11:01:10,372 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,372 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvPCbywAkMKLcrRgnYWYVmvVzb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AJh7YuUPoTWHvL2e7zRojPjJ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,372 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,372 - DEBUG - response_closed.complete


2024-04-21 11:01:10,375 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,375 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvIYzjsb99QIJdprVkSECPc1Mv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OKfysJOj2NJuEWH1Bggme6KP', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,375 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,375 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'732'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4984'), (b'x-ratelimit-remaining-tokens', b'597567'), (b'x-ratelimit-reset-requests', b'181ms'), (b'x-ratelimit-reset-tokens', b'243ms'), (b'x-request-id', b'req_2d62270481769b5d45e21733cdd5231e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9cd52ac3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,375 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,375 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,376 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,376 - DEBUG - response_closed.started


2024-04-21 11:01:10,376 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'727'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4984'), (b'x-ratelimit-remaining-tokens', b'597453'), (b'x-ratelimit-reset-requests', b'187ms'), (b'x-ratelimit-reset-tokens', b'254ms'), (b'x-request-id', b'req_5ebf377dcf7cbfa432a8f9d5f682020f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9d592f4f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,376 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,376 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,376 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,376 - DEBUG - response_closed.started


2024-04-21 11:01:10,376 - DEBUG - response_closed.complete


2024-04-21 11:01:10,379 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,379 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv56QQrKnTPdhJQsLrhXg1L62S', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kOqiXc3R4MqS7MM5eqekUIm6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,379 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,379 - DEBUG - response_closed.complete


2024-04-21 11:01:10,382 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,382 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvbrie1O8SKvAL9CVFaeCux3GF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_os6PXUhAz7q4ENtpF6OgRaXJ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,382 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,384 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'707'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4966'), (b'x-ratelimit-remaining-tokens', b'594700'), (b'x-ratelimit-reset-requests', b'402ms'), (b'x-ratelimit-reset-tokens', b'529ms'), (b'x-request-id', b'req_6c3cd1da2c4f0994815250e4965e3bee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ab8d408aa-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,384 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,384 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,384 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,384 - DEBUG - response_closed.started


2024-04-21 11:01:10,384 - DEBUG - response_closed.complete


2024-04-21 11:01:10,387 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,387 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvbygmHxHzRZURK7zT2F2EFxLB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_u3X1LJupKOChg8uB3g3XajDI', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,387 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,387 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'711'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4962'), (b'x-ratelimit-remaining-tokens', b'594145'), (b'x-ratelimit-reset-requests', b'446ms'), (b'x-ratelimit-reset-tokens', b'585ms'), (b'x-request-id', b'req_d9251dfbb59034124cfba6c3f9ddddb1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ace0c0cd7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,387 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,387 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,387 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,387 - DEBUG - response_closed.started


2024-04-21 11:01:10,387 - DEBUG - response_closed.complete


2024-04-21 11:01:10,390 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,390 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvqiHtRThg0tyPfjcxDCDCjm0Q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_LbsUTmIML8FYqSxYXA7WVDjs', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,390 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,390 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'720'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4965'), (b'x-ratelimit-remaining-tokens', b'594518'), (b'x-ratelimit-reset-requests', b'414ms'), (b'x-ratelimit-reset-tokens', b'548ms'), (b'x-request-id', b'req_66e3afcd63d0cf1adb24e6eabe95b51e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471acd573173-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,390 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,390 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,391 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,391 - DEBUG - response_closed.started


2024-04-21 11:01:10,391 - DEBUG - response_closed.complete


2024-04-21 11:01:10,393 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,393 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv1lByBePnp5rAAsHqx8wxO5yb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_KtToc0YxMjB4rBTKYGIFkI8D', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,394 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,394 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'667'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4970'), (b'x-ratelimit-remaining-tokens', b'595274'), (b'x-ratelimit-reset-requests', b'357ms'), (b'x-ratelimit-reset-tokens', b'472ms'), (b'x-request-id', b'req_951e35ee5039c2b7a031e1a1076b194d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471abb9d0cdb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,394 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,394 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,394 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,394 - DEBUG - response_closed.started


2024-04-21 11:01:10,394 - DEBUG - response_closed.complete


2024-04-21 11:01:10,397 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,397 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvJpRAlVQKF4FygLdvojdLwGVQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ln0hlirCrIcXH201YwE5m7MZ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,397 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,397 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'726'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4961'), (b'x-ratelimit-remaining-tokens', b'594040'), (b'x-ratelimit-reset-requests', b'459ms'), (b'x-ratelimit-reset-tokens', b'595ms'), (b'x-request-id', b'req_93985b3f37594382659ac9436fb823a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471acdcd14fc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,397 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,397 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,397 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,397 - DEBUG - response_closed.started


2024-04-21 11:01:10,397 - DEBUG - response_closed.complete


2024-04-21 11:01:10,400 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,400 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvYqlM3RmYKWmXtdfVUqSfwI50', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wnEnAtOKHRlrLl0E13k9U3yw', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,400 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,401 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'619'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4974'), (b'x-ratelimit-remaining-tokens', b'595995'), (b'x-ratelimit-reset-requests', b'300ms'), (b'x-ratelimit-reset-tokens', b'400ms'), (b'x-request-id', b'req_4dd846f946f5bffc5dde2811331ba6a6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471abbae0fec-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,402 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,402 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,402 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,402 - DEBUG - response_closed.started


2024-04-21 11:01:10,402 - DEBUG - response_closed.complete


2024-04-21 11:01:10,405 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,405 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvt0A97rxANj8ty3D0SFb1FKpm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_xsKVWb63y24LM6TJMWCX7uOf', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,405 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,405 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'740'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4968'), (b'x-ratelimit-remaining-tokens', b'594986'), (b'x-ratelimit-reset-requests', b'379ms'), (b'x-ratelimit-reset-tokens', b'501ms'), (b'x-request-id', b'req_9b06c0bd1e560dee5ed77f4ed44e56ee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9e2a0cb7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,406 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,406 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,406 - DEBUG - response_closed.started


2024-04-21 11:01:10,406 - DEBUG - response_closed.complete


2024-04-21 11:01:10,409 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,409 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvWChribcUw6QwyG2U37Nths1u', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_peIHZEv3MJZ86WngPoBZFP4H', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,409 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,410 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'595'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4947'), (b'x-ratelimit-remaining-tokens', b'591874'), (b'x-ratelimit-reset-requests', b'625ms'), (b'x-ratelimit-reset-tokens', b'812ms'), (b'x-request-id', b'req_6cd5437929f2749bc28beab0fd366617'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471adae42f7c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,410 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,410 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,410 - DEBUG - response_closed.started


2024-04-21 11:01:10,410 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'721'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4944'), (b'x-ratelimit-remaining-tokens', b'591307'), (b'x-ratelimit-reset-requests', b'669ms'), (b'x-ratelimit-reset-tokens', b'869ms'), (b'x-request-id', b'req_33ed0a07592cc7aa3ac8e82bac49fe43'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ae8e02ac4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,410 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,410 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,410 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,410 - DEBUG - response_closed.started


2024-04-21 11:01:10,410 - DEBUG - response_closed.complete


2024-04-21 11:01:10,413 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,413 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvAPZi1rcAP7dZC5xs8GgGu8VH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_M6W4WifkyA3kgdGeyhD3Ldgo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,414 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,414 - DEBUG - response_closed.complete


2024-04-21 11:01:10,417 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,417 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvzVn5UcS60UHfSV1eokX3fMC9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_EsFmWlPieoqqqsbeAkj0lYxa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,417 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,417 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'770'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4980'), (b'x-ratelimit-remaining-tokens', b'596911'), (b'x-ratelimit-reset-requests', b'229ms'), (b'x-ratelimit-reset-tokens', b'308ms'), (b'x-request-id', b'req_c61c3ea17289722c729bec1529c405dd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9c520fb0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,417 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,417 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,417 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,417 - DEBUG - response_closed.started


2024-04-21 11:01:10,417 - DEBUG - response_closed.complete


2024-04-21 11:01:10,420 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,420 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvValb0g9XFSrZJIRtMnPiLaFe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kOqiXc3R4MqS7MM5eqekUIm6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,421 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,425 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'676'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4956'), (b'x-ratelimit-remaining-tokens', b'593189'), (b'x-ratelimit-reset-requests', b'526ms'), (b'x-ratelimit-reset-tokens', b'681ms'), (b'x-request-id', b'req_d177975278e71fb650a2c4836bad0d10'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471acd49dbc6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,425 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,425 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,425 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,425 - DEBUG - response_closed.started


2024-04-21 11:01:10,426 - DEBUG - response_closed.complete


2024-04-21 11:01:10,429 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,429 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvfXVktcsOyo7ePAUrcGScDDTN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_l84XRTmoZs1VEmiuIZvkiLLE', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,429 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,429 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'728'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4941'), (b'x-ratelimit-remaining-tokens', b'590867'), (b'x-ratelimit-reset-requests', b'704ms'), (b'x-ratelimit-reset-tokens', b'913ms'), (b'x-request-id', b'req_2d8f791d5eeb4a0c50b8885f80211e12'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ad9b07bad-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,429 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,429 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,429 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,429 - DEBUG - response_closed.started


2024-04-21 11:01:10,429 - DEBUG - response_closed.complete


2024-04-21 11:01:10,432 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,432 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvc0xAA1MkY85HOSULukG3j3yy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Fat3JLJ3tWyQwxi0geAOyOIC', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,433 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,439 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'689'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4955'), (b'x-ratelimit-remaining-tokens', b'592977'), (b'x-ratelimit-reset-requests', b'538ms'), (b'x-ratelimit-reset-tokens', b'702ms'), (b'x-request-id', b'req_d0c63f62511253a0f6539f541d981a3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ac82f0904-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,439 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,439 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,440 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,440 - DEBUG - response_closed.started


2024-04-21 11:01:10,440 - DEBUG - response_closed.complete


2024-04-21 11:01:10,443 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,443 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvS3EHdcRS4A2MIQ9MEvLn9sy2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_beSSvJfkjGPEmmVp2L8D0NSm', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,443 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,443 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'724'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4932'), (b'x-ratelimit-remaining-tokens', b'589576'), (b'x-ratelimit-reset-requests', b'809ms'), (b'x-ratelimit-reset-tokens', b'1.042s'), (b'x-request-id', b'req_338f297fc22cc5324e2bc691f5a3a7dd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aec9e7eb7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,443 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,443 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,443 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,443 - DEBUG - response_closed.started


2024-04-21 11:01:10,444 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'733'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4917'), (b'x-ratelimit-remaining-tokens', b'587219'), (b'x-ratelimit-reset-requests', b'994ms'), (b'x-ratelimit-reset-tokens', b'1.278s'), (b'x-request-id', b'req_631e19399087bec0ec96370b73ef7c61'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aed742f20-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,444 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,444 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,444 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,444 - DEBUG - response_closed.started


2024-04-21 11:01:10,444 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'774'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4977'), (b'x-ratelimit-remaining-tokens', b'596414'), (b'x-ratelimit-reset-requests', b'267ms'), (b'x-ratelimit-reset-tokens', b'358ms'), (b'x-request-id', b'req_782f8c10224550f8bb14ee4949ee4c80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aba2a0925-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,444 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,444 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,444 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,444 - DEBUG - response_closed.started


2024-04-21 11:01:10,444 - DEBUG - response_closed.complete


2024-04-21 11:01:10,447 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,448 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvZMHI8teu57L14nbPJTJb1HMZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3f7keMkwTCMNcBnQfCFxeHR2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,448 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,448 - DEBUG - response_closed.complete


2024-04-21 11:01:10,451 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,451 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvSD31g1DU6zYyUoviyJYsUwyq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lEjo4hV7UR5Td9HTcNtpzKNm', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,451 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,451 - DEBUG - response_closed.complete


2024-04-21 11:01:10,454 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,455 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvdVnnvsqqTrrnvcqtPzGsSHSw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_xNcXQRhWpdb3dpr4u0Es3Gw6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,455 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,455 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'472'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'599020'), (b'x-ratelimit-reset-requests', b'75ms'), (b'x-ratelimit-reset-tokens', b'97ms'), (b'x-request-id', b'req_060f0711e86f48cdb6d55b724b4671a3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a4de67bc7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,455 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,455 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,455 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,455 - DEBUG - response_closed.started


2024-04-21 11:01:10,455 - DEBUG - response_closed.complete


2024-04-21 11:01:10,458 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,459 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvWTOdxMJi48aANl2W4MpSvcXT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fZD8dEmtFRyzEuZL5wbn6lS8', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,459 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,467 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'731'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4958'), (b'x-ratelimit-remaining-tokens', b'593558'), (b'x-ratelimit-reset-requests', b'492ms'), (b'x-ratelimit-reset-tokens', b'644ms'), (b'x-request-id', b'req_3847464b6107c2ce6d0efcba6ce78b93'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471abce12f11-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,467 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,467 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,468 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,468 - DEBUG - response_closed.started


2024-04-21 11:01:10,468 - DEBUG - response_closed.complete


2024-04-21 11:01:10,471 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,471 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmv65J36ZypDjqKBk05DVPqb5yw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_W1i8vxl0ap2tp2IbAJaYSY3T', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,471 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,471 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'797'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4961'), (b'x-ratelimit-remaining-tokens', b'593999'), (b'x-ratelimit-reset-requests', b'457ms'), (b'x-ratelimit-reset-tokens', b'600ms'), (b'x-request-id', b'req_ad812e12264ca474fab46ccc844b7281'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ac9922f71-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,472 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,472 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,472 - DEBUG - response_closed.started


2024-04-21 11:01:10,472 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'733'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4956'), (b'x-ratelimit-remaining-tokens', b'593265'), (b'x-ratelimit-reset-requests', b'516ms'), (b'x-ratelimit-reset-tokens', b'673ms'), (b'x-request-id', b'req_523edcffdb5f0bc08288127ec1bf1cf8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ac9410fcf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,472 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,472 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,472 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,472 - DEBUG - response_closed.started


2024-04-21 11:01:10,472 - DEBUG - response_closed.complete


2024-04-21 11:01:10,475 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,476 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvwy8YqcevUqBxvmbn3lx3fgik', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dXHGmD5xkvLXxKivF5eCbLgb', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,476 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,476 - DEBUG - response_closed.complete


2024-04-21 11:01:10,479 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,479 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvWTdSc0caoGEMwt0tAEhC2w6t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_JWHju6ke73qN7iGTFd2BiqYX', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,479 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,479 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'824'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4971'), (b'x-ratelimit-remaining-tokens', b'595410'), (b'x-ratelimit-reset-requests', b'346ms'), (b'x-ratelimit-reset-tokens', b'458ms'), (b'x-request-id', b'req_4de49476a24e52cf069192c1af13c4f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ab9640d24-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,480 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,480 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,480 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,480 - DEBUG - response_closed.started


2024-04-21 11:01:10,480 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'734'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4977'), (b'x-ratelimit-remaining-tokens', b'596317'), (b'x-ratelimit-reset-requests', b'273ms'), (b'x-ratelimit-reset-tokens', b'368ms'), (b'x-request-id', b'req_829633e83382206da46e7d8f91edc1b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aaa917c92-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,480 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,480 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,480 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,480 - DEBUG - response_closed.started


2024-04-21 11:01:10,480 - DEBUG - response_closed.complete


2024-04-21 11:01:10,483 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,483 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmw7AyuWzlKng5rJzTLqL5jYhjP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QjjMu1xGRpzZUE2lyavQklhG', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722470, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,484 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,484 - DEBUG - response_closed.complete


2024-04-21 11:01:10,487 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,487 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvZjpTpxWWtWezzi4lwAXQACdr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yWVenwMjD4SI82UARK1dmWmW', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,487 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,503 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'811'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4931'), (b'x-ratelimit-remaining-tokens', b'589398'), (b'x-ratelimit-reset-requests', b'821ms'), (b'x-ratelimit-reset-tokens', b'1.06s'), (b'x-request-id', b'req_df59984d88ce79931c8385b21bf34ebd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeb532f5d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,503 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,503 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,504 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,504 - DEBUG - response_closed.started


2024-04-21 11:01:10,504 - DEBUG - response_closed.complete


2024-04-21 11:01:10,507 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,507 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvnEU8Kwas0N0DqABdzopBrhEG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qK3xsaRHJ6tird8vPEQQWfzn', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,508 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,514 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'716'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4913'), (b'x-ratelimit-remaining-tokens', b'586639'), (b'x-ratelimit-reset-requests', b'1.037s'), (b'x-ratelimit-reset-tokens', b'1.336s'), (b'x-request-id', b'req_dd2261bec102c8b468b36b2894e504a5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ad9a62ae3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,514 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,514 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,514 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,514 - DEBUG - response_closed.started


2024-04-21 11:01:10,514 - DEBUG - response_closed.complete


2024-04-21 11:01:10,518 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,518 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvcymUqllJSVICDRJByrLlnYM4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yWVenwMjD4SI82UARK1dmWmW', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,518 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,541 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4927'), (b'x-ratelimit-remaining-tokens', b'588786'), (b'x-ratelimit-reset-requests', b'870ms'), (b'x-ratelimit-reset-tokens', b'1.121s'), (b'x-request-id', b'req_046a56280da009b2d07374ec60f375da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471aeb23db8a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,541 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,541 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,542 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,542 - DEBUG - response_closed.started


2024-04-21 11:01:10,542 - DEBUG - response_closed.complete


2024-04-21 11:01:10,548 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,548 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmwlL8n6qMWUnlle8zHiir30jKa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bJxEaj5XURFd2BQ5IRv4P2Jb', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722470, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,548 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,550 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'927'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4990'), (b'x-ratelimit-remaining-tokens', b'598402'), (b'x-ratelimit-reset-requests', b'113ms'), (b'x-ratelimit-reset-tokens', b'159ms'), (b'x-request-id', b'req_edfa6856f1e26c58f061df39520cd5ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a8f050fc4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,550 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,550 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,550 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,550 - DEBUG - response_closed.started


2024-04-21 11:01:10,550 - DEBUG - response_closed.complete


2024-04-21 11:01:10,555 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,556 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmwv4PmxHUDYG9wFb6ga99v0DtC', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_S2Ec1Pa2UCgHvREcqtonOiD9', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722470, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,556 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,602 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4960'), (b'x-ratelimit-remaining-tokens', b'593848'), (b'x-ratelimit-reset-requests', b'469ms'), (b'x-ratelimit-reset-tokens', b'615ms'), (b'x-request-id', b'req_6ab30746b4bbb98d5a992d2508748d2b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471ac87e2f4b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,602 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,602 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,602 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,602 - DEBUG - response_closed.started


2024-04-21 11:01:10,602 - DEBUG - response_closed.complete


2024-04-21 11:01:10,608 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,608 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvqxSL23q99crbFD92IJzV4UDu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dNzOSQvkHAqUnQDkXeD8sYaU', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,608 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,621 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'654'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4930'), (b'x-ratelimit-remaining-tokens', b'588582'), (b'x-ratelimit-reset-requests', b'837ms'), (b'x-ratelimit-reset-tokens', b'1.141s'), (b'x-request-id', b'req_2899148763d78d9da2475e12c3d64dfb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471caf600fd0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,621 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,621 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,621 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,622 - DEBUG - response_closed.started


2024-04-21 11:01:10,622 - DEBUG - response_closed.complete


2024-04-21 11:01:10,627 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,627 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmvJ9skZ9iamzJ9VqbtSIdXHYrF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_RLm2d1Bs354V98JN8ESEw9GF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722469, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,628 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,727 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1140'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'598915'), (b'x-ratelimit-reset-requests', b'83ms'), (b'x-ratelimit-reset-tokens', b'108ms'), (b'x-request-id', b'req_9e8a912211336479cd45799780967f1a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a3fb51009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,728 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,729 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,729 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,729 - DEBUG - response_closed.started


2024-04-21 11:01:10,730 - DEBUG - response_closed.complete


2024-04-21 11:01:10,742 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,742 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmw9MTzb6bIUn8uqVw8cCQmo0gA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_C7gL719zLP4JLnzEnOze4ThS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722470, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,743 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,818 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1185'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597611'), (b'x-ratelimit-reset-requests', b'174ms'), (b'x-ratelimit-reset-tokens', b'238ms'), (b'x-request-id', b'req_b4b8cbf61ff08f434de913521aa741ca'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f471a9ca10fc7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:10,820 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:10,820 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,821 - DEBUG - receive_response_body.complete


2024-04-21 11:01:10,821 - DEBUG - response_closed.started


2024-04-21 11:01:10,821 - DEBUG - response_closed.complete


2024-04-21 11:01:10,840 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:10,841 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmwABDq92rHm2WcbuMi6QJYqpbV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_C7gL719zLP4JLnzEnOze4ThS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713722470, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:01:10,842 - INFO - Received completion from the model:
valid=False


2024-04-21 11:01:10,846 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}
	{'role': 'user', 'content': 'yes'}


2024-04-21 11:01:10,850 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage4'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'yes'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}}


2024-04-21 11:01:10,850 - DEBUG - max_retries: 8


2024-04-21 11:01:10,850 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107dc4a00>


2024-04-21 11:01:10,857 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'yes'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}]}}


2024-04-21 11:01:10,865 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:01:10,866 - DEBUG - send_request_headers.complete


2024-04-21 11:01:10,866 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:01:10,866 - DEBUG - send_request_body.complete


2024-04-21 11:01:10,866 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:01:13,509 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:01:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2289'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'593963'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'603ms'), (b'x-request-id', b'req_ffbbb02e0f58206e8056b4a8b1358f0a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4722fba71009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:01:13,512 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:01:13,512 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:01:13,513 - DEBUG - receive_response_body.complete


2024-04-21 11:01:13,513 - DEBUG - response_closed.started


2024-04-21 11:01:13,514 - DEBUG - response_closed.complete


2024-04-21 11:01:13,531 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:01:13,532 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVmwiGd1z1TlnqFmvlxLOOsXZaCN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YVajdyd3pbKO81ATpnUwjCSP', function=Function(arguments='{"report_guide":null,"questions":"Could you please provide more details on how you would like the report to be structured? What specific elements do you want to be included in the report based on the collection of tweets?"}', name='Stage4'), type='function')]))], created=1713722470, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=45, prompt_tokens=277, total_tokens=322))


2024-04-21 11:01:13,533 - INFO - Received completion from the model:
report_guide: None
questions: Could you please provide more details on how you would like the report to be structured? What specific elements do you want to be included in the report based on the collection of tweets?


2024-04-21 11:05:24,760 - INFO - filter: {'id': '3f4aafb5-cb1c-4584-802b-0c0ef5d02336', 'user_id': 'brian', 'name': 'XDevChallengeUpdate', 'target': 'reports', 'primary_prompt': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.", 'report_guide': 'simple, concise', 'filter_period': 7, 'filter_prompt': 'x dev challenge', 'usernames': [''], 'only_search_followers': False, 'return_min': 5, 'return_cap': 20, 'keyword_groups': [['']], 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'hi id like to search for reports\n'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nSearch for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'x dev challenge\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nx dev challenge"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'simple, concise'}, {'role': 'assistant', 'content': "If you like this report guide and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nsimple, concise"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'assistant', 'content': 'When searching with query ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("event started yesterday") -is:reply, found 100 tweets.'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the primary prompt.'}, {'role': 'assistant', 'content': 'Not enough valid tweets, broadening primary prompt'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the new primary prompt: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}, {'role': 'assistant', 'content': "Here are the results for your filter 'XDevChallengeUpdate':\n\n"}]}


2024-04-21 11:05:24,767 - INFO - filter: {'id': '3f4aafb5-cb1c-4584-802b-0c0ef5d02336', 'user_id': 'brian', 'name': 'XDevChallengeUpdate', 'target': 'reports', 'primary_prompt': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.", 'report_guide': 'simple, concise', 'filter_period': 7, 'filter_prompt': 'x dev challenge', 'usernames': [''], 'only_search_followers': False, 'return_min': 5, 'return_cap': 20, 'keyword_groups': [['']], 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'hi id like to search for reports\n'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nSearch for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'x dev challenge\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nx dev challenge"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'simple, concise'}, {'role': 'assistant', 'content': "If you like this report guide and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nsimple, concise"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'assistant', 'content': 'When searching with query ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("event started yesterday") -is:reply, found 100 tweets.'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the primary prompt.'}, {'role': 'assistant', 'content': 'Not enough valid tweets, broadening primary prompt'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the new primary prompt: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}, {'role': 'assistant', 'content': "Here are the results for your filter 'XDevChallengeUpdate':\n\n"}]}


2024-04-21 11:05:24,767 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}
	{'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nThe user shared these example keywords with us: [['']]"}


2024-04-21 11:05:24,780 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.GenerateKeywordGroups'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nThe user shared these example keywords with us: [['']]"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}}


2024-04-21 11:05:24,782 - DEBUG - max_retries: 8


2024-04-21 11:05:24,782 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e77d30>


2024-04-21 11:05:24,789 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nThe user shared these example keywords with us: [['']]"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:05:24,836 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:05:24,877 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1042f52a0>


2024-04-21 11:05:24,877 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x103613e40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:05:24,900 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1042f40a0>


2024-04-21 11:05:24,900 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:05:24,901 - DEBUG - send_request_headers.complete


2024-04-21 11:05:24,901 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:05:24,901 - DEBUG - send_request_body.complete


2024-04-21 11:05:24,901 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:05:27,429 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:05:27 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2223'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599435'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'56ms'), (b'x-request-id', b'req_892cf76a110c5d835f5c07f779839b3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=byrSdaJVCCVyyA0E3RcqHiT1mcQgBuv3Nc.QtZ9SyOk-1713722727-1.0.1.1-EZERsu5T7ub_VF8_84b9I1x1pi9avPfw0buGczTxeE9aUXhq2UvZhAzRXZtRgIpzgdcMFe0B2jVVJ28cZLEKng; path=/; expires=Sun, 21-Apr-24 18:35:27 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=9juSBcTxo9ChK9Z.dgxECzkrTygM1nISp3uFa074F7w-1713722727345-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4d56c94c091c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:05:27,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:05:27,433 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:05:27,434 - DEBUG - receive_response_body.complete


2024-04-21 11:05:27,435 - DEBUG - response_closed.started


2024-04-21 11:05:27,435 - DEBUG - response_closed.complete


2024-04-21 11:05:27,436 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:05:27,445 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVr3EAie97DskSVhvnNydxKE2Q6p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qA77rQJwBXqJwhWukJRvLakK', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "participant experiences"],\n    ["X Dev Challenge", "significant occurrences", "since yesterday"]\n  ]\n}', name='GenerateKeywordGroups'), type='function')]))], created=1713722725, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=62, prompt_tokens=541, total_tokens=603))


2024-04-21 11:05:27,447 - INFO - Received completion from the model:
keyword_groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]


2024-04-21 11:05:27,450 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences" "since yesterday") -is:reply


2024-04-21 11:05:27,451 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:05:27Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences" "since yesterday") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:05:27,481 - DEBUG - Starting new HTTPS connection (1): api.twitter.com:443


2024-04-21 11:05:27,661 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A05%3A27Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+%22participant+experiences%22%29+OR+%28%22X+Dev+Challenge%22+%22significant+occurrences%22+%22since+yesterday%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:05:27,664 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:05:27 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'set-cookie': 'guest_id_marketing=v1%3A171372272760363483; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:05:27 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id_ads=v1%3A171372272760363483; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:05:27 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, personalization_id="v1_D3h2jgU5lYDE2GjHVvUgEw=="; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:05:27 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id=v1%3A171372272760363483; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:05:27 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'c9e14e9d82978e09', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713723627', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '449', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '63', 'x-connection-hash': '3a24d8449e5530a660ecc2b5020aaa2bafffcc47163f73d8069815dcf64c1f19'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:05:27,665 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [[''], ['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]\n\nPlease provide a new keyword group."}


2024-04-21 11:05:27,668 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [[''], ['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:05:27,668 - DEBUG - max_retries: 8


2024-04-21 11:05:27,668 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x104349ba0>


2024-04-21 11:05:27,672 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [[''], ['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:05:27,674 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:05:27,674 - DEBUG - send_request_headers.complete


2024-04-21 11:05:27,674 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:05:27,675 - DEBUG - send_request_body.complete


2024-04-21 11:05:27,675 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:05:30,756 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:05:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2934'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599718'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_230f1cdb333fc5868751f469a29aac53'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4d681864091c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:05:30,757 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:05:30,757 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:05:30,757 - DEBUG - receive_response_body.complete


2024-04-21 11:05:30,757 - DEBUG - response_closed.started


2024-04-21 11:05:30,758 - DEBUG - response_closed.complete


2024-04-21 11:05:30,758 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:05:30,759 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVr582BcSQlATuBvyVc1Gw6l4UAV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_51sgme7uZMY5gvi9is7gDUBw', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "participant experiences"],\n    ["X Dev Challenge", "significant occurrences"],\n    ["X Dev Challenge", "since yesterday"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722727, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=68, prompt_tokens=307, total_tokens=375))


2024-04-21 11:05:30,761 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'since yesterday']]


2024-04-21 11:05:30,764 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences") OR ("X Dev Challenge" "since yesterday") -is:reply


2024-04-21 11:05:30,764 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:05:30Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences") OR ("X Dev Challenge" "since yesterday") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:05:30,901 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A05%3A30Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+%22participant+experiences%22%29+OR+%28%22X+Dev+Challenge%22+%22significant+occurrences%22%29+OR+%28%22X+Dev+Challenge%22+%22since+yesterday%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:05:30,903 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:05:30 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '3d495fee523f8c5a', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713723627', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '448', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '97', 'x-connection-hash': '3a24d8449e5530a660ecc2b5020aaa2bafffcc47163f73d8069815dcf64c1f19'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:05:30,904 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'since yesterday']]\n\nPlease provide a new keyword group."}


2024-04-21 11:05:30,912 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'since yesterday']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:05:30,912 - DEBUG - max_retries: 8


2024-04-21 11:05:30,912 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10434b6d0>


2024-04-21 11:05:30,927 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences'], ['X Dev Challenge', 'since yesterday']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:05:30,929 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:05:30,929 - DEBUG - send_request_headers.complete


2024-04-21 11:05:30,930 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:05:30,930 - DEBUG - send_request_body.complete


2024-04-21 11:05:30,930 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:05:33,879 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:05:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2782'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599716'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_8a1f398ef32655a0e0e19df2aa81a9ba'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4d7c6a57091c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:05:33,881 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:05:33,881 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:05:33,882 - DEBUG - receive_response_body.complete


2024-04-21 11:05:33,883 - DEBUG - response_closed.started


2024-04-21 11:05:33,883 - DEBUG - response_closed.complete


2024-04-21 11:05:33,883 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:05:33,885 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVr9HxjuPAN0TgFOqGUGgAHRsiQc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i7UwYONmjEt0IzAvlmdyKDCk', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["participant experiences"],\n    ["significant occurrences"],\n    ["since yesterday"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722731, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=53, prompt_tokens=310, total_tokens=363))


2024-04-21 11:05:33,887 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['participant experiences'], ['significant occurrences'], ['since yesterday']]


2024-04-21 11:05:33,891 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("since yesterday") -is:reply


2024-04-21 11:05:33,891 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:05:33Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("since yesterday") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:05:34,496 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A05%3A33Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22participant+experiences%22%29+OR+%28%22significant+occurrences%22%29+OR+%28%22since+yesterday%22%29+-is%3Areply HTTP/1.1" 200 8931


2024-04-21 11:05:34,499 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:05:34 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '8931', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '57249d9221757daf', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713723627', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '447', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '495', 'x-connection-hash': '3a24d8449e5530a660ecc2b5020aaa2bafffcc47163f73d8069815dcf64c1f19'}
Content: b'{"data":[{"text":"RT @ttumcials: the waterworks have not stopped since yesterday #BABII247Concert https://t.co/9iU0xaYpbi","edit_history_tweet_ids":["1782108344695828551"],"id":"1782108344695828551","author_id":"1682582622973865986"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782108022183014495"],"id":"1782108022183014495","author_id":"1682248354061774849"},{"text":"RT @QueenBeeInd1: I am so proud of the queen that she is , after having hormonal issues which tigger crazy mood swings and other health pro\xe2\x80\xa6","edit_history_tweet_ids":["1782107972694618241"],"id":"1782107972694618241","author_id":"3146075416"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107867006296487"],"id":"1782107867006296487","author_id":"2786811027"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107835494457842"],"id":"1782107835494457842","author_id":"863151625992634368"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107709728289081"],"id":"1782107709728289081","author_id":"1391299076"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107492601991477"],"id":"1782107492601991477","author_id":"913062226595999744"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107444405027177"],"id":"1782107444405027177","author_id":"824004076211945472"},{"text":"What is going on with @MTNNG network since yesterday? Why did i ever port back to this network? They are terrible. Same network i made a complaint to and they canteven resolve it. I have to leave them else my business will suffer","edit_history_tweet_ids":["1782107346757357945"],"id":"1782107346757357945","author_id":"311111360"},{"text":"RT @BorahaePh7: GOOD. \\nI know an apology would be a long shot (knowing that media hates admitting they\xe2\x80\x99re wrong), but MBC needs to apologiz\xe2\x80\xa6","edit_history_tweet_ids":["1782107309847585118"],"id":"1782107309847585118","author_id":"1781170940006514688"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107284358774854"],"id":"1782107284358774854","author_id":"1695792271738679296"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107221645553737"],"id":"1782107221645553737","author_id":"1598217786555334658"},{"text":"RT @QudsNen: Circulating images from the alleyways of Nur Shams refugee camp show several Palestinians killed by Israeli occupation forces.\xe2\x80\xa6","edit_history_tweet_ids":["1782107202700063220"],"id":"1782107202700063220","author_id":"1755625172445409280"},{"text":"RT @TuckCoin: It all went downhill when we changed the $TUCKER buy gif on Telegram. \\n\\nThe old buy gif with the shitty rocket - we just brou\xe2\x80\xa6","edit_history_tweet_ids":["1782107181736751462"],"id":"1782107181736751462","author_id":"248287946"},{"text":"Since I have no means to leave Nigeria and travel abroad , na AC go save my life for this Nigeria even thou we have light since yesterday Kuma har yanxu nepa no carry light but  the heat will just be reminding you how jahannam is 100x hotter \\uD83E\\uDD72","edit_history_tweet_ids":["1782107179744370893"],"id":"1782107179744370893","author_id":"1559840812497833985"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782107068364619830"],"id":"1782107068364619830","author_id":"42884497"},{"text":"RT @ANI: #WATCH | Chhattisgarh: At Bastar\'s Jagdalpur PM Modi says, \\"Since yesterday, Congress leaders are saying \'jitni aabadi utna haq\'..\xe2\x80\xa6","edit_history_tweet_ids":["1782107022730915917"],"id":"1782107022730915917","author_id":"1411894153294741506"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106986315674084"],"id":"1782106986315674084","author_id":"1629625427605041152"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106941986107403"],"id":"1782106941986107403","author_id":"2359273048"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106853993742813"],"id":"1782106853993742813","author_id":"1157589660"},{"text":"RT @holymeccaa: 508/1267\\nNo donos since yesterday afternoon.\\nTermination is scheduled for 8am tomorrow, and it will cost more to reconnect\xe2\x80\xa6","edit_history_tweet_ids":["1782106780517990865"],"id":"1782106780517990865","author_id":"1184149123756376064"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106649907310649"],"id":"1782106649907310649","author_id":"862668144426590214"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106648590328289"],"id":"1782106648590328289","author_id":"205289858"},{"text":"RT @Appy_Sama: Since yesterday was Lucina\'s day, have the only Lucina render I made as a supporter reward for this #sundayrepost https://t.\xe2\x80\xa6","edit_history_tweet_ids":["1782106632975003667"],"id":"1782106632975003667","author_id":"1061618371085680641"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106554764013969"],"id":"1782106554764013969","author_id":"1181374198326759424"},{"text":"Make Arsenal use Chelsea to increase goal margin, I never hear @akinzeus voice since yesterday, if nah Arsenal now, nah Cho Cho Cho we go Dey hear\\uD83E\\uDD23\\uD83E\\uDD23","edit_history_tweet_ids":["1782106518331994252"],"id":"1782106518331994252","author_id":"446368986"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106487986291011"],"id":"1782106487986291011","author_id":"290483042"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106478335463770"],"id":"1782106478335463770","author_id":"4903580696"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106439470752041"],"id":"1782106439470752041","author_id":"3124279521"},{"text":"been watching those Indian bride makeup trend and that jare jare pawan song has been stuck in my head since yesterday help","edit_history_tweet_ids":["1782106432281903234"],"id":"1782106432281903234","author_id":"1682783316028817409"},{"text":"Our internet landline has been down since yesterday (Saturday) afternoon, @RogersHelps. I\'ve been using lots of data, which is very inconvenient, searching for updates. It\'s now 24 hours later &amp; still no resolution. Might it be prudent to communicate with your users who reported?","edit_history_tweet_ids":["1782106378150035625"],"id":"1782106378150035625","author_id":"103469507"},{"text":"RT @Kuroishi1003: #BNK48_KissMe_Handshake\\n#YoghurtBNK48 #YoghurtHSreview\\n\\nRound 5 D2\\n\\n\\uD83E\\uDD63 Hello again\\n\\uD83D\\uDC68\\uD83C\\uDFFB\xe2\x80\x8d\\uD83D\\uDE80 Hi nong yo 555\\n\\uD83E\\uDD63 Hai Bli Yo! Thank\xe2\x80\xa6","edit_history_tweet_ids":["1782106374543200353"],"id":"1782106374543200353","author_id":"939415223454203905"},{"text":"RT @lutminlen52315: @phoenixpaul2023 @narendramodi @AmitShah @SCofIndia @thewire_in In today\'s tragic incident, Meitei assailants launched\xe2\x80\xa6","edit_history_tweet_ids":["1782106374086012978"],"id":"1782106374086012978","author_id":"1699136604810666008"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106364870897676"],"id":"1782106364870897676","author_id":"455239973"},{"text":"RT @Appy_Sama: Since yesterday was Lucina\'s day, have the only Lucina render I made as a supporter reward for this #sundayrepost https://t.\xe2\x80\xa6","edit_history_tweet_ids":["1782106316007244006"],"id":"1782106316007244006","author_id":"1253032404106850317"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106302308618402"],"id":"1782106302308618402","author_id":"494576583"},{"text":"RT @ha__F18: 2 donations since yesterday, u can do more\xe2\x80\xbc\xef\xb8\x8f\\ngive what u can and shareee please\xe2\x80\xbc\xef\xb8\x8f\\uD83D\\uDE4F\\uD83C\\uDFFB \\n\\nhttps://t.co/0x2gS09zUJ","edit_history_tweet_ids":["1782106270343786990"],"id":"1782106270343786990","author_id":"550003530"},{"text":"My head been hurting since yesterday \\uD83D\\uDE2D","edit_history_tweet_ids":["1782106259015037191"],"id":"1782106259015037191","author_id":"231312029"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106214257611028"],"id":"1782106214257611028","author_id":"80956859"},{"text":"RT @ha__F18: 2 donations since yesterday, u can do more\xe2\x80\xbc\xef\xb8\x8f\\ngive what u can and shareee please\xe2\x80\xbc\xef\xb8\x8f\\uD83D\\uDE4F\\uD83C\\uDFFB \\n\\nhttps://t.co/0x2gS09zUJ","edit_history_tweet_ids":["1782106200567362045"],"id":"1782106200567362045","author_id":"289202543"},{"text":"RT @NugentDaveon: By confirmed information since yesterday there have been 3 police involved killings of Dons/top shooters in Spanish Town\xe2\x80\xa6","edit_history_tweet_ids":["1782106186105450685"],"id":"1782106186105450685","author_id":"2818253448"},{"text":"RT @QueenBeeInd1: I am so proud of the queen that she is , after having hormonal issues which tigger crazy mood swings and other health pro\xe2\x80\xa6","edit_history_tweet_ids":["1782106180678218041"],"id":"1782106180678218041","author_id":"1246635092484612097"},{"text":"RT @Eromonsele_: If you watched City\'s performance yesterday, you\'d see how dreadful it was. But, since yesterday Pep has been singing thei\xe2\x80\xa6","edit_history_tweet_ids":["1782106172834644083"],"id":"1782106172834644083","author_id":"1371420662015918080"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106065565303015"],"id":"1782106065565303015","author_id":"1634270507053752322"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782106015825047813"],"id":"1782106015825047813","author_id":"1521300780069892096"},{"text":"RT @SignAi_ETH: Hello $sai fam!\\n\\nLong time no posts but still working hard !\\n\\nSince yesterday we introduced 2 new trade levels to get earli\xe2\x80\xa6","edit_history_tweet_ids":["1782105977082331382"],"id":"1782105977082331382","author_id":"810233037313245189"},{"text":"RT @BlissAmbassador: \\uD83C\\uDD98 \\uD83C\\uDD98 \\uD83C\\uDD98 \\uD83C\\uDD98 \\nIn today\'s tragic incident, Meitei assailants launched attacks that continue since yesterday on PHAILENGMOL A\xe2\x80\xa6","edit_history_tweet_ids":["1782105836145520667"],"id":"1782105836145520667","author_id":"1699136604810666008"},{"text":"RT @Appy_Sama: Since yesterday was Lucina\'s day, have the only Lucina render I made as a supporter reward for this #sundayrepost https://t.\xe2\x80\xa6","edit_history_tweet_ids":["1782105715806503419"],"id":"1782105715806503419","author_id":"1466127835"},{"text":"Na since yesterday you don dey tweet about Chelsea. Egbon Emma are you hurt about yesterday\'s loss?\\n\\nBut you said you don\'t care nau. E con lament Kiri TL https://t.co/GmJU9RXg1F","edit_history_tweet_ids":["1782105689248141670"],"id":"1782105689248141670","author_id":"1596197047530569729"},{"text":"RT @_AsiwajuLerry: Posting my full post match comps by 1pm today. Sometimes pictures don\xe2\x80\x99t tell the full story. Everybody just dey drag Ler\xe2\x80\xa6","edit_history_tweet_ids":["1782105612949602609"],"id":"1782105612949602609","author_id":"1204442204804136960"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105580083064887"],"id":"1782105580083064887","author_id":"139676556"},{"text":"RT @kings_spicy: Good evening and happy Sunday guys,I have been offline since yesterday I hope everyone is doing well?","edit_history_tweet_ids":["1782105506594632185"],"id":"1782105506594632185","author_id":"1210572352926486531"},{"text":"That\xe2\x80\x99s the only negative comment I\xe2\x80\x99m going to reply to. I\xe2\x80\x99ve been on cloud 9 since yesterday morning. Yall can\xe2\x80\x99t bring me down with yall","edit_history_tweet_ids":["1782105478530568470"],"id":"1782105478530568470","author_id":"2339714221"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105403452473822"],"id":"1782105403452473822","author_id":"2701633188"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105364177072312"],"id":"1782105364177072312","author_id":"1084856929191636992"},{"text":"Was really hoping to finish the stg 3 remaster today but I\'ve been stuck in rendering error hell since yesterday \\uD83D\\uDE2D \\nI\'m gonna attempt some black magic with Audacity out of desperation hopefully tonight will be it \\uD83D\\uDE4F \\uD83D\\uDE4F","edit_history_tweet_ids":["1782105362176315418"],"id":"1782105362176315418","author_id":"2387335184"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105354916270264"],"id":"1782105354916270264","author_id":"1152110797293670401"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105303276015865"],"id":"1782105303276015865","author_id":"1501985741831737344"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105209814020098"],"id":"1782105209814020098","author_id":"1018535019982159872"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782105190625128689"],"id":"1782105190625128689","author_id":"1661272980"},{"text":"I\'ve had thia vision en my head since yesterday, and i can\'t stop thinking about it \\n\\na mashup between Florida, who\'s afraid of little old me and wonderland\\n\\ndo we see the vision????","edit_history_tweet_ids":["1782105148065480989"],"id":"1782105148065480989","author_id":"1728056582607380481"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104976304546002"],"id":"1782104976304546002","author_id":"531329367"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104879659716915"],"id":"1782104879659716915","author_id":"1168247042411352065"},{"text":"RT @BorahaePh7: GOOD. \\nI know an apology would be a long shot (knowing that media hates admitting they\xe2\x80\x99re wrong), but MBC needs to apologiz\xe2\x80\xa6","edit_history_tweet_ids":["1782104861594779719"],"id":"1782104861594779719","author_id":"1139398423591837697"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104730283520399"],"id":"1782104730283520399","author_id":"2759558918"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104688483061926"],"id":"1782104688483061926","author_id":"1720780885220347904"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104674029502765"],"id":"1782104674029502765","author_id":"1346180383679852546"},{"text":"RT @BorahaePh7: GOOD. \\nI know an apology would be a long shot (knowing that media hates admitting they\xe2\x80\x99re wrong), but MBC needs to apologiz\xe2\x80\xa6","edit_history_tweet_ids":["1782104668480700910"],"id":"1782104668480700910","author_id":"873225853"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104659437473843"],"id":"1782104659437473843","author_id":"1114621409291112448"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104654257549760"],"id":"1782104654257549760","author_id":"122977347"},{"text":"RT @TPourchaire: First @IndyCar qualifying done \xe2\x9c\x85 \\n\\nSince yesterday, I enjoy every single lap and I adapted pretty quickly to the car !  \\nI\xe2\x80\xa6","edit_history_tweet_ids":["1782104607650422977"],"id":"1782104607650422977","author_id":"774146034"},{"text":"RT @nnamexi: The toughest question on Nigerian twitter since yesterday (Saturday) is \\"Why did you vote Buhari in 2015?","edit_history_tweet_ids":["1782104573651374386"],"id":"1782104573651374386","author_id":"761339240315781120"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104495394066722"],"id":"1782104495394066722","author_id":"1716858701586350080"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104466009071991"],"id":"1782104466009071991","author_id":"389385052"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104464721162391"],"id":"1782104464721162391","author_id":"1634301482534092801"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104374514520132"],"id":"1782104374514520132","author_id":"1240639126119968773"},{"text":"Have been seeing phaintee saga since yesterday. Many for, against &amp; out of context brigades. It does not concern me at all. I do not follow Qaiser Raja neither he represents all muslims. Therefore, whatever he says on this, does not hold any value to me; neither shud to others!","edit_history_tweet_ids":["1782104320634429580"],"id":"1782104320634429580","author_id":"84046017"},{"text":"RT @BorahaePh7: GOOD. \\nI know an apology would be a long shot (knowing that media hates admitting they\xe2\x80\x99re wrong), but MBC needs to apologiz\xe2\x80\xa6","edit_history_tweet_ids":["1782104223460594059"],"id":"1782104223460594059","author_id":"4245078393"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104169391784269"],"id":"1782104169391784269","author_id":"732226980184260608"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782104147774275837"],"id":"1782104147774275837","author_id":"1287338845"},{"text":"RT @DittiePE: Here\xe2\x80\x99s @RepMTG AGAIN, whining about not getting her way. \\nIn fact, she\xe2\x80\x99s been rage-tweeting all morning, like someone orange\xe2\x80\xa6","edit_history_tweet_ids":["1782104025640436185"],"id":"1782104025640436185","author_id":"25183440"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103981721899226"],"id":"1782103981721899226","author_id":"246389614"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103825438105723"],"id":"1782103825438105723","author_id":"3231391844"},{"text":"Wait, I haven\'t gone out since yesterday and I am noticing now. Wow.","edit_history_tweet_ids":["1782103795331174661"],"id":"1782103795331174661","author_id":"1518297026416590850"},{"text":"ive been wanting to tweet this since yesterday. anyway. WHAT THE FUCK https://t.co/gRZa5AcPLJ","edit_history_tweet_ids":["1782103784539427129"],"id":"1782103784539427129","author_id":"1671728894997839874"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103674736488719"],"id":"1782103674736488719","author_id":"1154993832972496901"},{"text":"RT @QueenBeeInd1: I am so proud of the queen that she is , after having hormonal issues which tigger crazy mood swings and other health pro\xe2\x80\xa6","edit_history_tweet_ids":["1782103624912699489"],"id":"1782103624912699489","author_id":"109892153"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103621376626732"],"id":"1782103621376626732","author_id":"2879691410"},{"text":"RT @iansummer1: And they want me to march with them so much for the Scotland United pish. I wasn\xe2\x80\x99t even too harsh with them. \\nIt appears th\xe2\x80\xa6","edit_history_tweet_ids":["1782103609548689477"],"id":"1782103609548689477","author_id":"939955614826008576"},{"text":"RT @Appy_Sama: Since yesterday was Lucina\'s day, have the only Lucina render I made as a supporter reward for this #sundayrepost https://t.\xe2\x80\xa6","edit_history_tweet_ids":["1782103605308252278"],"id":"1782103605308252278","author_id":"1404904254"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103498429251675"],"id":"1782103498429251675","author_id":"1024737671485087744"},{"text":"man\\uD83D\\uDE02\\uD83D\\uDE02i been on a roll since yesterday \\uD83D\\uDE02\\uD83D\\uDE02\\uD83D\\uDE02\\uD83D\\uDE02\\uD83D\\uDE02\\uD83D\\uDE02that shi was too funny &amp; u mfs on here made it even funnier i love social media &amp; hate it at the same time\\uD83D\\uDE02","edit_history_tweet_ids":["1782103423116034495"],"id":"1782103423116034495","author_id":"1738054123222679552"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103379545587982"],"id":"1782103379545587982","author_id":"2612807188"},{"text":"RT @miawnamz: IM CRYING HE SAW IT \\uD83D\\uDE2D\\uD83D\\uDE2D LIKE IVE BEEN LAUGHING AT THIS VIDEO SINCE YESTERDAY https://t.co/NKLYHPSljN","edit_history_tweet_ids":["1782103377658486889"],"id":"1782103377658486889","author_id":"1188065120091402241"},{"text":"RT @kings_spicy: Good evening and happy Sunday guys,I have been offline since yesterday I hope everyone is doing well?","edit_history_tweet_ids":["1782103353490555131"],"id":"1782103353490555131","author_id":"880004903825022976"},{"text":"RT @AnVRaemdonck: Students at #Yale University and since yesterday #UniversityofNorthCarolina are following the example of the #GazaSolidar\xe2\x80\xa6","edit_history_tweet_ids":["1782103285853302847"],"id":"1782103285853302847","author_id":"352299223"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103249958383789"],"id":"1782103249958383789","author_id":"1209236601542455296"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782103199912165587"],"id":"1782103199912165587","author_id":"1427954976035205124"},{"text":"RT @momentskyeknew: anyone else who hasnt listened to any non-ttpd songs since yesterday morning or am i just insane","edit_history_tweet_ids":["1782102832801272193"],"id":"1782102832801272193","author_id":"1781417178442465280"},{"text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","edit_history_tweet_ids":["1782102782822248590"],"id":"1782102782822248590","author_id":"783960380"}],"includes":{"users":[{"id":"1682582622973865986","name":"Tn_.","username":"TThalaengjit"},{"id":"1682248354061774849","name":"hoja","username":"ranhoj4"},{"id":"3146075416","name":"jayshree","username":"jayashree_125"},{"id":"2786811027","name":"\xd7\xa7\xd7\xa2\xd7\x9c\xd7\x95\xd7\x95\xd7\x99\xd7\x9f \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"wavesbegging"},{"id":"863151625992634368","name":"rayan meguebli\\uD83C\\uDF5D","username":"rayan_meguebli"},{"id":"1391299076","name":"Christian Nyumbayire","username":"Chritchen"},{"id":"913062226595999744","name":"\\uD83C\\uDDF5\\uD83C\\uDDF8 Riverto \\uD83C\\uDDF5\\uD83C\\uDDF8 Thesea \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"KingTherapy"},{"id":"824004076211945472","name":"Deirdre Beck","username":"Deirdrewbeck"},{"id":"311111360","name":"Youduak","username":"youduakfoods"},{"id":"1781170940006514688","name":"lemonpie","username":"dokyeomieda"},{"id":"1695792271738679296","name":"Lama \\uD83C\\uDF49","username":"palpan77"},{"id":"1598217786555334658","name":"bint e adam","username":"bint_e_adam66"},{"id":"1755625172445409280","name":"Kanat Ruzgar","username":"Ruzgar_Rider08"},{"id":"248287946","name":"LILY.Threelt","username":"LILY_Threelt"},{"id":"1559840812497833985","name":"selflover","username":"ameerahloverly"},{"id":"42884497","name":"Salma S. Zohdi","username":"SalmaZohdi"},{"id":"1411894153294741506","name":"Kalyug","username":"Goutam84270959"},{"id":"1629625427605041152","name":"OLAASM","username":"craigtoennies"},{"id":"2359273048","name":"andreapst\\uD83C\\uDF49","username":"andreapst1"},{"id":"1157589660","name":"old woman josie \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"PanicStation26"},{"id":"1184149123756376064","name":"Madame Zeroni","username":"BayouPriestess"},{"id":"862668144426590214","name":"inky labyrinth \\uD83C\\uDF49\\uD83D\\uDDDD\xef\xb8\x8f","username":"InkyLabyrinth"},{"id":"205289858","name":"Khaldoun Khelil \\uD83C\\uDDF5\\uD83C\\uDDF8\\uD83C\\uDDE9\\uD83C\\uDDFF #freePalestine","username":"kkhelil"},{"id":"1061618371085680641","name":"what","username":"nahbthanks"},{"id":"1181374198326759424","name":"Jesse \\uD83E\\uDD87\\uD83D\\uDD78\xef\xb8\x8f","username":"cultofbats"},{"id":"446368986","name":"Logan","username":"Oluso_LA"},{"id":"290483042","name":"mary lindsay","username":"maurlind"},{"id":"4903580696","name":"Vivian\\uD83C\\uDF49 \xe2\x9e\xa1 marcilled . tumblr","username":"aeonlamb"},{"id":"3124279521","name":"giz \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08 \\uD83C\\uDF49","username":"dsfkgfd"},{"id":"1682783316028817409","name":"reis","username":"althreis"},{"id":"103469507","name":"S. Sooknanan","username":"SSooknanan"},{"id":"939415223454203905","name":"\xea\x9c\xb0\xe1\xb4\x8f\xca\x80 more","username":"ottarfp"},{"id":"1699136604810666008","name":"Neici (Kuki Parivar)","username":"c48364"},{"id":"455239973","name":"Steve Webster","username":"croft1a"},{"id":"1253032404106850317","name":"AJN","username":"AJN_RULES_50"},{"id":"494576583","name":"chilled chuck","username":"jilatos"},{"id":"550003530","name":"Ahmed\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"AhmedSaadGaza"},{"id":"231312029","name":"Jazz M.S\\uD83E\\uDD8B","username":"Love_Me_Jaz"},{"id":"80956859","name":"\xd7\xa1\xd7\x95\xd7\xa4\xd7\x99 king dyke","username":"devilhornsdyke"},{"id":"289202543","name":"Jeem Alef \\uD83D\\uDD3B","username":"joseph664"},{"id":"2818253448","name":"Tashe\xe2\x98\xba\xe2\x99\xa5","username":"EmpressTashe"},{"id":"1246635092484612097","name":"shubhi\xe2\x81\xb7 \\uD83C\\uDF49 | pro-boycott","username":"tanniesmysky"},{"id":"1371420662015918080","name":"The Blueprint","username":"barneskiva"},{"id":"1634270507053752322","name":"Done","username":"achwerty77"},{"id":"1521300780069892096","name":"Shangrila","username":"Shangrila1313"},{"id":"810233037313245189","name":"smo","username":"smolleyes80"},{"id":"1466127835","name":"Robert","username":"ShurimanSoul"},{"id":"1596197047530569729","name":"Olaamide!","username":"ProlificMidey"},{"id":"1204442204804136960","name":"KziTech","username":"Kazeemtomiwa1"},{"id":"139676556","name":"\\uD83D\\uDD3B\xd8\xa7\xd9\x85\xd9\x8a\xd8\xb1\xd9\x87","username":"VertePanthere"},{"id":"1210572352926486531","name":"HORKE GRAPHIX","username":"OkeSodiq12"},{"id":"2339714221","name":"Fanta$y \\uD83D\\uDC99","username":"girlsthathoop"},{"id":"2701633188","name":"\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f MomoOfCourse \\uD83C\\uDF49 \xe2\x99\xbf\xef\xb8\x8f","username":"Momo0fCourse"},{"id":"1084856929191636992","name":"Dimitra Andritsou","username":"andrdimitra"},{"id":"2387335184","name":"Aka Kyuketsuki","username":"Kinreigh"},{"id":"1152110797293670401","name":"\\uD83C\\uDDF5\\uD83C\\uDDF8\\uD83C\\uDF49\\uD83D\\uDFE3\xd8\xa8\xd8\xb1\xd8\xa7\xd8\xaf\xd8\xa7 Prada I \\uD83D\\uDFE3\\uD83D\\uDC08\xe2\x80\x8d\xe2\xac\x9b\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"mynameprada"},{"id":"1501985741831737344","name":"Lunatic Lunar Lagomorph","username":"udungetit"},{"id":"1018535019982159872","name":"Jessie Dhaliwall","username":"JDhaliwall"},{"id":"1661272980","name":"Mackenzie \\uD83C\\uDF39\\uD83C\\uDFBB crying over OP5","username":"Kiarrionss"},{"id":"1728056582607380481","name":"Frann | Netflix im coming after you","username":"notfrann_side"},{"id":"531329367","name":"Rehan","username":"rehan_ahm"},{"id":"1168247042411352065","name":"( Ravyn)fan acct \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08\\uD83C\\uDF49","username":"saltymulti"},{"id":"1139398423591837697","name":"BTSVT\\uD83D\\uDC9C\\uD83D\\uDC99","username":"Janhavi12858063"},{"id":"2759558918","name":"Francis Watts \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f","username":"kilowattsup"},{"id":"1720780885220347904","name":"HanJ.1","username":"alienne92"},{"id":"1346180383679852546","name":"cui bono/who benefits?","username":"BerkeleyEve"},{"id":"873225853","name":"An","username":"An_lsmnh"},{"id":"1114621409291112448","name":"Xikers lore enthusiasts \xe2\x99\x9f\xef\xb8\x8f ||-//","username":"Mythoi_exe"},{"id":"122977347","name":"\\uD83D\\uDD3B sentiocentrist \\uD83D\\uDD3B","username":"Sentiocentrist"},{"id":"774146034","name":"Natts L\xc3\xb3pez \xe2\xad\x90\xe2\xad\x90\xe2\xad\x90\\uD83D\\uDC99\\uD83E\\uDD0D\\uD83D\\uDC99","username":"Natts_Lopez"},{"id":"761339240315781120","name":"Alpha","username":"_gekwu"},{"id":"1716858701586350080","name":"Tali \\uD83E\\uDEAC\\uD83C\\uDF36\xef\xb8\x8f\\uD83E\\uDE81","username":"TalulaSha"},{"id":"389385052","name":"Zaman #FreePalestine \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"ZamanX90"},{"id":"1634301482534092801","name":"lookingglass","username":"pinkiesbrain007"},{"id":"1240639126119968773","name":"EliboreBark \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"eliborebark"},{"id":"84046017","name":"Haroon","username":"GalileoGabi"},{"id":"4245078393","name":"Bishan","username":"Bishanishi"},{"id":"732226980184260608","name":"Daphne","username":"daphnereads"},{"id":"1287338845","name":"Reyes","username":"Encantinada"},{"id":"25183440","name":"Nina Ekman","username":"Nina_Ekman"},{"id":"246389614","name":"-poppy-","username":"mxxnchild_x"},{"id":"3231391844","name":"ftrtts \\uD83C\\uDF49","username":"cintheclown"},{"id":"1518297026416590850","name":"E\'fraim Chakechake Kamanga","username":"efraimkamanga"},{"id":"1671728894997839874","name":"\\uD83C\\uDF83sleepsomniac\xee\xa8\x80 #FreePalestine\\uD83C\\uDF49","username":"logistic5721"},{"id":"1154993832972496901","name":"\\uD83C\\uDF49Daddy with Issues\\uD83C\\uDF49 - \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f","username":"ScorchCakeTM"},{"id":"109892153","name":"Damini","username":"DammitDamini"},{"id":"2879691410","name":"kit","username":"FreeScot45"},{"id":"939955614826008576","name":"Shire loon","username":"loon_shire"},{"id":"1404904254","name":"FeetAddictLoser","username":"BetaSniffslave"},{"id":"1024737671485087744","name":"\xec\x95\xa4\xec\xa0\xa4 uwu\'s \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08A.C.E, SKZ, VICTON\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08","username":"multi_stanning"},{"id":"1738054123222679552","name":"BIGSheaaa\\uD83E\\uDEE6","username":"KiyahRasheaaa"},{"id":"2612807188","name":"\\uD83D\\uDC95 fleur delis \xee\xa8\x80 \\uD83D\\uDD4A\xef\xb8\x8f \xe1\x93\x9a\xe1\x98\x8f\xe1\x97\xa2 \\uD83E\\uDD44#MECFS \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"fleurdelis30"},{"id":"1188065120091402241","name":"\xe1\xb4\xae\xe1\xb4\xb1 Ruby \xe2\x81\xb7| \\uD83C\\uDFF4","username":"i_l0velies_ruby"},{"id":"880004903825022976","name":"CAC ACCREDITED  AGENTS","username":"cacagents"},{"id":"352299223","name":"Koen Bogaert","username":"koenraadBogaert"},{"id":"1209236601542455296","name":"DiaryOfAScreenwriter \\uD83C\\uDDF1\\uD83C\\uDDE7\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"DiaryOfAWriter9"},{"id":"1427954976035205124","name":"Eric Y","username":"EricY49116930"},{"id":"1781417178442465280","name":"andrew\xe2\xad\x91 \xe2\x9c\x9f","username":"andrew622556"},{"id":"783960380","name":"Haisam Saeed","username":"HaisamSaeed"}]},"meta":{"newest_id":"1782108344695828551","oldest_id":"1782102782822248590","result_count":100,"next_token":"b26v89c19zqg8o3fr5zcxov76kimjwzh8t50sl62gbjp9"}}'


2024-04-21 11:05:34,503 - DEBUG - Making API request: GET https://api.twitter.com/2/users
Parameters: {'ids': '1682582622973865986,1682248354061774849,3146075416,2786811027,863151625992634368,1391299076,913062226595999744,824004076211945472,311111360,1781170940006514688,1695792271738679296,1598217786555334658,1755625172445409280,248287946,1559840812497833985,42884497,1411894153294741506,1629625427605041152,2359273048,1157589660,1184149123756376064,862668144426590214,205289858,1061618371085680641,1181374198326759424,446368986,290483042,4903580696,3124279521,1682783316028817409,103469507,939415223454203905,1699136604810666008,455239973,1253032404106850317,494576583,550003530,231312029,80956859,289202543,2818253448,1246635092484612097,1371420662015918080,1634270507053752322,1521300780069892096,810233037313245189,1699136604810666008,1466127835,1596197047530569729,1204442204804136960,139676556,1210572352926486531,2339714221,2701633188,1084856929191636992,2387335184,1152110797293670401,1501985741831737344,1018535019982159872,1661272980,1728056582607380481,531329367,1168247042411352065,1139398423591837697,2759558918,1720780885220347904,1346180383679852546,873225853,1114621409291112448,122977347,774146034,761339240315781120,1716858701586350080,389385052,1634301482534092801,1240639126119968773,84046017,4245078393,732226980184260608,1287338845,25183440,246389614,3231391844,1518297026416590850,1671728894997839874,1154993832972496901,109892153,2879691410,939955614826008576,1404904254,1024737671485087744,1738054123222679552,2612807188,1188065120091402241,880004903825022976,352299223,1209236601542455296,1427954976035205124,1781417178442465280,783960380'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:05:34,748 - DEBUG - https://api.twitter.com:443 "GET /2/users?ids=1682582622973865986%2C1682248354061774849%2C3146075416%2C2786811027%2C863151625992634368%2C1391299076%2C913062226595999744%2C824004076211945472%2C311111360%2C1781170940006514688%2C1695792271738679296%2C1598217786555334658%2C1755625172445409280%2C248287946%2C1559840812497833985%2C42884497%2C1411894153294741506%2C1629625427605041152%2C2359273048%2C1157589660%2C1184149123756376064%2C862668144426590214%2C205289858%2C1061618371085680641%2C1181374198326759424%2C446368986%2C290483042%2C4903580696%2C3124279521%2C1682783316028817409%2C103469507%2C939415223454203905%2C1699136604810666008%2C455239973%2C1253032404106850317%2C494576583%2C550003530%2C231312029%2C80956859%2C289202543%2C2818253448%2C1246635092484612097%2C1371420662015918080%2C1634270507053752322%2C1521300780069892096%2C810233037313245189%2C1699136604810666008%2C1466127835%2C1596197047530569729%2C1204442204804136960%2C139676556%2C1210572352926486531%2C2339714221%2C2701633188%2C1084856929191636992%2C2387335184%2C1152110797293670401%2C1501985741831737344%2C1018535019982159872%2C1661272980%2C1728056582607380481%2C531329367%2C1168247042411352065%2C1139398423591837697%2C2759558918%2C1720780885220347904%2C1346180383679852546%2C873225853%2C1114621409291112448%2C122977347%2C774146034%2C761339240315781120%2C1716858701586350080%2C389385052%2C1634301482534092801%2C1240639126119968773%2C84046017%2C4245078393%2C732226980184260608%2C1287338845%2C25183440%2C246389614%2C3231391844%2C1518297026416590850%2C1671728894997839874%2C1154993832972496901%2C109892153%2C2879691410%2C939955614826008576%2C1404904254%2C1024737671485087744%2C1738054123222679552%2C2612807188%2C1188065120091402241%2C880004903825022976%2C352299223%2C1209236601542455296%2C1427954976035205124%2C1781417178442465280%2C783960380 HTTP/1.1" 200 3359


2024-04-21 11:05:34,750 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:05:34 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '3359', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '53cf9b1db2b02e84', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713723361', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '298', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '199', 'x-connection-hash': '3a24d8449e5530a660ecc2b5020aaa2bafffcc47163f73d8069815dcf64c1f19'}
Content: b'{"data":[{"id":"1682582622973865986","name":"Tn_.","username":"TThalaengjit"},{"id":"1682248354061774849","name":"hoja","username":"ranhoj4"},{"id":"3146075416","name":"jayshree","username":"jayashree_125"},{"id":"2786811027","name":"\xd7\xa7\xd7\xa2\xd7\x9c\xd7\x95\xd7\x95\xd7\x99\xd7\x9f \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"wavesbegging"},{"id":"863151625992634368","name":"rayan meguebli\\uD83C\\uDF5D","username":"rayan_meguebli"},{"id":"1391299076","name":"Christian Nyumbayire","username":"Chritchen"},{"id":"913062226595999744","name":"\\uD83C\\uDDF5\\uD83C\\uDDF8 Riverto \\uD83C\\uDDF5\\uD83C\\uDDF8 Thesea \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"KingTherapy"},{"id":"824004076211945472","name":"Deirdre Beck","username":"Deirdrewbeck"},{"id":"311111360","name":"Youduak","username":"youduakfoods"},{"id":"1781170940006514688","name":"lemonpie","username":"dokyeomieda"},{"id":"1695792271738679296","name":"Lama \\uD83C\\uDF49","username":"palpan77"},{"id":"1598217786555334658","name":"bint e adam","username":"bint_e_adam66"},{"id":"1755625172445409280","name":"Kanat Ruzgar","username":"Ruzgar_Rider08"},{"id":"248287946","name":"LILY.Threelt","username":"LILY_Threelt"},{"id":"1559840812497833985","name":"selflover","username":"ameerahloverly"},{"id":"42884497","name":"Salma S. Zohdi","username":"SalmaZohdi"},{"id":"1411894153294741506","name":"Kalyug","username":"Goutam84270959"},{"id":"1629625427605041152","name":"OLAASM","username":"craigtoennies"},{"id":"2359273048","name":"andreapst\\uD83C\\uDF49","username":"andreapst1"},{"id":"1157589660","name":"old woman josie \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"PanicStation26"},{"id":"1184149123756376064","name":"Madame Zeroni","username":"BayouPriestess"},{"id":"862668144426590214","name":"inky labyrinth \\uD83C\\uDF49\\uD83D\\uDDDD\xef\xb8\x8f","username":"InkyLabyrinth"},{"id":"205289858","name":"Khaldoun Khelil \\uD83C\\uDDF5\\uD83C\\uDDF8\\uD83C\\uDDE9\\uD83C\\uDDFF #freePalestine","username":"kkhelil"},{"id":"1061618371085680641","name":"what","username":"nahbthanks"},{"id":"1181374198326759424","name":"Jesse \\uD83E\\uDD87\\uD83D\\uDD78\xef\xb8\x8f","username":"cultofbats"},{"id":"446368986","name":"Logan","username":"Oluso_LA"},{"id":"290483042","name":"mary lindsay","username":"maurlind"},{"id":"4903580696","name":"Vivian\\uD83C\\uDF49 \xe2\x9e\xa1 marcilled . tumblr","username":"aeonlamb"},{"id":"3124279521","name":"giz \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08 \\uD83C\\uDF49","username":"dsfkgfd"},{"id":"1682783316028817409","name":"reis","username":"althreis"},{"id":"103469507","name":"S. Sooknanan","username":"SSooknanan"},{"id":"939415223454203905","name":"\xea\x9c\xb0\xe1\xb4\x8f\xca\x80 more","username":"ottarfp"},{"id":"1699136604810666008","name":"Neici (Kuki Parivar)","username":"c48364"},{"id":"455239973","name":"Steve Webster","username":"croft1a"},{"id":"1253032404106850317","name":"AJN","username":"AJN_RULES_50"},{"id":"494576583","name":"chilled chuck","username":"jilatos"},{"id":"550003530","name":"Ahmed\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"AhmedSaadGaza"},{"id":"231312029","name":"Jazz M.S\\uD83E\\uDD8B","username":"Love_Me_Jaz"},{"id":"80956859","name":"\xd7\xa1\xd7\x95\xd7\xa4\xd7\x99 king dyke","username":"devilhornsdyke"},{"id":"289202543","name":"Jeem Alef \\uD83D\\uDD3B","username":"joseph664"},{"id":"2818253448","name":"Tashe\xe2\x98\xba\xe2\x99\xa5","username":"EmpressTashe"},{"id":"1246635092484612097","name":"shubhi\xe2\x81\xb7 \\uD83C\\uDF49 | pro-boycott","username":"tanniesmysky"},{"id":"1371420662015918080","name":"The Blueprint","username":"barneskiva"},{"id":"1634270507053752322","name":"Done","username":"achwerty77"},{"id":"1521300780069892096","name":"Shangrila","username":"Shangrila1313"},{"id":"810233037313245189","name":"smo","username":"smolleyes80"},{"id":"1699136604810666008","name":"Neici (Kuki Parivar)","username":"c48364"},{"id":"1466127835","name":"Robert","username":"ShurimanSoul"},{"id":"1596197047530569729","name":"Olaamide!","username":"ProlificMidey"},{"id":"1204442204804136960","name":"KziTech","username":"Kazeemtomiwa1"},{"id":"139676556","name":"\\uD83D\\uDD3B\xd8\xa7\xd9\x85\xd9\x8a\xd8\xb1\xd9\x87","username":"VertePanthere"},{"id":"1210572352926486531","name":"HORKE GRAPHIX","username":"OkeSodiq12"},{"id":"2339714221","name":"Fanta$y \\uD83D\\uDC99","username":"girlsthathoop"},{"id":"2701633188","name":"\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f MomoOfCourse \\uD83C\\uDF49 \xe2\x99\xbf\xef\xb8\x8f","username":"Momo0fCourse"},{"id":"1084856929191636992","name":"Dimitra Andritsou","username":"andrdimitra"},{"id":"2387335184","name":"Aka Kyuketsuki","username":"Kinreigh"},{"id":"1152110797293670401","name":"\\uD83C\\uDDF5\\uD83C\\uDDF8\\uD83C\\uDF49\\uD83D\\uDFE3\xd8\xa8\xd8\xb1\xd8\xa7\xd8\xaf\xd8\xa7 Prada I \\uD83D\\uDFE3\\uD83D\\uDC08\xe2\x80\x8d\xe2\xac\x9b\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"mynameprada"},{"id":"1501985741831737344","name":"Lunatic Lunar Lagomorph","username":"udungetit"},{"id":"1018535019982159872","name":"Jessie Dhaliwall","username":"JDhaliwall"},{"id":"1661272980","name":"Mackenzie \\uD83C\\uDF39\\uD83C\\uDFBB crying over OP5","username":"Kiarrionss"},{"id":"1728056582607380481","name":"Frann | Netflix im coming after you","username":"notfrann_side"},{"id":"531329367","name":"Rehan","username":"rehan_ahm"},{"id":"1168247042411352065","name":"( Ravyn)fan acct \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08\\uD83C\\uDF49","username":"saltymulti"},{"id":"1139398423591837697","name":"BTSVT\\uD83D\\uDC9C\\uD83D\\uDC99","username":"Janhavi12858063"},{"id":"2759558918","name":"Francis Watts \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f","username":"kilowattsup"},{"id":"1720780885220347904","name":"HanJ.1","username":"alienne92"},{"id":"1346180383679852546","name":"cui bono/who benefits?","username":"BerkeleyEve"},{"id":"873225853","name":"An","username":"An_lsmnh"},{"id":"1114621409291112448","name":"Xikers lore enthusiasts \xe2\x99\x9f\xef\xb8\x8f ||-//","username":"Mythoi_exe"},{"id":"122977347","name":"\\uD83D\\uDD3B sentiocentrist \\uD83D\\uDD3B","username":"Sentiocentrist"},{"id":"774146034","name":"Natts L\xc3\xb3pez \xe2\xad\x90\xe2\xad\x90\xe2\xad\x90\\uD83D\\uDC99\\uD83E\\uDD0D\\uD83D\\uDC99","username":"Natts_Lopez"},{"id":"761339240315781120","name":"Alpha","username":"_gekwu"},{"id":"1716858701586350080","name":"Tali \\uD83E\\uDEAC\\uD83C\\uDF36\xef\xb8\x8f\\uD83E\\uDE81","username":"TalulaSha"},{"id":"389385052","name":"Zaman #FreePalestine \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"ZamanX90"},{"id":"1634301482534092801","name":"lookingglass","username":"pinkiesbrain007"},{"id":"1240639126119968773","name":"EliboreBark \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"eliborebark"},{"id":"84046017","name":"Haroon","username":"GalileoGabi"},{"id":"4245078393","name":"Bishan","username":"Bishanishi"},{"id":"732226980184260608","name":"Daphne","username":"daphnereads"},{"id":"1287338845","name":"Reyes","username":"Encantinada"},{"id":"25183440","name":"Nina Ekman","username":"Nina_Ekman"},{"id":"246389614","name":"-poppy-","username":"mxxnchild_x"},{"id":"3231391844","name":"ftrtts \\uD83C\\uDF49","username":"cintheclown"},{"id":"1518297026416590850","name":"E\'fraim Chakechake Kamanga","username":"efraimkamanga"},{"id":"1671728894997839874","name":"\\uD83C\\uDF83sleepsomniac\xee\xa8\x80 #FreePalestine\\uD83C\\uDF49","username":"logistic5721"},{"id":"1154993832972496901","name":"\\uD83C\\uDF49Daddy with Issues\\uD83C\\uDF49 - \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\xe2\x9a\xa7\xef\xb8\x8f","username":"ScorchCakeTM"},{"id":"109892153","name":"Damini","username":"DammitDamini"},{"id":"2879691410","name":"kit","username":"FreeScot45"},{"id":"939955614826008576","name":"Shire loon","username":"loon_shire"},{"id":"1404904254","name":"FeetAddictLoser","username":"BetaSniffslave"},{"id":"1024737671485087744","name":"\xec\x95\xa4\xec\xa0\xa4 uwu\'s \\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08A.C.E, SKZ, VICTON\\uD83C\\uDFF3\xef\xb8\x8f\xe2\x80\x8d\\uD83C\\uDF08","username":"multi_stanning"},{"id":"1738054123222679552","name":"BIGSheaaa\\uD83E\\uDEE6","username":"KiyahRasheaaa"},{"id":"2612807188","name":"\\uD83D\\uDC95 fleur delis \xee\xa8\x80 \\uD83D\\uDD4A\xef\xb8\x8f \xe1\x93\x9a\xe1\x98\x8f\xe1\x97\xa2 \\uD83E\\uDD44#MECFS \\uD83C\\uDDF5\\uD83C\\uDDF8","username":"fleurdelis30"},{"id":"1188065120091402241","name":"\xe1\xb4\xae\xe1\xb4\xb1 Ruby \xe2\x81\xb7| \\uD83C\\uDFF4","username":"i_l0velies_ruby"},{"id":"880004903825022976","name":"CAC ACCREDITED  AGENTS","username":"cacagents"},{"id":"352299223","name":"Koen Bogaert","username":"koenraadBogaert"},{"id":"1209236601542455296","name":"DiaryOfAScreenwriter \\uD83C\\uDDF1\\uD83C\\uDDE7\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"DiaryOfAWriter9"},{"id":"1427954976035205124","name":"Eric Y","username":"EricY49116930"},{"id":"1781417178442465280","name":"andrew\xe2\xad\x91 \xe2\x9c\x9f","username":"andrew622556"},{"id":"783960380","name":"Haisam Saeed","username":"HaisamSaeed"}]}'


2024-04-21 11:05:34,755 - DEBUG - Making API request: GET https://api.twitter.com/2/users/by
Parameters: {'user.fields': 'id', 'usernames': ''}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:05:34,806 - DEBUG - https://api.twitter.com:443 "GET /2/users/by?user.fields=id&usernames= HTTP/1.1" 400 224


2024-04-21 11:05:34,807 - DEBUG - Received API response: 400 Bad Request
Headers: {'date': 'Sun, 21 Apr 2024 18:05:34 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '224', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'e7ff44093b2e1dde', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713723634', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '299', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '14', 'x-connection-hash': '3a24d8449e5530a660ecc2b5020aaa2bafffcc47163f73d8069815dcf64c1f19'}
Content: b'{"errors":[{"parameters":{"usernames":[""]},"message":"The number of values in the `usernames` query parameter list [0] is not between 1 and 100"}],"title":"Invalid Request","detail":"One or more parameters to your request was invalid.","type":"https://api.twitter.com/2/problems/invalid-request"}'


2024-04-21 11:06:14,111 - INFO - filter: {'id': '3f4aafb5-cb1c-4584-802b-0c0ef5d02336', 'user_id': 'brian', 'name': 'XDevChallengeUpdate', 'target': 'reports', 'primary_prompt': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.", 'report_guide': 'simple, concise', 'filter_period': 7, 'filter_prompt': 'x dev challenge', 'usernames': [''], 'only_search_followers': False, 'return_min': 5, 'return_cap': 20, 'keyword_groups': [['']], 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'hi id like to search for reports\n'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nSearch for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'x dev challenge\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nx dev challenge"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'simple, concise'}, {'role': 'assistant', 'content': "If you like this report guide and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nsimple, concise"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'assistant', 'content': 'When searching with query ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("event started yesterday") -is:reply, found 100 tweets.'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the primary prompt.'}, {'role': 'assistant', 'content': 'Not enough valid tweets, broadening primary prompt'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the new primary prompt: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}, {'role': 'assistant', 'content': "Here are the results for your filter 'XDevChallengeUpdate':\n\n"}, {'role': 'assistant', 'content': 'When searching with query ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("since yesterday") -is:reply, found 100 tweets.'}]}


2024-04-21 11:06:14,113 - INFO - filter: {'id': '3f4aafb5-cb1c-4584-802b-0c0ef5d02336', 'user_id': 'brian', 'name': 'XDevChallengeUpdate', 'target': 'reports', 'primary_prompt': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.", 'report_guide': 'simple, concise', 'filter_period': 7, 'filter_prompt': 'x dev challenge', 'usernames': [''], 'only_search_followers': False, 'return_min': 5, 'return_cap': 20, 'keyword_groups': [['']], 'messages': [{'role': 'assistant', 'content': 'Hello! I am X-Filter, a bot designed to assist users in finding specific content on X (Twitter). Can you tell me what you are looking for? Are you looking for users, tweets or reports (a summary of a collection of tweets)?'}, {'role': 'user', 'content': 'hi id like to search for reports\n'}, {'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'can you update me on the x dev challenge? and whats happening with the event? it just started yesterday\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nSearch for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday."}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'x dev challenge\n'}, {'role': 'assistant', 'content': "If you like this prompt and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nx dev challenge"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'simple, concise'}, {'role': 'assistant', 'content': "If you like this report guide and are ready to move on, say 'yes'. Otherwise tell me what to change or improve:\nsimple, concise"}, {'role': 'user', 'content': 'yes'}, {'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'assistant', 'content': 'When searching with query ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("event started yesterday") -is:reply, found 100 tweets.'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the primary prompt.'}, {'role': 'assistant', 'content': 'Not enough valid tweets, broadening primary prompt'}, {'role': 'assistant', 'content': 'Found 0 valid tweets when using the new primary prompt: Search for recent updates on the X Dev Challenge, including details on event progress, announcements, participant feedback, and notable events.'}, {'role': 'assistant', 'content': "Here are the results for your filter 'XDevChallengeUpdate':\n\n"}, {'role': 'assistant', 'content': 'When searching with query ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("participant experiences") OR ("significant occurrences") OR ("since yesterday") -is:reply, found 100 tweets.'}]}


2024-04-21 11:06:14,114 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}
	{'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nThe user shared these example keywords with us: [['']]"}


2024-04-21 11:06:14,118 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.GenerateKeywordGroups'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nThe user shared these example keywords with us: [['']]"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}}


2024-04-21 11:06:14,119 - DEBUG - max_retries: 8


2024-04-21 11:06:14,119 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1076efd00>


2024-04-21 11:06:14,123 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': "Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nThe user shared these example keywords with us: [['']]"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:06:14,157 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:14,174 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d6cb80>


2024-04-21 11:06:14,174 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:14,193 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107bf2320>


2024-04-21 11:06:14,193 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:14,194 - DEBUG - send_request_headers.complete


2024-04-21 11:06:14,194 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:14,194 - DEBUG - send_request_body.complete


2024-04-21 11:06:14,194 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:17,092 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:17 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2639'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599435'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'56ms'), (b'x-request-id', b'req_42db048a7e61d4afa6595410fc2ac600'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=dSDpjvomPphu8iA9fcnd7CXxpEB_9k8u3MQ1Q9kvJJI-1713722777-1.0.1.1-kYFU5X79WoGKXLThwScmznZUgWnfoMMwxq5IVhV4tG8oxLjOejOVDkzQ4AH5oqDzWWGHNNBL0qvT68V2Oliv7g; path=/; expires=Sun, 21-Apr-24 18:36:17 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=sHBVzEQQXL7QHMUEtnNnIyUfc3rayq_sQZuYumNXImY-1713722777072-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4e8adddc0d04-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:17,095 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:17,096 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:17,097 - DEBUG - receive_response_body.complete


2024-04-21 11:06:17,097 - DEBUG - response_closed.started


2024-04-21 11:06:17,097 - DEBUG - response_closed.complete


2024-04-21 11:06:17,098 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:17,106 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrq2926XlnCvxYGMYa2Uzx3N4kK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3LAme8J21m2tkJOaEHdHETR5', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge", "updates"],\n    ["X Dev Challenge", "progress"],\n    ["X Dev Challenge", "announcements"],\n    ["X Dev Challenge", "participant experiences"],\n    ["X Dev Challenge", "significant occurrences", "since yesterday"]\n  ]\n}', name='GenerateKeywordGroups'), type='function')]))], created=1713722774, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=62, prompt_tokens=541, total_tokens=603))


2024-04-21 11:06:17,107 - INFO - Received completion from the model:
keyword_groups: [['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]


2024-04-21 11:06:17,109 - INFO - Searching for tweets with query: ("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences" "since yesterday") -is:reply


2024-04-21 11:06:17,110 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:06:17Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge" updates) OR ("X Dev Challenge" progress) OR ("X Dev Challenge" announcements) OR ("X Dev Challenge" "participant experiences") OR ("X Dev Challenge" "significant occurrences" "since yesterday") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:06:17,114 - DEBUG - Starting new HTTPS connection (1): api.twitter.com:443


2024-04-21 11:06:17,289 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A06%3A17Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22+updates%29+OR+%28%22X+Dev+Challenge%22+progress%29+OR+%28%22X+Dev+Challenge%22+announcements%29+OR+%28%22X+Dev+Challenge%22+%22participant+experiences%22%29+OR+%28%22X+Dev+Challenge%22+%22significant+occurrences%22+%22since+yesterday%22%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:06:17,290 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:06:17 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'set-cookie': 'guest_id_marketing=v1%3A171372277722136280; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:06:17 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id_ads=v1%3A171372277722136280; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:06:17 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, personalization_id="v1_zXocA4q1/MpGnH4L9/E0PQ=="; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:06:17 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id=v1%3A171372277722136280; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:06:17 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'eee0fb2ecffeba51', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713723627', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '446', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '76', 'x-connection-hash': 'b8fff2dca7fa0be6e71093ccf84ed4cab4dfe9e412d206cd990538cff173af37'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:06:17,290 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [[''], ['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]\n\nPlease provide a new keyword group."}


2024-04-21 11:06:17,291 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [[''], ['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:06:17,291 - DEBUG - max_retries: 8


2024-04-21 11:06:17,291 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107dc9b40>


2024-04-21 11:06:17,294 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.\n\nCurrent keyword groups: [[''], ['X Dev Challenge', 'updates'], ['X Dev Challenge', 'progress'], ['X Dev Challenge', 'announcements'], ['X Dev Challenge', 'participant experiences'], ['X Dev Challenge', 'significant occurrences', 'since yesterday']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:06:17,294 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:17,295 - DEBUG - send_request_headers.complete


2024-04-21 11:06:17,295 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:17,295 - DEBUG - send_request_body.complete


2024-04-21 11:06:17,295 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:19,244 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1702'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599718'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'28ms'), (b'x-request-id', b'req_4b3859dade9acb24d47baf98546a893f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4e9e3f3e0d04-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:19,246 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:19,246 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:19,247 - DEBUG - receive_response_body.complete


2024-04-21 11:06:19,247 - DEBUG - response_closed.started


2024-04-21 11:06:19,248 - DEBUG - response_closed.complete


2024-04-21 11:06:19,248 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:19,250 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrtTxlU0BSCdOQsQ0deXY59hPnX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_WgdSMyiii5danh4WkB4XUIab', function=Function(arguments='{\n  "keyword_groups": [\n    ["X Dev Challenge"],\n    ["updates"],\n    ["progress"],\n    ["announcements"],\n    ["participant experiences"],\n    ["significant occurrences"],\n    ["since yesterday"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713722777, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=44, prompt_tokens=307, total_tokens=351))


2024-04-21 11:06:19,253 - INFO - Received completion from the model:
keyword_groups=[['X Dev Challenge'], ['updates'], ['progress'], ['announcements'], ['participant experiences'], ['significant occurrences'], ['since yesterday']]


2024-04-21 11:06:19,257 - INFO - Searching for tweets with query: ("X Dev Challenge") OR (updates) OR (progress) OR (announcements) OR ("participant experiences") OR ("significant occurrences") OR ("since yesterday") -is:reply


2024-04-21 11:06:19,257 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:06:19Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("X Dev Challenge") OR (updates) OR (progress) OR (announcements) OR ("participant experiences") OR ("significant occurrences") OR ("since yesterday") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:06:19,889 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A06%3A19Z&tweet.fields=author_id&expansions=author_id&query=%28%22X+Dev+Challenge%22%29+OR+%28updates%29+OR+%28progress%29+OR+%28announcements%29+OR+%28%22participant+experiences%22%29+OR+%28%22significant+occurrences%22%29+OR+%28%22since+yesterday%22%29+-is%3Areply HTTP/1.1" 200 12611


2024-04-21 11:06:19,891 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:06:19 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '12611', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'b3cfe4c36a696d06', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713723627', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '445', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '544', 'x-connection-hash': 'b8fff2dca7fa0be6e71093ccf84ed4cab4dfe9e412d206cd990538cff173af37'}
Content: b'{"data":[{"edit_history_tweet_ids":["1782108574329516127"],"id":"1782108574329516127","text":"RT @dermotmcorrigan: Lots of Clasico build-up in the blog with @polballus @MarioCortegana @tomas_hill @mikedominski @edmackey11 &amp; the gang.\xe2\x80\xa6","author_id":"185302424"},{"edit_history_tweet_ids":["1782108574002638893"],"id":"1782108574002638893","text":"RT @puniisanijianti: Dramatubers will splice together images that paint a narrative, do niji stock watch streams, give updates on el1r@\xe2\x80\x98s s\xe2\x80\xa6","author_id":"3257717136"},{"edit_history_tweet_ids":["1782108572958015588"],"id":"1782108572958015588","text":"@EphraimSng Reach out to Michael and Esther\\n through them telegram to get recent updates in improving your trading skills,signal strength and earn daily from them profitable trades,this is the link below \\n\\uD83D\\uDC47\\nhttps://t.co/QAG601SPwY","author_id":"1727911837482786816"},{"edit_history_tweet_ids":["1782108571888501118"],"id":"1782108571888501118","text":"RT @favourite131: $BRICK stands as a pillar of innovation and progress in the crypto space \\uD83C\\uDF0C\\n\\n#Brick_By_Brick\\n\\nhttps://t.co/CRUXoFfqwW\\n\\nWeb\xe2\x80\xa6","author_id":"1764052098474221569"},{"edit_history_tweet_ids":["1782108569745191137"],"id":"1782108569745191137","text":"\\uD83E\\uDD16 AI is the next frontier for Near, which began as an AI company. With AI integration, Near aims to lead the pack in blockchain innovation, and the anticipation is already showing in the token prices. Follow @Kruys_Collins for more updates!","author_id":"1733520921233637376"},{"edit_history_tweet_ids":["1782108569569284226"],"id":"1782108569569284226","text":"RT @mengjuns125087: Final stage call: https://t.co/cltoTRmL6q\'s final departure to the happy island is scheduled between the 23rd and 28th\xe2\x80\xa6","author_id":"1774513197992509442"},{"edit_history_tweet_ids":["1782108568784871932"],"id":"1782108568784871932","text":"RT @Justice78602373: \\"Law and order exist for the purpose of establishing justice and when they fail in this purpose they become the danger\xe2\x80\xa6","author_id":"1448596613115437056"},{"edit_history_tweet_ids":["1782108568088629549"],"id":"1782108568088629549","text":"RT @LeishaRiddel: Great progress today on Sister Minnie Everywhere All At Once https://t.co/6V876nDLXD","author_id":"3821370612"},{"edit_history_tweet_ids":["1782108568038322568"],"id":"1782108568038322568","text":"RT @Web3_Protocol: \\uD83C\\uDF99\xef\xb8\x8fJoin Our New X Telegram Text #AMA With @VaraNetwork \\n\\n\\uD83E\\uDD20Guest: Claire (Head of Community Growth)\\n\\uD83C\\uDF0E Host: Lovely ( Web3\xe2\x80\xa6","author_id":"1771115656366174209"},{"edit_history_tweet_ids":["1782108565206962226"],"id":"1782108565206962226","text":"RT @ChimaeraCrypto: @Thorshammergems I mean this might as well be a baby Alt coin at this point. But @KittenWif_SOL for sure.\\n\\nThey got a b\xe2\x80\xa6","author_id":"1730939485053984768"},{"edit_history_tweet_ids":["1782108562702860300"],"id":"1782108562702860300","text":"Day 30 of the #100DaysOfCode Challenge\\n\\nToday , I implemented the snack bar and progress bar functionality for our authentication pages in our chat app\\n\\n#100daysofcodechallenge #learning #webdev #developement","author_id":"1657001931754307585"},{"edit_history_tweet_ids":["1782108562300268967"],"id":"1782108562300268967","text":"Every step you take, no matter how small, brings you closer to that day\\uD83D\\uDCAA #Progress #Achievement #KeepGoing","author_id":"1782108455412662272"},{"edit_history_tweet_ids":["1782108558525440130"],"id":"1782108558525440130","text":"@Hodl_Investor Join Kyle Chasse great mentorship program to receive valuable updates &amp; projects on mining/trading. Plus, gain free entry to the advanced Copy Trade setup to enhance your portfolio. Send a quick greeting via Telegram to join the trading committee...\\uD83D\\uDC47\\nhttps://t.co/7xp9knMnnY","author_id":"1685506592177840128"},{"edit_history_tweet_ids":["1782108557850091727"],"id":"1782108557850091727","text":"RT @gaystudents_: \xe2\x9a\xa0\xef\xb8\x8f WARNING \xe2\x9a\xa0\xef\xb8\x8f\\nSeeding In Progress","author_id":"1489338747057582081"},{"edit_history_tweet_ids":["1782108550770127049"],"id":"1782108550770127049","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"1131452371463233536"},{"edit_history_tweet_ids":["1782108549784465645"],"id":"1782108549784465645","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"2569403326"},{"edit_history_tweet_ids":["1782108548102779254"],"id":"1782108548102779254","text":"Work in progress &gt;&lt; https://t.co/aSDUbrCzCw","author_id":"1533256694603558912"},{"edit_history_tweet_ids":["1782108547389513881"],"id":"1782108547389513881","text":"RT @VTodayOfficial: Chudai          \\n\\n-&gt; Share this video with your friends and visit my Twitter account for more similar content.\xe2\x80\xa6","author_id":"1774468457658044416"},{"edit_history_tweet_ids":["1782108547100102761"],"id":"1782108547100102761","text":"@Altsteinn Absolutely! $TOR is on fire \\uD83D\\uDD25 Exciting times ahead with its innovative technology and strong team updates. Buckle up, it\'s going to be a thrilling ride! \\uD83D\\uDE80 #TOR #crypto #excited","author_id":"1717481544732807168"},{"edit_history_tweet_ids":["1782108545703403719"],"id":"1782108545703403719","text":"RT @ASPertierra: Following the late Cold War era of juntas and strongmen in the southern cone there was a wave of even limited accountabili\xe2\x80\xa6","author_id":"45989616"},{"edit_history_tweet_ids":["1782108544537600238"],"id":"1782108544537600238","text":"RT @TunaChain: Dear Tuna fam\\uD83D\\uDC1F\\uD83D\\uDD17\\n\\nWe are excited to update you on our progress and the exciting developments aligned with our roadmap!\\uD83C\\uDF89\\n\\n1/\\uD83E\\uDDF5\xe2\x80\xa6","author_id":"1775356427592433664"},{"edit_history_tweet_ids":["1782108543971172825"],"id":"1782108543971172825","text":"RT @eesee_io: eesee Rewards Phase 2 coming soon \xe2\x9a\xa1\xef\xb8\x8f\\n\\nTurn on all your notifications and stay tuned for the latest updates!\\uD83D\\uDD14 https://t.co/Nvl\xe2\x80\xa6","author_id":"1658719364034461696"},{"edit_history_tweet_ids":["1782108543279079430"],"id":"1782108543279079430","text":"@100xAltcoinGems @Bohalving $BOLHALVING just launched \\uD83D\\uDD25\\uD83D\\uDD25 \\nSuper low Mc on the rise \\uD83D\\uDCC8\\nHuge marketing &amp; based team so I know it\xe2\x80\x99s gonna send to millions \\n\\nDon\xe2\x80\x99t fade on this bullish opportunity, another 1000x Gem to buy in &amp; hold to millions \\n\\nFollow @Bohalving for more bullish updates \\uD83D\\uDD25\\uD83D\\uDCC8 https://t.co/OTMkZp4Qvd","author_id":"1782093603549888512"},{"edit_history_tweet_ids":["1782108542721273873"],"id":"1782108542721273873","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"1617744519050534913"},{"edit_history_tweet_ids":["1782108542696079801"],"id":"1782108542696079801","text":"RT @JaCockXXL: OMG \\uD83D\\uDE31 I WANT IT SO HARD IN MY ASS! AND U?\\uD83D\\uDE0F\\uD83C\\uDF46\\uD83D\\uDD25\\n\\nDo you want see more\xe2\x81\x89\xef\xb8\x8f Join here \\uD83D\\uDC47\\n\\nhttps://t.co/SxVlXHAHzB\\n\\n\\uD83C\\uDF46 + 10K Hot model\xe2\x80\xa6","author_id":"1649174659793911810"},{"edit_history_tweet_ids":["1782108542432158140"],"id":"1782108542432158140","text":"RT @LegendofArcadia: $ARCA IS COMING \xe2\x9a\x94\xef\xb8\x8f\\n\\nARCA token ($ARCA) is the primary governance token of Legend of Arcadia and serves as an essential\xe2\x80\xa6","author_id":"1617211497868062720"},{"edit_history_tweet_ids":["1782108542176006391"],"id":"1782108542176006391","text":"RT @xblast_app: \\uD83D\\uDCE2All Type Refining Machines Sale Will Be Closed in the Next 72 Hours.\\n\\n\\uD83D\\uDC40Stay tuned for the new features updates.\\n\\n\xe2\x9d\x93How many\xe2\x80\xa6","author_id":"4419879219"},{"edit_history_tweet_ids":["1782108541744234755"],"id":"1782108541744234755","text":"RT @CharacterXAI: \\uD83D\\uDE80 The #countdown to Pre-season has officially begun! Are you ready to embark on the next chapter of our journey? \\n\\n\\uD83E\\uDD14 Chec\xe2\x80\xa6","author_id":"1781306658779779072"},{"edit_history_tweet_ids":["1782108539072192976"],"id":"1782108539072192976","text":"RT @Jokioro: In progress animation from last year https://t.co/r8RdZsMaiS","author_id":"1433567078615715840"},{"edit_history_tweet_ids":["1782108538061701483"],"id":"1782108538061701483","text":"RT @mamaa_shakunii: @MeghUpdates Its strange that Karnataka govt is not taking strict actions Suo Moto...when they acted thats only because\xe2\x80\xa6","author_id":"1507610784943120384"},{"edit_history_tweet_ids":["1782108534185832578"],"id":"1782108534185832578","text":"@jamaallane1 Reach out to Micheal &amp; Esther through their telegram to get recent updates in improving your trading skills,signal strength and earn daily from their profitable trades,they posted the telegram link here\\n\\uD83D\\uDC47\\n\\nhttps://t.co/bSnwC368UR","author_id":"1720613753161478145"},{"edit_history_tweet_ids":["1782108532235747354"],"id":"1782108532235747354","text":"RT @sun_young212: SkechersTH IG Updates \\n\\nAPO NATTAWIN BA SKECHERS\\n\\n#SkechersxAPO | #SkechersTH \\n#ApoNattawin | @Nnattawin1\\n\\nhttps://t.co/s\xe2\x80\xa6","author_id":"1408824086436876288"},{"edit_history_tweet_ids":["1782108531430138119"],"id":"1782108531430138119","text":"RT @FreebornMaryAnn: Yay! Looks like the Flying Monkey in Plymouth, NH survived. No updates yet. Fire started in pizza place next door and\xe2\x80\xa6","author_id":"878568181748695040"},{"edit_history_tweet_ids":["1782108530318934275"],"id":"1782108530318934275","text":"#CivilServiceDay - A Day to Honor the Pillars of India\'s Progress\\n\\nToday, on Civil Service Day, we extend our heartfelt gratitude to the dedicated individuals who have chosen the noble path of civil service. Their unwavering commitment to the nation\'s development and the\xe2\x80\xa6 https://t.co/8Q5wnZanhm https://t.co/DwDG3sc3iS","author_id":"1628306266555817985"},{"edit_history_tweet_ids":["1782108526803857497"],"id":"1782108526803857497","text":"@Saving_Progress @guroworm yeah it was me","author_id":"1516924093869838336"},{"edit_history_tweet_ids":["1782108526141153299"],"id":"1782108526141153299","text":"RT @L0an47: I wanna start a new concept on my channel. I wanna showcase Sonic Speed Simulator updates in the form of music clips and with s\xe2\x80\xa6","author_id":"1688589903834103809"},{"edit_history_tweet_ids":["1782108525939789839"],"id":"1782108525939789839","text":"RT @MahaGaza: Relentless Israeli bombing of the central Gaza Strip. The bombing hasn\'t stopped for one hour since yesterday evening.","author_id":"39327935"},{"edit_history_tweet_ids":["1782108524534984946"],"id":"1782108524534984946","text":"\xe2\x81\xa6@ncaagym_updates\xe2\x81\xa9  coverage in the San Jose merc today https://t.co/izyq9QJgvx","author_id":"393797506"},{"edit_history_tweet_ids":["1782108523561689401"],"id":"1782108523561689401","text":"\\uD83D\\uDE80 Exciting times at #FILLiquid! Our testnet is bustling with activity and we\'ve got major updates coming your way! \\uD83C\\uDF1F\\n\\n\\uD83D\\uDD39 $FIG Staking is almost ready for testnet release\xe2\x80\x94our devs are on it! \\uD83D\\uDEE0\xef\xb8\x8f \\uD83D\\uDD39 Stay tuned for the results from our external audit, coming very soon! \\uD83D\\uDCCA \\uD83D\\uDD39 Plus,\xe2\x80\xa6 https://t.co/NXwTEQP29F","author_id":"1612655895519039488"},{"edit_history_tweet_ids":["1782108520952807875"],"id":"1782108520952807875","text":"RT @KitsuneEcchi: Fischl x Slime [WIP]\\n\\nLooks like she\'s ready for round 2, and the slime is too (\xef\xbd\xa1&gt; \xe2\x80\xbf \xe2\x97\x95\xef\xbd\xa1)\\n\\nLovely voice work by @riizuwu a\xe2\x80\xa6","author_id":"1655132768819453954"},{"edit_history_tweet_ids":["1782108519962988908"],"id":"1782108519962988908","text":"RT @AshleyRayne2K: The progress is real! \\n\\n2018 vs 2024 https://t.co/4OrswtVcpX","author_id":"330527647"},{"edit_history_tweet_ids":["1782108518591410629"],"id":"1782108518591410629","text":"Monad Weekly Updates (Week 7\xef\xb8\x8f\xe2\x83\xa3) \\uD83D\\uDC9C\\n\\nIncase you missed last week\xe2\x80\x99s recap here is the link to it https://t.co/3o7jPODTR0","author_id":"1556565610745700352"},{"edit_history_tweet_ids":["1782108517920346228"],"id":"1782108517920346228","text":"@WrestlingWCC \\uD83D\\uDCCD We\'re in the Cryptocurrency Pump season where we can see so many hidden tokens pump as high as X100\\n\\n\\uD83D\\uDCCD Join this Channel for FREE Crypto Updates &amp; Signals \xe2\x80\xbc\xef\xb8\x8fLet\'s make money together \\n\\nhttps://t.co/epmvtry3sO","author_id":"1506371641890287626"},{"edit_history_tweet_ids":["1782108516808851576"],"id":"1782108516808851576","text":"RT @carrieunderwood: Get this new year started off right with @fit52!  I am so proud of the progress I\xe2\x80\x99m seeing from the fit52 fam. Whether\xe2\x80\xa6","author_id":"1781704758635454464"},{"edit_history_tweet_ids":["1782108516557504721"],"id":"1782108516557504721","text":"This is a really great and excellent project. Thank you for this opportunity. I hope this project will continue to progress and successful.\\n@Daman95858498 @Norasih5 @Dewi85598913 https://t.co/Amo9z2VBBA","author_id":"1504471261371518978"},{"edit_history_tweet_ids":["1782108514913022167"],"id":"1782108514913022167","text":"RT @gnnhdofficial: \xd8\xb3\xd9\x86\xd8\xaf\xda\xbe \xd9\x85\xdb\x8c\xda\xba \xd9\xbe\xd9\x88\xd9\x84\xd9\x86\xda\xaf \xd8\xb9\xd9\x85\xd9\x84\xdb\x81 \xd9\xb9\xda\xbe\xd9\xbe\xdb\x92 \xd9\x84\xda\xaf\xd8\xa7\xd8\xaa\xdb\x92 \xd8\xb1\xd9\x86\xda\xaf\xdb\x92 \xdb\x81\xd8\xa7\xd8\xaa\xda\xbe\xd9\x88\xda\xba \xd9\xbe\xda\xa9\xda\x91\xd8\xa7 \xda\xaf\xdb\x8c\xd8\xa7\\n#GNN #BreakingNews #NewsUpdates #GNN_Updates https://t.co/0PeGkycyGc","author_id":"1593627877580447745"},{"edit_history_tweet_ids":["1782108514250629562"],"id":"1782108514250629562","text":"RT @garagarabola_: Kita bisa lolos dari grup yang diisi negara beginian!\\n\\nMereka lebih punya pengalaman di level Asia, tapi Timnas mampu me\xe2\x80\xa6","author_id":"1675118159999926272"},{"edit_history_tweet_ids":["1782108514007327098"],"id":"1782108514007327098","text":"RT @LetsBeGoodHuman: Along with my 100M MVs on YT, I\'ll start updating on our progress with 1B goals too.\\n\\nBlood Sweat &amp; Tears --&gt; 29,7M le\xe2\x80\xa6","author_id":"704968334710689792"},{"edit_history_tweet_ids":["1782108512220569631"],"id":"1782108512220569631","text":"RT @LeishaRiddel: Great progress today on Sister Minnie Everywhere All At Once https://t.co/6V876nDLXD","author_id":"1237950852226117632"},{"edit_history_tweet_ids":["1782108511939526875"],"id":"1782108511939526875","text":"RT @Bybit_Official: \\uD83D\\uDD25 #Bybit x #MASA: 12,660,200 $MASA Up for Grabs!\\n\\nHow?\\n1. Follow @Bybit_Official and @getmasafi\\n2. Quote/retweet this p\xe2\x80\xa6","author_id":"1322069021005615104"},{"edit_history_tweet_ids":["1782108509888209135"],"id":"1782108509888209135","text":"Invest in innovation and progress with $PARAM and @ParamLaboratory. Your contribution matters!","author_id":"1223942723994030091"},{"edit_history_tweet_ids":["1782108509594693974"],"id":"1782108509594693974","text":"@Natanae25968123 Join Kyle Chasse great mentorship program to receive valuable updates &amp; projects on mining/trading. Plus, gain free entry to the advanced Copy Trade setup to enhance your portfolio. Send a quick greeting via Telegram to join the trading committee...\\uD83D\\uDC47\\nhttps://t.co/7xp9knMnnY","author_id":"1685506592177840128"},{"edit_history_tweet_ids":["1782108509506544126"],"id":"1782108509506544126","text":"RT @CharlieMurphy50: Far from perfect but it\xe2\x80\x99s progress! \\n\\n6 stone gone.\\n\\nStill motivated to become the best and healthy version of myself.\xe2\x80\xa6","author_id":"1636081952477401088"},{"edit_history_tweet_ids":["1782108508231815443"],"id":"1782108508231815443","text":"RT @playboycrypt0: More good news to report post halving this coming week guys with 1 weekend yielding 2 Crucial updates today\\uD83E\\uDD1D\\n\\n\\uD83D\\uDCD5The @bowl\xe2\x80\xa6","author_id":"1781250504133320704"},{"edit_history_tweet_ids":["1782108508143415653"],"id":"1782108508143415653","text":"RT @backstreetboys: We\xe2\x80\x99ll be posting live updates from Cancun tonight and revealing the 30 for 30 show set list you guys voted on! Stay tun\xe2\x80\xa6","author_id":"1013435835126026240"},{"edit_history_tweet_ids":["1782108507526889846"],"id":"1782108507526889846","text":"RT @pmln_org: A vote for SHER is a vote for continued progress.\\n\\nA vote for SHER is a vote for continued development.\\n\\nA vote for SHER is a\xe2\x80\xa6","author_id":"1690264131436253184"},{"edit_history_tweet_ids":["1782108505400315999"],"id":"1782108505400315999","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"2822836785"},{"edit_history_tweet_ids":["1782108504838295613"],"id":"1782108504838295613","text":"RT @RobJimFleming: If you need more permanent colleagues, to progress and develop in your organisation, Specialty Doctors have:  \\n\\nA medica\xe2\x80\xa6","author_id":"1605592840507105286"},{"edit_history_tweet_ids":["1782108504653705382"],"id":"1782108504653705382","text":"RT @Ms_Elizzaah: Here, $WNT is displaying bullish signals, hinting at a potential significant upward movement. Keep a close watch and stay\xe2\x80\xa6","author_id":"1648601181323755520"},{"edit_history_tweet_ids":["1782108504364302683"],"id":"1782108504364302683","text":"RT @xblast_app: \\uD83D\\uDCE2All Type Refining Machines Sale Will Be Closed in the Next 72 Hours.\\n\\n\\uD83D\\uDC40Stay tuned for the new features updates.\\n\\n\xe2\x9d\x93How many\xe2\x80\xa6","author_id":"293135099"},{"edit_history_tweet_ids":["1782108503374549217"],"id":"1782108503374549217","text":"RT @kenklippenstein: Q: Israel wants to do a military operation in Rafah. When do you expect to have any updates about their plan?\\n\\nPENTAGO\xe2\x80\xa6","author_id":"548873794"},{"edit_history_tweet_ids":["1782108503244415139"],"id":"1782108503244415139","text":"RT @PropFirmMatch: #PropFirm Payout Amounts for March \\uD83D\\uDCCA\\n\\n- Based on the firms\' own announcements.\\n- Includes only the firms that have share\xe2\x80\xa6","author_id":"1730348166673747968"},{"edit_history_tweet_ids":["1782108502393225286"],"id":"1782108502393225286","text":"RT @lukefoxjukebox: Sheldon Keefe:\\n\\n\xe2\x80\x9cNo updates on William.\xe2\x80\x9d\\n\xe2\x80\x9cNo updates on goaltending.\xe2\x80\x9d\\n\xe2\x80\x9cNo updates on lineup.\xe2\x80\x9d","author_id":"799446786280747008"},{"edit_history_tweet_ids":["1782108501965459816"],"id":"1782108501965459816","text":"RT @MasssToken: Hello $MASS Fellas, \\n\\nWe\'re pleased to announce that we\'ve started the much needed Smart contract Audit process with SOLID-\xe2\x80\xa6","author_id":"1727833172623142912"},{"edit_history_tweet_ids":["1782108501390856413"],"id":"1782108501390856413","text":"@RepHaleyStevens What did you do, whose counsel did you seek, to make such a decision? Why $60 billion? What progress was made w the billions already sent? Trump get prosecuted for a clerical tax error but no accounting for Zelensky. You are all traitors!","author_id":"1642426585956638720"},{"edit_history_tweet_ids":["1782108501147341028"],"id":"1782108501147341028","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"369412662"},{"edit_history_tweet_ids":["1782108500451082448"],"id":"1782108500451082448","text":"@VernersViews Thank you Dr Wheelock. It\'s so pleasing to see the progress low carb is finally making in the main stream. The truth cannot be suppressed.","author_id":"20058088"},{"edit_history_tweet_ids":["1782108500002251039"],"id":"1782108500002251039","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"1475845667415277571"},{"edit_history_tweet_ids":["1782108497670263127"],"id":"1782108497670263127","text":"@ModishaRichie @zsimayi I see you now getting it. Slowly but surely we making progress. \\n\\nBeing European has got nothing to do with residency","author_id":"926451329379258368"},{"edit_history_tweet_ids":["1782108495334314162"],"id":"1782108495334314162","text":"RT @dramapotatoe: #ZhengFanxing updates Xiaohongshu https://t.co/Tqz0gmz9eQ","author_id":"1727971656298377216"},{"edit_history_tweet_ids":["1782108494981701976"],"id":"1782108494981701976","text":"RT @grindery_io: Team Grindery had a blast at @token2049 this week in Dubai \\uD83C\\uDDE6\\uD83C\\uDDEA\\n\\nIt was amazing to see how the Web3 space and community is t\xe2\x80\xa6","author_id":"1588683239232872448"},{"edit_history_tweet_ids":["1782108494402896219"],"id":"1782108494402896219","text":"When @warnermusic finally updates her official Albums Sales #Madonna #Queenofpop https://t.co/dZCbMtoUns","author_id":"542914958"},{"edit_history_tweet_ids":["1782108493979205911"],"id":"1782108493979205911","text":"RT @toshine4u: I am really not happy Man utd won on penalties, that team doesn\'t deserve to progress in FA cup","author_id":"1648325227321982976"},{"edit_history_tweet_ids":["1782108493631111246"],"id":"1782108493631111246","text":"@Wasim_wazir @FaisalAminKhan Wror jana domra support ma warkawa. Ali amin gandapur Rehan zeb koranaye sara derr zyatay wako. Ghalaty faislay kavi lagia dy. NA  08  bare ke hm sa updates war kawa. Aghy halkay bara ke  arrho sa way na","author_id":"4502914394"},{"edit_history_tweet_ids":["1782108493337489812"],"id":"1782108493337489812","text":"RT @silkyfangs: This Snooty Snek In Progress (of undressing) is sending you some encouragement today \\uD83D\\uDC0D \\uD83C\\uDFDD https://t.co/gQDWJmSTs1","author_id":"1738746828193927169"},{"edit_history_tweet_ids":["1782108492058312787"],"id":"1782108492058312787","text":"RT @ChimaeraCrypto: @Thorshammergems I mean this might as well be a baby Alt coin at this point. But @KittenWif_SOL for sure.\\n\\nThey got a b\xe2\x80\xa6","author_id":"1300746166078976001"},{"edit_history_tweet_ids":["1782108491269726665"],"id":"1782108491269726665","text":"RT @KalFulsom: @RaelleLogan1 We are human, but we can be much more.\\n\\n\\"SHIFTERS\\"\\nBook 01: Survival is not Optional\\nA galactic conflict of ep\xe2\x80\xa6","author_id":"925830864625373184"},{"edit_history_tweet_ids":["1782108490464420310"],"id":"1782108490464420310","text":"RT @UXLINKofficial: Hats off to the incredible organizers of Dubai @token2049 \\uD83C\\uDFA9What\'s next? \\n\\nFollow us @airdrop2049 for exciting updates a\xe2\x80\xa6","author_id":"1717760027082027009"},{"edit_history_tweet_ids":["1782108488073961473"],"id":"1782108488073961473","text":"RT @ChimaeraCrypto: @Thorshammergems I mean this might as well be a baby Alt coin at this point. But @KittenWif_SOL for sure.\\n\\nThey got a b\xe2\x80\xa6","author_id":"1005849343780245509"},{"edit_history_tweet_ids":["1782108486890885149"],"id":"1782108486890885149","text":"RT @EternalReturnIV: Messy-progress-of-one-of-my-dear\'s-portraits https://t.co/CrstQJmKiZ","author_id":"1595825112175054849"},{"edit_history_tweet_ids":["1782108486672724219"],"id":"1782108486672724219","text":"50 % off at BelAmi, Click here to get this super deal \xe2\x9e\xa1\xef\xb8\x8f https://t.co/5Yt1NbH7Ij \xe2\xac\x85\xef\xb8\x8f https://t.co/fG3M8tKYas","author_id":"1367510122902261763"},{"edit_history_tweet_ids":["1782108486156849260"],"id":"1782108486156849260","text":"RT @Web3_Protocol: \\uD83C\\uDF99\xef\xb8\x8fJoin Our New X Telegram Text #AMA With @VaraNetwork \\n\\n\\uD83E\\uDD20Guest: Claire (Head of Community Growth)\\n\\uD83C\\uDF0E Host: Lovely ( Web3\xe2\x80\xa6","author_id":"1667283682799788039"},{"edit_history_tweet_ids":["1782108480842916218"],"id":"1782108480842916218","text":"RT @thomasbirm: BREAKING: Student organizers with the Yale divestment encampment have just been informed that as of 11:30 tonight, any stud\xe2\x80\xa6","author_id":"1060107439197052928"},{"edit_history_tweet_ids":["1782108480720994563"],"id":"1782108480720994563","text":"RT @JimBair62221006: \'Parts of India are being seared under a heatwave with maximum temperatures ranging from 40\xc2\xb0C to 46\xc2\xb0C [104-115\xc2\xb0F] in m\xe2\x80\xa6","author_id":"2983249025"},{"edit_history_tweet_ids":["1782108479072727057"],"id":"1782108479072727057","text":"RT @GaySexyMens: Gay Sex Video &amp; #BelAmiBoys  \\uD83D\\uDD25\\uD83D\\uDD1E \\n \\n\\uD83D\\uDCF9 Find more #BelAmiBoys videos here: \\uD83D\\uDC49  https://t.co/8ctB8GKI1a  \\uD83D\\uDE0B\\nRT https://t.co/pJlJ\xe2\x80\xa6","author_id":"1747611755759468545"},{"edit_history_tweet_ids":["1782108478678446482"],"id":"1782108478678446482","text":"@wesrucker247 Personally, I really appreciate your updates!!","author_id":"20543874"},{"edit_history_tweet_ids":["1782108476979978685"],"id":"1782108476979978685","text":"Watch\\n\\n#TATAIPL2024 #CSKvsLSG 23 April 06:58pm Live on Star Utsav Movies (DD Free Dish)\\n\\n@StarSportsIndia\\n\\nFor more updates follow \\n@AyaanY3 https://t.co/Vae1gz49LM","author_id":"1533675660828286977"},{"edit_history_tweet_ids":["1782108476380180509"],"id":"1782108476380180509","text":"RT @xblast_app: \\uD83D\\uDCE2All Type Refining Machines Sale Will Be Closed in the Next 72 Hours.\\n\\n\\uD83D\\uDC40Stay tuned for the new features updates.\\n\\n\xe2\x9d\x93How many\xe2\x80\xa6","author_id":"1780842511113814016"},{"edit_history_tweet_ids":["1782108476237299841"],"id":"1782108476237299841","text":"RT @CharlieMurphy50: Far from perfect but it\xe2\x80\x99s progress! \\n\\n6 stone gone.\\n\\nStill motivated to become the best and healthy version of myself.\xe2\x80\xa6","author_id":"1104402429607591936"},{"edit_history_tweet_ids":["1782108474396049911"],"id":"1782108474396049911","text":"RT @Neversol_coin: The market is recovering little by little what makes it perfect timing to make some announcements\\uD83D\\uDC40 https://t.co/8cCEyR95\xe2\x80\xa6","author_id":"1776046492580528128"},{"edit_history_tweet_ids":["1782108471640678738"],"id":"1782108471640678738","text":"During the week of April 14-20, the First Presidency issued temple garment statement, 2024-2025 area leadership released, updates for several temples, plus six more stories.\\n\\nhttps://t.co/oUKv1GFRVT","author_id":"285184644"},{"edit_history_tweet_ids":["1782108469090521366"],"id":"1782108469090521366","text":"RT @Emo__Base: mother of meme\\n\\nhttps://t.co/rUZvFjFKet\\n\\nThe only official website for #EMO, more announcements will be made publicly\\n\\nWhat\xe2\x80\xa6","author_id":"1558025068856635392"},{"edit_history_tweet_ids":["1782108469031805328"],"id":"1782108469031805328","text":"RT @TunaChain: Dear Tuna fam\\uD83D\\uDC1F\\uD83D\\uDD17\\n\\nWe are excited to update you on our progress and the exciting developments aligned with our roadmap!\\uD83C\\uDF89\\n\\n1/\\uD83E\\uDDF5\xe2\x80\xa6","author_id":"1778520880852910080"},{"edit_history_tweet_ids":["1782108467450503599"],"id":"1782108467450503599","text":"RT @TunaChain: Dear Tuna fam\\uD83D\\uDC1F\\uD83D\\uDD17\\n\\nWe are excited to update you on our progress and the exciting developments aligned with our roadmap!\\uD83C\\uDF89\\n\\n1/\\uD83E\\uDDF5\xe2\x80\xa6","author_id":"1777168932694261760"},{"edit_history_tweet_ids":["1782108462228316299"],"id":"1782108462228316299","text":"RT @SebastianWols17: If I had to choose only one coin to hold\\n\\nIt would be this:)\\n\\n@NakamotoGames Outperforming all the GameFi coins by a m\xe2\x80\xa6","author_id":"224288902"},{"edit_history_tweet_ids":["1782108461683151239"],"id":"1782108461683151239","text":"RT @aividgenerator: GM! \\uD83C\\uDF89 Congrats to our \\uD83D\\uDC51\xe3\x83\xbb Winners!\\uD83C\\uDF89\\nhttps://t.co/qvsBifSgmS\\nYou\'ve secured your exclusive role and are set to receive to\xe2\x80\xa6","author_id":"996972896"},{"edit_history_tweet_ids":["1782108459875385515"],"id":"1782108459875385515","text":"RT @Imaginary_Ones: \\uD83E\\uDEE7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers \\uD83C\\uDFAE\\n\\n#BUBBLERANGERS $BUBBLE\xe2\x80\xa6","author_id":"1260731841142755331"},{"edit_history_tweet_ids":["1782108456775798983"],"id":"1782108456775798983","text":"@CPD_Media Thank you for the timely update. Praying for the quick recovery of the police officer and for the safety of all involved. Looking forward to more updates.","author_id":"1683398339327565827"},{"edit_history_tweet_ids":["1782108456364982588"],"id":"1782108456364982588","text":"RT @CharacterXAI: \\uD83D\\uDE80 The #countdown to Pre-season has officially begun! Are you ready to embark on the next chapter of our journey? \\n\\n\\uD83E\\uDD14 Chec\xe2\x80\xa6","author_id":"1777643653474947072"},{"edit_history_tweet_ids":["1782108455807181295"],"id":"1782108455807181295","text":"RT @TunaChain: Dear Tuna fam\\uD83D\\uDC1F\\uD83D\\uDD17\\n\\nWe are excited to update you on our progress and the exciting developments aligned with our roadmap!\\uD83C\\uDF89\\n\\n1/\\uD83E\\uDDF5\xe2\x80\xa6","author_id":"1776939570799742976"}],"includes":{"users":[{"id":"185302424","name":"Michael Dominski","username":"mikedominski"},{"id":"3257717136","name":"BLACK CAT DA BESTIII\xe2\x9c\xa8\xef\xb8\x8fMAZE\xe2\x9c\xa8\xef\xb8\x8f","username":"Pan_1248"},{"id":"1727911837482786816","name":"Jennifer Watson","username":"JenniferWa29558"},{"id":"1764052098474221569","name":"Sophia_CMT","username":"Sophia_CMT_"},{"id":"1733520921233637376","name":"Kruys Collins","username":"Kruys_Collins"},{"id":"1774513197992509442","name":"Kingo(,)","username":"Kingo828088"},{"id":"1448596613115437056","name":"Purnima","username":"Purnimasen123"},{"id":"3821370612","name":"helen - \xe4\xb8\x83\xe6\xb5\xb7\xe5\xbb\xba\xe4\xba\xba","username":"YO1NAGUMO"},{"id":"1771115656366174209","name":"Aakah","username":"Aakah1297419"},{"id":"1730939485053984768","name":"\xce\x93\xce\xb9\xcf\x8e\xcf\x81\xce\xb3\xce\xbf\xcf\x82 \xce\x92.","username":"Geotrading"},{"id":"1657001931754307585","name":"Vishal Chauhan","username":"Vishal_ch08"},{"id":"1782108455412662272","name":"Meron \\uD83C\\uDF3B","username":"DPablo9477"},{"id":"1685506592177840128","name":"Conrad Gaskell","username":"ConradGask7487"},{"id":"1489338747057582081","name":"Dexterxxl","username":"Dexterxxl76","withheld":{"country_codes":["ID"]}},{"id":"1131452371463233536","name":"$MOJOFatunmbi Gabriel $BEYOND","username":"FatunmbiGabriel"},{"id":"2569403326","name":"King of The North","username":"erhnakb"},{"id":"1533256694603558912","name":"Cheese Cheese","username":"Cheese12367"},{"id":"1774468457658044416","name":"papaversamnefer","username":"papaversam99384"},{"id":"1717481544732807168","name":"ArcticDiamond\\uD83D\\uDC8E $BUBBLE \\uD83E\\uDEE7\\uD83E\\uDEE7\\uD83E\\uDEE7","username":"ArcticDiam3s"},{"id":"45989616","name":"H Mantegazzi \\uD83D\\uDE88\\uD83C\\uDDE8\\uD83C\\uDDF1\\uD83C\\uDF33 @chilemasto.casa@hmantegazzi","username":"hmantegazzi"},{"id":"1775356427592433664","name":"Sgsg","username":"Sgsg155705"},{"id":"1658719364034461696","name":"Marble","username":"i_am_marble_"},{"id":"1782093603549888512","name":"tho","username":"tusexzy12345"},{"id":"1617744519050534913","name":"Frank Chidex $BUBBLE","username":"Chidex12Frank"},{"id":"1649174659793911810","name":"dirty sweet","username":"dirtysweet27"},{"id":"1617211497868062720","name":"Mansory","username":"nftmuryo"},{"id":"4419879219","name":"AfrikanRebel \\uD83C\\uDF0D \\uD83D\\uDD79$RCADE","username":"i_am_macd"},{"id":"1781306658779779072","name":"Rocky","username":"Rocky29761"},{"id":"1433567078615715840","name":"AUSTRALUS_THE_AUSTRALOPITHECUS","username":"MR_PITHECUS"},{"id":"1507610784943120384","name":"ROY","username":"isopegus"},{"id":"1720613753161478145","name":"Paula Wilson","username":"wilson_pau90293"},{"id":"1408824086436876288","name":"minka Lim","username":"sun_minka"},{"id":"878568181748695040","name":"Lake Winnipesaukee \\uD83E\\uDD47","username":"myWinnipesaukee"},{"id":"1628306266555817985","name":"Bureaucrats Media","username":"MBureaucrats"},{"id":"1516924093869838336","name":"Ghost Blues","username":"GhostBlues4"},{"id":"1688589903834103809","name":"Sonic Fan","username":"abigsonicfans"},{"id":"39327935","name":"absurdist lemon tree","username":"IskandarSolmaz"},{"id":"393797506","name":"Diana","username":"dianajc99"},{"id":"1612655895519039488","name":"FILLiquid","username":"FILLiquid"},{"id":"1655132768819453954","name":"fernando","username":"fernand75923154"},{"id":"330527647","name":"K-BREEZY4EVER","username":"K_BREEZY4ever"},{"id":"1556565610745700352","name":"Tobez","username":"tobezticated"},{"id":"1506371641890287626","name":"Oladweston","username":"oladweston"},{"id":"1781704758635454464","name":"Carrie Underwood","username":"Real_carrie_org"},{"id":"1504471261371518978","name":"Ikyy | Argy Bargy\xe2\x9d\xa4\xef\xb8\x8f","username":"ikyy2397"},{"id":"1593627877580447745","name":"Adnan Ahmad","username":"adnanahmad35101"},{"id":"1675118159999926272","name":"\\uD83C\\uDD71\xef\xb8\x8f","username":"nooortham"},{"id":"704968334710689792","name":"Monday\xe2\x81\xb7","username":"monday2soon1"},{"id":"1237950852226117632","name":"\xe0\xb1\xa8\xe0\xa7\x8e \\uD83D\\uDC08\xe2\x80\x8d\xe2\xac\x9b \xe0\xbe\x80\xe0\xbd\xb2","username":"dummydumpling"},{"id":"1322069021005615104","name":"\xe2\x9d\xa4\xef\xb8\x8f Memecoin","username":"TMuhsir"},{"id":"1223942723994030091","name":"Ahsan","username":"Ahsanghaffar_2"},{"id":"1636081952477401088","name":"X \xce\x9b V Y \xef\xb8\xbb\xe2\x95\xa6\xcc\xb5\xcc\xb5\xcc\xbf\xe2\x95\xa4\xe2\x94\x80 \xd2\x89~\xe2\x80\xa2 \xe3\x80\x8c5/21\xe3\x80\x8d","username":"elianiscrazy4me"},{"id":"1781250504133320704","name":"Kse","username":"Kse_vbb"},{"id":"1013435835126026240","name":"Ella \\uD83C\\uDDFA\\uD83C\\uDDE6","username":"Ella_Alicea"},{"id":"1690264131436253184","name":"\xd9\xbe\xd9\x86\xd8\xac\xd8\xa7\xd8\xa8\xdb\x8c \xda\x88\xdb\x8c\xd8\xb1\xdb\x81","username":"punjabidaira"},{"id":"2822836785","name":"PAP","username":"official_pap_"},{"id":"1605592840507105286","name":"Ahmad Barotchi","username":"ABarotchi1"},{"id":"1648601181323755520","name":"Daniela","username":"DanielaRosali8"},{"id":"293135099","name":"BI-LO-SEL-HI \\uD83D\\uDD79\xef\xb8\x8f $RCADE $BUBBLE plena","username":"only_biloselhi"},{"id":"548873794","name":"tiff","username":"tifffuxxsake"},{"id":"1730348166673747968","name":"ROCKY","username":"rockypips"},{"id":"799446786280747008","name":"Daddy KB","username":"KPBails"},{"id":"1727833172623142912","name":"Yahya","username":"yalomari73"},{"id":"1642426585956638720","name":"Chrizzy","username":"MerklingCh74427"},{"id":"369412662","name":"Artemis\xe2\x84\xa2\xef\xb8\x8f $BEYOND","username":"Ifedaryo"},{"id":"20058088","name":"The-Fat:Controller \\uD83C\\uDFC1\\uD83D\\uDEE1\\uD83D\\uDE00\\uD83D\\uDFE5\\uD83E\\uDD95\\uD83E\\uDD69 \\uD83D\\uDDFD","username":"itsjillgardner"},{"id":"1475845667415277571","name":"St. NFTmagee $BEYOND $BUBBLE","username":"NFTMageee"},{"id":"926451329379258368","name":"Nathan","username":"nathanmahachi"},{"id":"1727971656298377216","name":"\xe0\xb9\x82\xe0\xb8\x9b\xe0\xb8\xa3\xe0\xb8\x94","username":"xiaodongestax"},{"id":"1588683239232872448","name":"Ayomide Alade","username":"Wizayomide"},{"id":"542914958","name":"Crzy4Madnna","username":"cr_nna"},{"id":"1648325227321982976","name":"Aminatu Hamisu","username":"Ameenatu0"},{"id":"4502914394","name":"Abid hayat","username":"Abidsaim16"},{"id":"1738746828193927169","name":"Tulip\'s Spicy alt","username":"Tulipsspicyalt"},{"id":"1300746166078976001","name":"akm","username":"akm18468959"},{"id":"925830864625373184","name":"James Macdougall","username":"JamesMacD1984"},{"id":"1717760027082027009","name":"Isbah Arshad","username":"isbah_arshad"},{"id":"1005849343780245509","name":"Donkey Kong","username":"VCuajotor"},{"id":"1595825112175054849","name":"The Pentagram \xe2\x9b\xa7 Burns \\uD83D\\uDD25","username":"pentagramburns_"},{"id":"1367510122902261763","name":"RawLockerroom","username":"RawLockerroom"},{"id":"1667283682799788039","name":"\\uD83D\\uDC09$MON Kavi.moon","username":"sensei_kavi"},{"id":"1060107439197052928","name":"Digital Craft","username":"DigiCraft360"},{"id":"2983249025","name":"arbma\\uD83C\\uDF3B","username":"arbmacip"},{"id":"1747611755759468545","name":"Jens Gedved","username":"JGedved1965"},{"id":"20543874","name":"Laree Hensley","username":"lahensley"},{"id":"1533675660828286977","name":"Ayaan Y","username":"AyaanY3"},{"id":"1780842511113814016","name":"Ateng wilson","username":"AtengWilson"},{"id":"1104402429607591936","name":"FRXNCH!","username":"FRXNCHPoet"},{"id":"1776046492580528128","name":"bobmo","username":"bobmo688847"},{"id":"285184644","name":"Church News","username":"the_churchnews"},{"id":"1558025068856635392","name":"ito na naman","username":"riegosaurus"},{"id":"1778520880852910080","name":"jahid","username":"jahid0113228684"},{"id":"1777168932694261760","name":"b4cs4dxvyw","username":"b4cs4dxvyw38465"},{"id":"224288902","name":"Peter","username":"gentleaction"},{"id":"996972896","name":"freya \\uD83D\\uDC09 $MON","username":"ambre134"},{"id":"1260731841142755331","name":"Mansoor $BUBBLE $BEYOND","username":"_Mansoor_ahm"},{"id":"1683398339327565827","name":"Puzzle Princess","username":"puzz1e_princess"},{"id":"1777643653474947072","name":"Hnun","username":"Hnun51345"},{"id":"1776939570799742976","name":"Sobuj123","username":"Sobuj123334589"}]},"meta":{"newest_id":"1782108574329516127","oldest_id":"1782108455807181295","result_count":100,"next_token":"b26v89c19zqg8o3fr5zcxov7fnlyr82pe1c5dpb3yw9dp"}}'


2024-04-21 11:06:19,894 - DEBUG - Making API request: GET https://api.twitter.com/2/users
Parameters: {'ids': '185302424,3257717136,1727911837482786816,1764052098474221569,1733520921233637376,1774513197992509442,1448596613115437056,3821370612,1771115656366174209,1730939485053984768,1657001931754307585,1782108455412662272,1685506592177840128,1489338747057582081,1131452371463233536,2569403326,1533256694603558912,1774468457658044416,1717481544732807168,45989616,1775356427592433664,1658719364034461696,1782093603549888512,1617744519050534913,1649174659793911810,1617211497868062720,4419879219,1781306658779779072,1433567078615715840,1507610784943120384,1720613753161478145,1408824086436876288,878568181748695040,1628306266555817985,1516924093869838336,1688589903834103809,39327935,393797506,1612655895519039488,1655132768819453954,330527647,1556565610745700352,1506371641890287626,1781704758635454464,1504471261371518978,1593627877580447745,1675118159999926272,704968334710689792,1237950852226117632,1322069021005615104,1223942723994030091,1685506592177840128,1636081952477401088,1781250504133320704,1013435835126026240,1690264131436253184,2822836785,1605592840507105286,1648601181323755520,293135099,548873794,1730348166673747968,799446786280747008,1727833172623142912,1642426585956638720,369412662,20058088,1475845667415277571,926451329379258368,1727971656298377216,1588683239232872448,542914958,1648325227321982976,4502914394,1738746828193927169,1300746166078976001,925830864625373184,1717760027082027009,1005849343780245509,1595825112175054849,1367510122902261763,1667283682799788039,1060107439197052928,2983249025,1747611755759468545,20543874,1533675660828286977,1780842511113814016,1104402429607591936,1776046492580528128,285184644,1558025068856635392,1778520880852910080,1777168932694261760,224288902,996972896,1260731841142755331,1683398339327565827,1777643653474947072,1776939570799742976'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:06:20,164 - DEBUG - https://api.twitter.com:443 "GET /2/users?ids=185302424%2C3257717136%2C1727911837482786816%2C1764052098474221569%2C1733520921233637376%2C1774513197992509442%2C1448596613115437056%2C3821370612%2C1771115656366174209%2C1730939485053984768%2C1657001931754307585%2C1782108455412662272%2C1685506592177840128%2C1489338747057582081%2C1131452371463233536%2C2569403326%2C1533256694603558912%2C1774468457658044416%2C1717481544732807168%2C45989616%2C1775356427592433664%2C1658719364034461696%2C1782093603549888512%2C1617744519050534913%2C1649174659793911810%2C1617211497868062720%2C4419879219%2C1781306658779779072%2C1433567078615715840%2C1507610784943120384%2C1720613753161478145%2C1408824086436876288%2C878568181748695040%2C1628306266555817985%2C1516924093869838336%2C1688589903834103809%2C39327935%2C393797506%2C1612655895519039488%2C1655132768819453954%2C330527647%2C1556565610745700352%2C1506371641890287626%2C1781704758635454464%2C1504471261371518978%2C1593627877580447745%2C1675118159999926272%2C704968334710689792%2C1237950852226117632%2C1322069021005615104%2C1223942723994030091%2C1685506592177840128%2C1636081952477401088%2C1781250504133320704%2C1013435835126026240%2C1690264131436253184%2C2822836785%2C1605592840507105286%2C1648601181323755520%2C293135099%2C548873794%2C1730348166673747968%2C799446786280747008%2C1727833172623142912%2C1642426585956638720%2C369412662%2C20058088%2C1475845667415277571%2C926451329379258368%2C1727971656298377216%2C1588683239232872448%2C542914958%2C1648325227321982976%2C4502914394%2C1738746828193927169%2C1300746166078976001%2C925830864625373184%2C1717760027082027009%2C1005849343780245509%2C1595825112175054849%2C1367510122902261763%2C1667283682799788039%2C1060107439197052928%2C2983249025%2C1747611755759468545%2C20543874%2C1533675660828286977%2C1780842511113814016%2C1104402429607591936%2C1776046492580528128%2C285184644%2C1558025068856635392%2C1778520880852910080%2C1777168932694261760%2C224288902%2C996972896%2C1260731841142755331%2C1683398339327565827%2C1777643653474947072%2C1776939570799742976 HTTP/1.1" 200 3326


2024-04-21 11:06:20,166 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:06:20 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '3326', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '1c3aa5c2eb91e536', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713723361', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '297', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '220', 'x-connection-hash': 'b8fff2dca7fa0be6e71093ccf84ed4cab4dfe9e412d206cd990538cff173af37'}
Content: b'{"data":[{"id":"185302424","name":"Michael Dominski","username":"mikedominski"},{"id":"3257717136","name":"BLACK CAT DA BESTIII\xe2\x9c\xa8\xef\xb8\x8fMAZE\xe2\x9c\xa8\xef\xb8\x8f","username":"Pan_1248"},{"id":"1727911837482786816","name":"Jennifer Watson","username":"JenniferWa29558"},{"id":"1764052098474221569","name":"Sophia_CMT","username":"Sophia_CMT_"},{"id":"1733520921233637376","name":"Kruys Collins","username":"Kruys_Collins"},{"id":"1774513197992509442","name":"Kingo(,)","username":"Kingo828088"},{"id":"1448596613115437056","name":"Purnima","username":"Purnimasen123"},{"id":"3821370612","name":"helen - \xe4\xb8\x83\xe6\xb5\xb7\xe5\xbb\xba\xe4\xba\xba","username":"YO1NAGUMO"},{"id":"1771115656366174209","name":"Aakah","username":"Aakah1297419"},{"id":"1730939485053984768","name":"\xce\x93\xce\xb9\xcf\x8e\xcf\x81\xce\xb3\xce\xbf\xcf\x82 \xce\x92.","username":"Geotrading"},{"id":"1657001931754307585","name":"Vishal Chauhan","username":"Vishal_ch08"},{"id":"1782108455412662272","name":"Meron \\uD83C\\uDF3B","username":"DPablo9477"},{"id":"1685506592177840128","name":"Conrad Gaskell","username":"ConradGask7487"},{"id":"1489338747057582081","name":"Dexterxxl","username":"Dexterxxl76","withheld":{"country_codes":["ID"]}},{"id":"1131452371463233536","name":"$MOJOFatunmbi Gabriel $BEYOND","username":"FatunmbiGabriel"},{"id":"2569403326","name":"King of The North","username":"erhnakb"},{"id":"1533256694603558912","name":"Cheese Cheese","username":"Cheese12367"},{"id":"1774468457658044416","name":"papaversamnefer","username":"papaversam99384"},{"id":"1717481544732807168","name":"ArcticDiamond\\uD83D\\uDC8E $BUBBLE \\uD83E\\uDEE7\\uD83E\\uDEE7\\uD83E\\uDEE7","username":"ArcticDiam3s"},{"id":"45989616","name":"H Mantegazzi \\uD83D\\uDE88\\uD83C\\uDDE8\\uD83C\\uDDF1\\uD83C\\uDF33 @chilemasto.casa@hmantegazzi","username":"hmantegazzi"},{"id":"1775356427592433664","name":"Sgsg","username":"Sgsg155705"},{"id":"1658719364034461696","name":"Marble","username":"i_am_marble_"},{"id":"1782093603549888512","name":"tho","username":"tusexzy12345"},{"id":"1617744519050534913","name":"Frank Chidex $BUBBLE","username":"Chidex12Frank"},{"id":"1649174659793911810","name":"dirty sweet","username":"dirtysweet27"},{"id":"1617211497868062720","name":"Mansory","username":"nftmuryo"},{"id":"4419879219","name":"AfrikanRebel \\uD83C\\uDF0D \\uD83D\\uDD79$RCADE","username":"i_am_macd"},{"id":"1781306658779779072","name":"Rocky","username":"Rocky29761"},{"id":"1433567078615715840","name":"AUSTRALUS_THE_AUSTRALOPITHECUS","username":"MR_PITHECUS"},{"id":"1507610784943120384","name":"ROY","username":"isopegus"},{"id":"1720613753161478145","name":"Paula Wilson","username":"wilson_pau90293"},{"id":"1408824086436876288","name":"minka Lim","username":"sun_minka"},{"id":"878568181748695040","name":"Lake Winnipesaukee \\uD83E\\uDD47","username":"myWinnipesaukee"},{"id":"1628306266555817985","name":"Bureaucrats Media","username":"MBureaucrats"},{"id":"1516924093869838336","name":"Ghost Blues","username":"GhostBlues4"},{"id":"1688589903834103809","name":"Sonic Fan","username":"abigsonicfans"},{"id":"39327935","name":"absurdist lemon tree","username":"IskandarSolmaz"},{"id":"393797506","name":"Diana","username":"dianajc99"},{"id":"1612655895519039488","name":"FILLiquid","username":"FILLiquid"},{"id":"1655132768819453954","name":"fernando","username":"fernand75923154"},{"id":"330527647","name":"K-BREEZY4EVER","username":"K_BREEZY4ever"},{"id":"1556565610745700352","name":"Tobez","username":"tobezticated"},{"id":"1506371641890287626","name":"Oladweston","username":"oladweston"},{"id":"1781704758635454464","name":"Carrie Underwood","username":"Real_carrie_org"},{"id":"1504471261371518978","name":"Ikyy | Argy Bargy\xe2\x9d\xa4\xef\xb8\x8f","username":"ikyy2397"},{"id":"1593627877580447745","name":"Adnan Ahmad","username":"adnanahmad35101"},{"id":"1675118159999926272","name":"\\uD83C\\uDD71\xef\xb8\x8f","username":"nooortham"},{"id":"704968334710689792","name":"Monday\xe2\x81\xb7","username":"monday2soon1"},{"id":"1237950852226117632","name":"\xe0\xb1\xa8\xe0\xa7\x8e \\uD83D\\uDC08\xe2\x80\x8d\xe2\xac\x9b \xe0\xbe\x80\xe0\xbd\xb2","username":"dummydumpling"},{"id":"1322069021005615104","name":"\xe2\x9d\xa4\xef\xb8\x8f Memecoin","username":"TMuhsir"},{"id":"1223942723994030091","name":"Ahsan","username":"Ahsanghaffar_2"},{"id":"1685506592177840128","name":"Conrad Gaskell","username":"ConradGask7487"},{"id":"1636081952477401088","name":"X \xce\x9b V Y \xef\xb8\xbb\xe2\x95\xa6\xcc\xb5\xcc\xb5\xcc\xbf\xe2\x95\xa4\xe2\x94\x80 \xd2\x89~\xe2\x80\xa2 \xe3\x80\x8c5/21\xe3\x80\x8d","username":"elianiscrazy4me"},{"id":"1781250504133320704","name":"Kse","username":"Kse_vbb"},{"id":"1013435835126026240","name":"Ella \\uD83C\\uDDFA\\uD83C\\uDDE6","username":"Ella_Alicea"},{"id":"1690264131436253184","name":"\xd9\xbe\xd9\x86\xd8\xac\xd8\xa7\xd8\xa8\xdb\x8c \xda\x88\xdb\x8c\xd8\xb1\xdb\x81","username":"punjabidaira"},{"id":"2822836785","name":"PAP","username":"official_pap_"},{"id":"1605592840507105286","name":"Ahmad Barotchi","username":"ABarotchi1"},{"id":"1648601181323755520","name":"Daniela","username":"DanielaRosali8"},{"id":"293135099","name":"BI-LO-SEL-HI \\uD83D\\uDD79\xef\xb8\x8f $RCADE $BUBBLE plena","username":"only_biloselhi"},{"id":"548873794","name":"tiff","username":"tifffuxxsake"},{"id":"1730348166673747968","name":"ROCKY","username":"rockypips"},{"id":"799446786280747008","name":"Daddy KB","username":"KPBails"},{"id":"1727833172623142912","name":"Yahya","username":"yalomari73"},{"id":"1642426585956638720","name":"Chrizzy","username":"MerklingCh74427"},{"id":"369412662","name":"Artemis\xe2\x84\xa2\xef\xb8\x8f $BEYOND","username":"Ifedaryo"},{"id":"20058088","name":"The-Fat:Controller \\uD83C\\uDFC1\\uD83D\\uDEE1\\uD83D\\uDE00\\uD83D\\uDFE5\\uD83E\\uDD95\\uD83E\\uDD69 \\uD83D\\uDDFD","username":"itsjillgardner"},{"id":"1475845667415277571","name":"St. NFTmagee $BEYOND $BUBBLE","username":"NFTMageee"},{"id":"926451329379258368","name":"Nathan","username":"nathanmahachi"},{"id":"1727971656298377216","name":"\xe0\xb9\x82\xe0\xb8\x9b\xe0\xb8\xa3\xe0\xb8\x94","username":"xiaodongestax"},{"id":"1588683239232872448","name":"Ayomide Alade","username":"Wizayomide"},{"id":"542914958","name":"Crzy4Madnna","username":"cr_nna"},{"id":"1648325227321982976","name":"Aminatu Hamisu","username":"Ameenatu0"},{"id":"4502914394","name":"Abid hayat","username":"Abidsaim16"},{"id":"1738746828193927169","name":"Tulip\'s Spicy alt","username":"Tulipsspicyalt"},{"id":"1300746166078976001","name":"akm","username":"akm18468959"},{"id":"925830864625373184","name":"James Macdougall","username":"JamesMacD1984"},{"id":"1717760027082027009","name":"Isbah Arshad","username":"isbah_arshad"},{"id":"1005849343780245509","name":"Donkey Kong","username":"VCuajotor"},{"id":"1595825112175054849","name":"The Pentagram \xe2\x9b\xa7 Burns \\uD83D\\uDD25","username":"pentagramburns_"},{"id":"1367510122902261763","name":"RawLockerroom","username":"RawLockerroom"},{"id":"1667283682799788039","name":"\\uD83D\\uDC09$MON Kavi.moon","username":"sensei_kavi"},{"id":"1060107439197052928","name":"Digital Craft","username":"DigiCraft360"},{"id":"2983249025","name":"arbma\\uD83C\\uDF3B","username":"arbmacip"},{"id":"1747611755759468545","name":"Jens Gedved","username":"JGedved1965"},{"id":"20543874","name":"Laree Hensley","username":"lahensley"},{"id":"1533675660828286977","name":"Ayaan Y","username":"AyaanY3"},{"id":"1780842511113814016","name":"Ateng wilson","username":"AtengWilson"},{"id":"1104402429607591936","name":"FRXNCH!","username":"FRXNCHPoet"},{"id":"1776046492580528128","name":"bobmo","username":"bobmo688847"},{"id":"285184644","name":"Church News","username":"the_churchnews"},{"id":"1558025068856635392","name":"ito na naman","username":"riegosaurus"},{"id":"1778520880852910080","name":"jahid","username":"jahid0113228684"},{"id":"1777168932694261760","name":"b4cs4dxvyw","username":"b4cs4dxvyw38465"},{"id":"224288902","name":"Peter","username":"gentleaction"},{"id":"996972896","name":"freya \\uD83D\\uDC09 $MON","username":"ambre134"},{"id":"1260731841142755331","name":"Mansoor $BUBBLE $BEYOND","username":"_Mansoor_ahm"},{"id":"1683398339327565827","name":"Puzzle Princess","username":"puzz1e_princess"},{"id":"1777643653474947072","name":"Hnun","username":"Hnun51345"},{"id":"1776939570799742976","name":"Sobuj123","username":"Sobuj123334589"}]}'


2024-04-21 11:06:20,172 - DEBUG - Making API request: GET https://api.twitter.com/2/users/by
Parameters: {'user.fields': 'id', 'usernames': ''}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:06:20,223 - DEBUG - https://api.twitter.com:443 "GET /2/users/by?user.fields=id&usernames= HTTP/1.1" 400 224


2024-04-21 11:06:20,224 - DEBUG - Received API response: 400 Bad Request
Headers: {'date': 'Sun, 21 Apr 2024 18:06:20 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '224', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'f8ae56e390169814', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713723634', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '298', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '14', 'x-connection-hash': 'b8fff2dca7fa0be6e71093ccf84ed4cab4dfe9e412d206cd990538cff173af37'}
Content: b'{"errors":[{"parameters":{"usernames":[""]},"message":"The number of values in the `usernames` query parameter list [0] is not between 1 and 100"}],"title":"Invalid Request","detail":"One or more parameters to your request was invalid.","type":"https://api.twitter.com/2/problems/invalid-request"}'


2024-04-21 11:06:20,225 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @dermotmcorrigan: Lots of Clasico build-up in the blog with @polballus @MarioCortegana @tomas_hill @mikedominski @edmackey11 &amp; the gang.…'}


2024-04-21 11:06:20,232 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @dermotmcorrigan: Lots of Clasico build-up in the blog with @polballus @MarioCortegana @tomas_hill @mikedominski @edmackey11 &amp; the gang.…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,233 - DEBUG - max_retries: 8


2024-04-21 11:06:20,233 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107dcbc10>


2024-04-21 11:06:20,239 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @dermotmcorrigan: Lots of Clasico build-up in the blog with @polballus @MarioCortegana @tomas_hill @mikedominski @edmackey11 &amp; the gang.…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,241 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @puniisanijianti: Dramatubers will splice together images that paint a narrative, do niji stock watch streams, give updates on el1r@‘s s…'}


2024-04-21 11:06:20,243 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @puniisanijianti: Dramatubers will splice together images that paint a narrative, do niji stock watch streams, give updates on el1r@‘s s…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,243 - DEBUG - max_retries: 8


2024-04-21 11:06:20,243 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f4d2d0>


2024-04-21 11:06:20,248 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @puniisanijianti: Dramatubers will splice together images that paint a narrative, do niji stock watch streams, give updates on el1r@‘s s…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,248 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: @EphraimSng Reach out to Michael and Esther\n through them telegram to get recent updates in improving your trading skills,signal strength and earn daily from them profitable trades,this is the link below \n👇\nhttps://t.co/QAG601SPwY'}


2024-04-21 11:06:20,250 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: @EphraimSng Reach out to Michael and Esther\n through them telegram to get recent updates in improving your trading skills,signal strength and earn daily from them profitable trades,this is the link below \n👇\nhttps://t.co/QAG601SPwY'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,250 - DEBUG - max_retries: 8


2024-04-21 11:06:20,250 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107dcaec0>


2024-04-21 11:06:20,254 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: @EphraimSng Reach out to Michael and Esther\n through them telegram to get recent updates in improving your trading skills,signal strength and earn daily from them profitable trades,this is the link below \n👇\nhttps://t.co/QAG601SPwY'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,255 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @favourite131: $BRICK stands as a pillar of innovation and progress in the crypto space 🌌\n\n#Brick_By_Brick\n\nhttps://t.co/CRUXoFfqwW\n\nWeb…'}


2024-04-21 11:06:20,256 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @favourite131: $BRICK stands as a pillar of innovation and progress in the crypto space 🌌\n\n#Brick_By_Brick\n\nhttps://t.co/CRUXoFfqwW\n\nWeb…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,256 - DEBUG - max_retries: 8


2024-04-21 11:06:20,256 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f32920>


2024-04-21 11:06:20,260 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @favourite131: $BRICK stands as a pillar of innovation and progress in the crypto space 🌌\n\n#Brick_By_Brick\n\nhttps://t.co/CRUXoFfqwW\n\nWeb…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,261 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: 🤖 AI is the next frontier for Near, which began as an AI company. With AI integration, Near aims to lead the pack in blockchain innovation, and the anticipation is already showing in the token prices. Follow @Kruys_Collins for more updates!'}


2024-04-21 11:06:20,262 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: 🤖 AI is the next frontier for Near, which began as an AI company. With AI integration, Near aims to lead the pack in blockchain innovation, and the anticipation is already showing in the token prices. Follow @Kruys_Collins for more updates!'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,262 - DEBUG - max_retries: 8


2024-04-21 11:06:20,262 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f6ca60>


2024-04-21 11:06:20,265 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: 🤖 AI is the next frontier for Near, which began as an AI company. With AI integration, Near aims to lead the pack in blockchain innovation, and the anticipation is already showing in the token prices. Follow @Kruys_Collins for more updates!'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,266 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': "Tweet: RT @mengjuns125087: Final stage call: https://t.co/cltoTRmL6q's final departure to the happy island is scheduled between the 23rd and 28th…"}


2024-04-21 11:06:20,267 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': "Tweet: RT @mengjuns125087: Final stage call: https://t.co/cltoTRmL6q's final departure to the happy island is scheduled between the 23rd and 28th…"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,267 - DEBUG - max_retries: 8


2024-04-21 11:06:20,267 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f6ec20>


2024-04-21 11:06:20,270 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': "Tweet: RT @mengjuns125087: Final stage call: https://t.co/cltoTRmL6q's final departure to the happy island is scheduled between the 23rd and 28th…"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,270 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @Justice78602373: "Law and order exist for the purpose of establishing justice and when they fail in this purpose they become the danger…'}


2024-04-21 11:06:20,271 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Justice78602373: "Law and order exist for the purpose of establishing justice and when they fail in this purpose they become the danger…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,271 - DEBUG - max_retries: 8


2024-04-21 11:06:20,271 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f6c580>


2024-04-21 11:06:20,274 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Justice78602373: "Law and order exist for the purpose of establishing justice and when they fail in this purpose they become the danger…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,275 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @LeishaRiddel: Great progress today on Sister Minnie Everywhere All At Once https://t.co/6V876nDLXD'}


2024-04-21 11:06:20,276 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @LeishaRiddel: Great progress today on Sister Minnie Everywhere All At Once https://t.co/6V876nDLXD'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,276 - DEBUG - max_retries: 8


2024-04-21 11:06:20,276 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f83340>


2024-04-21 11:06:20,279 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @LeishaRiddel: Great progress today on Sister Minnie Everywhere All At Once https://t.co/6V876nDLXD'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,279 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @Web3_Protocol: 🎙️Join Our New X Telegram Text #AMA With @VaraNetwork \n\n🤠Guest: Claire (Head of Community Growth)\n🌎 Host: Lovely ( Web3…'}


2024-04-21 11:06:20,280 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Web3_Protocol: 🎙️Join Our New X Telegram Text #AMA With @VaraNetwork \n\n🤠Guest: Claire (Head of Community Growth)\n🌎 Host: Lovely ( Web3…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,280 - DEBUG - max_retries: 8


2024-04-21 11:06:20,280 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f83130>


2024-04-21 11:06:20,283 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Web3_Protocol: 🎙️Join Our New X Telegram Text #AMA With @VaraNetwork \n\n🤠Guest: Claire (Head of Community Growth)\n🌎 Host: Lovely ( Web3…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,283 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @ChimaeraCrypto: @Thorshammergems I mean this might as well be a baby Alt coin at this point. But @KittenWif_SOL for sure.\n\nThey got a b…'}


2024-04-21 11:06:20,284 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @ChimaeraCrypto: @Thorshammergems I mean this might as well be a baby Alt coin at this point. But @KittenWif_SOL for sure.\n\nThey got a b…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,284 - DEBUG - max_retries: 8


2024-04-21 11:06:20,284 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107fa1cf0>


2024-04-21 11:06:20,287 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @ChimaeraCrypto: @Thorshammergems I mean this might as well be a baby Alt coin at this point. But @KittenWif_SOL for sure.\n\nThey got a b…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,287 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: Day 30 of the #100DaysOfCode Challenge\n\nToday , I implemented the snack bar and progress bar functionality for our authentication pages in our chat app\n\n#100daysofcodechallenge #learning #webdev #developement'}


2024-04-21 11:06:20,288 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: Day 30 of the #100DaysOfCode Challenge\n\nToday , I implemented the snack bar and progress bar functionality for our authentication pages in our chat app\n\n#100daysofcodechallenge #learning #webdev #developement'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,288 - DEBUG - max_retries: 8


2024-04-21 11:06:20,288 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107f83010>


2024-04-21 11:06:20,290 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: Day 30 of the #100DaysOfCode Challenge\n\nToday , I implemented the snack bar and progress bar functionality for our authentication pages in our chat app\n\n#100daysofcodechallenge #learning #webdev #developement'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,290 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: Every step you take, no matter how small, brings you closer to that day💪 #Progress #Achievement #KeepGoing'}


2024-04-21 11:06:20,291 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: Every step you take, no matter how small, brings you closer to that day💪 #Progress #Achievement #KeepGoing'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,291 - DEBUG - max_retries: 8


2024-04-21 11:06:20,291 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107fae410>


2024-04-21 11:06:20,293 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: Every step you take, no matter how small, brings you closer to that day💪 #Progress #Achievement #KeepGoing'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,294 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: @Hodl_Investor Join Kyle Chasse great mentorship program to receive valuable updates &amp; projects on mining/trading. Plus, gain free entry to the advanced Copy Trade setup to enhance your portfolio. Send a quick greeting via Telegram to join the trading committee...👇\nhttps://t.co/7xp9knMnnY'}


2024-04-21 11:06:20,294 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: @Hodl_Investor Join Kyle Chasse great mentorship program to receive valuable updates &amp; projects on mining/trading. Plus, gain free entry to the advanced Copy Trade setup to enhance your portfolio. Send a quick greeting via Telegram to join the trading committee...👇\nhttps://t.co/7xp9knMnnY'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,295 - DEBUG - max_retries: 8


2024-04-21 11:06:20,295 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107fc03a0>


2024-04-21 11:06:20,297 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: @Hodl_Investor Join Kyle Chasse great mentorship program to receive valuable updates &amp; projects on mining/trading. Plus, gain free entry to the advanced Copy Trade setup to enhance your portfolio. Send a quick greeting via Telegram to join the trading committee...👇\nhttps://t.co/7xp9knMnnY'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,297 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @gaystudents_: ⚠️ WARNING ⚠️\nSeeding In Progress'}


2024-04-21 11:06:20,298 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @gaystudents_: ⚠️ WARNING ⚠️\nSeeding In Progress'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,298 - DEBUG - max_retries: 8


2024-04-21 11:06:20,298 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107fc2560>


2024-04-21 11:06:20,300 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @gaystudents_: ⚠️ WARNING ⚠️\nSeeding In Progress'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,300 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @Imaginary_Ones: \U0001fae7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers 🎮\n\n#BUBBLERANGERS $BUBBLE…'}


2024-04-21 11:06:20,301 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Imaginary_Ones: \U0001fae7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers 🎮\n\n#BUBBLERANGERS $BUBBLE…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,301 - DEBUG - max_retries: 8


2024-04-21 11:06:20,301 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107fd47c0>


2024-04-21 11:06:20,303 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Imaginary_Ones: \U0001fae7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers 🎮\n\n#BUBBLERANGERS $BUBBLE…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,303 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @Imaginary_Ones: \U0001fae7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers 🎮\n\n#BUBBLERANGERS $BUBBLE…'}


2024-04-21 11:06:20,304 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Imaginary_Ones: \U0001fae7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers 🎮\n\n#BUBBLERANGERS $BUBBLE…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,304 - DEBUG - max_retries: 8


2024-04-21 11:06:20,304 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107fc20b0>


2024-04-21 11:06:20,306 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @Imaginary_Ones: \U0001fae7Bubbling up your week on a high note! Stay tuned for more exciting updates to Bubble Rangers 🎮\n\n#BUBBLERANGERS $BUBBLE…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,307 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: Work in progress &gt;&lt; https://t.co/aSDUbrCzCw'}


2024-04-21 11:06:20,307 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: Work in progress &gt;&lt; https://t.co/aSDUbrCzCw'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,307 - DEBUG - max_retries: 8


2024-04-21 11:06:20,307 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ff4cd0>


2024-04-21 11:06:20,309 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: Work in progress &gt;&lt; https://t.co/aSDUbrCzCw'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,309 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @VTodayOfficial: Chudai          \n\n-&gt; Share this video with your friends and visit my Twitter account for more similar content.…'}


2024-04-21 11:06:20,310 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @VTodayOfficial: Chudai          \n\n-&gt; Share this video with your friends and visit my Twitter account for more similar content.…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,310 - DEBUG - max_retries: 8


2024-04-21 11:06:20,310 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x107ff6dd0>


2024-04-21 11:06:20,312 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @VTodayOfficial: Chudai          \n\n-&gt; Share this video with your friends and visit my Twitter account for more similar content.…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,312 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': "Tweet: @Altsteinn Absolutely! $TOR is on fire 🔥 Exciting times ahead with its innovative technology and strong team updates. Buckle up, it's going to be a thrilling ride! 🚀 #TOR #crypto #excited"}


2024-04-21 11:06:20,313 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': "Tweet: @Altsteinn Absolutely! $TOR is on fire 🔥 Exciting times ahead with its innovative technology and strong team updates. Buckle up, it's going to be a thrilling ride! 🚀 #TOR #crypto #excited"}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,313 - DEBUG - max_retries: 8


2024-04-21 11:06:20,313 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11010c7f0>


2024-04-21 11:06:20,315 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': "Tweet: @Altsteinn Absolutely! $TOR is on fire 🔥 Exciting times ahead with its innovative technology and strong team updates. Buckle up, it's going to be a thrilling ride! 🚀 #TOR #crypto #excited"}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,315 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}
	{'role': 'user', 'content': 'Tweet: RT @ASPertierra: Following the late Cold War era of juntas and strongmen in the southern cone there was a wave of even limited accountabili…'}


2024-04-21 11:06:20,316 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.CreateTweetReport'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @ASPertierra: Following the late Cold War era of juntas and strongmen in the southern cone there was a wave of even limited accountabili…'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}}


2024-04-21 11:06:20,316 - DEBUG - max_retries: 8


2024-04-21 11:06:20,316 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x11010da20>


2024-04-21 11:06:20,318 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "Write a report for this tweet following this report guide:\nsimple, concise\n\nThe user's search interest is: Search for tweets providing updates on the X Dev Challenge, including information on the event's progress, announcements, participant experiences, and any significant occurrences since it started yesterday.."}, {'role': 'user', 'content': 'Tweet: RT @ASPertierra: Following the late Cold War era of juntas and strongmen in the southern cone there was a wave of even limited accountabili…'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'CreateTweetReport'}}, 'tools': [{'type': 'function', 'function': {'name': 'CreateTweetReport', 'description': 'Correctly extracted `CreateTweetReport` with all the required parameters with correct types', 'parameters': {'properties': {'report': {'description': "Write this tweet's report here.", 'title': 'Report', 'type': 'string'}}, 'required': ['report'], 'type': 'object'}}}]}}


2024-04-21 11:06:20,318 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,318 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,318 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,319 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,319 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,320 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,321 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,321 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,321 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:06:20,334 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d6fa60>


2024-04-21 11:06:20,334 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,334 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d6efb0>


2024-04-21 11:06:20,334 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,335 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f82860>


2024-04-21 11:06:20,335 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,335 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f80940>


2024-04-21 11:06:20,335 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,336 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010e7d0>


2024-04-21 11:06:20,336 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,338 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010d750>


2024-04-21 11:06:20,338 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010e230>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010eaa0>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010e500>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010ed70>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010f5e0>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010f040>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,339 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010f310>


2024-04-21 11:06:20,339 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,340 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010c190>


2024-04-21 11:06:20,340 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,340 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010f8b0>


2024-04-21 11:06:20,340 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,342 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010cf40>


2024-04-21 11:06:20,342 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,342 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010cdc0>


2024-04-21 11:06:20,342 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,342 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11012c160>


2024-04-21 11:06:20,342 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,342 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11012c700>


2024-04-21 11:06:20,342 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x1062efe40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:06:20,352 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f4ff40>


2024-04-21 11:06:20,353 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,353 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f31cc0>


2024-04-21 11:06:20,353 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,353 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,353 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,353 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,353 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,353 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,353 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,353 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,353 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,356 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f83100>


2024-04-21 11:06:20,356 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,356 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,356 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,356 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,356 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,357 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f33dc0>


2024-04-21 11:06:20,358 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107fa3850>


2024-04-21 11:06:20,359 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f82620>


2024-04-21 11:06:20,359 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107d6f880>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,359 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,359 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,359 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,359 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,359 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,359 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,359 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,359 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,360 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,360 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,361 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107fd6440>


2024-04-21 11:06:20,361 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f6e560>


2024-04-21 11:06:20,361 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107faf640>


2024-04-21 11:06:20,362 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107f82560>


2024-04-21 11:06:20,362 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ff62f0>


2024-04-21 11:06:20,362 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107fc0460>


2024-04-21 11:06:20,362 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,362 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,362 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,362 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,362 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,362 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,362 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107faf880>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,363 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,363 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,363 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,363 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,363 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,363 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107fd62c0>


2024-04-21 11:06:20,363 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,363 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,363 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,363 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,364 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,364 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,364 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,364 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,364 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,364 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,364 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,364 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,364 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,364 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,364 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,365 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,365 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,365 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,365 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,365 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ff6170>


2024-04-21 11:06:20,365 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010dea0>


2024-04-21 11:06:20,365 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,365 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,365 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,365 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,365 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x11010db70>


2024-04-21 11:06:20,366 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x107ff7d90>


2024-04-21 11:06:20,366 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,366 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,366 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,366 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,366 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,366 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_headers.complete


2024-04-21 11:06:20,366 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,366 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:20,366 - DEBUG - send_request_body.complete


2024-04-21 11:06:20,366 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:06:23,031 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:22 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2480'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'598423'), (b'x-ratelimit-reset-requests', b'132ms'), (b'x-ratelimit-reset-tokens', b'157ms'), (b'x-request-id', b'req_bcbca14cc18422f2be241a901d51d457'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16bf87ed7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,033 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,033 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,034 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,034 - DEBUG - response_closed.started


2024-04-21 11:06:23,035 - DEBUG - response_closed.complete


2024-04-21 11:06:23,035 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,037 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwt8jZgImZvq8S7lsVmYECVVi7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PWs73fbCtjGE5L7s9AyE1TUP', function=Function(arguments='{"report":"The tweet does not provide any updates on the X Dev Challenge. It contains a motivational message about making progress and achieving goals, using hashtags such as #Progress, #Achievement, and #KeepGoing. There is no specific information related to the event\'s progress, announcements, participant experiences, or significant occurrences since the challenge started."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=70, prompt_tokens=162, total_tokens=232))


2024-04-21 11:06:23,038 - INFO - Received completion from the model:
report="The tweet does not provide any updates on the X Dev Challenge. It contains a motivational message about making progress and achieving goals, using hashtags such as #Progress, #Achievement, and #KeepGoing. There is no specific information related to the event's progress, announcements, participant experiences, or significant occurrences since the challenge started."


2024-04-21 11:06:23,058 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2487'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'599084'), (b'x-ratelimit-reset-requests', b'80ms'), (b'x-ratelimit-reset-tokens', b'91ms'), (b'x-request-id', b'req_5107fd59e58ff0744f7401f94dbe16d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb15a967e80-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,059 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,060 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,060 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,061 - DEBUG - response_closed.started


2024-04-21 11:06:23,061 - DEBUG - response_closed.complete


2024-04-21 11:06:23,062 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,063 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrw03NpcAy6aEyai94QuWvzK9uY', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fZD8dEmtFRyzEuZL5wbn6lS8', function=Function(arguments='{"report":"The tweet from @EphraimSng does not provide updates on the X Dev Challenge. Instead, it appears to be a promotional message encouraging users to contact Michael and Esther via Telegram for trading skills improvement, signal strength, and daily earnings from trades. The tweet includes a link for further action."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=65, prompt_tokens=192, total_tokens=257))


2024-04-21 11:06:23,064 - INFO - Received completion from the model:
report='The tweet from @EphraimSng does not provide updates on the X Dev Challenge. Instead, it appears to be a promotional message encouraging users to contact Michael and Esther via Telegram for trading skills improvement, signal strength, and daily earnings from trades. The tweet includes a link for further action.'


2024-04-21 11:06:23,067 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4986'), (b'x-ratelimit-remaining-tokens', b'598066'), (b'x-ratelimit-reset-requests', b'164ms'), (b'x-ratelimit-reset-tokens', b'193ms'), (b'x-request-id', b'req_fe5948bd254c929cb78338477a22644f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16df72a92-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,067 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,068 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,068 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,068 - DEBUG - response_closed.started


2024-04-21 11:06:23,068 - DEBUG - response_closed.complete


2024-04-21 11:06:23,069 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,070 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwfnYN6jjQKjaCdknwC4ueCtyU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yfUJ8zKUW8qQYFRaPLYKHuAh', function=Function(arguments='{"report":"The tweet reports on the user\'s progress on day 30 of the #100DaysOfCode Challenge. The user has successfully implemented a snack bar and progress bar for the authentication pages of a chat application they are developing. The tweet includes hashtags related to coding, learning, web development, and development."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=64, prompt_tokens=183, total_tokens=247))


2024-04-21 11:06:23,071 - INFO - Received completion from the model:
report="The tweet reports on the user's progress on day 30 of the #100DaysOfCode Challenge. The user has successfully implemented a snack bar and progress bar for the authentication pages of a chat application they are developing. The tweet includes hashtags related to coding, learning, web development, and development."


2024-04-21 11:06:23,072 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2496'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'599118'), (b'x-ratelimit-reset-requests', b'75ms'), (b'x-ratelimit-reset-tokens', b'88ms'), (b'x-request-id', b'req_4fd177b0c4bb7dd7810f382b1b101f79'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16a7b2f1b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,072 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,073 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,073 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,073 - DEBUG - response_closed.started


2024-04-21 11:06:23,073 - DEBUG - response_closed.complete


2024-04-21 11:06:23,074 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,075 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwwY8IeoJikSVXO5Jv81llkaEX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BnFugaxVnr5znUECwju9zEyb', function=Function(arguments='{"report":"The tweet from @Imaginary_Ones teases upcoming updates for Bubble Rangers, a game associated with the hashtag #BUBBLERANGERS and the ticker $BUBBLE. The tweet aims to generate excitement for future announcements, suggesting that more information will be shared soon."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=61, prompt_tokens=183, total_tokens=244))


2024-04-21 11:06:23,076 - INFO - Received completion from the model:
report='The tweet from @Imaginary_Ones teases upcoming updates for Bubble Rangers, a game associated with the hashtag #BUBBLERANGERS and the ticker $BUBBLE. The tweet aims to generate excitement for future announcements, suggesting that more information will be shared soon.'


2024-04-21 11:06:23,443 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2793'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4991'), (b'x-ratelimit-remaining-tokens', b'598839'), (b'x-ratelimit-reset-requests', b'97ms'), (b'x-ratelimit-reset-tokens', b'116ms'), (b'x-request-id', b'req_5e01880b483b4d09776ddca4b46ed44a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16e7b0908-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,444 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,445 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,446 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,446 - DEBUG - response_closed.started


2024-04-21 11:06:23,447 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2788'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4987'), (b'x-ratelimit-remaining-tokens', b'598216'), (b'x-ratelimit-reset-requests', b'152ms'), (b'x-ratelimit-reset-tokens', b'178ms'), (b'x-request-id', b'req_93faa497dfb9028de2803a8a2bb3f6f8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16f0b2b82-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,448 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,448 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,448 - DEBUG - response_closed.started


2024-04-21 11:06:23,449 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2938'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4991'), (b'x-ratelimit-remaining-tokens', b'598823'), (b'x-ratelimit-reset-requests', b'98ms'), (b'x-ratelimit-reset-tokens', b'117ms'), (b'x-request-id', b'req_f972837ee1cad523b404515bcb8898ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16c467bfb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:23,450 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:23,450 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:23,450 - DEBUG - receive_response_body.complete


2024-04-21 11:06:23,451 - DEBUG - response_closed.started


2024-04-21 11:06:23,451 - DEBUG - response_closed.complete


2024-04-21 11:06:23,452 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,453 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwlpXbNdTLskfKQWDFIjyaRmUh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dmKUkKkGzPPkxGBmS8aNt0kk', function=Function(arguments='{"report":"The tweet from @Hodl_Investor promotes Kyle Chasse\'s mentorship program, which offers updates and projects related to mining and trading. Participants can also access an advanced Copy Trade setup for free to improve their investment portfolio. Interested individuals are invited to join the trading committee by sending a greeting on Telegram, with a link provided for further action."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=75, prompt_tokens=208, total_tokens=283))


2024-04-21 11:06:23,457 - INFO - Received completion from the model:
report="The tweet from @Hodl_Investor promotes Kyle Chasse's mentorship program, which offers updates and projects related to mining and trading. Participants can also access an advanced Copy Trade setup for free to improve their investment portfolio. Interested individuals are invited to join the trading committee by sending a greeting on Telegram, with a link provided for further action."


2024-04-21 11:06:23,458 - DEBUG - response_closed.complete


2024-04-21 11:06:23,458 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,459 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrww9IvMJQcjOkny6fWBAN7DFhf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yyC8RfM5YhDgP5sBgJacL4P2', function=Function(arguments='{"report":"The tweet appears to be spam or contains inappropriate content. It does not provide any relevant information about the X Dev Challenge or any updates related to the event. The tweet is not suitable for the user\'s search interest."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=47, prompt_tokens=166, total_tokens=213))


2024-04-21 11:06:23,460 - INFO - Received completion from the model:
report="The tweet appears to be spam or contains inappropriate content. It does not provide any relevant information about the X Dev Challenge or any updates related to the event. The tweet is not suitable for the user's search interest."


2024-04-21 11:06:23,460 - DEBUG - response_closed.complete


2024-04-21 11:06:23,461 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:23,461 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwMhA9y1XVbPlpaCYMe4K0CowT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_peIHZEv3MJZ86WngPoBZFP4H', function=Function(arguments='{"report":"The tweet is a retweet from the user @ASPertierra, discussing historical political trends in the southern cone of South America. It mentions the transition from a period of military juntas and authoritarian leaders during the late Cold War to a time of increased accountability, although limited. The tweet does not provide updates on the X Dev Challenge or any related event progress, announcements, participant experiences, or significant occurrences."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=85, prompt_tokens=169, total_tokens=254))


2024-04-21 11:06:23,462 - INFO - Received completion from the model:
report='The tweet is a retweet from the user @ASPertierra, discussing historical political trends in the southern cone of South America. It mentions the transition from a period of military juntas and authoritarian leaders during the late Cold War to a time of increased accountability, although limited. The tweet does not provide updates on the X Dev Challenge or any related event progress, announcements, participant experiences, or significant occurrences.'


2024-04-21 11:06:24,058 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3382'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599520'), (b'x-ratelimit-reset-requests', b'41ms'), (b'x-ratelimit-reset-tokens', b'47ms'), (b'x-request-id', b'req_b6b8053fc9146582b732bdb106435de9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16b717e86-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:24,059 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:24,060 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:24,061 - DEBUG - receive_response_body.complete


2024-04-21 11:06:24,061 - DEBUG - response_closed.started


2024-04-21 11:06:24,062 - DEBUG - response_closed.complete


2024-04-21 11:06:24,063 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:24,064 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwTJIwU985kz19FpbnqvbmYLRL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0j6NsLwAUINYuJVsbOJJBukF', function=Function(arguments='{"report":"The tweet is a retweet from the user @Justice78602373, which contains a quote about the purpose of law and order. It states that law and order are meant to establish justice, and when they fail to do so, they become a dangerously structured dam that blocks the flow of social progress. The tweet does not provide any updates on the X Dev Challenge or information related to the event\'s progress, announcements, participant experiences, or significant occurrences since it started."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=98, prompt_tokens=166, total_tokens=264))


2024-04-21 11:06:24,066 - INFO - Received completion from the model:
report="The tweet is a retweet from the user @Justice78602373, which contains a quote about the purpose of law and order. It states that law and order are meant to establish justice, and when they fail to do so, they become a dangerously structured dam that blocks the flow of social progress. The tweet does not provide any updates on the X Dev Challenge or information related to the event's progress, announcements, participant experiences, or significant occurrences since it started."


2024-04-21 11:06:24,349 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3807'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'599343'), (b'x-ratelimit-reset-requests', b'60ms'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_27b89d6c9021154534e743c56341cb19'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb15b947e89-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:24,350 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:24,350 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:24,351 - DEBUG - receive_response_body.complete


2024-04-21 11:06:24,352 - DEBUG - response_closed.started


2024-04-21 11:06:24,352 - DEBUG - response_closed.complete


2024-04-21 11:06:24,354 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:24,356 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwCfiMeyZeleDU6PZBfanO3b2T', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_JxbOcEp7ZsMYsqi8VMUwLTIO', function=Function(arguments='{"report":"The tweet is a retweet from the user @favourite131, expressing support for the cryptocurrency $BRICK. The tweet praises $BRICK as a \'pillar of innovation and progress in the crypto space.\' It includes the hashtag #Brick_By_Brick and a link, presumably for more information. The tweet does not provide updates on the X Dev Challenge or any related event progress, announcements, participant experiences, or significant occurrences."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=91, prompt_tokens=183, total_tokens=274))


2024-04-21 11:06:24,358 - INFO - Received completion from the model:
report="The tweet is a retweet from the user @favourite131, expressing support for the cryptocurrency $BRICK. The tweet praises $BRICK as a 'pillar of innovation and progress in the crypto space.' It includes the hashtag #Brick_By_Brick and a link, presumably for more information. The tweet does not provide updates on the X Dev Challenge or any related event progress, announcements, participant experiences, or significant occurrences."


2024-04-21 11:06:24,549 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4061'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4995'), (b'x-ratelimit-remaining-tokens', b'599354'), (b'x-ratelimit-reset-requests', b'57ms'), (b'x-ratelimit-reset-tokens', b'64ms'), (b'x-request-id', b'req_9d5d52da2803644a112df7a03c8ba7b2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16fb17bec-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:24,551 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:24,551 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:24,554 - DEBUG - receive_response_body.complete


2024-04-21 11:06:24,555 - DEBUG - response_closed.started


2024-04-21 11:06:24,556 - DEBUG - response_closed.complete


2024-04-21 11:06:24,557 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:24,558 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwWJh5jbXLTs6pJaHrxTTEtj5J', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QCRHDNxj8IJfz2553w6hAa01', function=Function(arguments='{"report":"The tweet is a retweet from the user @ChimaeraCrypto, responding to @Thorshammergems. The content suggests that a certain entity, possibly a cryptocurrency or project, is being compared to a \'baby Alt coin.\' The user @ChimaeraCrypto endorses @KittenWif_SOL, implying support or a positive opinion. The tweet cuts off with \'They got a b…\', indicating an incomplete message. This tweet does not provide any updates on the X Dev Challenge or relevant information about the event\'s progress, announcements, participant experiences, or significant occurrences."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=121, prompt_tokens=178, total_tokens=299))


2024-04-21 11:06:24,560 - INFO - Received completion from the model:
report="The tweet is a retweet from the user @ChimaeraCrypto, responding to @Thorshammergems. The content suggests that a certain entity, possibly a cryptocurrency or project, is being compared to a 'baby Alt coin.' The user @ChimaeraCrypto endorses @KittenWif_SOL, implying support or a positive opinion. The tweet cuts off with 'They got a b…', indicating an incomplete message. This tweet does not provide any updates on the X Dev Challenge or relevant information about the event's progress, announcements, participant experiences, or significant occurrences."


2024-04-21 11:06:24,876 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4235'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4990'), (b'x-ratelimit-remaining-tokens', b'598673'), (b'x-ratelimit-reset-requests', b'109ms'), (b'x-ratelimit-reset-tokens', b'132ms'), (b'x-request-id', b'req_f804cb1df5e00925f290d3c461ff55d4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16eb10fd0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:24,878 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:24,878 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:24,879 - DEBUG - receive_response_body.complete


2024-04-21 11:06:24,879 - DEBUG - response_closed.started


2024-04-21 11:06:24,880 - DEBUG - response_closed.complete


2024-04-21 11:06:24,882 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:24,883 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwPxNdfwOGk8UgU4yjKeHnmI3K', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dgcyHrJ1epWMkuEanmY1DXfv', function=Function(arguments='{"report":"The tweet from @Kruys_Collins highlights Near\'s origins as an AI company and its current focus on integrating AI into its blockchain technology. The user expresses optimism about Near\'s potential to innovate in the blockchain space, noting that this anticipation is reflected in the token\'s market performance. Followers are encouraged to stay tuned to @Kruys_Collins for further updates."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=80, prompt_tokens=191, total_tokens=271))


2024-04-21 11:06:24,885 - INFO - Received completion from the model:
report="The tweet from @Kruys_Collins highlights Near's origins as an AI company and its current focus on integrating AI into its blockchain technology. The user expresses optimism about Near's potential to innovate in the blockchain space, noting that this anticipation is reflected in the token's market performance. Followers are encouraged to stay tuned to @Kruys_Collins for further updates."


2024-04-21 11:06:24,886 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599865'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'13ms'), (b'x-request-id', b'req_21e866633430c5e84ccf4978577e1f69'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb11f690d04-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:24,887 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:24,887 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:24,887 - DEBUG - receive_response_body.complete


2024-04-21 11:06:24,887 - DEBUG - response_closed.started


2024-04-21 11:06:24,888 - DEBUG - response_closed.complete


2024-04-21 11:06:24,889 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:24,889 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwWXNqdvOv1TsMc5hukyVgrpb8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wz5Y7bBp0A2TQZbkhc94GTLq', function=Function(arguments='{"report":"The tweet is a retweet from user @dermotmcorrigan, mentioning a blog post with build-up to the Clasico. The blog features contributions from @polballus, @MarioCortegana, @tomas_hill, @mikedominski, @edmackey11, and others. However, this tweet does not provide updates on the X Dev Challenge or any related information. It is focused on sports commentary and does not align with the user\'s search interest in the X Dev Challenge."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=110, prompt_tokens=186, total_tokens=296))


2024-04-21 11:06:24,890 - INFO - Received completion from the model:
report="The tweet is a retweet from user @dermotmcorrigan, mentioning a blog post with build-up to the Clasico. The blog features contributions from @polballus, @MarioCortegana, @tomas_hill, @mikedominski, @edmackey11, and others. However, this tweet does not provide updates on the X Dev Challenge or any related information. It is focused on sports commentary and does not align with the user's search interest in the X Dev Challenge."


2024-04-21 11:06:24,988 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4494'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597961'), (b'x-ratelimit-reset-requests', b'172ms'), (b'x-ratelimit-reset-tokens', b'203ms'), (b'x-request-id', b'req_16d3a59a4af141d1ae4710bfe6950107'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16e6c5214-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:24,989 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:24,989 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:24,990 - DEBUG - receive_response_body.complete


2024-04-21 11:06:24,990 - DEBUG - response_closed.started


2024-04-21 11:06:24,991 - DEBUG - response_closed.complete


2024-04-21 11:06:24,992 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:24,993 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrw7BRSHttHxsnWdaMo0GPbPpmx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Q3w6KLd3mDzw1UXaEjvBRcRs', function=Function(arguments='{"report":"The tweet from @Altsteinn expresses enthusiasm about the cryptocurrency $TOR, highlighting its \\"innovative technology\\" and \\"strong team updates.\\" The user anticipates exciting developments and encourages others to prepare for a \\"thrilling ride.\\" The use of fire and rocket emojis conveys a sense of momentum and upward potential in the context of cryptocurrency markets. The hashtags #TOR, #crypto, and #excited are used to categorize the tweet and reach a broader audience interested in these topics."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=103, prompt_tokens=185, total_tokens=288))


2024-04-21 11:06:24,995 - INFO - Received completion from the model:
report='The tweet from @Altsteinn expresses enthusiasm about the cryptocurrency $TOR, highlighting its "innovative technology" and "strong team updates." The user anticipates exciting developments and encourages others to prepare for a "thrilling ride." The use of fire and rocket emojis conveys a sense of momentum and upward potential in the context of cryptocurrency markets. The hashtags #TOR, #crypto, and #excited are used to categorize the tweet and reach a broader audience interested in these topics.'


2024-04-21 11:06:25,003 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4527'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'598350'), (b'x-ratelimit-reset-requests', b'139ms'), (b'x-ratelimit-reset-tokens', b'164ms'), (b'x-request-id', b'req_257d5610a4cf9f6499aaf0239fbc9421'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb169ca2f07-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:25,004 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:25,004 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:25,005 - DEBUG - receive_response_body.complete


2024-04-21 11:06:25,005 - DEBUG - response_closed.started


2024-04-21 11:06:25,005 - DEBUG - response_closed.complete


2024-04-21 11:06:25,007 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:25,008 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwbz6zTuANQI10hOOVV3HMSCvt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_IRLlF1ou5IAjK5U5vNyfMj2H', function=Function(arguments='{"report":"The tweet from @Imaginary_Ones teases upcoming updates for Bubble Rangers, a game associated with the hashtag #BUBBLERANGERS and possibly a related cryptocurrency or token, indicated by the symbol $BUBBLE. The tweet aims to generate anticipation and encourages followers to stay tuned for further news."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=67, prompt_tokens=183, total_tokens=250))


2024-04-21 11:06:25,009 - INFO - Received completion from the model:
report='The tweet from @Imaginary_Ones teases upcoming updates for Bubble Rangers, a game associated with the hashtag #BUBBLERANGERS and possibly a related cryptocurrency or token, indicated by the symbol $BUBBLE. The tweet aims to generate anticipation and encourages followers to stay tuned for further news.'


2024-04-21 11:06:25,107 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4538'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599865'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'13ms'), (b'x-request-id', b'req_55fb580fecd03e548a307ac004babe56'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb1592178d8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:25,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:25,108 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:25,109 - DEBUG - receive_response_body.complete


2024-04-21 11:06:25,109 - DEBUG - response_closed.started


2024-04-21 11:06:25,109 - DEBUG - response_closed.complete


2024-04-21 11:06:25,111 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:25,112 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrw2Dt0QQP5BjM23cQxlIdlgzGl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wlJktKUBP0zlmGRvpIiNK0MN', function=Function(arguments='{"report":"The tweet is a retweet from the user @puniisanijianti. It discusses the activities of \'Dramatubers,\' who are presumably content creators that focus on drama within certain communities. The tweet mentions that these creators compile images to create narratives, host streams related to stock watching for \'niji,\' and provide updates on \'el1r@\'s situation.\' However, this tweet does not provide updates on the X Dev Challenge or any related event progress, announcements, participant experiences, or significant occurrences. Therefore, it is not relevant to the user\'s search interest."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=123, prompt_tokens=176, total_tokens=299))


2024-04-21 11:06:25,114 - INFO - Received completion from the model:
report="The tweet is a retweet from the user @puniisanijianti. It discusses the activities of 'Dramatubers,' who are presumably content creators that focus on drama within certain communities. The tweet mentions that these creators compile images to create narratives, host streams related to stock watching for 'niji,' and provide updates on 'el1r@'s situation.' However, this tweet does not provide updates on the X Dev Challenge or any related event progress, announcements, participant experiences, or significant occurrences. Therefore, it is not relevant to the user's search interest."


2024-04-21 11:06:25,270 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'4643'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597880'), (b'x-ratelimit-reset-requests', b'179ms'), (b'x-ratelimit-reset-tokens', b'211ms'), (b'x-request-id', b'req_1c3b673aba5112bab633d141b5555ec3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16a730fcf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:25,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:25,271 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:25,271 - DEBUG - receive_response_body.complete


2024-04-21 11:06:25,271 - DEBUG - response_closed.started


2024-04-21 11:06:25,271 - DEBUG - response_closed.complete


2024-04-21 11:06:25,272 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:25,272 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwcb8Eae08pgcSeURu5tT49N38', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_g1RijtIztikvKsW3Otgcq1sm', function=Function(arguments='{"report":"The tweet is a retweet from the user @LeishaRiddel, expressing satisfaction with the progress made on a project or initiative titled \'Sister Minnie Everywhere All At Once.\' The tweet does not provide specific updates on the X Dev Challenge, its progress, announcements, participant experiences, or any significant occurrences related to the event. It appears to be unrelated to the user\'s search interest in the X Dev Challenge."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=89, prompt_tokens=166, total_tokens=255))


2024-04-21 11:06:25,273 - INFO - Received completion from the model:
report="The tweet is a retweet from the user @LeishaRiddel, expressing satisfaction with the progress made on a project or initiative titled 'Sister Minnie Everywhere All At Once.' The tweet does not provide specific updates on the X Dev Challenge, its progress, announcements, participant experiences, or any significant occurrences related to the event. It appears to be unrelated to the user's search interest in the X Dev Challenge."


2024-04-21 11:06:25,692 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5206'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4998'), (b'x-ratelimit-remaining-tokens', b'599733'), (b'x-ratelimit-reset-requests', b'23ms'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'req_16a09849d3d6824f7fa89ead7433eef0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb1592969bc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:25,694 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:25,694 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:25,695 - DEBUG - receive_response_body.complete


2024-04-21 11:06:25,695 - DEBUG - response_closed.started


2024-04-21 11:06:25,695 - DEBUG - response_closed.complete


2024-04-21 11:06:25,698 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:25,699 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwvAxJJbEe41p4JHWLCVJXQdtw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BX5F0cNOPrcuNwwszVGYqN6e', function=Function(arguments='{"report":"The tweet is a retweet from the account @Web3_Protocol, announcing an upcoming Ask Me Anything (AMA) session on Telegram with a guest named Claire, who is the Head of Community Growth at VaraNetwork. The host of the AMA is identified as Lovely from Web3. The tweet includes the hashtag #AMA, indicating the interactive nature of the event where participants can ask questions."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=84, prompt_tokens=184, total_tokens=268))


2024-04-21 11:06:25,701 - INFO - Received completion from the model:
report='The tweet is a retweet from the account @Web3_Protocol, announcing an upcoming Ask Me Anything (AMA) session on Telegram with a guest named Claire, who is the Head of Community Growth at VaraNetwork. The host of the AMA is identified as Lovely from Web3. The tweet includes the hashtag #AMA, indicating the interactive nature of the event where participants can ask questions.'


2024-04-21 11:06:26,001 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5400'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4983'), (b'x-ratelimit-remaining-tokens', b'597758'), (b'x-ratelimit-reset-requests', b'192ms'), (b'x-ratelimit-reset-tokens', b'224ms'), (b'x-request-id', b'req_cdab423a6338168be958dd1ac0b12783'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16ffa7be6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:26,002 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:26,002 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:26,003 - DEBUG - receive_response_body.complete


2024-04-21 11:06:26,003 - DEBUG - response_closed.started


2024-04-21 11:06:26,003 - DEBUG - response_closed.complete


2024-04-21 11:06:26,006 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:26,007 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwoV1u5tyzQZ90oqkGWBZ2npOw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0yUELMtof0BNXMRd4IqgLMrk', function=Function(arguments='{"report":"The tweet is a retweet from the user @gaystudents_ containing a warning message indicating that seeding is currently in progress. The context of the seeding is not provided within the tweet, so it is unclear what is being referred to. The use of the warning sign emoji suggests that the seeding process is important and that there may be implications for those involved or affected by it. The tweet does not contain any specific updates or details about the X Dev Challenge, participant experiences, or significant occurrences related to the event."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=106, prompt_tokens=155, total_tokens=261))


2024-04-21 11:06:26,008 - INFO - Received completion from the model:
report='The tweet is a retweet from the user @gaystudents_ containing a warning message indicating that seeding is currently in progress. The context of the seeding is not provided within the tweet, so it is unclear what is being referred to. The use of the warning sign emoji suggests that the seeding process is important and that there may be implications for those involved or affected by it. The tweet does not contain any specific updates or details about the X Dev Challenge, participant experiences, or significant occurrences related to the event.'


2024-04-21 11:06:26,702 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'6221'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'598315'), (b'x-ratelimit-reset-requests', b'143ms'), (b'x-ratelimit-reset-tokens', b'168ms'), (b'x-request-id', b'req_b973b6ae0176c83af4d0b1208e14b0b9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb16a3108f7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:26,704 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:26,704 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:26,706 - DEBUG - receive_response_body.complete


2024-04-21 11:06:26,706 - DEBUG - response_closed.started


2024-04-21 11:06:26,706 - DEBUG - response_closed.complete


2024-04-21 11:06:26,708 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:26,710 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwfEpKWLCMSnbj8P51y7mKXjfR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_nmdh0297n35G79BziZi2aK66', function=Function(arguments='{"report":"The tweet contains a brief message indicating ongoing work, accompanied by a link that presumably leads to more details or visual content related to the progress. The text \\"Work in progress >_<\\" suggests that the user is in the midst of an activity, possibly related to the X Dev Challenge, and is sharing a real-time update or expressing a moment of intensity or challenge. The link is likely intended for followers to access additional information or updates on the user\'s work or the event\'s progress."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=101, prompt_tokens=156, total_tokens=257))


2024-04-21 11:06:26,712 - INFO - Received completion from the model:
report='The tweet contains a brief message indicating ongoing work, accompanied by a link that presumably leads to more details or visual content related to the progress. The text "Work in progress >_<" suggests that the user is in the midst of an activity, possibly related to the X Dev Challenge, and is sharing a real-time update or expressing a moment of intensity or challenge. The link is likely intended for followers to access additional information or updates on the user\'s work or the event\'s progress.'


2024-04-21 11:06:26,734 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:06:26 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'6113'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4987'), (b'x-ratelimit-remaining-tokens', b'598140'), (b'x-ratelimit-reset-requests', b'153ms'), (b'x-ratelimit-reset-tokens', b'185ms'), (b'x-request-id', b'req_024a59326ba6a7e802b9235041f54e98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f4eb168041036-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:06:26,735 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:06:26,736 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:06:26,737 - DEBUG - receive_response_body.complete


2024-04-21 11:06:26,737 - DEBUG - response_closed.started


2024-04-21 11:06:26,738 - DEBUG - response_closed.complete


2024-04-21 11:06:26,742 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:06:26,743 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GVrwtF2GDDwNLIrSVvWgpNzk1gVX', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9IVr24X1OCDYIv6rmidh93TM', function=Function(arguments='{"report":"The tweet is a retweet from user @mengjuns125087 announcing the final stage of the X Dev Challenge. The tweet indicates that the final phase of the event is scheduled to take place between the 23rd and 28th, which may refer to the dates of a month not specified in the tweet. The mention of \'happy island\' could be metaphorical for the successful conclusion of the event or a theme related to the challenge. No specific details about the event\'s progress, announcements, participant experiences, or significant occurrences are provided in this tweet."}', name='CreateTweetReport'), type='function')]))], created=1713722780, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=118, prompt_tokens=179, total_tokens=297))


2024-04-21 11:06:26,745 - INFO - Received completion from the model:
report="The tweet is a retweet from user @mengjuns125087 announcing the final stage of the X Dev Challenge. The tweet indicates that the final phase of the event is scheduled to take place between the 23rd and 28th, which may refer to the dates of a month not specified in the tweet. The mention of 'happy island' could be metaphorical for the successful conclusion of the event or a theme related to the challenge. No specific details about the event's progress, announcements, participant experiences, or significant occurrences are provided in this tweet."


2024-04-21 11:21:59,904 - INFO - Received chat message: user_id='brian' message='hi can i get reports\n'


2024-04-21 11:21:59,907 - INFO - Called the handcrafted conversation flow


2024-04-21 11:21:59,907 - INFO - Received event in the handler


2024-04-21 11:21:59,910 - INFO - Received event in the determine_filter_target function


2024-04-21 11:21:59,910 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}
	{'role': 'user', 'content': 'hi can i get reports\n'}


2024-04-21 11:21:59,923 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage1'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'hi can i get reports\n'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}}


2024-04-21 11:21:59,924 - DEBUG - max_retries: 8


2024-04-21 11:21:59,924 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103857e20>


2024-04-21 11:21:59,930 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "We've inquired whether the user's interest lies in users, tweets, or reports. Please indicate their preference by updating the target field. Should their response deviate or lack clarity, prompting further inquiry, kindly reiterate the question to maintain focus. Below are insights into each option to assist in addressing their queries effectively:\n- **Tweets**: Should the user express a desire to sift through an overwhelming volume of tweets or seek out tweets pertaining to a particular idea, topic, or event, this option aligns with their needs.\n- **Users**: This option is apt for users on the lookout for specific individuals, be it for recruitment purposes or to connect with those sharing similar beliefs or skills.\n- **Reports**: Opt for this if the user expects not just a curated selection of tweets but also desires analytical reports based on them.\nSo fill out the 'filter_target' field if the user made a choice. If they haven't fill out the 'message' field."}, {'role': 'user', 'content': 'hi can i get reports\n'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage1'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage1', 'description': 'Determine what the FilterTarget.', 'parameters': {'$defs': {'FilterTarget': {'enum': ['users', 'tweets', 'reports'], 'title': 'FilterTarget', 'type': 'string'}}, 'properties': {'filter_target': {'anyOf': [{'$ref': '#/$defs/FilterTarget'}, {'type': 'null'}], 'default': None}, 'message': {'title': 'Message', 'type': 'string'}}, 'required': ['message'], 'type': 'object'}}}]}}


2024-04-21 11:21:59,968 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:22:00,002 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103cd5180>


2024-04-21 11:22:00,002 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:22:00,020 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103c68430>


2024-04-21 11:22:00,021 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:22:00,021 - DEBUG - send_request_headers.complete


2024-04-21 11:22:00,021 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:22:00,021 - DEBUG - send_request_body.complete


2024-04-21 11:22:00,021 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:22:02,095 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:22:02 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1885'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599733'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'26ms'), (b'x-request-id', b'req_0e308eac8513345889117c414f434e7c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Set-Cookie', b'__cf_bm=xSa0LErN2x8WWJKw11vcoq3qRHvOeqctcQ6i2VqfKnY-1713723722-1.0.1.1-eEcbmTUx_foanzWscw5Ch6JcKvflTR_cpBD4wppfT6i_gqlgEsYEZLPYn24paiSBQl3VEw7UvTPN8WdBmS56GQ; path=/; expires=Sun, 21-Apr-24 18:52:02 GMT; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Set-Cookie', b'_cfuvid=WlFHvs1V8GD1q4BWskZKiqKi0PgjHKDzuVbtvydQwnQ-1713723722093-0.0.1.1-604800000; path=/; domain=.api.openai.com; HttpOnly; Secure; SameSite=None'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f65a23cd32f3e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:22:02,108 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:22:02,110 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:22:02,111 - DEBUG - receive_response_body.complete


2024-04-21 11:22:02,112 - DEBUG - response_closed.started


2024-04-21 11:22:02,112 - DEBUG - response_closed.complete


2024-04-21 11:22:02,113 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:22:02,118 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GW76B1rwre1ger1TJdJbKVUHHtbE', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yy3RG79ezJEXvIAKFeyfyj7x', function=Function(arguments='{"filter_target":"reports","message":""}', name='Stage1'), type='function')]))], created=1713723720, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=9, prompt_tokens=286, total_tokens=295))


2024-04-21 11:22:02,120 - INFO - Received completion from the model:
filter_target: reports
message: 


2024-04-21 11:26:59,906 - INFO - Received chat message: user_id='brian' message='im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'


2024-04-21 11:26:59,908 - INFO - Called the handcrafted conversation flow


2024-04-21 11:26:59,908 - INFO - Received event in the handler


2024-04-21 11:26:59,909 - INFO - Received event in the build_primary_prompt function


2024-04-21 11:26:59,909 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}
	{'role': 'user', 'content': 'im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}
	{'role': 'user', 'content': 'im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'}


2024-04-21 11:26:59,911 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage2'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': 'im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}}


2024-04-21 11:26:59,911 - DEBUG - max_retries: 8


2024-04-21 11:26:59,911 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103d35000>


2024-04-21 11:26:59,917 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Great! Now that we've established the target, could you explain to me what type of tweets you're looking for? Be as specific as possible. Are there any specific topics, events, or ideas you're looking for?"}, {'role': 'user', 'content': 'im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "primary prompt" describing what the user wants. Choose one of the following options:\n\n1. **Clarify the Search**: If the user\'s request is unclear, ask questions in the \'questions\' field to better understand what they want. If there\'s acronyms or things that you don\'t aren\'t familiar about ask them detailed questions about it. Record these questions in the \'questions\' field. Skip this step if the user\'s intent is already clear. If the user wants reports, clarify that at this stage we\'re only talking about what types of tweets you want to search for.\n\n2. **Write the Primary Prompt**: If you don\'t have any further questions to ask, write the primary prompt in the \'rewritten_primary_prompt\' field. Try to include everything the user talked about and wanted in this prompt. It\'s crucial that this is as comprehensive as humanlly possible.\n\nLastly, when you do write the primary prompt, try to come up with a good and short 1-3 word name for this filter.'}, {'role': 'user', 'content': 'im interested in using LLMs to create, organize and manage a tree of data. the llms can take any data as input and navigate the nodes by their metadata to find the best place to store the data. later when the llm receives a question it can try to navigate the tree with its query and the nodes metadata. this tree is O(logn) and thus very scalable. I believe that this sort of structure is going to be the solution to large scale memory for ai systems. I want to find people, users, tweets who understand, agree or are exploring this idea or similar ides.\n'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage2'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage2', 'description': 'Correctly extracted `Stage2` with all the required parameters with correct types', 'parameters': {'properties': {'rewritten_primary_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Rewritten Primary Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}, 'name': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Name'}}, 'required': ['name', 'questions', 'rewritten_primary_prompt'], 'type': 'object'}}}]}}


2024-04-21 11:26:59,918 - DEBUG - close.started


2024-04-21 11:26:59,918 - DEBUG - close.complete


2024-04-21 11:26:59,918 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:27:00,028 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103d371f0>


2024-04-21 11:27:00,028 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:27:00,053 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103d36d70>


2024-04-21 11:27:00,054 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:27:00,054 - DEBUG - send_request_headers.complete


2024-04-21 11:27:00,054 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:27:00,054 - DEBUG - send_request_body.complete


2024-04-21 11:27:00,054 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:27:03,662 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:27:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3461'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599399'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'60ms'), (b'x-request-id', b'req_0c10e85c72ee01f8d081b1a59c74ff4d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6cf57b2208ca-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:27:03,664 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:27:03,664 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:27:03,665 - DEBUG - receive_response_body.complete


2024-04-21 11:27:03,666 - DEBUG - response_closed.started


2024-04-21 11:27:03,666 - DEBUG - response_closed.complete


2024-04-21 11:27:03,667 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:27:03,669 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWBwvQZTHov2rsJc8XqV3541Epk8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_GzDB04MX9LRKFUbPPOE94nLj', function=Function(arguments='{"rewritten_primary_prompt":"Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.","questions":null,"name":"Data Tree LLM"}', name='Stage2'), type='function')]))], created=1713724020, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=95, prompt_tokens=614, total_tokens=709))


2024-04-21 11:27:03,672 - INFO - Received completion from the model:
rewritten_primary_prompt: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.
questions: None


2024-04-21 11:27:13,776 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-21 11:27:13,778 - INFO - Called the handcrafted conversation flow


2024-04-21 11:27:13,778 - INFO - Received event in the handler


2024-04-21 11:27:13,780 - INFO - Received event in the build_primary_prompt function


2024-04-21 11:27:30,593 - INFO - Received chat message: user_id='brian' message='can u make them for me?'


2024-04-21 11:27:30,597 - INFO - Called the handcrafted conversation flow


2024-04-21 11:27:30,598 - INFO - Received event in the handler


2024-04-21 11:27:30,604 - INFO - Received event in the build_filter_prompt function


2024-04-21 11:27:30,605 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}
	{'role': 'user', 'content': 'can u make them for me?'}
	{'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the minimum and maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}
	{'role': 'user', 'content': 'can u make them for me?'}


2024-04-21 11:27:30,615 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage3'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'can u make them for me?'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the minimum and maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'can u make them for me?'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}}


2024-04-21 11:27:30,615 - DEBUG - max_retries: 8


2024-04-21 11:27:30,616 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e58850>


2024-04-21 11:27:30,622 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Now that we've pinpointed the main focus of your search, it's time to fine-tune it with some additional filters. You're not required to specify everything—just share what matters most to you:\n\n- How often would you like this filter to run? The default setting is weekly, but we can adjust this based on your preference.\n- Minimum and maximum tweets/users would you like to see in each report?\n- Are there specific usernames (@username) you're interested in? Do you want to limit your search to these users, or do you want us to find other users as well? You may also choose to limit the search to people you follow.\n- Are there any keywords or specific combinations of keywords you think will be useful to search by? We will generate a combinations of keywords to search, but if you have any specific ones you want to mention, please do so."}, {'role': 'user', 'content': 'can u make them for me?'}, {'role': 'system', 'content': "At this stage we are building a filter prompt. The user can tell us how often they want the filter to run, the minimum and maximum number of tweets/users they want to see in each report, specific usernames they are interested in and if they want to limit the search to those they specified, or if they want to limit the search to people they follow, or if they are okay with us finding new users.  Also did they mention any specific keywords they want us to search for? If so, write them that in the 'filter_prompt' field as well. Try to include everything the user talked about and wanted in this prompt. The user might ask you to change it, so be ready to make adjustments. If the user doesn't want any filters, just fill out the 'filter_prompt' field with 'No specific filters in mind'. The user doesen't have to fill out any of these, but if they make something very unclear choose to ask questions."}, {'role': 'user', 'content': 'can u make them for me?'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage3'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage3', 'description': 'Correctly extracted `Stage3` with all the required parameters with correct types', 'parameters': {'properties': {'filter_prompt': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Filter Prompt'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['filter_prompt', 'questions'], 'type': 'object'}}}]}}


2024-04-21 11:27:30,623 - DEBUG - close.started


2024-04-21 11:27:30,623 - DEBUG - close.complete


2024-04-21 11:27:30,623 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:27:30,639 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e59db0>


2024-04-21 11:27:30,639 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:27:30,658 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e58220>


2024-04-21 11:27:30,658 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:27:30,658 - DEBUG - send_request_headers.complete


2024-04-21 11:27:30,658 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:27:30,659 - DEBUG - send_request_body.complete


2024-04-21 11:27:30,659 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:27:31,855 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:27:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1004'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599531'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'46ms'), (b'x-request-id', b'req_28050bfc5466046484b39d5b1a82cae5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6db4b8d32f4a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:27:31,856 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:27:31,856 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:27:31,856 - DEBUG - receive_response_body.complete


2024-04-21 11:27:31,856 - DEBUG - response_closed.started


2024-04-21 11:27:31,856 - DEBUG - response_closed.complete


2024-04-21 11:27:31,856 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:27:31,857 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWCQIeYUOnbjoU6BXPi27HspcorQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gmur1KLczEOwLdu27UppYwcH', function=Function(arguments='{"filter_prompt":"No specific filters in mind","questions":null}', name='Stage3'), type='function')]))], created=1713724050, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=14, prompt_tokens=479, total_tokens=493))


2024-04-21 11:27:31,857 - INFO - Received completion from the model:
filter_prompt: No specific filters in mind
questions: None


2024-04-21 11:27:37,821 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-21 11:27:37,825 - INFO - Called the handcrafted conversation flow


2024-04-21 11:27:37,828 - INFO - Received event in the handler


2024-04-21 11:27:37,830 - INFO - Received event in the build_filter_prompt function


2024-04-21 11:28:04,182 - INFO - Received chat message: user_id='brian' message='depends. if they have insights concise, other wise no be brief'


2024-04-21 11:28:04,186 - INFO - Called the handcrafted conversation flow


2024-04-21 11:28:04,187 - INFO - Received event in the handler


2024-04-21 11:28:04,188 - INFO - Received event in the build_report_guide function


2024-04-21 11:28:04,188 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}
	{'role': 'user', 'content': 'depends. if they have insights concise, other wise no be brief'}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}
	{'role': 'user', 'content': 'depends. if they have insights concise, other wise no be brief'}


2024-04-21 11:28:04,193 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage4'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'depends. if they have insights concise, other wise no be brief'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'depends. if they have insights concise, other wise no be brief'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}}


2024-04-21 11:28:04,193 - DEBUG - max_retries: 8


2024-04-21 11:28:04,193 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e5ac80>


2024-04-21 11:28:04,202 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Fantastic! We're now transitioning to the report creation phase. Based on the primary prompt we've crafted together, we'll prepare individual reports for each tweet that aligns with your specified criteria. For example, you can tell us what level of detail you expect in each report - do you prefer a concise summary, a detailed analysis, or something in-between? Are there any specific insights or types of analysis you're particularly interested in for each tweet? What tone do you prefer for the reports - formal, informal, technical, or something else? Lastly, are you interested in an analytical perspective of the tweets, or would a straightforward listing of facts, insights, and ideas suffice? Feel free to provide any additional information or preferences you have regarding the report guide."}, {'role': 'user', 'content': 'depends. if they have insights concise, other wise no be brief'}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'depends. if they have insights concise, other wise no be brief'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}]}}


2024-04-21 11:28:04,203 - DEBUG - close.started


2024-04-21 11:28:04,204 - DEBUG - close.complete


2024-04-21 11:28:04,204 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:04,238 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103d37c70>


2024-04-21 11:28:04,238 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:04,258 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e58250>


2024-04-21 11:28:04,259 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:04,259 - DEBUG - send_request_headers.complete


2024-04-21 11:28:04,259 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:04,259 - DEBUG - send_request_body.complete


2024-04-21 11:28:04,259 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:06,632 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:06 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2150'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599615'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'38ms'), (b'x-request-id', b'req_768a20fe9cdc98e1b6d0a909e19eb043'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6e86b968101d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:06,634 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:06,634 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:06,634 - DEBUG - receive_response_body.complete


2024-04-21 11:28:06,635 - DEBUG - response_closed.started


2024-04-21 11:28:06,635 - DEBUG - response_closed.complete


2024-04-21 11:28:06,636 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:06,637 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWCyceE1ha67EzbUWTkqro1nrFV5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CNeTa65Ids3a6jFYpwW2NkvQ', function=Function(arguments='{"report_guide":"For tweets containing insights, provide a concise summary that captures the essence of the insight and its relevance. For all other tweets, be brief and stick to the most pertinent information without elaboration.","questions":null}', name='Stage4'), type='function')]))], created=1713724084, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=46, prompt_tokens=382, total_tokens=428))


2024-04-21 11:28:06,639 - INFO - Received completion from the model:
report_guide: For tweets containing insights, provide a concise summary that captures the essence of the insight and its relevance. For all other tweets, be brief and stick to the most pertinent information without elaboration.
questions: None


2024-04-21 11:28:12,383 - INFO - Received chat message: user_id='brian' message='yes'


2024-04-21 11:28:12,385 - INFO - Called the handcrafted conversation flow


2024-04-21 11:28:12,385 - INFO - Received event in the handler


2024-04-21 11:28:12,387 - INFO - Received event in the build_report_guide function


2024-04-21 11:28:12,401 - INFO - Building filter


2024-04-21 11:28:12,401 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}
	{'role': 'user', 'content': 'No specific filters in mind'}


2024-04-21 11:28:12,406 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.ExtractedFilters'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'No specific filters in mind'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fill in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'return_min': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask for a minimum number of tweets/users to return? If so fill in this field', 'title': 'Return Min'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report? If so fill in this field.', 'title': 'Return Cap'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}}, 'type': 'object', 'required': []}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}}


2024-04-21 11:28:12,406 - DEBUG - max_retries: 8


2024-04-21 11:28:12,406 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e59f30>


2024-04-21 11:28:12,410 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Given the prompt from the user, extract as many fields as possible accurately into the provided object. Leave anything not mentioned as None.'}, {'role': 'user', 'content': 'No specific filters in mind'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ExtractedFilters'}}, 'tools': [{'type': 'function', 'function': {'name': 'ExtractedFilters', 'description': 'Extract filters from the filter_prompt into the filter object', 'parameters': {'properties': {'filter_period': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user specify how often they want the filter to runs? Fill in this field in days.', 'title': 'Filter Period'}, 'usernames': {'anyOf': [{'items': {'type': 'string'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user mention any specific usernames to search for?', 'title': 'Usernames'}, 'only_search_specified_usernames': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the specific usernames they mentioned?', 'title': 'Only Search Specified Usernames'}, 'only_search_followers': {'anyOf': [{'type': 'boolean'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to only search for the people they follow?', 'title': 'Only Search Followers'}, 'return_min': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask for a minimum number of tweets/users to return? If so fill in this field', 'title': 'Return Min'}, 'return_cap': {'anyOf': [{'type': 'integer'}, {'type': 'null'}], 'default': None, 'description': 'Did the user ask to limit the number of tweets/users they want to see in each report? If so fill in this field.', 'title': 'Return Cap'}, 'keyword_groups': {'anyOf': [{'items': {'items': {'type': 'string'}, 'type': 'array'}, 'type': 'array'}, {'type': 'null'}], 'default': None, 'description': 'Did the user provide any keyword groups to search for?', 'title': 'Keyword Groups'}}, 'type': 'object', 'required': []}}}]}}


2024-04-21 11:28:12,411 - DEBUG - close.started


2024-04-21 11:28:12,411 - DEBUG - close.complete


2024-04-21 11:28:12,411 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:12,428 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e67a90>


2024-04-21 11:28:12,428 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:12,446 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e67610>


2024-04-21 11:28:12,446 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:12,446 - DEBUG - send_request_headers.complete


2024-04-21 11:28:12,446 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:12,446 - DEBUG - send_request_body.complete


2024-04-21 11:28:12,446 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:13,059 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:13 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'399'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599940'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'6ms'), (b'x-request-id', b'req_c8bb47fa93bb1fd2e8f6568a350a8d36'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6eb9ed1b2b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:13,061 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:13,062 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:13,062 - DEBUG - receive_response_body.complete


2024-04-21 11:28:13,063 - DEBUG - response_closed.started


2024-04-21 11:28:13,063 - DEBUG - response_closed.complete


2024-04-21 11:28:13,064 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:13,066 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWD6Rf9UAQpMO5Mya8hI9Y2m05Ol', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UHWl2ql1BYFY7lBvtoXlspGh', function=Function(arguments='{}', name='ExtractedFilters'), type='function')]))], created=1713724092, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=1, prompt_tokens=343, total_tokens=344))


2024-04-21 11:28:13,072 - INFO - Received completion from the model:
filter_period: None, usernames: None, only_search_specified_usernames: None, only_search_followers: None, return_cap: None


2024-04-21 11:28:13,075 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}
	{'role': 'user', 'content': 'Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:13,080 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.GenerateKeywordGroups'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': 'Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}}


2024-04-21 11:28:13,080 - DEBUG - max_retries: 8


2024-04-21 11:28:13,080 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e65f60>


2024-04-21 11:28:13,088 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'Your task is to distill keyword groups from the user\'s prompt with precision, populating the provided object effectively. This step is crucial for honing in on the most relevant search results. Here\'s how to structure the data:\n- Use the outer list to compile groups of keywords that, when searched together, should be considered as separate search queries (OR logic).\n- Within each group, list keywords that must all be present in a search result (AND logic).\nConsider this user prompt as an example:\n"I\'m specifically looking for tweets that deliver insights into new methods in RAG, addressing new challenges. I\'m interested in new chunking methods in RAG, top vector databases, and models fine-tuned for RAG. Additionally, I\'m keen on methods that go beyond vector similarity, utilizing metadata, descriptions, or an LLM to navigate through a structured data system. A system that autonomously organizes arbitrary data into a structured file system, with descriptive labeling and LLM-based search capabilities, would be of particular interest."\nA simplistic keyword grouping like [[\'RAG\'], [\'solve\', \'new problems\'], [\'file structure\']] is inadequate. Such broad terms will yield an overwhelming number of irrelevant tweets. The goal is to craft keyword groups that are both comprehensive and precise, ensuring relevance without overlooking potential insights. Aim for specificity and thoughtful combinations that capture the essence of the user\'s request.\nA more effective approach might include:\n[["chunking", "RAG"], ["models", "finetuned", "RAG"], ["file structure", "LLM", "RAG"], ["vector databases", "state of the art", "RAG"], ["metadata", "data organization", "LLM"]].\nIn addition, you can see this example is quite a specific field, so you should go on to create many more combinations of keywords. In the other hand, if the user\'s request is by default more broad, you can create less combinations of keywords.'}, {'role': 'user', 'content': 'Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'GenerateKeywordGroups'}}, 'tools': [{'type': 'function', 'function': {'name': 'GenerateKeywordGroups', 'description': 'Extract combinations of keyword groups to search', 'parameters': {'properties': {'keyword_groups': {'description': 'List of keyword groups to search for. Each sublist is a group of keywords to be ANDed together. The outer list is a list of groups to be ORed together.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:28:13,089 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:13,090 - DEBUG - send_request_headers.complete


2024-04-21 11:28:13,090 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:13,090 - DEBUG - send_request_body.complete


2024-04-21 11:28:13,090 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:19,831 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:19 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'6609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599400'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'59ms'), (b'x-request-id', b'req_b6cabd5cd5660d5ab695ff44a008c829'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6ebdeac22b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:19,834 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:19,835 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:19,836 - DEBUG - receive_response_body.complete


2024-04-21 11:28:19,836 - DEBUG - response_closed.started


2024-04-21 11:28:19,836 - DEBUG - response_closed.complete


2024-04-21 11:28:19,837 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:19,839 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWD7qGZt9HV1SQdjBfylOJiPkDmj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fNRvnZ6rfnfuLeqsltId3CRo', function=Function(arguments='{\n  "keyword_groups": [\n    ["LLMs", "scalable data trees", "O(logn) complexity"],\n    ["LLMs", "metadata-driven tree structure", "large-scale memory", "AI systems"],\n    ["LLMs", "data organization", "scalable", "O(logn)"],\n    ["LLMs", "managing data", "scalable trees"],\n    ["LLMs", "navigating data", "metadata", "AI systems"],\n    ["Large Language Models", "data trees", "scalability", "memory efficiency"],\n    ["LLMs", "data storage", "logarithmic complexity"],\n    ["LLMs", "metadata", "data management", "scalability"],\n    ["LLMs", "tree structure", "data navigation", "AI memory solutions"]\n  ]\n}', name='GenerateKeywordGroups'), type='function')]))], created=1713724093, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=167, prompt_tokens=575, total_tokens=742))


2024-04-21 11:28:19,842 - INFO - Received completion from the model:
keyword_groups: [['LLMs', 'scalable data trees', 'O(logn) complexity'], ['LLMs', 'metadata-driven tree structure', 'large-scale memory', 'AI systems'], ['LLMs', 'data organization', 'scalable', 'O(logn)'], ['LLMs', 'managing data', 'scalable trees'], ['LLMs', 'navigating data', 'metadata', 'AI systems'], ['Large Language Models', 'data trees', 'scalability', 'memory efficiency'], ['LLMs', 'data storage', 'logarithmic complexity'], ['LLMs', 'metadata', 'data management', 'scalability'], ['LLMs', 'tree structure', 'data navigation', 'AI memory solutions']]


2024-04-21 11:28:19,845 - INFO - Searching for tweets with query: (LLMs "scalable data trees" "O(logn) complexity") OR (LLMs "metadata-driven tree structure" "large-scale memory" "AI systems") OR (LLMs "data organization" scalable O(logn)) OR (LLMs "managing data" "scalable trees") OR (LLMs "navigating data" metadata "AI systems") OR ("Large Language Models" "data trees" scalability "memory efficiency") OR (LLMs "data storage" "logarithmic complexity") OR (LLMs metadata "data management" scalability) -is:reply


2024-04-21 11:28:19,846 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:28:19Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '(LLMs "scalable data trees" "O(logn) complexity") OR (LLMs "metadata-driven tree structure" "large-scale memory" "AI systems") OR (LLMs "data organization" scalable O(logn)) OR (LLMs "managing data" "scalable trees") OR (LLMs "navigating data" metadata "AI systems") OR ("Large Language Models" "data trees" scalability "memory efficiency") OR (LLMs "data storage" "logarithmic complexity") OR (LLMs metadata "data management" scalability) -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:28:19,881 - DEBUG - Starting new HTTPS connection (1): api.twitter.com:443


2024-04-21 11:28:20,078 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A28%3A19Z&tweet.fields=author_id&expansions=author_id&query=%28LLMs+%22scalable+data+trees%22+%22O%28logn%29+complexity%22%29+OR+%28LLMs+%22metadata-driven+tree+structure%22+%22large-scale+memory%22+%22AI+systems%22%29+OR+%28LLMs+%22data+organization%22+scalable+O%28logn%29%29+OR+%28LLMs+%22managing+data%22+%22scalable+trees%22%29+OR+%28LLMs+%22navigating+data%22+metadata+%22AI+systems%22%29+OR+%28%22Large+Language+Models%22+%22data+trees%22+scalability+%22memory+efficiency%22%29+OR+%28LLMs+%22data+storage%22+%22logarithmic+complexity%22%29+OR+%28LLMs+metadata+%22data+management%22+scalability%29+-is%3Areply HTTP/1.1" 200 53


2024-04-21 11:28:20,082 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:28:20 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'set-cookie': 'guest_id_marketing=v1%3A171372410001732365; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:28:20 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id_ads=v1%3A171372410001732365; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:28:20 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, personalization_id="v1_p0qM3R27/uuSp3KUTBiIDQ=="; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:28:20 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None, guest_id=v1%3A171372410001732365; Max-Age=63072000; Expires=Tue, 21 Apr 2026 18:28:20 GMT; Path=/; Domain=.twitter.com; Secure; SameSite=None', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '53', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'd859ec6b70c5aeb3', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713725000', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '449', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '60', 'x-connection-hash': 'e78de214b281ea3eb36a08392bcd7db8c37698f437c6138d1f3f3e2108191a92'}
Content: b'{"meta":{"result_count":0}}'


2024-04-21 11:28:20,083 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.\n\nCurrent keyword groups: [['LLMs', 'scalable data trees', 'O(logn) complexity'], ['LLMs', 'metadata-driven tree structure', 'large-scale memory', 'AI systems'], ['LLMs', 'data organization', 'scalable', 'O(logn)'], ['LLMs', 'managing data', 'scalable trees'], ['LLMs', 'navigating data', 'metadata', 'AI systems'], ['Large Language Models', 'data trees', 'scalability', 'memory efficiency'], ['LLMs', 'data storage', 'logarithmic complexity'], ['LLMs', 'metadata', 'data management', 'scalability'], ['LLMs', 'tree structure', 'data navigation', 'AI memory solutions']]\n\nPlease provide a new keyword group."}


2024-04-21 11:28:20,091 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.\n\nCurrent keyword groups: [['LLMs', 'scalable data trees', 'O(logn) complexity'], ['LLMs', 'metadata-driven tree structure', 'large-scale memory', 'AI systems'], ['LLMs', 'data organization', 'scalable', 'O(logn)'], ['LLMs', 'managing data', 'scalable trees'], ['LLMs', 'navigating data', 'metadata', 'AI systems'], ['Large Language Models', 'data trees', 'scalability', 'memory efficiency'], ['LLMs', 'data storage', 'logarithmic complexity'], ['LLMs', 'metadata', 'data management', 'scalability'], ['LLMs', 'tree structure', 'data navigation', 'AI memory solutions']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:28:20,091 - DEBUG - max_retries: 8


2024-04-21 11:28:20,091 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e64f40>


2024-04-21 11:28:20,101 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.\n\nCurrent keyword groups: [['LLMs', 'scalable data trees', 'O(logn) complexity'], ['LLMs', 'metadata-driven tree structure', 'large-scale memory', 'AI systems'], ['LLMs', 'data organization', 'scalable', 'O(logn)'], ['LLMs', 'managing data', 'scalable trees'], ['LLMs', 'navigating data', 'metadata', 'AI systems'], ['Large Language Models', 'data trees', 'scalability', 'memory efficiency'], ['LLMs', 'data storage', 'logarithmic complexity'], ['LLMs', 'metadata', 'data management', 'scalability'], ['LLMs', 'tree structure', 'data navigation', 'AI memory solutions']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:28:20,102 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:20,103 - DEBUG - send_request_headers.complete


2024-04-21 11:28:20,103 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:20,104 - DEBUG - send_request_body.complete


2024-04-21 11:28:20,104 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:23,282 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3066'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599591'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'40ms'), (b'x-request-id', b'req_e9d7eba5f09b317144f27ce85a96e9a7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6ee9bd8e2b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:23,283 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:23,283 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:23,284 - DEBUG - receive_response_body.complete


2024-04-21 11:28:23,284 - DEBUG - response_closed.started


2024-04-21 11:28:23,284 - DEBUG - response_closed.complete


2024-04-21 11:28:23,285 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:23,287 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDEXWjZWVrkZLEuIYMfYkyXUy4p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zBd6VkhJxucbm6gh3sgrfckq', function=Function(arguments='{"keyword_groups":[["Large Language Models","scalable data trees"],["O(logn) complexity"],["metadata-driven tree structure"],["large-scale memory","AI systems"],["data organization","scalable"],["managing data","scalable trees"],["navigating data","metadata"],["data trees","scalability","memory efficiency"],["data storage","logarithmic complexity"],["metadata","data management"],["tree structure","data navigation","AI memory solutions"]]}', name='MakeNewKeywordGroup'), type='function')]))], created=1713724100, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=86, prompt_tokens=451, total_tokens=537))


2024-04-21 11:28:23,287 - INFO - Received completion from the model:
keyword_groups=[['Large Language Models', 'scalable data trees'], ['O(logn) complexity'], ['metadata-driven tree structure'], ['large-scale memory', 'AI systems'], ['data organization', 'scalable'], ['managing data', 'scalable trees'], ['navigating data', 'metadata'], ['data trees', 'scalability', 'memory efficiency'], ['data storage', 'logarithmic complexity'], ['metadata', 'data management'], ['tree structure', 'data navigation', 'AI memory solutions']]


2024-04-21 11:28:23,289 - INFO - Searching for tweets with query: ("Large Language Models" "scalable data trees") OR ("O(logn) complexity") OR ("metadata-driven tree structure") OR ("large-scale memory" "AI systems") OR ("data organization" scalable) OR ("managing data" "scalable trees") OR ("navigating data" metadata) OR ("data trees" scalability "memory efficiency") OR ("data storage" "logarithmic complexity") OR (metadata "data management") OR ("tree structure" "data navigation" "AI memory solutions") -is:reply


2024-04-21 11:28:23,289 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:28:23Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("Large Language Models" "scalable data trees") OR ("O(logn) complexity") OR ("metadata-driven tree structure") OR ("large-scale memory" "AI systems") OR ("data organization" scalable) OR ("managing data" "scalable trees") OR ("navigating data" metadata) OR ("data trees" scalability "memory efficiency") OR ("data storage" "logarithmic complexity") OR (metadata "data management") OR ("tree structure" "data navigation" "AI memory solutions") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:28:23,508 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A28%3A23Z&tweet.fields=author_id&expansions=author_id&query=%28%22Large+Language+Models%22+%22scalable+data+trees%22%29+OR+%28%22O%28logn%29+complexity%22%29+OR+%28%22metadata-driven+tree+structure%22%29+OR+%28%22large-scale+memory%22+%22AI+systems%22%29+OR+%28%22data+organization%22+scalable%29+OR+%28%22managing+data%22+%22scalable+trees%22%29+OR+%28%22navigating+data%22+metadata%29+OR+%28%22data+trees%22+scalability+%22memory+efficiency%22%29+OR+%28%22data+storage%22+%22logarithmic+complexity%22%29+OR+%28metadata+%22data+management%22%29+OR+%28%22tree+structure%22+%22data+navigation%22+%22AI+memory+solutions%22%29+-is%3Areply HTTP/1.1" 200 1347


2024-04-21 11:28:23,509 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:28:23 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '1347', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '917d621187c87c41', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713725000', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '448', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '169', 'x-connection-hash': 'e78de214b281ea3eb36a08392bcd7db8c37698f437c6138d1f3f3e2108191a92'}
Content: b'{"data":[{"id":"1782001559670288709","edit_history_tweet_ids":["1782001559670288709"],"author_id":"1621875741733289984","text":"4/7 New Concepts: Metadata\\nIntroducing the \\"Metadata\\" concept in the Huddle01 SDK. Attach additional information to Peers and the Room as a flexible data store. Stay organized and enhance data management capabilities."},{"id":"1781746398792474965","edit_history_tweet_ids":["1781746398792474965"],"author_id":"2999198566","text":"RT @NuklaiData: BDP\xe2\x80\x99s diverse data sources will be able to benefit from Nuklai\xe2\x80\x99s data management features such as #metadata enhancement, da\xe2\x80\xa6"},{"id":"1781648634402189362","edit_history_tweet_ids":["1781648634402189362"],"author_id":"1260028007168618496","text":"\xe5\x88\x9d\xe3\x82\x81\xe3\x81\xa6\xe7\x9f\xa5\xe3\x81\xa3\xe3\x81\x9f metadata-first architecture\\n\\nBanish metadata silos, fragmented expertise, and long-term data management complexity. https://t.co/Es2pRpBWjR"},{"id":"1781065374999412894","edit_history_tweet_ids":["1781065374999412894"],"author_id":"1150119717350379520","text":"DYK? You\xe2\x80\x99ll notice better productivity, more accurate models, faster cycle times, more flexibility, and auditable, transparent data if you share metadata across data management and analytics so that promotes collaboration and makes business model deployment easier."},{"id":"1781051914454548850","edit_history_tweet_ids":["1781051914454548850"],"author_id":"1780944285082279936","text":"RT @NuklaiData: BDP\xe2\x80\x99s diverse data sources will be able to benefit from Nuklai\xe2\x80\x99s data management features such as #metadata enhancement, da\xe2\x80\xa6"},{"id":"1780364930979385539","edit_history_tweet_ids":["1780364930979385539"],"author_id":"3219617708","text":"BE CAREFUL NEO CYBER CRIMINALS ARE DESTROYING FILES METADATA TO VANISH THE FILES ORDER AND DATA BASES OF THE USERS AND CREATE A SOUP OF CONTENT THAT WILL WORK FOR THEIR SPYWARE AND KEEP THE USER WASTING TIME IN DATA MANAGEMENT WHILE PIRATES USE THE HARDWARE! PLUS IDENTITY CRIMES!"},{"id":"1780362732933689525","edit_history_tweet_ids":["1780362732933689525"],"author_id":"322286421","text":"RT @NuklaiData: BDP\xe2\x80\x99s diverse data sources will be able to benefit from Nuklai\xe2\x80\x99s data management features such as #metadata enhancement, da\xe2\x80\xa6"},{"id":"1779859671035093293","edit_history_tweet_ids":["1779859671035093293"],"author_id":"751574151853404160","text":"RT @NuklaiData: BDP\xe2\x80\x99s diverse data sources will be able to benefit from Nuklai\xe2\x80\x99s data management features such as #metadata enhancement, da\xe2\x80\xa6"}],"includes":{"users":[{"id":"1621875741733289984","name":"Emem offum","username":"Cryptoemem"},{"id":"2999198566","name":"Pushpendra singh \\"Ultiverse\xe2\x9a\xa1\xef\xb8\x8f\\uD83D\\uDC11\\" \\"\xe2\x9d\xa4\xef\xb8\x8f $WELL\\" $MOJO","username":"ppushpendrasin1"},{"id":"1260028007168618496","name":"K","username":"vvkdt"},{"id":"1150119717350379520","name":"mike","username":"mike50914835"},{"id":"1780944285082279936","name":"\\uD83D\\uDE14","username":"unknowntigg"},{"id":"3219617708","name":"Alberto Pickering Brunel","username":"PickeringBrunel"},{"id":"322286421","name":"crypt0gemhunter plena","username":"crypt0gemhunter"},{"id":"751574151853404160","name":"Anifowose Masturoh","username":"mhztewrah"}]},"meta":{"newest_id":"1782001559670288709","oldest_id":"1779859671035093293","result_count":8}}'


2024-04-21 11:28:23,509 - DEBUG - Making API request: GET https://api.twitter.com/2/users
Parameters: {'ids': '1621875741733289984,2999198566,1260028007168618496,1150119717350379520,1780944285082279936,3219617708,322286421,751574151853404160'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:28:23,590 - DEBUG - https://api.twitter.com:443 "GET /2/users?ids=1621875741733289984%2C2999198566%2C1260028007168618496%2C1150119717350379520%2C1780944285082279936%2C3219617708%2C322286421%2C751574151853404160 HTTP/1.1" 200 382


2024-04-21 11:28:23,591 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:28:23 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '382', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'd5c6a2badb1ae2d3', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713725003', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '299', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '45', 'x-connection-hash': 'e78de214b281ea3eb36a08392bcd7db8c37698f437c6138d1f3f3e2108191a92'}
Content: b'{"data":[{"id":"1621875741733289984","name":"Emem offum","username":"Cryptoemem"},{"id":"2999198566","name":"Pushpendra singh \\"Ultiverse\xe2\x9a\xa1\xef\xb8\x8f\\uD83D\\uDC11\\" \\"\xe2\x9d\xa4\xef\xb8\x8f $WELL\\" $MOJO","username":"ppushpendrasin1"},{"id":"1260028007168618496","name":"K","username":"vvkdt"},{"id":"1150119717350379520","name":"mike","username":"mike50914835"},{"id":"1780944285082279936","name":"\\uD83D\\uDE14","username":"unknowntigg"},{"id":"3219617708","name":"Alberto Pickering Brunel","username":"PickeringBrunel"},{"id":"322286421","name":"crypt0gemhunter plena","username":"crypt0gemhunter"},{"id":"751574151853404160","name":"Anifowose Masturoh","username":"mhztewrah"}]}'


2024-04-21 11:28:23,592 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}
	{'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.\n\nCurrent keyword groups: [['Large Language Models', 'scalable data trees'], ['O(logn) complexity'], ['metadata-driven tree structure'], ['large-scale memory', 'AI systems'], ['data organization', 'scalable'], ['managing data', 'scalable trees'], ['navigating data', 'metadata'], ['data trees', 'scalability', 'memory efficiency'], ['data storage', 'logarithmic complexity'], ['metadata', 'data management'], ['tree structure', 'data navigation', 'AI memory solutions']]\n\nPlease provide a new keyword group."}


2024-04-21 11:28:23,594 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewKeywordGroup'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.\n\nCurrent keyword groups: [['Large Language Models', 'scalable data trees'], ['O(logn) complexity'], ['metadata-driven tree structure'], ['large-scale memory', 'AI systems'], ['data organization', 'scalable'], ['managing data', 'scalable trees'], ['navigating data', 'metadata'], ['data trees', 'scalability', 'memory efficiency'], ['data storage', 'logarithmic complexity'], ['metadata', 'data management'], ['tree structure', 'data navigation', 'AI memory solutions']]\n\nPlease provide a new keyword group."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}}


2024-04-21 11:28:23,595 - DEBUG - max_retries: 8


2024-04-21 11:28:23,595 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e65d50>


2024-04-21 11:28:23,599 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "The current query is not returning enough results. Please provide a new more general keyword group to broaden the search. By the way, to clarify, you are REWRITING the keyword groups, not adding to them. Keyword groups work by treating each sublist as a set of 'AND' conditions, and the lists themselves are 'ORed' together. The best way to broaden a search is to create fewer 'ANDs' (sublists with fewer items) and more 'ORs' (more sublists). So, consider splitting up the inner sublists to increase 'ORs'."}, {'role': 'user', 'content': "The user is looking for stuff that matches this: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.\n\nCurrent keyword groups: [['Large Language Models', 'scalable data trees'], ['O(logn) complexity'], ['metadata-driven tree structure'], ['large-scale memory', 'AI systems'], ['data organization', 'scalable'], ['managing data', 'scalable trees'], ['navigating data', 'metadata'], ['data trees', 'scalability', 'memory efficiency'], ['data storage', 'logarithmic complexity'], ['metadata', 'data management'], ['tree structure', 'data navigation', 'AI memory solutions']]\n\nPlease provide a new keyword group."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewKeywordGroup'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewKeywordGroup', 'description': 'Correctly extracted `MakeNewKeywordGroup` with all the required parameters with correct types', 'parameters': {'properties': {'keyword_groups': {'description': 'Enter a new keyword group.', 'items': {'items': {'type': 'string'}, 'type': 'array'}, 'title': 'Keyword Groups', 'type': 'array'}}, 'required': ['keyword_groups'], 'type': 'object'}}}]}}


2024-04-21 11:28:23,600 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:23,600 - DEBUG - send_request_headers.complete


2024-04-21 11:28:23,600 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:23,600 - DEBUG - send_request_body.complete


2024-04-21 11:28:23,600 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:29,156 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'5321'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599616'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'38ms'), (b'x-request-id', b'req_718e8b27481bdca1a91bdb79d86490d1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6eff9dcf2b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:29,158 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:29,158 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:29,159 - DEBUG - receive_response_body.complete


2024-04-21 11:28:29,159 - DEBUG - response_closed.started


2024-04-21 11:28:29,159 - DEBUG - response_closed.complete


2024-04-21 11:28:29,159 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:29,161 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDH2UaxHyP3WO6aRJJP98oHp46A', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OG4Bg8PRFuAxvXfCHrOGy5zB', function=Function(arguments='{\n  "keyword_groups": [\n    ["Large Language Models"],\n    ["scalable data trees"],\n    ["O(logn) complexity"],\n    ["metadata-driven"],\n    ["tree structure"],\n    ["large-scale memory"],\n    ["AI systems"],\n    ["data organization"],\n    ["managing data"],\n    ["navigating data"],\n    ["scalability"],\n    ["memory efficiency"],\n    ["data storage"],\n    ["logarithmic complexity"],\n    ["metadata"],\n    ["data management"],\n    ["data navigation"],\n    ["AI memory solutions"]\n  ]\n}', name='MakeNewKeywordGroup'), type='function')]))], created=1713724103, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=112, prompt_tokens=405, total_tokens=517))


2024-04-21 11:28:29,162 - INFO - Received completion from the model:
keyword_groups=[['Large Language Models'], ['scalable data trees'], ['O(logn) complexity'], ['metadata-driven'], ['tree structure'], ['large-scale memory'], ['AI systems'], ['data organization'], ['managing data'], ['navigating data'], ['scalability'], ['memory efficiency'], ['data storage'], ['logarithmic complexity'], ['metadata'], ['data management'], ['data navigation'], ['AI memory solutions']]


2024-04-21 11:28:29,165 - INFO - Searching for tweets with query: ("Large Language Models") OR ("scalable data trees") OR ("O(logn) complexity") OR (metadata-driven) OR ("tree structure") OR ("large-scale memory") OR ("AI systems") OR ("data organization") OR ("managing data") OR ("navigating data") OR (scalability) OR ("memory efficiency") OR ("data storage") OR ("logarithmic complexity") OR (metadata) OR ("data management") OR ("data navigation") OR ("AI memory solutions") -is:reply


2024-04-21 11:28:29,165 - DEBUG - Making API request: GET https://api.twitter.com/2/tweets/search/recent
Parameters: {'max_results': 100, 'start_time': '2024-04-15T11:28:29Z', 'tweet.fields': 'author_id', 'expansions': 'author_id', 'query': '("Large Language Models") OR ("scalable data trees") OR ("O(logn) complexity") OR (metadata-driven) OR ("tree structure") OR ("large-scale memory") OR ("AI systems") OR ("data organization") OR ("managing data") OR ("navigating data") OR (scalability) OR ("memory efficiency") OR ("data storage") OR ("logarithmic complexity") OR (metadata) OR ("data management") OR ("data navigation") OR ("AI memory solutions") -is:reply'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:28:29,777 - DEBUG - https://api.twitter.com:443 "GET /2/tweets/search/recent?max_results=100&start_time=2024-04-15T11%3A28%3A29Z&tweet.fields=author_id&expansions=author_id&query=%28%22Large+Language+Models%22%29+OR+%28%22scalable+data+trees%22%29+OR+%28%22O%28logn%29+complexity%22%29+OR+%28metadata-driven%29+OR+%28%22tree+structure%22%29+OR+%28%22large-scale+memory%22%29+OR+%28%22AI+systems%22%29+OR+%28%22data+organization%22%29+OR+%28%22managing+data%22%29+OR+%28%22navigating+data%22%29+OR+%28scalability%29+OR+%28%22memory+efficiency%22%29+OR+%28%22data+storage%22%29+OR+%28%22logarithmic+complexity%22%29+OR+%28metadata%29+OR+%28%22data+management%22%29+OR+%28%22data+navigation%22%29+OR+%28%22AI+memory+solutions%22%29+-is%3Areply HTTP/1.1" 200 9082


2024-04-21 11:28:29,779 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:28:29 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '9082', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': '1f502385f20fae2d', 'x-xss-protection': '0', 'x-rate-limit-limit': '450', 'x-rate-limit-reset': '1713725000', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '447', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '567', 'x-connection-hash': 'e78de214b281ea3eb36a08392bcd7db8c37698f437c6138d1f3f3e2108191a92'}
Content: b'{"data":[{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1633818496738967552","id":"1782114150484738342","edit_history_tweet_ids":["1782114150484738342"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1696879894318157825","id":"1782114145803903375","edit_history_tweet_ids":["1782114145803903375"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1356872876247277573","id":"1782114140653531355","edit_history_tweet_ids":["1782114140653531355"]},{"text":"RT @withmoodxtnt: \xe0\xb8\xad\xe0\xb8\xb1\xe0\xb8\xa5\xe0\xb8\x9a\xe0\xb8\xb1\xe0\xb9\x89\xe0\xb8\xa1 Data storage \xe0\xb8\x82\xe0\xb8\xad\xe0\xb8\x87\xe0\xb8\x9e\xe0\xb9\x89\xe0\xb8\xad\xe0\xb8\x81\xe0\xb8\xaa\xe0\xb8\xb5\xe0\xb8\x84\xe0\xb9\x89\xe0\xb8\xb2\xe0\xb8\x9a \xe0\xb8\x94\xe0\xb8\xb5\xe0\xb9\x80\xe0\xb8\x97\xe0\xb8\xa5\xe0\xb8\x88\xe0\xb8\xb8\xe0\xb8\x81\xe0\xb9\x86 \xe0\xb8\x87\xe0\xb8\xb2\xe0\xb8\x99\xe0\xb8\xad\xe0\xb8\xb2\xe0\xb8\xa3\xe0\xb9\x8c\xe0\xb8\x95\xe0\xb8\xaa\xe0\xb8\xb2\xe0\xb9\x81\xe0\xb8\x81\xe0\xb9\x88\xe0\xb9\x83\xe0\xb8\x88 \xe0\xb8\x82\xe0\xb8\xad\xe0\xb8\x87\xe0\xb8\x94\xe0\xb8\xb5\xe0\xb8\x97\xe0\xb8\xb5\xe0\xb8\x9b\xe0\xb9\x89\xe0\xb8\xad\xe0\xb8\x9b\xe0\xb8\xa1\xe0\xb8\xb2\xe0\xb8\x81 \\uD83D\\uDE2D https://t.co/CaJ7qRAs9C","author_id":"1390165050103533576","id":"1782114129039462820","edit_history_tweet_ids":["1782114129039462820"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1780626201922433025","id":"1782114125931331707","edit_history_tweet_ids":["1782114125931331707"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1767658090348818432","id":"1782114122676527595","edit_history_tweet_ids":["1782114122676527595"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1779957563968118786","id":"1782114093626744910","edit_history_tweet_ids":["1782114093626744910"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1774339975640662016","id":"1782114083002540295","edit_history_tweet_ids":["1782114083002540295"]},{"text":"RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \\n\\nThe next st\xe2\x80\xa6","author_id":"225889683","id":"1782114062479892828","edit_history_tweet_ids":["1782114062479892828"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1592910151446577153","id":"1782114056490328552","edit_history_tweet_ids":["1782114056490328552"]},{"text":"@ShardsOfficial \\uD83D\\uDD17 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let\'s shape the future together! \\uD83C\\uDF10\\uD83D\\uDE80 #blockchain","author_id":"2596360582","id":"1782114042833670404","edit_history_tweet_ids":["1782114042833670404"]},{"text":"RT @NexAcademyx: Nexa is;\\nBetter Security than #Bitcoin\\nMore Capacity than #Solana\\nand as much programmability as #ethereum\\nThat is #Nexa 1\xe2\x80\xa6","author_id":"2924674454","id":"1782114004703363349","edit_history_tweet_ids":["1782114004703363349"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1034177311153823745","id":"1782113989545079249","edit_history_tweet_ids":["1782113989545079249"]},{"text":"RT @Cookie3_com: \\uD83C\\uDF6A High Throughput: Faster transaction processing.\\n\\uD83C\\uDF6A Lower Fees: Lower transaction costs.\\n\\uD83C\\uDF6A Compatibility: Seamless integra\xe2\x80\xa6","author_id":"1739763436844892160","id":"1782113981689184631","edit_history_tweet_ids":["1782113981689184631"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1739787898839330816","id":"1782113979197788657","edit_history_tweet_ids":["1782113979197788657"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1335993994107621380","id":"1782113968984555633","edit_history_tweet_ids":["1782113968984555633"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"735400714957127680","id":"1782113962915487994","edit_history_tweet_ids":["1782113962915487994"]},{"text":"RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! \\uD83C\\uDF89\\n\\nAn up-and-coming project with great airdrop potential has surfaced. Intr\xe2\x80\xa6","author_id":"1777232868739313664","id":"1782113962412359843","edit_history_tweet_ids":["1782113962412359843"]},{"text":"RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\\nThe differentia\xe2\x80\xa6","author_id":"1307801885764706305","id":"1782113958037500324","edit_history_tweet_ids":["1782113958037500324"]},{"text":"traits/metadata updated soon!!!\\n\\nlook out for 42069 main characters, overlays\\n\\nand the super rare golden guns\\n\\nnice https://t.co/WFON5jZ9CB","author_id":"1769616063728381952","id":"1782113952245362983","edit_history_tweet_ids":["1782113952245362983"]},{"text":"RT @withmoodxtnt: \xe0\xb8\xad\xe0\xb8\xb1\xe0\xb8\xa5\xe0\xb8\x9a\xe0\xb8\xb1\xe0\xb9\x89\xe0\xb8\xa1 Data storage \xe0\xb8\x82\xe0\xb8\xad\xe0\xb8\x87\xe0\xb8\x9e\xe0\xb9\x89\xe0\xb8\xad\xe0\xb8\x81\xe0\xb8\xaa\xe0\xb8\xb5\xe0\xb8\x84\xe0\xb9\x89\xe0\xb8\xb2\xe0\xb8\x9a \xe0\xb8\x94\xe0\xb8\xb5\xe0\xb9\x80\xe0\xb8\x97\xe0\xb8\xa5\xe0\xb8\x88\xe0\xb8\xb8\xe0\xb8\x81\xe0\xb9\x86 \xe0\xb8\x87\xe0\xb8\xb2\xe0\xb8\x99\xe0\xb8\xad\xe0\xb8\xb2\xe0\xb8\xa3\xe0\xb9\x8c\xe0\xb8\x95\xe0\xb8\xaa\xe0\xb8\xb2\xe0\xb9\x81\xe0\xb8\x81\xe0\xb9\x88\xe0\xb9\x83\xe0\xb8\x88 \xe0\xb8\x82\xe0\xb8\xad\xe0\xb8\x87\xe0\xb8\x94\xe0\xb8\xb5\xe0\xb8\x97\xe0\xb8\xb5\xe0\xb8\x9b\xe0\xb9\x89\xe0\xb8\xad\xe0\xb8\x9b\xe0\xb8\xa1\xe0\xb8\xb2\xe0\xb8\x81 \\uD83D\\uDE2D https://t.co/CaJ7qRAs9C","author_id":"1611786056348889089","id":"1782113908842705407","edit_history_tweet_ids":["1782113908842705407"]},{"text":"RT @vrjar_: metadata refreshed, everything looks ok now \xe2\x9c\xa8","author_id":"1650701737391538176","id":"1782113899187183929","edit_history_tweet_ids":["1782113899187183929"]},{"text":"RT @Web3lounge_: Great news for all airdrop seekers! \\uD83D\\uDCA5\\n\\nA promising new project with substantial airdrop potential has appeared. Let\'s welc\xe2\x80\xa6","author_id":"1777232868739313664","id":"1782113887535681953","edit_history_tweet_ids":["1782113887535681953"]},{"text":"RT @Sagaxyz__: Infinite horizontal scalability.","author_id":"1458116670","id":"1782113879104872504","edit_history_tweet_ids":["1782113879104872504"]},{"text":"@LDN_Blockchain Not gonna lie, I\'m pretty impressed by the technical details of Jiritsu\'s Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?","author_id":"1272991390214098944","id":"1782113874470215883","edit_history_tweet_ids":["1782113874470215883"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1483445146087989252","id":"1782113842362810637","edit_history_tweet_ids":["1782113842362810637"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1320648461528739840","id":"1782113832581689581","edit_history_tweet_ids":["1782113832581689581"]},{"text":"RT @palmaierc: \\uD83C\\uDF34 $PALM Utility Showcase: AI Location Search\\n\\n\\uD83D\\uDCF7 Recently we\'ve noticed people using PaLM AI to identify locations based on p\xe2\x80\xa6","author_id":"558736498","id":"1782113828605768156","edit_history_tweet_ids":["1782113828605768156"]},{"text":"Nexa is;\\nBetter Security than #Bitcoin\\nMore Capacity than #Solana\\nand as much programmability as #ethereum\\nThat is #Nexa 100K Tps and infinitely scalability\\n@NexaMoney \\n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B","author_id":"1578476287924084737","id":"1782113820279742774","edit_history_tweet_ids":["1782113820279742774"]},{"text":"RT @wardenprotocol: Warden Whitepaper is released\\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati\xe2\x80\xa6","author_id":"1433831944496816131","id":"1782113819189186591","edit_history_tweet_ids":["1782113819189186591"]},{"text":"RT @Somnia_Network: #Somnia\xe2\x80\x99s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil\xe2\x80\xa6","author_id":"1777652476725936128","id":"1782113808867025277","edit_history_tweet_ids":["1782113808867025277"]},{"text":"EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.","author_id":"1045029523031494658","id":"1782113798670696831","edit_history_tweet_ids":["1782113798670696831"]},{"text":"@Pawan2001564157 @SenderLabs 282.   \\"Ethereum\'s scalability solutions: addressing network congestion.   \\uD83C\\uDF10\\uD83D\\uDEA7\\"","author_id":"1773929722457821184","id":"1782113775203877140","edit_history_tweet_ids":["1782113775203877140"]},{"text":"RT @xallyai: \\uD83C\\uDF10 Big News on the Horizon! \\uD83D\\uDE80\\n\\nWe\'re thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr\xe2\x80\xa6","author_id":"1647075542913433600","id":"1782113741623984402","edit_history_tweet_ids":["1782113741623984402"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1659297093742129164","id":"1782113727749267660","edit_history_tweet_ids":["1782113727749267660"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1626725619693244417","id":"1782113690264728021","edit_history_tweet_ids":["1782113690264728021"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1751621938307375105","id":"1782113677576896915","edit_history_tweet_ids":["1782113677576896915"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"3233147055","id":"1782113653749059840","edit_history_tweet_ids":["1782113653749059840"]},{"text":"RT @Somnia_Network: #Somnia\xe2\x80\x99s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil\xe2\x80\xa6","author_id":"1594033883384684545","id":"1782113638372769839","edit_history_tweet_ids":["1782113638372769839"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1627554932415991810","id":"1782113622468002026","edit_history_tweet_ids":["1782113622468002026"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1613540580121796608","id":"1782113621742322153","edit_history_tweet_ids":["1782113621742322153"]},{"text":"RT @Cookie3_com: \\uD83C\\uDF6A High Throughput: Faster transaction processing.\\n\\uD83C\\uDF6A Lower Fees: Lower transaction costs.\\n\\uD83C\\uDF6A Compatibility: Seamless integra\xe2\x80\xa6","author_id":"1778532000355520512","id":"1782113618433073392","edit_history_tweet_ids":["1782113618433073392"]},{"text":"RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino\xe2\x80\xa6","author_id":"1596750503404183553","id":"1782113616273223694","edit_history_tweet_ids":["1782113616273223694"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"963218502130831360","id":"1782113613777441055","edit_history_tweet_ids":["1782113613777441055"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1298200714460696576","id":"1782113612552692101","edit_history_tweet_ids":["1782113612552692101"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"403382903","id":"1782113607150416267","edit_history_tweet_ids":["1782113607150416267"]},{"text":"RT @xallyai: \\uD83C\\uDF10 Big News on the Horizon! \\uD83D\\uDE80\\n\\nWe\'re thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr\xe2\x80\xa6","author_id":"1426850073820991494","id":"1782113603786531166","edit_history_tweet_ids":["1782113603786531166"]},{"text":"RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\\n\\nLarge language models are real AI that is smarter than 99\xe2\x80\xa6","author_id":"24652017","id":"1782113599487648224","edit_history_tweet_ids":["1782113599487648224"]},{"text":"RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s\xe2\x80\xa6","author_id":"1376102702250389505","id":"1782113595750281660","edit_history_tweet_ids":["1782113595750281660"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1509254086025265156","id":"1782113594466857431","edit_history_tweet_ids":["1782113594466857431"]},{"text":"RT @usesendtokens: \xe2\x9a\xa1\xef\xb8\x8fBitcoin\'s future is bright!\xe2\x9a\xa1\xef\xb8\x8f Sendtokens integrates with @Photon_L2  by @SatoshiSync!\\n\\nThis unlocks:\\n\\nScalability for\xe2\x80\xa6","author_id":"1584767008574345216","id":"1782113594316116461","edit_history_tweet_ids":["1782113594316116461"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1682373927983513600","id":"1782113590838759854","edit_history_tweet_ids":["1782113590838759854"]},{"text":"Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.","author_id":"1775891812009304064","id":"1782113575244333421","edit_history_tweet_ids":["1782113575244333421"]},{"text":"RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! \\uD83C\\uDF89\\n\\nAn up-and-coming project with great airdrop potential has surfaced. Intr\xe2\x80\xa6","author_id":"1777228037375021056","id":"1782113569905221690","edit_history_tweet_ids":["1782113569905221690"]},{"text":"@KrystalVil96992 \xe2\x9a\xb0 \xef\xb8\x8f \xef\xb8\x8f \\uD83C\\uDF49 \\uD83C\\uDF17 9167188853 \\uD83E\\uDD9C \xef\xb8\x8f \\uD83C\\uDF8D Who tree structure receive guy guess run.","author_id":"1760805644473384960","id":"1782113544084856981","edit_history_tweet_ids":["1782113544084856981"]},{"text":"RT @palmaierc: \\uD83C\\uDF34 $PALM Utility Showcase: AI Location Search\\n\\n\\uD83D\\uDCF7 Recently we\'ve noticed people using PaLM AI to identify locations based on p\xe2\x80\xa6","author_id":"1398664090399215620","id":"1782113539953414458","edit_history_tweet_ids":["1782113539953414458"]},{"text":"6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. \\uD83D\\uDD10\\uD83D\\uDCA1","author_id":"1369403802638557195","id":"1782113528326860931","edit_history_tweet_ids":["1782113528326860931"]},{"text":"RT @Web3lounge_: Great news for all airdrop seekers! \\uD83D\\uDCA5\\n\\nA promising new project with substantial airdrop potential has appeared. Let\'s welc\xe2\x80\xa6","author_id":"1777228037375021056","id":"1782113498794955208","edit_history_tweet_ids":["1782113498794955208"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1777642536745508864","id":"1782113496445939999","edit_history_tweet_ids":["1782113496445939999"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"4701981923","id":"1782113478867571044","edit_history_tweet_ids":["1782113478867571044"]},{"text":"RT @vrjar_: metadata refreshed, everything looks ok now \xe2\x9c\xa8","author_id":"1673003814914342915","id":"1782113477147930754","edit_history_tweet_ids":["1782113477147930754"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1558929982881251328","id":"1782113477026328810","edit_history_tweet_ids":["1782113477026328810"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1691899786088349696","id":"1782113468558033066","edit_history_tweet_ids":["1782113468558033066"]},{"text":"RT @burkov: I see too many people don\xe2\x80\x99t understand why Meta spends billions to train and then gives away its large language models. They th\xe2\x80\xa6","author_id":"66651296","id":"1782113432914833574","edit_history_tweet_ids":["1782113432914833574"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1437412585654169608","id":"1782113424173896087","edit_history_tweet_ids":["1782113424173896087"]},{"text":"RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e\xe2\x80\xa6","author_id":"1329136317029081092","id":"1782113417043529922","edit_history_tweet_ids":["1782113417043529922"]},{"text":"RT @Sagaxyz__: Infinite horizontal scalability.","author_id":"288118043","id":"1782113410810822877","edit_history_tweet_ids":["1782113410810822877"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1761640741762215936","id":"1782113407723819450","edit_history_tweet_ids":["1782113407723819450"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1461244693472292873","id":"1782113407283429646","edit_history_tweet_ids":["1782113407283429646"]},{"text":"RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e\xe2\x80\xa6","author_id":"757830632231702528","id":"1782113378451787895","edit_history_tweet_ids":["1782113378451787895"]},{"text":"RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\\n\\nHe began with a reality check: \\"Machine Learning falls s\xe2\x80\xa6","author_id":"36023344","id":"1782113348235980899","edit_history_tweet_ids":["1782113348235980899"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1488896742804312066","id":"1782113334629658665","edit_history_tweet_ids":["1782113334629658665"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1701859166468390912","id":"1782113325788102853","edit_history_tweet_ids":["1782113325788102853"]},{"text":"@DaanCrypto \\"Incredible potentials here! With features focused on scalability and security, this project is set for big things.\\" @TRUMP2024_TOKEN\\n#Trump2024Token https://t.co/LQFNowRXUy","author_id":"1774917264002670594","id":"1782113316917170191","edit_history_tweet_ids":["1782113316917170191"]},{"text":"@Lauramaywendel future ai systems. Open AI have two really big cards under it\'s sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.","author_id":"1551027139855761409","id":"1782113292917301489","edit_history_tweet_ids":["1782113292917301489"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1761385387241394176","id":"1782113292703395884","edit_history_tweet_ids":["1782113292703395884"]},{"text":"RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! \\uD83C\\uDF89\\n\\nAn up-and-coming project with great airdrop potential has surfaced. Intr\xe2\x80\xa6","author_id":"1777227365665669121","id":"1782113284981932275","edit_history_tweet_ids":["1782113284981932275"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1752356306113982464","id":"1782113258897350837","edit_history_tweet_ids":["1782113258897350837"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1777387349661675520","id":"1782113228874777061","edit_history_tweet_ids":["1782113228874777061"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1689394075789639681","id":"1782113227813372185","edit_history_tweet_ids":["1782113227813372185"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"878313178861457409","id":"1782113225200239036","edit_history_tweet_ids":["1782113225200239036"]},{"text":"RT @Web3lounge_: Great news for all airdrop seekers! \\uD83D\\uDCA5\\n\\nA promising new project with substantial airdrop potential has appeared. Let\'s welc\xe2\x80\xa6","author_id":"1777227365665669121","id":"1782113221614420031","edit_history_tweet_ids":["1782113221614420031"]},{"text":"RT @jacksonhinklle: \\uD83D\\uDEA8\\uD83C\\uDDEE\\uD83C\\uDDF1\\uD83C\\uDDFA\\uD83C\\uDDF8 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1","author_id":"1595081152498466816","id":"1782113221052190926","edit_history_tweet_ids":["1782113221052190926"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1594687257843097600","id":"1782113220221923796","edit_history_tweet_ids":["1782113220221923796"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1780489003046744064","id":"1782113204442702059","edit_history_tweet_ids":["1782113204442702059"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1682225554169184256","id":"1782113197140390174","edit_history_tweet_ids":["1782113197140390174"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"711984815797608448","id":"1782113176328290516","edit_history_tweet_ids":["1782113176328290516"]},{"text":"RT @Somnia_Network: #Somnia\xe2\x80\x99s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil\xe2\x80\xa6","author_id":"1349190511899283456","id":"1782113168900124686","edit_history_tweet_ids":["1782113168900124686"]},{"text":"RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \\n\\n- Scalability \\n- interoperability \\n- Secure\\n- Ma\xe2\x80\xa6","author_id":"1475563858228039684","id":"1782113157647118341","edit_history_tweet_ids":["1782113157647118341"]},{"text":"RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh\xe2\x80\xa6","author_id":"1719701375603359744","id":"1782113149602402388","edit_history_tweet_ids":["1782113149602402388"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1775310344753192960","id":"1782113143101002009","edit_history_tweet_ids":["1782113143101002009"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1457695415625822219","id":"1782113129746346128","edit_history_tweet_ids":["1782113129746346128"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1380493269461823488","id":"1782113127745630655","edit_history_tweet_ids":["1782113127745630655"]},{"text":"RT @Web3lounge_: Great news for all airdrop seekers! \\uD83D\\uDCA5\\n\\nA promising new project with substantial airdrop potential has appeared. Let\'s welc\xe2\x80\xa6","author_id":"729128458274639872","id":"1782113124398838144","edit_history_tweet_ids":["1782113124398838144"]},{"text":"RT @Somnia_Network: #Somnia\xe2\x80\x99s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil\xe2\x80\xa6","author_id":"1654403017876312064","id":"1782113119147602325","edit_history_tweet_ids":["1782113119147602325"]},{"text":"@boyney123 I\'ve not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I\'d prefer the central project to simply point at each service repo an pull the metadata from there.","author_id":"254132769","id":"1782113112717426937","edit_history_tweet_ids":["1782113112717426937"]},{"text":"@ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\\nfor Exemple ChatGPT","author_id":"3046932847","id":"1782113112356766068","edit_history_tweet_ids":["1782113112356766068"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"1354789355034968064","id":"1782113110486122553","edit_history_tweet_ids":["1782113110486122553"]},{"text":"RT @Revolving_Games: Power Status: 100% \xef\xb8\x8f\\uD83D\\uDD0B\\n\\nNexian Gems...\\nREFRESH YOUR METADATA.\\n\\nThe upgrade is complete. Nexian Gems have officially evo\xe2\x80\xa6","author_id":"2761120377","id":"1782113105612345851","edit_history_tweet_ids":["1782113105612345851"]},{"text":"RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! \\uD83C\\uDF89\\n\\nAn up-and-coming project with great airdrop potential has surfaced. Intr\xe2\x80\xa6","author_id":"729128458274639872","id":"1782113100982067263","edit_history_tweet_ids":["1782113100982067263"]}],"includes":{"users":[{"id":"1633818496738967552","name":"Rhoda Nnamani","username":"RhodaNnamani"},{"id":"1696879894318157825","name":"Daniel Nnamani (Dandyoz)","username":"DanielNna27784"},{"id":"1356872876247277573","name":"Trafalgar07","username":"AL72402862"},{"id":"1390165050103533576","name":"\xe0\xb8\xa1\xe0\xb8\xb9\xe0\xb8\xa1\xe0\xb8\xb4\xe0\xb8\x99\xe0\xb9\x80\xe0\xb8\x99\xe0\xb8\xb5\xe0\xb9\x88\xe0\xb8\xa2\xe0\xb8\x99","username":"wnndien"},{"id":"1780626201922433025","name":"\xd0\x9b\xd1\x8e\xd0\xb4\xd0\xbe\xd1\x87\xd0\xba\xd0\xb0 \xd0\x9a\xd1\x83\xd0\xb7\xd1\x8c\xd0\xbc\xd0\xb5\xd0\xbd\xd0\xba\xd0\xbe\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"KuzLudocka82185"},{"id":"1767658090348818432","name":"Den.plena.\\uD83D\\uDD79\xef\xb8\x8f $RCADE $MOJO","username":"DZalivsk"},{"id":"1779957563968118786","name":"xavierra \\uD83D\\uDCB0 BankBoost","username":"xavierra23xd"},{"id":"1774339975640662016","name":"Joshua Samuel \\uD83D\\uDD79\xef\xb8\x8f $RCADE $MOJO","username":"JoshuaSamu54295"},{"id":"225889683","name":"dansolovei","username":"danik_sol"},{"id":"1592910151446577153","name":"behrouzabb","username":"behrouzabb1"},{"id":"2596360582","name":"The Gunter Token","username":"Myownsumme_r"},{"id":"2924674454","name":"BRAVEHEART","username":"SUzunay56"},{"id":"1034177311153823745","name":"Sahar Ebrani","username":"saharebz"},{"id":"1739763436844892160","name":"Mir4777","username":"Mir4777"},{"id":"1739787898839330816","name":"The Unknown \\uD83D\\uDD79$ARCADE $PIXIZ $BUBBLE","username":"theunknown0097"},{"id":"1335993994107621380","name":"Laramie11","username":"Larabankole1"},{"id":"735400714957127680","name":"Evgeniy.NYAN\\uD83D\\uDD2B\\uD83D\\uDE3C","username":"SiteStroi"},{"id":"1777232868739313664","name":"MinervaMint","username":"MintMinerv27847"},{"id":"1307801885764706305","name":"enzo1990","username":"enzo19903"},{"id":"1769616063728381952","name":"42069","username":"42069onsol"},{"id":"1611786056348889089","name":"\xe0\xb8\x99\xe0\xb8\xa2\xe2\x98\x86","username":"ny_nnxy"},{"id":"1650701737391538176","name":"Lord mfer","username":"Lordmfer69"},{"id":"1458116670","name":"Kamlogjanty\xe2\x9d\xa4\xef\xb8\x8f Memecoin","username":"Kamlogjanty"},{"id":"1272991390214098944","name":"JUSTT RICHH.\xe2\x9a\xbd","username":"IAmRichEmmanuel"},{"id":"1483445146087989252","name":"Mamun Khan \\uD83D\\uDC09 $MON","username":"mamunk_975"},{"id":"1320648461528739840","name":"Mehdi","username":"mehdimahmodi990"},{"id":"558736498","name":"Connor","username":"condosh"},{"id":"1578476287924084737","name":"NexAcademy","username":"NexAcademyx"},{"id":"1433831944496816131","name":"smolco lombardi | \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"shinedairz"},{"id":"1777652476725936128","name":"qasim ali $BEYOND $BUBBLE","username":"qasimali1451535"},{"id":"1045029523031494658","name":"ALIYU ISYAKU ABDULLAHI","username":"AliyuIs00136912"},{"id":"1773929722457821184","name":"Rumble $XTER \\uD83D\\uDC09 $MON $MOJO $BUBBLE","username":"Rumble181547"},{"id":"1647075542913433600","name":"DCA_Crypto","username":"DCA_Crypto_Dean"},{"id":"1659297093742129164","name":"\\uD83D\\uDD79\xef\xb8\x8f $RCADE \\uD83D\\uDE80MATR1XCoin \xe2\x9d\xa4\xef\xb8\x8f $BLOCK .NYAN\\uD83D\\uDD2B Tabi","username":"comolokko72"},{"id":"1626725619693244417","name":"@Shaaban Magaji $Blockgame","username":"ShaabanMagaji"},{"id":"1751621938307375105","name":"Marla Singer \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"KripMarla"},{"id":"3233147055","name":"egoodnews.$RCADE.$BEYOND.$Affy.$BUBBLE\\uD83E\\uDEE7","username":"EdetEtop"},{"id":"1594033883384684545","name":"Ahmed Ovi Tabi \\uD83D\\uDFE7 $PARAM .NYAN\\uD83D\\uDD2B\\uD83D\\uDE3C \xe2\x9b\x93\xef\xb8\x8f SubQuery","username":"AhmedOvi2022"},{"id":"1627554932415991810","name":"Mouhamed yasin","username":"jack1112588"},{"id":"1613540580121796608","name":"\xd0\x86\xd0\xb2\xd0\xb0\xd0\xbd \xd0\x9f\xd0\xb0\xd1\x80\xd0\xb0\xd1\x89\xd0\xb0\xd0\xba\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"IvanParasak"},{"id":"1778532000355520512","name":"Hadi Tayebi$BUBBLE","username":"haditayebi0494"},{"id":"1596750503404183553","name":"Yuntod","username":"Yuntod1"},{"id":"963218502130831360","name":"Crypto Papas \\uD83D\\uDC09 $MON","username":"rothmans110"},{"id":"1298200714460696576","name":"Ibrahim Mannir","username":"Bin__Muneer"},{"id":"403382903","name":"\xc3\xb6zkan kaplan","username":"zkan_kaplan"},{"id":"1426850073820991494","name":"Anton \\uD83D\\uDD79\xef\xb8\x8f $RCADE l Velvet Dao Xally-AI","username":"Anton13925599"},{"id":"24652017","name":"Scott Layne","username":"DrNoDox"},{"id":"1376102702250389505","name":"Sabri Ajbilou","username":"AjbilouSabri"},{"id":"1509254086025265156","name":"Andrey Shestopal \\uD83D\\uDD79\xef\xb8\x8f $RCADE $BEYOND","username":"ShestopalAndrey"},{"id":"1584767008574345216","name":"Mike Wolf","username":"SpiderM07506934"},{"id":"1682373927983513600","name":"tupachill.eth Tabi \\uD83D\\uDFE7 $XTER","username":"CryptoMani91065"},{"id":"1775891812009304064","name":"Oxlade","username":"Oxlade14971801"},{"id":"1777228037375021056","name":"CipherDollar","username":"CDollar85278"},{"id":"1760805644473384960","name":"Jessica Davis","username":"Jessica06528885"},{"id":"1398664090399215620","name":"TakeMi","username":"TakeMi85402052"},{"id":"1369403802638557195","name":"pancarte\\uD83D\\uDEF9\\uD83D\\uDEF9","username":"pancartesol"},{"id":"1777642536745508864","name":"Ndarake Godwin$Rcade","username":"godwinNdarakeg"},{"id":"4701981923","name":"sadtr3x\\uD83D\\uDC09 $MON","username":"sadtr3x"},{"id":"1673003814914342915","name":"Flint Spark","username":"flintverse"},{"id":"1558929982881251328","name":"Karakaiser","username":"Karakaiser01"},{"id":"1691899786088349696","name":"Nurr Sbawa SRcade","username":"NurrSbawa22041"},{"id":"66651296","name":"Marek Suscak","username":"mareksuscak"},{"id":"1437412585654169608","name":"\xd0\xae\xd1\x80\xd0\xb8\xd0\xb9 \xd0\x97\xd0\xb0\xd0\xbf\xd0\xb5\xd0\xb2\xd0\xb0\xd0\xbb\xd0\xbe\xd0\xb2 $ELS","username":"pistonik30"},{"id":"1329136317029081092","name":"~Mykel~ \\uD83C\\uDDFB\\uD83C\\uDDF3","username":"Mykelicious1"},{"id":"288118043","name":"Velaa Freeler\xe2\x9d\xa4\xef\xb8\x8f Memecoin","username":"VelaaFreelerDKA"},{"id":"1761640741762215936","name":"Kabeer Zailanee\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"KZailanee"},{"id":"1461244693472292873","name":"All Service","username":"AllServ03796160"},{"id":"757830632231702528","name":"\xe5\xae\xb3\xe7\xbe\x9e\xe5\xa5\xb3\xe5\xad\xa9 \xe2\xad\x90 \\uD83C\\uDDE8\\uD83C\\uDDF3","username":"dat_shygirl"},{"id":"36023344","name":"Kiluti","username":"MutuaKiluti"},{"id":"1488896742804312066","name":"Felo","username":"FelixLoveday9"},{"id":"1701859166468390912","name":"The African Hunter\xc2\xae $PIXIZ $BEYOND $XTER","username":"TheAfrohunter"},{"id":"1774917264002670594","name":"jaweji","username":"jaweji141011"},{"id":"1551027139855761409","name":"John","username":"John4363463463"},{"id":"1761385387241394176","name":"Mubarak \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"TurakiIbr38828"},{"id":"1777227365665669121","name":"CoinCircuitry","username":"CCircuitry19142"},{"id":"1752356306113982464","name":"Aliyu Muhammad","username":"AMuhammad31368"},{"id":"1777387349661675520","name":"SR Crypto trader","username":"Sr20962Sr"},{"id":"1689394075789639681","name":"Lena Tabi \\uD83D\\uDFE7 \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"Lena84963488"},{"id":"878313178861457409","name":"Gentle_criminal","username":"Deathlord_sas"},{"id":"1595081152498466816","name":"Jack Queiroz","username":"ManuQuiroz13"},{"id":"1594687257843097600","name":"Balatrader\\uD83D\\uDC10\\uD83D\\uDEF8\\uD83D\\uDC3B\xe2\x9b\x93\xef\xb8\x8f.NYAN\\uD83D\\uDD2B\\uD83D\\uDE3C\\uD83D\\uDC09 $MON\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"Balatrader1"},{"id":"1780489003046744064","name":"\xd0\x9e\xd0\xbb\xd0\xb5\xd0\xba\xd1\x81\xd0\xb0\xd0\xbd\xd0\xb4\xd1\x80 \xd0\x91\xd0\xbe\xd0\xb9\xd0\xba\xd0\xbe \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"Akerman83611"},{"id":"1682225554169184256","name":"Ambo\xe2\x9d\xa4\xef\xb8\x8fLino\\uD83D\\uDC09 $MON|\\uD83D\\uDC8E $FYN|\\uD83D\\uDD79\xef\xb8\x8f $RCADE $MOJO $XTER","username":"AmboAnioki28704"},{"id":"711984815797608448","name":"\xd0\xaf\xd1\x80\xd0\xb8\xd0\xba (\\uD83C\\uDFAE,\\uD83D\\uDFE2)","username":"1910Yarik"},{"id":"1349190511899283456","name":"Heaven_Cat$UNIO$XTER","username":"Heavencat_NFT"},{"id":"1475563858228039684","name":"Ape_daddy","username":"Ape_daddyy"},{"id":"1719701375603359744","name":"Praba","username":"Praba1068207"},{"id":"1775310344753192960","name":"0xdunoxx $BEYOND","username":"0xdunoxx"},{"id":"1457695415625822219","name":"Sammy","username":"Sammyking_01"},{"id":"1380493269461823488","name":"Nnamdi Nwaideh","username":"NNwaideh"},{"id":"729128458274639872","name":"rojas chand","username":"rojasnamaste"},{"id":"1654403017876312064","name":"Asif Rahaman","username":"asifrahaman067"},{"id":"254132769","name":"\\uD83C\\uDF3B Franck","username":"Franck_chester"},{"id":"3046932847","name":"Sarah \xe3\x82\xb5\xe3\x83\xa9 \\uD83C\\uDDE9\\uD83C\\uDDFF\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"sarah__0001"},{"id":"1354789355034968064","name":"Jay\\uD83D\\uDD79\xef\xb8\x8f $RCADE$BUBBLE\\uD83E\\uDEE7\\uD83E\\uDEE7\\uD83E\\uDEE7","username":"Uyane_Joy"},{"id":"2761120377","name":"Abu Oustaan","username":"MLSSanda"}]},"meta":{"newest_id":"1782114150484738342","oldest_id":"1782113100982067263","result_count":100,"next_token":"b26v89c19zqg8o3fr5zcxovi0h87dp6t5uggtyo5qgcxp"}}'


2024-04-21 11:28:29,781 - DEBUG - Making API request: GET https://api.twitter.com/2/users
Parameters: {'ids': '1633818496738967552,1696879894318157825,1356872876247277573,1390165050103533576,1780626201922433025,1767658090348818432,1779957563968118786,1774339975640662016,225889683,1592910151446577153,2596360582,2924674454,1034177311153823745,1739763436844892160,1739787898839330816,1335993994107621380,735400714957127680,1777232868739313664,1307801885764706305,1769616063728381952,1611786056348889089,1650701737391538176,1777232868739313664,1458116670,1272991390214098944,1483445146087989252,1320648461528739840,558736498,1578476287924084737,1433831944496816131,1777652476725936128,1045029523031494658,1773929722457821184,1647075542913433600,1659297093742129164,1626725619693244417,1751621938307375105,3233147055,1594033883384684545,1627554932415991810,1613540580121796608,1778532000355520512,1596750503404183553,963218502130831360,1298200714460696576,403382903,1426850073820991494,24652017,1376102702250389505,1509254086025265156,1584767008574345216,1682373927983513600,1775891812009304064,1777228037375021056,1760805644473384960,1398664090399215620,1369403802638557195,1777228037375021056,1777642536745508864,4701981923,1673003814914342915,1558929982881251328,1691899786088349696,66651296,1437412585654169608,1329136317029081092,288118043,1761640741762215936,1461244693472292873,757830632231702528,36023344,1488896742804312066,1701859166468390912,1774917264002670594,1551027139855761409,1761385387241394176,1777227365665669121,1752356306113982464,1777387349661675520,1689394075789639681,878313178861457409,1777227365665669121,1595081152498466816,1594687257843097600,1780489003046744064,1682225554169184256,711984815797608448,1349190511899283456,1475563858228039684,1719701375603359744,1775310344753192960,1457695415625822219,1380493269461823488,729128458274639872,1654403017876312064,254132769,3046932847,1354789355034968064,2761120377,729128458274639872'}
Headers: {'User-Agent': 'Python/3.10.6 Requests/2.31.0 Tweepy/4.14.0', 'Authorization': 'Bearer AAAAAAAAAAAAAAAAAAAAAOhetQEAAAAAKc2iRaIHRh3BKbUKuHS1pJ0dy4k%3DzZmcc6NvJS4snjVyPMPA1BqJqG6EjsOeCbTVptZEUvKF9zvZcY'}
Body: None


2024-04-21 11:28:30,032 - DEBUG - https://api.twitter.com:443 "GET /2/users?ids=1633818496738967552%2C1696879894318157825%2C1356872876247277573%2C1390165050103533576%2C1780626201922433025%2C1767658090348818432%2C1779957563968118786%2C1774339975640662016%2C225889683%2C1592910151446577153%2C2596360582%2C2924674454%2C1034177311153823745%2C1739763436844892160%2C1739787898839330816%2C1335993994107621380%2C735400714957127680%2C1777232868739313664%2C1307801885764706305%2C1769616063728381952%2C1611786056348889089%2C1650701737391538176%2C1777232868739313664%2C1458116670%2C1272991390214098944%2C1483445146087989252%2C1320648461528739840%2C558736498%2C1578476287924084737%2C1433831944496816131%2C1777652476725936128%2C1045029523031494658%2C1773929722457821184%2C1647075542913433600%2C1659297093742129164%2C1626725619693244417%2C1751621938307375105%2C3233147055%2C1594033883384684545%2C1627554932415991810%2C1613540580121796608%2C1778532000355520512%2C1596750503404183553%2C963218502130831360%2C1298200714460696576%2C403382903%2C1426850073820991494%2C24652017%2C1376102702250389505%2C1509254086025265156%2C1584767008574345216%2C1682373927983513600%2C1775891812009304064%2C1777228037375021056%2C1760805644473384960%2C1398664090399215620%2C1369403802638557195%2C1777228037375021056%2C1777642536745508864%2C4701981923%2C1673003814914342915%2C1558929982881251328%2C1691899786088349696%2C66651296%2C1437412585654169608%2C1329136317029081092%2C288118043%2C1761640741762215936%2C1461244693472292873%2C757830632231702528%2C36023344%2C1488896742804312066%2C1701859166468390912%2C1774917264002670594%2C1551027139855761409%2C1761385387241394176%2C1777227365665669121%2C1752356306113982464%2C1777387349661675520%2C1689394075789639681%2C878313178861457409%2C1777227365665669121%2C1595081152498466816%2C1594687257843097600%2C1780489003046744064%2C1682225554169184256%2C711984815797608448%2C1349190511899283456%2C1475563858228039684%2C1719701375603359744%2C1775310344753192960%2C1457695415625822219%2C1380493269461823488%2C729128458274639872%2C1654403017876312064%2C254132769%2C3046932847%2C1354789355034968064%2C2761120377%2C729128458274639872 HTTP/1.1" 200 3444


2024-04-21 11:28:30,033 - DEBUG - Received API response: 200 OK
Headers: {'date': 'Sun, 21 Apr 2024 18:28:30 UTC', 'perf': '7402827104', 'server': 'tsa_p', 'api-version': '2.96', 'content-type': 'application/json; charset=utf-8', 'cache-control': 'no-cache, no-store, max-age=0', 'content-length': '3444', 'x-access-level': 'read', 'x-frame-options': 'SAMEORIGIN', 'content-encoding': 'gzip', 'x-transaction-id': 'e614587644359aed', 'x-xss-protection': '0', 'x-rate-limit-limit': '300', 'x-rate-limit-reset': '1713725003', 'content-disposition': 'attachment; filename=json.json', 'x-content-type-options': 'nosniff', 'x-rate-limit-remaining': '298', 'strict-transport-security': 'max-age=631138519', 'x-response-time': '205', 'x-connection-hash': 'e78de214b281ea3eb36a08392bcd7db8c37698f437c6138d1f3f3e2108191a92'}
Content: b'{"data":[{"id":"1633818496738967552","name":"Rhoda Nnamani","username":"RhodaNnamani"},{"id":"1696879894318157825","name":"Daniel Nnamani (Dandyoz)","username":"DanielNna27784"},{"id":"1356872876247277573","name":"Trafalgar07","username":"AL72402862"},{"id":"1390165050103533576","name":"\xe0\xb8\xa1\xe0\xb8\xb9\xe0\xb8\xa1\xe0\xb8\xb4\xe0\xb8\x99\xe0\xb9\x80\xe0\xb8\x99\xe0\xb8\xb5\xe0\xb9\x88\xe0\xb8\xa2\xe0\xb8\x99","username":"wnndien"},{"id":"1780626201922433025","name":"\xd0\x9b\xd1\x8e\xd0\xb4\xd0\xbe\xd1\x87\xd0\xba\xd0\xb0 \xd0\x9a\xd1\x83\xd0\xb7\xd1\x8c\xd0\xbc\xd0\xb5\xd0\xbd\xd0\xba\xd0\xbe\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"KuzLudocka82185"},{"id":"1767658090348818432","name":"Den.plena.\\uD83D\\uDD79\xef\xb8\x8f $RCADE $MOJO","username":"DZalivsk"},{"id":"1779957563968118786","name":"xavierra \\uD83D\\uDCB0 BankBoost","username":"xavierra23xd"},{"id":"1774339975640662016","name":"Joshua Samuel \\uD83D\\uDD79\xef\xb8\x8f $RCADE $MOJO","username":"JoshuaSamu54295"},{"id":"225889683","name":"dansolovei","username":"danik_sol"},{"id":"1592910151446577153","name":"behrouzabb","username":"behrouzabb1"},{"id":"2596360582","name":"The Gunter Token","username":"Myownsumme_r"},{"id":"2924674454","name":"BRAVEHEART","username":"SUzunay56"},{"id":"1034177311153823745","name":"Sahar Ebrani","username":"saharebz"},{"id":"1739763436844892160","name":"Mir4777","username":"Mir4777"},{"id":"1739787898839330816","name":"The Unknown \\uD83D\\uDD79$ARCADE $PIXIZ $BUBBLE","username":"theunknown0097"},{"id":"1335993994107621380","name":"Laramie11","username":"Larabankole1"},{"id":"735400714957127680","name":"Evgeniy.NYAN\\uD83D\\uDD2B\\uD83D\\uDE3C","username":"SiteStroi"},{"id":"1777232868739313664","name":"MinervaMint","username":"MintMinerv27847"},{"id":"1307801885764706305","name":"enzo1990","username":"enzo19903"},{"id":"1769616063728381952","name":"42069","username":"42069onsol"},{"id":"1611786056348889089","name":"\xe0\xb8\x99\xe0\xb8\xa2\xe2\x98\x86","username":"ny_nnxy"},{"id":"1650701737391538176","name":"Lord mfer","username":"Lordmfer69"},{"id":"1777232868739313664","name":"MinervaMint","username":"MintMinerv27847"},{"id":"1458116670","name":"Kamlogjanty\xe2\x9d\xa4\xef\xb8\x8f Memecoin","username":"Kamlogjanty"},{"id":"1272991390214098944","name":"JUSTT RICHH.\xe2\x9a\xbd","username":"IAmRichEmmanuel"},{"id":"1483445146087989252","name":"Mamun Khan \\uD83D\\uDC09 $MON","username":"mamunk_975"},{"id":"1320648461528739840","name":"Mehdi","username":"mehdimahmodi990"},{"id":"558736498","name":"Connor","username":"condosh"},{"id":"1578476287924084737","name":"NexAcademy","username":"NexAcademyx"},{"id":"1433831944496816131","name":"smolco lombardi | \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"shinedairz"},{"id":"1777652476725936128","name":"qasim ali $BEYOND $BUBBLE","username":"qasimali1451535"},{"id":"1045029523031494658","name":"ALIYU ISYAKU ABDULLAHI","username":"AliyuIs00136912"},{"id":"1773929722457821184","name":"Rumble $XTER \\uD83D\\uDC09 $MON $MOJO $BUBBLE","username":"Rumble181547"},{"id":"1647075542913433600","name":"DCA_Crypto","username":"DCA_Crypto_Dean"},{"id":"1659297093742129164","name":"\\uD83D\\uDD79\xef\xb8\x8f $RCADE \\uD83D\\uDE80MATR1XCoin \xe2\x9d\xa4\xef\xb8\x8f $BLOCK .NYAN\\uD83D\\uDD2B Tabi","username":"comolokko72"},{"id":"1626725619693244417","name":"@Shaaban Magaji $Blockgame","username":"ShaabanMagaji"},{"id":"1751621938307375105","name":"Marla Singer \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"KripMarla"},{"id":"3233147055","name":"egoodnews.$RCADE.$BEYOND.$Affy.$BUBBLE\\uD83E\\uDEE7","username":"EdetEtop"},{"id":"1594033883384684545","name":"Ahmed Ovi Tabi \\uD83D\\uDFE7 $PARAM .NYAN\\uD83D\\uDD2B\\uD83D\\uDE3C \xe2\x9b\x93\xef\xb8\x8f SubQuery","username":"AhmedOvi2022"},{"id":"1627554932415991810","name":"Mouhamed yasin","username":"jack1112588"},{"id":"1613540580121796608","name":"\xd0\x86\xd0\xb2\xd0\xb0\xd0\xbd \xd0\x9f\xd0\xb0\xd1\x80\xd0\xb0\xd1\x89\xd0\xb0\xd0\xba\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"IvanParasak"},{"id":"1778532000355520512","name":"Hadi Tayebi$BUBBLE","username":"haditayebi0494"},{"id":"1596750503404183553","name":"Yuntod","username":"Yuntod1"},{"id":"963218502130831360","name":"Crypto Papas \\uD83D\\uDC09 $MON","username":"rothmans110"},{"id":"1298200714460696576","name":"Ibrahim Mannir","username":"Bin__Muneer"},{"id":"403382903","name":"\xc3\xb6zkan kaplan","username":"zkan_kaplan"},{"id":"1426850073820991494","name":"Anton \\uD83D\\uDD79\xef\xb8\x8f $RCADE l Velvet Dao Xally-AI","username":"Anton13925599"},{"id":"24652017","name":"Scott Layne","username":"DrNoDox"},{"id":"1376102702250389505","name":"Sabri Ajbilou","username":"AjbilouSabri"},{"id":"1509254086025265156","name":"Andrey Shestopal \\uD83D\\uDD79\xef\xb8\x8f $RCADE $BEYOND","username":"ShestopalAndrey"},{"id":"1584767008574345216","name":"Mike Wolf","username":"SpiderM07506934"},{"id":"1682373927983513600","name":"tupachill.eth Tabi \\uD83D\\uDFE7 $XTER","username":"CryptoMani91065"},{"id":"1775891812009304064","name":"Oxlade","username":"Oxlade14971801"},{"id":"1777228037375021056","name":"CipherDollar","username":"CDollar85278"},{"id":"1760805644473384960","name":"Jessica Davis","username":"Jessica06528885"},{"id":"1398664090399215620","name":"TakeMi","username":"TakeMi85402052"},{"id":"1369403802638557195","name":"pancarte\\uD83D\\uDEF9\\uD83D\\uDEF9","username":"pancartesol"},{"id":"1777228037375021056","name":"CipherDollar","username":"CDollar85278"},{"id":"1777642536745508864","name":"Ndarake Godwin$Rcade","username":"godwinNdarakeg"},{"id":"4701981923","name":"sadtr3x\\uD83D\\uDC09 $MON","username":"sadtr3x"},{"id":"1673003814914342915","name":"Flint Spark","username":"flintverse"},{"id":"1558929982881251328","name":"Karakaiser","username":"Karakaiser01"},{"id":"1691899786088349696","name":"Nurr Sbawa SRcade","username":"NurrSbawa22041"},{"id":"66651296","name":"Marek Suscak","username":"mareksuscak"},{"id":"1437412585654169608","name":"\xd0\xae\xd1\x80\xd0\xb8\xd0\xb9 \xd0\x97\xd0\xb0\xd0\xbf\xd0\xb5\xd0\xb2\xd0\xb0\xd0\xbb\xd0\xbe\xd0\xb2 $ELS","username":"pistonik30"},{"id":"1329136317029081092","name":"~Mykel~ \\uD83C\\uDDFB\\uD83C\\uDDF3","username":"Mykelicious1"},{"id":"288118043","name":"Velaa Freeler\xe2\x9d\xa4\xef\xb8\x8f Memecoin","username":"VelaaFreelerDKA"},{"id":"1761640741762215936","name":"Kabeer Zailanee\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"KZailanee"},{"id":"1461244693472292873","name":"All Service","username":"AllServ03796160"},{"id":"757830632231702528","name":"\xe5\xae\xb3\xe7\xbe\x9e\xe5\xa5\xb3\xe5\xad\xa9 \xe2\xad\x90 \\uD83C\\uDDE8\\uD83C\\uDDF3","username":"dat_shygirl"},{"id":"36023344","name":"Kiluti","username":"MutuaKiluti"},{"id":"1488896742804312066","name":"Felo","username":"FelixLoveday9"},{"id":"1701859166468390912","name":"The African Hunter\xc2\xae $PIXIZ $BEYOND $XTER","username":"TheAfrohunter"},{"id":"1774917264002670594","name":"jaweji","username":"jaweji141011"},{"id":"1551027139855761409","name":"John","username":"John4363463463"},{"id":"1761385387241394176","name":"Mubarak \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"TurakiIbr38828"},{"id":"1777227365665669121","name":"CoinCircuitry","username":"CCircuitry19142"},{"id":"1752356306113982464","name":"Aliyu Muhammad","username":"AMuhammad31368"},{"id":"1777387349661675520","name":"SR Crypto trader","username":"Sr20962Sr"},{"id":"1689394075789639681","name":"Lena Tabi \\uD83D\\uDFE7 \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"Lena84963488"},{"id":"878313178861457409","name":"Gentle_criminal","username":"Deathlord_sas"},{"id":"1777227365665669121","name":"CoinCircuitry","username":"CCircuitry19142"},{"id":"1595081152498466816","name":"Jack Queiroz","username":"ManuQuiroz13"},{"id":"1594687257843097600","name":"Balatrader\\uD83D\\uDC10\\uD83D\\uDEF8\\uD83D\\uDC3B\xe2\x9b\x93\xef\xb8\x8f.NYAN\\uD83D\\uDD2B\\uD83D\\uDE3C\\uD83D\\uDC09 $MON\\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"Balatrader1"},{"id":"1780489003046744064","name":"\xd0\x9e\xd0\xbb\xd0\xb5\xd0\xba\xd1\x81\xd0\xb0\xd0\xbd\xd0\xb4\xd1\x80 \xd0\x91\xd0\xbe\xd0\xb9\xd0\xba\xd0\xbe \\uD83D\\uDD79\xef\xb8\x8f $RCADE","username":"Akerman83611"},{"id":"1682225554169184256","name":"Ambo\xe2\x9d\xa4\xef\xb8\x8fLino\\uD83D\\uDC09 $MON|\\uD83D\\uDC8E $FYN|\\uD83D\\uDD79\xef\xb8\x8f $RCADE $MOJO $XTER","username":"AmboAnioki28704"},{"id":"711984815797608448","name":"\xd0\xaf\xd1\x80\xd0\xb8\xd0\xba (\\uD83C\\uDFAE,\\uD83D\\uDFE2)","username":"1910Yarik"},{"id":"1349190511899283456","name":"Heaven_Cat$UNIO$XTER","username":"Heavencat_NFT"},{"id":"1475563858228039684","name":"Ape_daddy","username":"Ape_daddyy"},{"id":"1719701375603359744","name":"Praba","username":"Praba1068207"},{"id":"1775310344753192960","name":"0xdunoxx $BEYOND","username":"0xdunoxx"},{"id":"1457695415625822219","name":"Sammy","username":"Sammyking_01"},{"id":"1380493269461823488","name":"Nnamdi Nwaideh","username":"NNwaideh"},{"id":"729128458274639872","name":"rojas chand","username":"rojasnamaste"},{"id":"1654403017876312064","name":"Asif Rahaman","username":"asifrahaman067"},{"id":"254132769","name":"\\uD83C\\uDF3B Franck","username":"Franck_chester"},{"id":"3046932847","name":"Sarah \xe3\x82\xb5\xe3\x83\xa9 \\uD83C\\uDDE9\\uD83C\\uDDFF\\uD83C\\uDDF5\\uD83C\\uDDF8","username":"sarah__0001"},{"id":"1354789355034968064","name":"Jay\\uD83D\\uDD79\xef\xb8\x8f $RCADE$BUBBLE\\uD83E\\uDEE7\\uD83E\\uDEE7\\uD83E\\uDEE7","username":"Uyane_Joy"},{"id":"2761120377","name":"Abu Oustaan","username":"MLSSanda"},{"id":"729128458274639872","name":"rojas chand","username":"rojasnamaste"}]}'


2024-04-21 11:28:30,041 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,046 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,046 - DEBUG - max_retries: 8


2024-04-21 11:28:30,046 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e7bdf0>


2024-04-21 11:28:30,057 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,058 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,060 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,061 - DEBUG - max_retries: 8


2024-04-21 11:28:30,061 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed46d0>


2024-04-21 11:28:30,066 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,067 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,068 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,068 - DEBUG - max_retries: 8


2024-04-21 11:28:30,068 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed6d10>


2024-04-21 11:28:30,073 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,074 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,075 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,075 - DEBUG - max_retries: 8


2024-04-21 11:28:30,075 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103edc910>


2024-04-21 11:28:30,080 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,080 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,081 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,082 - DEBUG - max_retries: 8


2024-04-21 11:28:30,082 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103edead0>


2024-04-21 11:28:30,085 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,086 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,087 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,087 - DEBUG - max_retries: 8


2024-04-21 11:28:30,087 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103eece50>


2024-04-21 11:28:30,090 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,091 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,092 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,092 - DEBUG - max_retries: 8


2024-04-21 11:28:30,092 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ede980>


2024-04-21 11:28:30,095 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,096 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,097 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,097 - DEBUG - max_retries: 8


2024-04-21 11:28:30,097 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f01240>


2024-04-21 11:28:30,100 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,100 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \n\nThe next st…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,101 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \n\nThe next st…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,101 - DEBUG - max_retries: 8


2024-04-21 11:28:30,101 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f03340>


2024-04-21 11:28:30,104 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \n\nThe next st…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,104 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,105 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,105 - DEBUG - max_retries: 8


2024-04-21 11:28:30,105 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f21540>


2024-04-21 11:28:30,108 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,108 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @ShardsOfficial 🔗 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let's shape the future together! 🌐🚀 #blockchain\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,109 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @ShardsOfficial 🔗 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let's shape the future together! 🌐🚀 #blockchain\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,109 - DEBUG - max_retries: 8


2024-04-21 11:28:30,109 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f03310>


2024-04-21 11:28:30,112 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @ShardsOfficial 🔗 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let's shape the future together! 🌐🚀 #blockchain\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,112 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @NexAcademyx: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 1…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,113 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @NexAcademyx: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 1…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,113 - DEBUG - max_retries: 8


2024-04-21 11:28:30,113 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f23be0>


2024-04-21 11:28:30,115 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @NexAcademyx: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 1…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,116 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,116 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,116 - DEBUG - max_retries: 8


2024-04-21 11:28:30,116 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080105e0>


2024-04-21 11:28:30,119 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,119 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,120 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,120 - DEBUG - max_retries: 8


2024-04-21 11:28:30,120 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108011d20>


2024-04-21 11:28:30,122 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,123 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,123 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,123 - DEBUG - max_retries: 8


2024-04-21 11:28:30,123 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108012170>


2024-04-21 11:28:30,126 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,126 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,126 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,127 - DEBUG - max_retries: 8


2024-04-21 11:28:30,127 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080133a0>


2024-04-21 11:28:30,129 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,129 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,129 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,130 - DEBUG - max_retries: 8


2024-04-21 11:28:30,130 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108038220>


2024-04-21 11:28:30,132 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,132 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,133 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,133 - DEBUG - max_retries: 8


2024-04-21 11:28:30,133 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108038070>


2024-04-21 11:28:30,135 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,135 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\nThe differentia…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,136 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\nThe differentia…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,136 - DEBUG - max_retries: 8


2024-04-21 11:28:30,136 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108013e80>


2024-04-21 11:28:30,138 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\nThe differentia…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,138 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: traits/metadata updated soon!!!\n\nlook out for 42069 main characters, overlays\n\nand the super rare golden guns\n\nnice https://t.co/WFON5jZ9CB\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,139 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: traits/metadata updated soon!!!\n\nlook out for 42069 main characters, overlays\n\nand the super rare golden guns\n\nnice https://t.co/WFON5jZ9CB\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,139 - DEBUG - max_retries: 8


2024-04-21 11:28:30,139 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10803aa70>


2024-04-21 11:28:30,140 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: traits/metadata updated soon!!!\n\nlook out for 42069 main characters, overlays\n\nand the super rare golden guns\n\nnice https://t.co/WFON5jZ9CB\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,141 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,142 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,142 - DEBUG - max_retries: 8


2024-04-21 11:28:30,142 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10803a500>


2024-04-21 11:28:30,144 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,144 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,145 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,145 - DEBUG - max_retries: 8


2024-04-21 11:28:30,145 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108064b50>


2024-04-21 11:28:30,147 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,147 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,147 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,148 - DEBUG - max_retries: 8


2024-04-21 11:28:30,148 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108065300>


2024-04-21 11:28:30,149 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,150 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,150 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,150 - DEBUG - max_retries: 8


2024-04-21 11:28:30,150 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108066260>


2024-04-21 11:28:30,152 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,153 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @LDN_Blockchain Not gonna lie, I'm pretty impressed by the technical details of Jiritsu's Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,153 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @LDN_Blockchain Not gonna lie, I'm pretty impressed by the technical details of Jiritsu's Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,153 - DEBUG - max_retries: 8


2024-04-21 11:28:30,153 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080671c0>


2024-04-21 11:28:30,155 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @LDN_Blockchain Not gonna lie, I'm pretty impressed by the technical details of Jiritsu's Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,156 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,156 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,156 - DEBUG - max_retries: 8


2024-04-21 11:28:30,156 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108066410>


2024-04-21 11:28:30,158 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,159 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,159 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,159 - DEBUG - max_retries: 8


2024-04-21 11:28:30,159 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108067af0>


2024-04-21 11:28:30,161 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,161 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,162 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,162 - DEBUG - max_retries: 8


2024-04-21 11:28:30,162 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108085ab0>


2024-04-21 11:28:30,164 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,164 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 100K Tps and infinitely scalability\n@NexaMoney \n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,165 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 100K Tps and infinitely scalability\n@NexaMoney \n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,165 - DEBUG - max_retries: 8


2024-04-21 11:28:30,165 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108085540>


2024-04-21 11:28:30,167 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 100K Tps and infinitely scalability\n@NexaMoney \n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,167 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @wardenprotocol: Warden Whitepaper is released\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,168 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @wardenprotocol: Warden Whitepaper is released\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,168 - DEBUG - max_retries: 8


2024-04-21 11:28:30,168 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108087b50>


2024-04-21 11:28:30,170 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @wardenprotocol: Warden Whitepaper is released\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,170 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,171 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,171 - DEBUG - max_retries: 8


2024-04-21 11:28:30,171 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080c4340>


2024-04-21 11:28:30,173 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,173 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,173 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,174 - DEBUG - max_retries: 8


2024-04-21 11:28:30,174 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108086890>


2024-04-21 11:28:30,175 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,176 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @Pawan2001564157 @SenderLabs 282.   "Ethereum\'s scalability solutions: addressing network congestion.   🌐🚧"\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,176 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @Pawan2001564157 @SenderLabs 282.   "Ethereum\'s scalability solutions: addressing network congestion.   🌐🚧"\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,176 - DEBUG - max_retries: 8


2024-04-21 11:28:30,176 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080c6200>


2024-04-21 11:28:30,178 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @Pawan2001564157 @SenderLabs 282.   "Ethereum\'s scalability solutions: addressing network congestion.   🌐🚧"\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,179 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,179 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,179 - DEBUG - max_retries: 8


2024-04-21 11:28:30,179 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080c5d50>


2024-04-21 11:28:30,181 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,182 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,182 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,182 - DEBUG - max_retries: 8


2024-04-21 11:28:30,182 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080c7c40>


2024-04-21 11:28:30,184 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,185 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,185 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,185 - DEBUG - max_retries: 8


2024-04-21 11:28:30,185 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080dc430>


2024-04-21 11:28:30,187 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,187 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,188 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,188 - DEBUG - max_retries: 8


2024-04-21 11:28:30,188 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080dd240>


2024-04-21 11:28:30,190 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,190 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,191 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,191 - DEBUG - max_retries: 8


2024-04-21 11:28:30,191 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080de2f0>


2024-04-21 11:28:30,193 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,193 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,194 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,194 - DEBUG - max_retries: 8


2024-04-21 11:28:30,194 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1080dc1c0>


2024-04-21 11:28:30,196 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,196 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,197 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,197 - DEBUG - max_retries: 8


2024-04-21 11:28:30,197 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108208220>


2024-04-21 11:28:30,199 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,199 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,199 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,200 - DEBUG - max_retries: 8


2024-04-21 11:28:30,200 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082089d0>


2024-04-21 11:28:30,201 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,202 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,202 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,202 - DEBUG - max_retries: 8


2024-04-21 11:28:30,202 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108209db0>


2024-04-21 11:28:30,204 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,205 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,205 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,205 - DEBUG - max_retries: 8


2024-04-21 11:28:30,205 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10820a890>


2024-04-21 11:28:30,207 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,207 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,208 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,208 - DEBUG - max_retries: 8


2024-04-21 11:28:30,208 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10820a530>


2024-04-21 11:28:30,210 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,210 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,211 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,211 - DEBUG - max_retries: 8


2024-04-21 11:28:30,211 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082387c0>


2024-04-21 11:28:30,213 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,213 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,214 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,214 - DEBUG - max_retries: 8


2024-04-21 11:28:30,214 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108238f70>


2024-04-21 11:28:30,216 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,216 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,217 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,217 - DEBUG - max_retries: 8


2024-04-21 11:28:30,217 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10823a320>


2024-04-21 11:28:30,219 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,219 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\n\nLarge language models are real AI that is smarter than 99…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,219 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\n\nLarge language models are real AI that is smarter than 99…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,220 - DEBUG - max_retries: 8


2024-04-21 11:28:30,220 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10823ae30>


2024-04-21 11:28:30,221 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\n\nLarge language models are real AI that is smarter than 99…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,222 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,222 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,222 - DEBUG - max_retries: 8


2024-04-21 11:28:30,222 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10823aad0>


2024-04-21 11:28:30,224 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,225 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,225 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,225 - DEBUG - max_retries: 8


2024-04-21 11:28:30,225 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108268d60>


2024-04-21 11:28:30,227 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,228 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @usesendtokens: ⚡️Bitcoin's future is bright!⚡️ Sendtokens integrates with @Photon_L2  by @SatoshiSync!\n\nThis unlocks:\n\nScalability for…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,228 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @usesendtokens: ⚡️Bitcoin's future is bright!⚡️ Sendtokens integrates with @Photon_L2  by @SatoshiSync!\n\nThis unlocks:\n\nScalability for…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,228 - DEBUG - max_retries: 8


2024-04-21 11:28:30,228 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108269510>


2024-04-21 11:28:30,230 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @usesendtokens: ⚡️Bitcoin's future is bright!⚡️ Sendtokens integrates with @Photon_L2  by @SatoshiSync!\n\nThis unlocks:\n\nScalability for…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,230 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,231 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,231 - DEBUG - max_retries: 8


2024-04-21 11:28:30,231 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826a8c0>


2024-04-21 11:28:30,233 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,233 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,234 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,234 - DEBUG - max_retries: 8


2024-04-21 11:28:30,234 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826b3d0>


2024-04-21 11:28:30,236 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,236 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,237 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,237 - DEBUG - max_retries: 8


2024-04-21 11:28:30,237 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826a3e0>


2024-04-21 11:28:30,239 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,239 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @KrystalVil96992 ⚰ ️ ️ 🍉 🌗 9167188853 🦜 ️ 🎍 Who tree structure receive guy guess run.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,240 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @KrystalVil96992 ⚰ ️ ️ 🍉 🌗 9167188853 🦜 ️ 🎍 Who tree structure receive guy guess run.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,240 - DEBUG - max_retries: 8


2024-04-21 11:28:30,240 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829cf70>


2024-04-21 11:28:30,242 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @KrystalVil96992 ⚰ ️ ️ 🍉 🌗 9167188853 🦜 ️ 🎍 Who tree structure receive guy guess run.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,242 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,243 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,243 - DEBUG - max_retries: 8


2024-04-21 11:28:30,243 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829d720>


2024-04-21 11:28:30,245 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,245 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: 6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. 🔐💡\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,245 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: 6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. 🔐💡\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,245 - DEBUG - max_retries: 8


2024-04-21 11:28:30,246 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829ead0>


2024-04-21 11:28:30,247 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: 6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. 🔐💡\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,248 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,248 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,248 - DEBUG - max_retries: 8


2024-04-21 11:28:30,248 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829f5e0>


2024-04-21 11:28:30,250 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,251 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,251 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,251 - DEBUG - max_retries: 8


2024-04-21 11:28:30,251 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829ebc0>


2024-04-21 11:28:30,253 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,253 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,254 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,254 - DEBUG - max_retries: 8


2024-04-21 11:28:30,254 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082bd510>


2024-04-21 11:28:30,256 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,256 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,257 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,257 - DEBUG - max_retries: 8


2024-04-21 11:28:30,257 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082bdcc0>


2024-04-21 11:28:30,259 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,259 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,260 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,260 - DEBUG - max_retries: 8


2024-04-21 11:28:30,260 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082bf070>


2024-04-21 11:28:30,262 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,262 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,263 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,263 - DEBUG - max_retries: 8


2024-04-21 11:28:30,263 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082bfb80>


2024-04-21 11:28:30,265 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,265 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @burkov: I see too many people don’t understand why Meta spends billions to train and then gives away its large language models. They th…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,265 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @burkov: I see too many people don’t understand why Meta spends billions to train and then gives away its large language models. They th…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,266 - DEBUG - max_retries: 8


2024-04-21 11:28:30,266 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082beb90>


2024-04-21 11:28:30,267 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @burkov: I see too many people don’t understand why Meta spends billions to train and then gives away its large language models. They th…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,268 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,268 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,268 - DEBUG - max_retries: 8


2024-04-21 11:28:30,268 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082edab0>


2024-04-21 11:28:30,270 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,271 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,271 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,271 - DEBUG - max_retries: 8


2024-04-21 11:28:30,271 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082ee260>


2024-04-21 11:28:30,273 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,273 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,274 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,274 - DEBUG - max_retries: 8


2024-04-21 11:28:30,274 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082ef610>


2024-04-21 11:28:30,276 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,276 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,277 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,277 - DEBUG - max_retries: 8


2024-04-21 11:28:30,277 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108318160>


2024-04-21 11:28:30,279 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,279 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,280 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,280 - DEBUG - max_retries: 8


2024-04-21 11:28:30,280 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108318b20>


2024-04-21 11:28:30,282 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,282 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,283 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,283 - DEBUG - max_retries: 8


2024-04-21 11:28:30,283 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10831a050>


2024-04-21 11:28:30,285 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,285 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\n\nHe began with a reality check: "Machine Learning falls s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,285 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\n\nHe began with a reality check: "Machine Learning falls s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,285 - DEBUG - max_retries: 8


2024-04-21 11:28:30,286 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10831a800>


2024-04-21 11:28:30,287 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\n\nHe began with a reality check: "Machine Learning falls s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,288 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,288 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,288 - DEBUG - max_retries: 8


2024-04-21 11:28:30,288 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10831bbb0>


2024-04-21 11:28:30,290 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,291 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,291 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,291 - DEBUG - max_retries: 8


2024-04-21 11:28:30,291 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108348700>


2024-04-21 11:28:30,293 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,293 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @DaanCrypto "Incredible potentials here! With features focused on scalability and security, this project is set for big things." @TRUMP2024_TOKEN\n#Trump2024Token https://t.co/LQFNowRXUy\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,294 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @DaanCrypto "Incredible potentials here! With features focused on scalability and security, this project is set for big things." @TRUMP2024_TOKEN\n#Trump2024Token https://t.co/LQFNowRXUy\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,294 - DEBUG - max_retries: 8


2024-04-21 11:28:30,294 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083490c0>


2024-04-21 11:28:30,296 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @DaanCrypto "Incredible potentials here! With features focused on scalability and security, this project is set for big things." @TRUMP2024_TOKEN\n#Trump2024Token https://t.co/LQFNowRXUy\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,297 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @Lauramaywendel future ai systems. Open AI have two really big cards under it's sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,297 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @Lauramaywendel future ai systems. Open AI have two really big cards under it's sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,297 - DEBUG - max_retries: 8


2024-04-21 11:28:30,297 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10834a230>


2024-04-21 11:28:30,299 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @Lauramaywendel future ai systems. Open AI have two really big cards under it's sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,299 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,300 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,300 - DEBUG - max_retries: 8


2024-04-21 11:28:30,300 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10834a9e0>


2024-04-21 11:28:30,302 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,302 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,303 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,303 - DEBUG - max_retries: 8


2024-04-21 11:28:30,303 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10834bd90>


2024-04-21 11:28:30,305 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,305 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,306 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,306 - DEBUG - max_retries: 8


2024-04-21 11:28:30,306 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083648e0>


2024-04-21 11:28:30,308 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,308 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,309 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,309 - DEBUG - max_retries: 8


2024-04-21 11:28:30,309 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083644f0>


2024-04-21 11:28:30,311 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,311 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,311 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,311 - DEBUG - max_retries: 8


2024-04-21 11:28:30,311 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108366860>


2024-04-21 11:28:30,313 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,314 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,314 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,314 - DEBUG - max_retries: 8


2024-04-21 11:28:30,314 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108367010>


2024-04-21 11:28:30,316 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,317 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,317 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,317 - DEBUG - max_retries: 8


2024-04-21 11:28:30,317 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108365690>


2024-04-21 11:28:30,319 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,319 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @jacksonhinklle: 🚨🇮🇱🇺🇸 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,320 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @jacksonhinklle: 🚨🇮🇱🇺🇸 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,320 - DEBUG - max_retries: 8


2024-04-21 11:28:30,320 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108388f10>


2024-04-21 11:28:30,322 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @jacksonhinklle: 🚨🇮🇱🇺🇸 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,322 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,323 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,323 - DEBUG - max_retries: 8


2024-04-21 11:28:30,323 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108388940>


2024-04-21 11:28:30,325 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,325 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,326 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,326 - DEBUG - max_retries: 8


2024-04-21 11:28:30,326 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10838ae00>


2024-04-21 11:28:30,328 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,328 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,329 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,329 - DEBUG - max_retries: 8


2024-04-21 11:28:30,329 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10838b5b0>


2024-04-21 11:28:30,331 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,331 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,331 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,332 - DEBUG - max_retries: 8


2024-04-21 11:28:30,332 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083888b0>


2024-04-21 11:28:30,333 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,334 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,334 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,334 - DEBUG - max_retries: 8


2024-04-21 11:28:30,334 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c14b0>


2024-04-21 11:28:30,336 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,337 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \n\n- Scalability \n- interoperability \n- Secure\n- Ma…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,337 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \n\n- Scalability \n- interoperability \n- Secure\n- Ma…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,337 - DEBUG - max_retries: 8


2024-04-21 11:28:30,337 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c0ee0>


2024-04-21 11:28:30,339 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \n\n- Scalability \n- interoperability \n- Secure\n- Ma…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,340 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,340 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,340 - DEBUG - max_retries: 8


2024-04-21 11:28:30,340 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c33a0>


2024-04-21 11:28:30,342 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,342 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,343 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,343 - DEBUG - max_retries: 8


2024-04-21 11:28:30,343 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c3b50>


2024-04-21 11:28:30,345 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,345 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,346 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,346 - DEBUG - max_retries: 8


2024-04-21 11:28:30,346 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c0e50>


2024-04-21 11:28:30,348 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,348 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,349 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,349 - DEBUG - max_retries: 8


2024-04-21 11:28:30,349 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083f9a50>


2024-04-21 11:28:30,351 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,351 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,352 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,352 - DEBUG - max_retries: 8


2024-04-21 11:28:30,352 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083fa830>


2024-04-21 11:28:30,354 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,354 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,355 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,355 - DEBUG - max_retries: 8


2024-04-21 11:28:30,355 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083fb580>


2024-04-21 11:28:30,357 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,357 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @boyney123 I've not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I'd prefer the central project to simply point at each service repo an pull the metadata from there.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}


2024-04-21 11:28:30,357 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @boyney123 I've not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I'd prefer the central project to simply point at each service repo an pull the metadata from there.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,357 - DEBUG - max_retries: 8


2024-04-21 11:28:30,357 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083fbd30>


2024-04-21 11:28:30,359 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @boyney123 I've not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I'd prefer the central project to simply point at each service repo an pull the metadata from there.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,360 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\nfor Exemple ChatGPT\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,360 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\nfor Exemple ChatGPT\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,360 - DEBUG - max_retries: 8


2024-04-21 11:28:30,360 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083fb310>


2024-04-21 11:28:30,362 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\nfor Exemple ChatGPT\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,363 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,363 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,363 - DEBUG - max_retries: 8


2024-04-21 11:28:30,363 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10840dc30>


2024-04-21 11:28:30,365 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,365 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,366 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,366 - DEBUG - max_retries: 8


2024-04-21 11:28:30,366 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10840d600>


2024-04-21 11:28:30,368 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,368 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:30,369 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:30,369 - DEBUG - max_retries: 8


2024-04-21 11:28:30,369 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10840fb20>


2024-04-21 11:28:30,371 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:30,371 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,372 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,372 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,372 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,372 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,372 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,372 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,372 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,372 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,372 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,373 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,374 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,375 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,375 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,375 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,375 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,375 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,375 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,376 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,376 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,376 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,376 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,376 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,376 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,377 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,378 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,379 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,380 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,381 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,381 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,381 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,381 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,381 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,382 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,382 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,382 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,382 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,382 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,382 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,383 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,383 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,383 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,383 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,383 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,383 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,384 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,384 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,384 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,384 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,384 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,384 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,385 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,385 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,385 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,385 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,385 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,386 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,386 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,386 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,387 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,387 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,387 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,387 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,387 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,387 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:30,391 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f00760>


2024-04-21 11:28:30,391 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,391 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080844f0>


2024-04-21 11:28:30,391 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,391 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec7f0>


2024-04-21 11:28:30,391 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,391 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108438bb0>


2024-04-21 11:28:30,391 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,391 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fb3d0>


2024-04-21 11:28:30,391 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,392 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eee9b0>


2024-04-21 11:28:30,392 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,392 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108438e80>


2024-04-21 11:28:30,392 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,392 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108439150>


2024-04-21 11:28:30,392 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,392 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084388e0>


2024-04-21 11:28:30,392 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,393 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820af80>


2024-04-21 11:28:30,393 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,393 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084396f0>


2024-04-21 11:28:30,393 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,395 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082ed690>


2024-04-21 11:28:30,395 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,395 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843a260>


2024-04-21 11:28:30,395 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,395 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108439cc0>


2024-04-21 11:28:30,395 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,395 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108319390>


2024-04-21 11:28:30,395 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,396 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843a530>


2024-04-21 11:28:30,396 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,396 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843a800>


2024-04-21 11:28:30,396 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,397 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843b4f0>


2024-04-21 11:28:30,397 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,400 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843afb0>


2024-04-21 11:28:30,400 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,400 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108367700>


2024-04-21 11:28:30,400 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,400 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843b820>


2024-04-21 11:28:30,400 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,400 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080672b0>


2024-04-21 11:28:30,400 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,400 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108460340>


2024-04-21 11:28:30,400 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,400 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108460820>


2024-04-21 11:28:30,400 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,401 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108460070>


2024-04-21 11:28:30,401 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,401 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840d270>


2024-04-21 11:28:30,401 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,402 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108461b70>


2024-04-21 11:28:30,402 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,402 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108461030>


2024-04-21 11:28:30,402 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,402 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108461360>


2024-04-21 11:28:30,402 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,403 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108461840>


2024-04-21 11:28:30,403 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,403 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084623e0>


2024-04-21 11:28:30,403 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,403 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108462110>


2024-04-21 11:28:30,403 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,403 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108461e40>


2024-04-21 11:28:30,403 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,404 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084628c0>


2024-04-21 11:28:30,404 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,406 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108488130>


2024-04-21 11:28:30,406 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,406 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108462e00>


2024-04-21 11:28:30,406 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,408 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084396c0>


2024-04-21 11:28:30,408 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,408 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108463130>


2024-04-21 11:28:30,408 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,409 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820b160>


2024-04-21 11:28:30,409 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,414 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eee6b0>


2024-04-21 11:28:30,414 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,414 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,415 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,415 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,415 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,416 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eecee0>


2024-04-21 11:28:30,418 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ef340>


2024-04-21 11:28:30,418 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,418 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,418 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f02620>


2024-04-21 11:28:30,418 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edc250>


2024-04-21 11:28:30,418 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f227a0>


2024-04-21 11:28:30,418 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fb430>


2024-04-21 11:28:30,419 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f22e60>


2024-04-21 11:28:30,422 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,422 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,422 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,422 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,422 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,422 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,422 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,422 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edde10>


2024-04-21 11:28:30,422 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108011f00>


2024-04-21 11:28:30,422 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108010370>


2024-04-21 11:28:30,422 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f02860>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f23460>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f23cd0>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080129e0>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10803be50>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108039450>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108013be0>


2024-04-21 11:28:30,423 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108013ca0>


2024-04-21 11:28:30,425 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,425 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,425 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,425 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,425 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,425 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,425 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,425 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,425 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,425 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,425 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,425 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,425 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,426 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,427 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108065a50>


2024-04-21 11:28:30,427 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10803b1c0>


2024-04-21 11:28:30,427 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108084c40>


2024-04-21 11:28:30,427 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10803b340>


2024-04-21 11:28:30,427 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10803aa40>


2024-04-21 11:28:30,427 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108067160>


2024-04-21 11:28:30,430 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,430 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108545ea0>


2024-04-21 11:28:30,430 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ef910>


2024-04-21 11:28:30,430 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084399c0>


2024-04-21 11:28:30,430 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,430 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,430 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a9300>


2024-04-21 11:28:30,430 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,430 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,430 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108439c90>


2024-04-21 11:28:30,430 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,430 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ef760>


2024-04-21 11:28:30,431 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,431 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,431 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,431 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a9420>


2024-04-21 11:28:30,431 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,431 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,431 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,432 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108067970>


2024-04-21 11:28:30,432 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108085210>


2024-04-21 11:28:30,432 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080c7610>


2024-04-21 11:28:30,432 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108086ad0>


2024-04-21 11:28:30,433 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080c4a90>


2024-04-21 11:28:30,433 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108087640>


2024-04-21 11:28:30,433 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080c50f0>


2024-04-21 11:28:30,433 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108086200>


2024-04-21 11:28:30,433 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108086e90>


2024-04-21 11:28:30,433 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080c6f80>


2024-04-21 11:28:30,434 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108546740>


2024-04-21 11:28:30,434 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,434 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084c9cc0>


2024-04-21 11:28:30,434 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,434 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,434 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514a60>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514bb0>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085147c0>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,435 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,435 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,435 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514f40>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515570>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085157b0>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514430>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,435 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,435 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,435 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,435 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,435 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a8220>


2024-04-21 11:28:30,435 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108547370>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082ecfd0>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515090>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,436 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,436 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,436 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085477f0>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a87c0>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,436 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a8040>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,436 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,436 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,436 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a84f0>


2024-04-21 11:28:30,436 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,437 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,437 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a9ab0>


2024-04-21 11:28:30,437 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,437 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,437 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084aaad0>


2024-04-21 11:28:30,437 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a8d60>


2024-04-21 11:28:30,437 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a9030>


2024-04-21 11:28:30,437 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a9f90>


2024-04-21 11:28:30,437 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084aa2c0>


2024-04-21 11:28:30,437 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,437 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,437 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,437 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,437 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,437 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,437 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,437 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,437 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,437 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,437 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,438 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,438 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080dfe50>


2024-04-21 11:28:30,439 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108209120>


2024-04-21 11:28:30,439 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080dcb80>


2024-04-21 11:28:30,439 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080de9e0>


2024-04-21 11:28:30,439 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080dd480>


2024-04-21 11:28:30,439 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ab070>


2024-04-21 11:28:30,439 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,439 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843aaa0>


2024-04-21 11:28:30,439 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,439 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ab820>


2024-04-21 11:28:30,439 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,439 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a9750>


2024-04-21 11:28:30,439 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,439 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ab340>


2024-04-21 11:28:30,439 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,439 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084a8a90>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084aa7a0>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083678e0>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085526b0>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108552380>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108552410>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,440 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108552d70>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108551c30>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108551b40>


2024-04-21 11:28:30,440 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,440 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,440 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,440 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085516c0>


2024-04-21 11:28:30,441 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,441 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843bfa0>


2024-04-21 11:28:30,441 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,441 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108547700>


2024-04-21 11:28:30,441 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,441 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084c83a0>


2024-04-21 11:28:30,441 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,441 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840c730>


2024-04-21 11:28:30,441 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,441 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,441 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,441 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,441 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,441 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,441 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,441 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,441 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,441 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,441 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,441 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,442 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,442 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,442 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,442 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,442 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,442 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,442 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084c93c0>


2024-04-21 11:28:30,442 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084cacb0>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084cad10>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,443 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084385e0>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ca080>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084cb460>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084cb640>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840e500>


2024-04-21 11:28:30,443 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,443 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,443 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,443 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,443 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,443 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,443 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,444 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,444 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,444 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084c92d0>


2024-04-21 11:28:30,444 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,444 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10843b2b0>


2024-04-21 11:28:30,444 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:30,444 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,444 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,444 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,444 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,444 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,444 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,444 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,444 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,444 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,445 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,445 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,445 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,445 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,445 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820aa70>


2024-04-21 11:28:30,445 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,445 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,445 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,445 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,451 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082383a0>


2024-04-21 11:28:30,451 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,451 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,451 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,451 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,451 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,453 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1080df520>


2024-04-21 11:28:30,453 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,453 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820bca0>


2024-04-21 11:28:30,453 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,453 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,453 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,453 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,453 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,453 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,453 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,453 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,453 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,455 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820bb20>


2024-04-21 11:28:30,455 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,455 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820a2f0>


2024-04-21 11:28:30,455 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108268160>


2024-04-21 11:28:30,456 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082396c0>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,456 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,456 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,456 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,456 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,456 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,456 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,456 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,456 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,456 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,457 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10826a9b0>


2024-04-21 11:28:30,457 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,457 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108268940>


2024-04-21 11:28:30,458 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,458 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829de70>


2024-04-21 11:28:30,458 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,458 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,458 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,458 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,458 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,458 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,458 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,460 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10823b520>


2024-04-21 11:28:30,460 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,460 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829c310>


2024-04-21 11:28:30,460 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,460 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,460 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,460 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,460 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,460 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,460 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,462 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,462 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,462 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082eeb30>


2024-04-21 11:28:30,462 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082bc8b0>


2024-04-21 11:28:30,462 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10823aa40>


2024-04-21 11:28:30,462 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108348340>


2024-04-21 11:28:30,462 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082ecca0>


2024-04-21 11:28:30,462 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108269c60>


2024-04-21 11:28:30,464 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,464 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,464 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,464 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,464 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,464 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,464 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082edcc0>


2024-04-21 11:28:30,464 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10831aef0>


2024-04-21 11:28:30,464 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10831a2c0>


2024-04-21 11:28:30,464 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082ed4e0>


2024-04-21 11:28:30,464 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829fcd0>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,465 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,465 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082bd6c0>


2024-04-21 11:28:30,466 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,466 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,466 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,466 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,466 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,467 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,467 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,467 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,467 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,467 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108365030>


2024-04-21 11:28:30,467 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10826bac0>


2024-04-21 11:28:30,467 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082bd0f0>


2024-04-21 11:28:30,470 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,470 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,470 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,470 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,470 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,470 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,470 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,470 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108348940>


2024-04-21 11:28:30,470 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083f9090>


2024-04-21 11:28:30,470 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829c940>


2024-04-21 11:28:30,470 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10834b0d0>


2024-04-21 11:28:30,470 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c3790>


2024-04-21 11:28:30,470 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108319570>


2024-04-21 11:28:30,471 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c26e0>


2024-04-21 11:28:30,471 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108349f00>


2024-04-21 11:28:30,471 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108365ba0>


2024-04-21 11:28:30,474 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,474 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,474 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,474 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,474 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,474 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10831a260>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838a140>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838bca0>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108348e50>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083f82e0>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083897e0>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840caf0>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082ee110>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108367760>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838a320>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840e380>


2024-04-21 11:28:30,475 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108319c30>


2024-04-21 11:28:30,475 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,476 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,476 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,476 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,476 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,476 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,477 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082be3b0>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,480 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,480 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,480 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,480 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,480 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,480 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,480 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,481 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840f580>


2024-04-21 11:28:30,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083f8550>


2024-04-21 11:28:30,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c0af0>


2024-04-21 11:28:30,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838b1f0>


2024-04-21 11:28:30,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c1c00>


2024-04-21 11:28:30,481 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840ee60>


2024-04-21 11:28:30,482 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840c4c0>


2024-04-21 11:28:30,482 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fb8e0>


2024-04-21 11:28:30,482 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083671f0>


2024-04-21 11:28:30,482 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10840e1d0>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,482 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,482 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,482 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,483 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,483 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,483 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,483 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,483 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,483 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,484 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,484 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,484 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,484 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,484 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_headers.complete


2024-04-21 11:28:30,484 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,484 - DEBUG - send_request_body.complete


2024-04-21 11:28:30,484 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:30,970 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'416'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4967'), (b'x-ratelimit-remaining-tokens', b'592764'), (b'x-ratelimit-reset-requests', b'384ms'), (b'x-ratelimit-reset-tokens', b'723ms'), (b'x-request-id', b'req_3496685dfd603846ec8be60e14ce1680'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a59012f2e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:30,972 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:30,973 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:30,973 - DEBUG - receive_response_body.complete


2024-04-21 11:28:30,974 - DEBUG - response_closed.started


2024-04-21 11:28:30,974 - DEBUG - response_closed.complete


2024-04-21 11:28:30,976 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:30,978 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDORMRlLO5crzK6EvSKX7P4090v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_E7FEhnMNBDZVve0fT1WG1xfn', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:30,980 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,014 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4955'), (b'x-ratelimit-remaining-tokens', b'590302'), (b'x-ratelimit-reset-requests', b'528ms'), (b'x-ratelimit-reset-tokens', b'969ms'), (b'x-request-id', b'req_92d7e7ee3717da17c9343dd37d673211'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a589f2f2d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,015 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,015 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,016 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,016 - DEBUG - response_closed.started


2024-04-21 11:28:31,016 - DEBUG - response_closed.complete


2024-04-21 11:28:31,017 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,019 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOe7MfxOmZByLyYN79FxRiTTri', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OnyFczPzFoSXHwf1YVHeHbNW', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,020 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,021 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4975'), (b'x-ratelimit-remaining-tokens', b'594579'), (b'x-ratelimit-reset-requests', b'294ms'), (b'x-ratelimit-reset-tokens', b'542ms'), (b'x-request-id', b'req_d47e7bebf586f1533a03be71339437ac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5b3adb92-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,023 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,023 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,025 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,025 - DEBUG - response_closed.started


2024-04-21 11:28:31,027 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4947'), (b'x-ratelimit-remaining-tokens', b'588242'), (b'x-ratelimit-reset-requests', b'634ms'), (b'x-ratelimit-reset-tokens', b'1.175s'), (b'x-request-id', b'req_65bc95f9ef2409e11274026a1ee0402a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8e55db7e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,027 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,028 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,028 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,028 - DEBUG - response_closed.started


2024-04-21 11:28:31,029 - DEBUG - response_closed.complete


2024-04-21 11:28:31,029 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,030 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOIzZGrTCZztS9xj7rQkcR0Ltc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Camfo6GeDwIWurCgXZJPVYJb', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=252, total_tokens=257))


2024-04-21 11:28:31,031 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,031 - DEBUG - response_closed.complete


2024-04-21 11:28:31,032 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,032 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO1OXNSGCRzwZMpmGKu5q3XqAh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8oURThiqDDhk33ykm1DoCN9h', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=225, total_tokens=230))


2024-04-21 11:28:31,033 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,034 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'426'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4918'), (b'x-ratelimit-remaining-tokens', b'582150'), (b'x-ratelimit-reset-requests', b'976ms'), (b'x-ratelimit-reset-tokens', b'1.784s'), (b'x-request-id', b'req_b506d1fbcde49c84cca0d1f9fcb951c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aaf8b2ef0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,034 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,034 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,035 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,035 - DEBUG - response_closed.started


2024-04-21 11:28:31,037 - DEBUG - response_closed.complete


2024-04-21 11:28:31,038 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,039 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOvu3ZdQok3PSr5Lo2J10Cr140', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QjjMu1xGRpzZUE2lyavQklhG', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,039 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,040 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'450'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4935'), (b'x-ratelimit-remaining-tokens', b'585663'), (b'x-ratelimit-reset-requests', b'776ms'), (b'x-ratelimit-reset-tokens', b'1.433s'), (b'x-request-id', b'req_f5185f784c164da5258e29f0afd8cd72'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8abf8406-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,040 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,040 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,041 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,041 - DEBUG - response_closed.started


2024-04-21 11:28:31,041 - DEBUG - response_closed.complete


2024-04-21 11:28:31,042 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,043 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOxjkGe4rtXDMPUffYbCIcXoIr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aJ3W5cRVlcW0qeraISb0hSmC', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=252, total_tokens=257))


2024-04-21 11:28:31,044 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,044 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'441'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4926'), (b'x-ratelimit-remaining-tokens', b'583783'), (b'x-ratelimit-reset-requests', b'881ms'), (b'x-ratelimit-reset-tokens', b'1.621s'), (b'x-request-id', b'req_809443237338640431658a14a1864463'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aa89a0caf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,045 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,045 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,045 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,045 - DEBUG - response_closed.started


2024-04-21 11:28:31,046 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'508'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599786'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'21ms'), (b'x-request-id', b'req_9ce9f7dc6c601a51065be9b35505d686'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a3b1452ef-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,046 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,046 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,046 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,046 - DEBUG - response_closed.started


2024-04-21 11:28:31,047 - DEBUG - response_closed.complete


2024-04-21 11:28:31,048 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,048 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOV8rdK7QJzJ8GQNq1OYCNs7v4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HVyxUCa9OrArIK6Ns5o30y2W', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=229, total_tokens=234))


2024-04-21 11:28:31,049 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,049 - DEBUG - response_closed.complete


2024-04-21 11:28:31,050 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,050 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOG6QbnUb9UdIVojHtbtequyMR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0FvYiOQfxk3sYLuHQ3sCvWKV', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,051 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,053 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'496'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4975'), (b'x-ratelimit-remaining-tokens', b'594877'), (b'x-ratelimit-reset-requests', b'292ms'), (b'x-ratelimit-reset-tokens', b'512ms'), (b'x-request-id', b'req_d26d42b6c6be7622cecfc93011e4ce2a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a580569c8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,053 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,054 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,054 - DEBUG - response_closed.started


2024-04-21 11:28:31,054 - DEBUG - response_closed.complete


2024-04-21 11:28:31,056 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,056 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOSDjNDZzm3itMk3pwHZ7LYhF3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_seYsqiBWhxucy9VmGxe7qQpD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=225, total_tokens=230))


2024-04-21 11:28:31,057 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,057 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'501'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4966'), (b'x-ratelimit-remaining-tokens', b'592640'), (b'x-ratelimit-reset-requests', b'406ms'), (b'x-ratelimit-reset-tokens', b'735ms'), (b'x-request-id', b'req_84d7fb0ba36c649ba356aa745999546a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a59562b6d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,058 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,058 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,058 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,058 - DEBUG - response_closed.started


2024-04-21 11:28:31,058 - DEBUG - response_closed.complete


2024-04-21 11:28:31,059 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,060 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOM46eniv2vNLV4c9xUKj4ZdMN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_TF55w1Y0Tl05gzZsFRXF8qZG', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=273, total_tokens=278))


2024-04-21 11:28:31,061 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,062 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'474'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4932'), (b'x-ratelimit-remaining-tokens', b'585081'), (b'x-ratelimit-reset-requests', b'806ms'), (b'x-ratelimit-reset-tokens', b'1.491s'), (b'x-request-id', b'req_05ad15014d51ccde5282b9016ba307d5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8db17c7a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,063 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,063 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,063 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,063 - DEBUG - response_closed.started


2024-04-21 11:28:31,063 - DEBUG - response_closed.complete


2024-04-21 11:28:31,064 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,065 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOVheJYeGxQFPSWzc6iPGlrDEm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_C96k6E67jHfchxFT5SgcM6dU', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,065 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,071 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'448'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4934'), (b'x-ratelimit-remaining-tokens', b'585682'), (b'x-ratelimit-reset-requests', b'784ms'), (b'x-ratelimit-reset-tokens', b'1.431s'), (b'x-request-id', b'req_aee11931fe47ee9b75d4bedce9556403'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a99b57bfb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,072 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,072 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,072 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,072 - DEBUG - response_closed.started


2024-04-21 11:28:31,072 - DEBUG - response_closed.complete


2024-04-21 11:28:31,073 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,073 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO97n1zof7ID9mbGOaPGICLJul', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jqH7izcPFZbmHrWfia6eeA2K', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:31,074 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,077 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'473'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4929'), (b'x-ratelimit-remaining-tokens', b'584455'), (b'x-ratelimit-reset-requests', b'840ms'), (b'x-ratelimit-reset-tokens', b'1.554s'), (b'x-request-id', b'req_6474b2afb3e5e7d3edce618e952ab118'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9a1e2b51-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,077 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,077 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,077 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,077 - DEBUG - response_closed.started


2024-04-21 11:28:31,077 - DEBUG - response_closed.complete


2024-04-21 11:28:31,078 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,079 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOsLYwEG1V3RSzYMzY96dQb3pi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aJ3NwgfXYGGDCBH7SoF55ax7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,079 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,086 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'531'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'596470'), (b'x-ratelimit-reset-requests', b'179ms'), (b'x-ratelimit-reset-tokens', b'352ms'), (b'x-request-id', b'req_a68ccc7c963472184940e795eea7ef64'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a58c32b8a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,087 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,087 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,087 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,087 - DEBUG - response_closed.started


2024-04-21 11:28:31,087 - DEBUG - response_closed.complete


2024-04-21 11:28:31,088 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,089 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO3BQf1PDBBprpZbuf7ClWcpbb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AO30dwoHiOwgdWiaxQd0ogzj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:31,089 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,089 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'418'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4913'), (b'x-ratelimit-remaining-tokens', b'580367'), (b'x-ratelimit-reset-requests', b'1.039s'), (b'x-ratelimit-reset-tokens', b'1.963s'), (b'x-request-id', b'req_74d605f67cc7fda428f05d4ef48c53a6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9c460ffd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,089 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,089 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,090 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,090 - DEBUG - response_closed.started


2024-04-21 11:28:31,090 - DEBUG - response_closed.complete


2024-04-21 11:28:31,091 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,091 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOyYFI9LZ2M363hChcDxnyvYZu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_p164XIsi89SNxwnovePRsdiT', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,091 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,102 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4912'), (b'x-ratelimit-remaining-tokens', b'580730'), (b'x-ratelimit-reset-requests', b'1.049s'), (b'x-ratelimit-reset-tokens', b'1.926s'), (b'x-request-id', b'req_a16361d33226fd36ff786751be858f57'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9d0c2f1c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,102 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,103 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,103 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,103 - DEBUG - response_closed.started


2024-04-21 11:28:31,103 - DEBUG - response_closed.complete


2024-04-21 11:28:31,104 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,104 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOrHWXucCcY95eRGieue7CY0qW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_to9YdOL2OG8lXyyFtdKMyQQa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,105 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,113 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4987'), (b'x-ratelimit-remaining-tokens', b'597315'), (b'x-ratelimit-reset-requests', b'144ms'), (b'x-ratelimit-reset-tokens', b'268ms'), (b'x-request-id', b'req_672e52f97ee15d55cd1cedfafe195193'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4aa22f70-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,114 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,114 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,114 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,114 - DEBUG - response_closed.started


2024-04-21 11:28:31,114 - DEBUG - response_closed.complete


2024-04-21 11:28:31,116 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,116 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOPntXSqozftaquv65Z1hc9v8J', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zEauZ7WD1RHBHwVdqBKj7onv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,117 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,123 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'485'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4991'), (b'x-ratelimit-remaining-tokens', b'598173'), (b'x-ratelimit-reset-requests', b'98ms'), (b'x-ratelimit-reset-tokens', b'182ms'), (b'x-request-id', b'req_de1f4caecd3c39fc985b05027071b310'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a48a05214-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,123 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,123 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,123 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,123 - DEBUG - response_closed.started


2024-04-21 11:28:31,123 - DEBUG - response_closed.complete


2024-04-21 11:28:31,124 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,125 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO1BcKGCdXgITzJwkHh9ojgr1f', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AjcNAz7ITtPLjW10xAIDV2DY', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,125 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,126 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'547'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4945'), (b'x-ratelimit-remaining-tokens', b'587844'), (b'x-ratelimit-reset-requests', b'655ms'), (b'x-ratelimit-reset-tokens', b'1.215s'), (b'x-request-id', b'req_4408db0c94945404976b142257cc0b94'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8dc57c2d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,126 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,126 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,126 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,127 - DEBUG - response_closed.started


2024-04-21 11:28:31,127 - DEBUG - response_closed.complete


2024-04-21 11:28:31,128 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,128 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOs2bmZecYsNjohwR002UdjwMs', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zBITqnuepEz9A0C8pgvrL6hJ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,128 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,134 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'526'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4929'), (b'x-ratelimit-remaining-tokens', b'584254'), (b'x-ratelimit-reset-requests', b'850ms'), (b'x-ratelimit-reset-tokens', b'1.574s'), (b'x-request-id', b'req_40c5a949662538cdf6418558ffceba4f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9c8b2b56-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,134 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,135 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,135 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,135 - DEBUG - response_closed.started


2024-04-21 11:28:31,135 - DEBUG - response_closed.complete


2024-04-21 11:28:31,136 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,136 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOPXeIQfO4qhcNnpxNmscAYqwF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_glCdsByViqEiu2lVFZsOCQRi', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,137 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,137 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'546'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4932'), (b'x-ratelimit-remaining-tokens', b'584909'), (b'x-ratelimit-reset-requests', b'813ms'), (b'x-ratelimit-reset-tokens', b'1.509s'), (b'x-request-id', b'req_d664fde2b30e795b5a859f21ab10121a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a882a2b61-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,137 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,137 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,137 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,137 - DEBUG - response_closed.started


2024-04-21 11:28:31,137 - DEBUG - response_closed.complete


2024-04-21 11:28:31,138 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,139 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO7HteAStQ0BesUx0kNpWBocgh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_7GIZH4fO5eloqAcIuCy5uESu', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=264, total_tokens=269))


2024-04-21 11:28:31,139 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,139 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'557'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4939'), (b'x-ratelimit-remaining-tokens', b'586590'), (b'x-ratelimit-reset-requests', b'721ms'), (b'x-ratelimit-reset-tokens', b'1.34s'), (b'x-request-id', b'req_755eee9c757f4eb2f33ecbbb1a848200'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7806533d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,139 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,139 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,140 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,140 - DEBUG - response_closed.started


2024-04-21 11:28:31,140 - DEBUG - response_closed.complete


2024-04-21 11:28:31,141 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,141 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOsmjZOOlmLoLQ2wNF6OBW751Q', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5T1ojJGZqEY7c225H7xvhmMc', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,142 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,142 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'560'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599785'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'21ms'), (b'x-request-id', b'req_541f701fd7fef5ffb905d3584cc3cbae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f29ee0c2b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,142 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,142 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,142 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,142 - DEBUG - response_closed.started


2024-04-21 11:28:31,142 - DEBUG - response_closed.complete


2024-04-21 11:28:31,144 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,144 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOKFpGcaJQ3OmK6pU6EOLCNAvx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PfGBS2IpwKMnDbn8W0qZYM9d', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,145 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,155 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'537'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'582786'), (b'x-ratelimit-reset-requests', b'931ms'), (b'x-ratelimit-reset-tokens', b'1.721s'), (b'x-request-id', b'req_d3ffa98d86bac20637c85e61752938cc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aa93f08fa-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,156 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,156 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,156 - DEBUG - response_closed.started


2024-04-21 11:28:31,156 - DEBUG - response_closed.complete


2024-04-21 11:28:31,158 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,158 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOWJP1Wi7qywwolog8A0gwgPBn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aJ3NwgfXYGGDCBH7SoF55ax7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,159 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,170 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'515'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4968'), (b'x-ratelimit-remaining-tokens', b'593092'), (b'x-ratelimit-reset-requests', b'372ms'), (b'x-ratelimit-reset-tokens', b'690ms'), (b'x-request-id', b'req_f70410c4fac62642c3492714e96d5bb2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5e18db7e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,170 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,170 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,170 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,170 - DEBUG - response_closed.started


2024-04-21 11:28:31,171 - DEBUG - response_closed.complete


2024-04-21 11:28:31,173 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,173 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOV5OEJrnlKrAEtqt8xZpFuRjv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BA7OI8dllHZy7naoFiMri5lX', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,174 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,201 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'499'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4926'), (b'x-ratelimit-remaining-tokens', b'583641'), (b'x-ratelimit-reset-requests', b'886ms'), (b'x-ratelimit-reset-tokens', b'1.635s'), (b'x-request-id', b'req_6c92f74fbc63f5893d4b4640e4075668'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aac8e7bb6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,202 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,202 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,202 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,203 - DEBUG - response_closed.started


2024-04-21 11:28:31,203 - DEBUG - response_closed.complete


2024-04-21 11:28:31,207 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,208 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO3EK9bUGPTP6zRmftcuIQmMtH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_t6457SwTOoSAZYSCcS6jMfi7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=251, total_tokens=256))


2024-04-21 11:28:31,209 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,209 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'543'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4987'), (b'x-ratelimit-remaining-tokens', b'597080'), (b'x-ratelimit-reset-requests', b'155ms'), (b'x-ratelimit-reset-tokens', b'291ms'), (b'x-request-id', b'req_018157f4461d2e8f378ced1c877da63f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4f802b95-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,210 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,210 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,210 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,210 - DEBUG - response_closed.started


2024-04-21 11:28:31,210 - DEBUG - response_closed.complete


2024-04-21 11:28:31,213 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,213 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO2fMofUjrlXRih2oRXvsA3CYt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Kos5ecBdQjxUoBgo5IPLQRA7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=300, total_tokens=305))


2024-04-21 11:28:31,214 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,214 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'512'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'582567'), (b'x-ratelimit-reset-requests', b'944ms'), (b'x-ratelimit-reset-tokens', b'1.743s'), (b'x-request-id', b'req_7cfbf6ecbc69a11fb8b54524d4814420'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9dc52ac5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,215 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,215 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,215 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,215 - DEBUG - response_closed.started


2024-04-21 11:28:31,215 - DEBUG - response_closed.complete


2024-04-21 11:28:31,218 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,219 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOJtTE1qiPnUEB0AQNpjc5L4nV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CmVOQLF0LYMnmrrpRiNIbCkI', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=247, total_tokens=252))


2024-04-21 11:28:31,219 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,220 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4984'), (b'x-ratelimit-remaining-tokens', b'596466'), (b'x-ratelimit-reset-requests', b'189ms'), (b'x-ratelimit-reset-tokens', b'353ms'), (b'x-request-id', b'req_848123a5ec9ded8bbaf1e9468c814996'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5d697ba1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,220 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,220 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,220 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,220 - DEBUG - response_closed.started


2024-04-21 11:28:31,220 - DEBUG - response_closed.complete


2024-04-21 11:28:31,223 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,223 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO8AGXKr6IV4uCblpUdW4jnUWJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Ol0V78iDn2Ow8fE0BrRVvQIg', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=251, total_tokens=256))


2024-04-21 11:28:31,224 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,224 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'545'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4962'), (b'x-ratelimit-remaining-tokens', b'591530'), (b'x-ratelimit-reset-requests', b'452ms'), (b'x-ratelimit-reset-tokens', b'846ms'), (b'x-request-id', b'req_f4b9e180213b52a5f5d3d49adf35d75d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7ffc69a9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,224 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,224 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,224 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,225 - DEBUG - response_closed.started


2024-04-21 11:28:31,225 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'538'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4950'), (b'x-ratelimit-remaining-tokens', b'589049'), (b'x-ratelimit-reset-requests', b'589ms'), (b'x-ratelimit-reset-tokens', b'1.095s'), (b'x-request-id', b'req_23dddeecb1508c7379f6fab75d7803f5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a88d67c62-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,225 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,225 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,225 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,225 - DEBUG - response_closed.started


2024-04-21 11:28:31,226 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'566'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4976'), (b'x-ratelimit-remaining-tokens', b'594775'), (b'x-ratelimit-reset-requests', b'283ms'), (b'x-ratelimit-reset-tokens', b'522ms'), (b'x-request-id', b'req_9037f1a97374f99baadda8d549e0c0af'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4a9a3235-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,226 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,226 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,226 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,226 - DEBUG - response_closed.started


2024-04-21 11:28:31,226 - DEBUG - response_closed.complete


2024-04-21 11:28:31,229 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,229 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOCex6WSbQObPK49ynnx7SWFZR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_zEauZ7WD1RHBHwVdqBKj7onv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,230 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,230 - DEBUG - response_closed.complete


2024-04-21 11:28:31,232 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,232 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDONZLQGK32HmJ5xNeEr9Ku8BBO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9zeuD3j5BY6E0XW8grseFngw', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=245, total_tokens=250))


2024-04-21 11:28:31,233 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,233 - DEBUG - response_closed.complete


2024-04-21 11:28:31,235 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,236 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOla3RoonLhHaxNUQxH5XsBPgq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_g1nCyXoBnDMF1c4mz0o1088F', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,236 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,236 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'574'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4966'), (b'x-ratelimit-remaining-tokens', b'592460'), (b'x-ratelimit-reset-requests', b'406ms'), (b'x-ratelimit-reset-tokens', b'753ms'), (b'x-request-id', b'req_2b8aa0604f9c3ee7c275220e13aa9a0e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5b762b82-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,236 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,237 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,237 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,237 - DEBUG - response_closed.started


2024-04-21 11:28:31,237 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'576'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4979'), (b'x-ratelimit-remaining-tokens', b'595408'), (b'x-ratelimit-reset-requests', b'246ms'), (b'x-ratelimit-reset-tokens', b'459ms'), (b'x-request-id', b'req_c570ebfc4b043c05fd5b9b945d767c96'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5e662a97-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,237 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,237 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,237 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,237 - DEBUG - response_closed.started


2024-04-21 11:28:31,238 - DEBUG - response_closed.complete


2024-04-21 11:28:31,240 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,240 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOpUJuGxctVFIXOuLJLce0gPWw', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HmShW4h8qae4h27cQuEY23j9', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=249, total_tokens=254))


2024-04-21 11:28:31,240 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,240 - DEBUG - response_closed.complete


2024-04-21 11:28:31,243 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,243 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOf3TecnHVmn5uwDtev6TAjdcv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_bcB16DwEhHyATZwiNYCpqU2B', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:31,243 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,244 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'560'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'588086'), (b'x-ratelimit-reset-requests', b'641ms'), (b'x-ratelimit-reset-tokens', b'1.191s'), (b'x-request-id', b'req_91a489f4c4a5dad84f457eb27a38849f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a79af2b7a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,244 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,244 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,244 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,244 - DEBUG - response_closed.started


2024-04-21 11:28:31,244 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'585'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4973'), (b'x-ratelimit-remaining-tokens', b'594173'), (b'x-ratelimit-reset-requests', b'316ms'), (b'x-ratelimit-reset-tokens', b'582ms'), (b'x-request-id', b'req_e7c46ca0ca69afaf9806c92fdee387b5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a58efdbe5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,245 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,245 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,245 - DEBUG - response_closed.started


2024-04-21 11:28:31,245 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'579'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4980'), (b'x-ratelimit-remaining-tokens', b'595622'), (b'x-ratelimit-reset-requests', b'234ms'), (b'x-ratelimit-reset-tokens', b'437ms'), (b'x-request-id', b'req_98932890bb064aef7f5e8bed04f9b9ad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a588f7d1f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,245 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,245 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,245 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,245 - DEBUG - response_closed.started


2024-04-21 11:28:31,245 - DEBUG - response_closed.complete


2024-04-21 11:28:31,247 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,248 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO9wMsaoc7b3sPeiGwJ0gygaSb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_GSnIs6bi1aJYgApchtF0B2zq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,248 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,248 - DEBUG - response_closed.complete


2024-04-21 11:28:31,250 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,250 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOVgIFPuJLxO7gMGKRPGdup1oP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Ol0V78iDn2Ow8fE0BrRVvQIg', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,251 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,251 - DEBUG - response_closed.complete


2024-04-21 11:28:31,253 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,253 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOxIgH8z7pUJY9ibya2yjz1Egg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Dsfi09t4Dv8hfSbZEB0ocKc4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=252, total_tokens=257))


2024-04-21 11:28:31,253 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,256 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'608'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4953'), (b'x-ratelimit-remaining-tokens', b'589661'), (b'x-ratelimit-reset-requests', b'556ms'), (b'x-ratelimit-reset-tokens', b'1.033s'), (b'x-request-id', b'req_f5b86fa2ce6af988d4b3cfe8d54b8880'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7b405371-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,256 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,256 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,256 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,256 - DEBUG - response_closed.started


2024-04-21 11:28:31,256 - DEBUG - response_closed.complete


2024-04-21 11:28:31,259 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,259 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOykneXLmX0ZdFOKev9xFUTCJ1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5MdqvejirSREu3bAbrZyQb9m', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,259 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,259 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'574'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4943'), (b'x-ratelimit-remaining-tokens', b'587500'), (b'x-ratelimit-reset-requests', b'680ms'), (b'x-ratelimit-reset-tokens', b'1.249s'), (b'x-request-id', b'req_1150926ee35500e7910186fe1ff14eb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a99e71031-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,260 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,260 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,260 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,260 - DEBUG - response_closed.started


2024-04-21 11:28:31,260 - DEBUG - response_closed.complete


2024-04-21 11:28:31,262 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,262 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO9E2g3mV3Kzl2ISZiaqznS6dO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_c0e5BOayxxclsiInWBhKKg0k', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,262 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,263 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'568'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4923'), (b'x-ratelimit-remaining-tokens', b'583215'), (b'x-ratelimit-reset-requests', b'919ms'), (b'x-ratelimit-reset-tokens', b'1.678s'), (b'x-request-id', b'req_153c00d817ee4b363f71fc46438589ef'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aac8508cc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,263 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,263 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,263 - DEBUG - response_closed.started


2024-04-21 11:28:31,263 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'722'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4986'), (b'x-ratelimit-remaining-tokens', b'596875'), (b'x-ratelimit-reset-requests', b'166ms'), (b'x-ratelimit-reset-tokens', b'312ms'), (b'x-request-id', b'req_de12c99547efafcfd23dc96b6c22a1ed'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a49c03179-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,263 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,263 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,263 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,263 - DEBUG - response_closed.started


2024-04-21 11:28:31,264 - DEBUG - response_closed.complete


2024-04-21 11:28:31,266 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,266 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOUQwEThSV2Bmhi5jXxYY1VvuG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_C7R9FgkC37tXCVEHf6Paptgr', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,266 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,266 - DEBUG - response_closed.complete


2024-04-21 11:28:31,268 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,268 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOEuYrvQvrl5PUIX2YqMSc32FL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_JeFz2Y0ZdIOWiI64gwck5QB7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,269 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,269 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'604'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4981'), (b'x-ratelimit-remaining-tokens', b'595833'), (b'x-ratelimit-reset-requests', b'222ms'), (b'x-ratelimit-reset-tokens', b'416ms'), (b'x-request-id', b'req_5c9da390b57269917316966789db672f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4ba469a4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,269 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,269 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,269 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,269 - DEBUG - response_closed.started


2024-04-21 11:28:31,269 - DEBUG - response_closed.complete


2024-04-21 11:28:31,271 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,271 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOu1A5bptNGFA9JaR2Ar9I0O50', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VkJwn5Ww7ritG85Dec8z6Q25', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=278, total_tokens=283))


2024-04-21 11:28:31,272 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,272 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'582738'), (b'x-ratelimit-reset-requests', b'945ms'), (b'x-ratelimit-reset-tokens', b'1.726s'), (b'x-request-id', b'req_e2ca8273064996098299f480f4ed679f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9dfedb66-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,272 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,272 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,272 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,272 - DEBUG - response_closed.started


2024-04-21 11:28:31,272 - DEBUG - response_closed.complete


2024-04-21 11:28:31,274 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,274 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO1MvTXbyPW4GjJE4ZOPKY4KDi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_abYaih1vpZw7Rri8XGhQQqv1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=257, total_tokens=262))


2024-04-21 11:28:31,275 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,281 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'598'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4941'), (b'x-ratelimit-remaining-tokens', b'587006'), (b'x-ratelimit-reset-requests', b'702ms'), (b'x-ratelimit-reset-tokens', b'1.299s'), (b'x-request-id', b'req_d32aa650832be489ff0971c3bc6509db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9a182b51-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,282 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,282 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,282 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,282 - DEBUG - response_closed.started


2024-04-21 11:28:31,282 - DEBUG - response_closed.complete


2024-04-21 11:28:31,284 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,284 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO2kfktGhBaORdG5ZfPkTa5cZ1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qiQA0Vqf3ZCX4DEr7VCIFAVY', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=245, total_tokens=250))


2024-04-21 11:28:31,284 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,284 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'618'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4977'), (b'x-ratelimit-remaining-tokens', b'595000'), (b'x-ratelimit-reset-requests', b'270ms'), (b'x-ratelimit-reset-tokens', b'499ms'), (b'x-request-id', b'req_89f1de200a83995b7eaf8c823aba974c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5f0f2ac0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,285 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,285 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,285 - DEBUG - response_closed.started


2024-04-21 11:28:31,285 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'724'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4963'), (b'x-ratelimit-remaining-tokens', b'591840'), (b'x-ratelimit-reset-requests', b'440ms'), (b'x-ratelimit-reset-tokens', b'815ms'), (b'x-request-id', b'req_865b53df764092f11552ba3547b66cc6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a6bea2f11-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,285 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,285 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,285 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,285 - DEBUG - response_closed.started


2024-04-21 11:28:31,285 - DEBUG - response_closed.complete


2024-04-21 11:28:31,287 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,288 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO1ZHRpyHvsvOWXzYDXcNCNvSG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_IoDhZRRXNR7up0qKzqcXFFOF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,288 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,288 - DEBUG - response_closed.complete


2024-04-21 11:28:31,290 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,290 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO5LPZTOtF08hHKZYGlU426xyT', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8linX4JbgDfzmlamBr6mJggx', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=252, total_tokens=257))


2024-04-21 11:28:31,290 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,290 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'593'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'582893'), (b'x-ratelimit-reset-requests', b'942ms'), (b'x-ratelimit-reset-tokens', b'1.71s'), (b'x-request-id', b'req_1461dc4980cb976b02ea7af700c5bad3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aaaf92a8b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,291 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,291 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,291 - DEBUG - response_closed.started


2024-04-21 11:28:31,291 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'745'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'597695'), (b'x-ratelimit-reset-requests', b'136ms'), (b'x-ratelimit-reset-tokens', b'230ms'), (b'x-request-id', b'req_90855a2a40ab753342944fc5e12e6d78'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4e0edb9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,291 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,291 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,291 - DEBUG - response_closed.started


2024-04-21 11:28:31,291 - DEBUG - response_closed.complete


2024-04-21 11:28:31,293 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,294 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDONePmTi1FVEGQ80R55VMPLmw7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Hfs0ZKA5OTQTNlquOVRsq8QF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:31,294 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,294 - DEBUG - response_closed.complete


2024-04-21 11:28:31,296 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,296 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOCvVqQbJKxC8C9HtlSeQqkpGj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pTT0KJqeK4GznPGZfH4Cxowr', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,296 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,296 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'616'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4960'), (b'x-ratelimit-remaining-tokens', b'591063'), (b'x-ratelimit-reset-requests', b'471ms'), (b'x-ratelimit-reset-tokens', b'893ms'), (b'x-request-id', b'req_27129ba4991f654f73427e1cb6cef62b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7de20fe0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,297 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,297 - DEBUG - response_closed.started


2024-04-21 11:28:31,297 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'602'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4952'), (b'x-ratelimit-remaining-tokens', b'589460'), (b'x-ratelimit-reset-requests', b'566ms'), (b'x-ratelimit-reset-tokens', b'1.053s'), (b'x-request-id', b'req_3068ab800cf98287ae37ba81090a4f22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8abc0ca3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,297 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,297 - DEBUG - response_closed.started


2024-04-21 11:28:31,297 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'604'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4964'), (b'x-ratelimit-remaining-tokens', b'592163'), (b'x-ratelimit-reset-requests', b'426ms'), (b'x-ratelimit-reset-tokens', b'783ms'), (b'x-request-id', b'req_ebe648e6476890b3f838ab3f185c49e2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5d802939-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,297 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,298 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,298 - DEBUG - response_closed.started


2024-04-21 11:28:31,298 - DEBUG - response_closed.complete


2024-04-21 11:28:31,300 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,300 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO7u45m9KgMeLT3NNE7QJKjkMt', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Mz3pU3WHCzm08nY6qIYjxnsd', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,300 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,300 - DEBUG - response_closed.complete


2024-04-21 11:28:31,302 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,302 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOTvtRDuRqkMO5m7weFzwQlwLN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UmdQGGwaHiYS0s6G7i6sjbQD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,302 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,303 - DEBUG - response_closed.complete


2024-04-21 11:28:31,305 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,305 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOY92EphQYw4L3edyGg5sd4N81', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_IMUShBJKc9cxY8t8fPazhXW4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,305 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,305 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'572'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4951'), (b'x-ratelimit-remaining-tokens', b'589250'), (b'x-ratelimit-reset-requests', b'578ms'), (b'x-ratelimit-reset-tokens', b'1.074s'), (b'x-request-id', b'req_eee5c74a17d5bc630fbd6d905f903f88'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a79490fc4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,305 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,305 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,305 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,305 - DEBUG - response_closed.started


2024-04-21 11:28:31,305 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4934'), (b'x-ratelimit-remaining-tokens', b'585504'), (b'x-ratelimit-reset-requests', b'783ms'), (b'x-ratelimit-reset-tokens', b'1.449s'), (b'x-request-id', b'req_3f0da672e46c56657a8df8594d4f818e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a99422ab0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,306 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,306 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,306 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,306 - DEBUG - response_closed.started


2024-04-21 11:28:31,306 - DEBUG - response_closed.complete


2024-04-21 11:28:31,308 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,308 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO5Elu9ie6xqYTjaUNY24MYpaD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kk0Sv48U5gFHUpijn6PysefV', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,308 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,308 - DEBUG - response_closed.complete


2024-04-21 11:28:31,310 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,310 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOHNnq698OeO1Jr3NubkpIn4ib', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QWbhD4nG0Ca3nZQJwrO1A9Yr', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,310 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,311 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'629'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4961'), (b'x-ratelimit-remaining-tokens', b'591524'), (b'x-ratelimit-reset-requests', b'462ms'), (b'x-ratelimit-reset-tokens', b'847ms'), (b'x-request-id', b'req_745fd598c219eedf5f25cca4ba30767c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a6c882abb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,311 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,311 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,311 - DEBUG - response_closed.started


2024-04-21 11:28:31,311 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'764'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599064'), (b'x-ratelimit-reset-requests', b'46ms'), (b'x-ratelimit-reset-tokens', b'93ms'), (b'x-request-id', b'req_c896590cf86c142805ba5b88bf1b2817'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4fbf2b8e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,311 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,311 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,311 - DEBUG - response_closed.started


2024-04-21 11:28:31,311 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'636'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4957'), (b'x-ratelimit-remaining-tokens', b'590641'), (b'x-ratelimit-reset-requests', b'504ms'), (b'x-ratelimit-reset-tokens', b'935ms'), (b'x-request-id', b'req_35d96f1f029f796688163d449ef9f858'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7fcb2f3b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,311 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,311 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,311 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,312 - DEBUG - response_closed.started


2024-04-21 11:28:31,312 - DEBUG - response_closed.complete


2024-04-21 11:28:31,313 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,314 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOiUhd71qft6UtSKp2VGMAtfUS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VkJwn5Ww7ritG85Dec8z6Q25', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,314 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,314 - DEBUG - response_closed.complete


2024-04-21 11:28:31,316 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,316 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOc1r58JohGWtor0I5VHOlGpJB', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pRODhuYEq7aUSV5nOvQK7UCy', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=250, total_tokens=255))


2024-04-21 11:28:31,316 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,316 - DEBUG - response_closed.complete


2024-04-21 11:28:31,318 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,318 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDORhAFD7TifLrkaXvN44GSMT04', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_42gKob7vHBWwkN333FMJJQ9B', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=243, total_tokens=248))


2024-04-21 11:28:31,319 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,319 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'753'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4995'), (b'x-ratelimit-remaining-tokens', b'598794'), (b'x-ratelimit-reset-requests', b'54ms'), (b'x-ratelimit-reset-tokens', b'120ms'), (b'x-request-id', b'req_97dc7b7523e049a8ccc07cc851ebe211'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a3a007d77-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,319 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,319 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,319 - DEBUG - response_closed.started


2024-04-21 11:28:31,319 - DEBUG - response_closed.complete


2024-04-21 11:28:31,321 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,321 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOWQZDY97tm5rk31WugVte64fx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_v6CtptRk1j2Cjj4VUaaDRBgP', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,321 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,322 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'716'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4917'), (b'x-ratelimit-remaining-tokens', b'581720'), (b'x-ratelimit-reset-requests', b'988ms'), (b'x-ratelimit-reset-tokens', b'1.827s'), (b'x-request-id', b'req_c82d7638c894a68ab7572418d5536b6d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aae372b73-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,322 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,322 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,322 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,322 - DEBUG - response_closed.started


2024-04-21 11:28:31,322 - DEBUG - response_closed.complete


2024-04-21 11:28:31,324 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,324 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOfYCHUzb89GsyiTKylCZSxuyi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pTT0KJqeK4GznPGZfH4Cxowr', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=273, total_tokens=278))


2024-04-21 11:28:31,324 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,324 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'674'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'596676'), (b'x-ratelimit-reset-requests', b'177ms'), (b'x-ratelimit-reset-tokens', b'332ms'), (b'x-request-id', b'req_1a119fc3169b2b6ae6fa1bd0e0e4b62f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4e532a97-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,324 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,325 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,325 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,325 - DEBUG - response_closed.started


2024-04-21 11:28:31,325 - DEBUG - response_closed.complete


2024-04-21 11:28:31,327 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,327 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO7e7OtJeuOxBWVUqDl6n0q0CS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dNzOSQvkHAqUnQDkXeD8sYaU', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,327 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,327 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'587'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'580696'), (b'x-ratelimit-reset-requests', b'1.025s'), (b'x-ratelimit-reset-tokens', b'1.93s'), (b'x-request-id', b'req_f764fba15bf267ae4b4e84bf19666187'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a89e82ea8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,327 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,327 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,327 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,327 - DEBUG - response_closed.started


2024-04-21 11:28:31,327 - DEBUG - response_closed.complete


2024-04-21 11:28:31,330 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,330 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOhKiikjBWmQP0PefRRQh39PmI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_m0VvzCqhs8wEEyV7cLNwKgF2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=251, total_tokens=256))


2024-04-21 11:28:31,330 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,334 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'589'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4916'), (b'x-ratelimit-remaining-tokens', b'581409'), (b'x-ratelimit-reset-requests', b'1s'), (b'x-ratelimit-reset-tokens', b'1.859s'), (b'x-request-id', b'req_17543f08041119201c37c723c11876fb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9e4569aa-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,334 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,334 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,334 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,334 - DEBUG - response_closed.started


2024-04-21 11:28:31,334 - DEBUG - response_closed.complete


2024-04-21 11:28:31,337 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,337 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOYlxHkXRLPgSYM8TWAUZ1Eiya', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_X1Mj6PaVmVmLjXb0TOuSDEXT', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=274, total_tokens=279))


2024-04-21 11:28:31,337 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,338 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'787'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4982'), (b'x-ratelimit-remaining-tokens', b'596073'), (b'x-ratelimit-reset-requests', b'211ms'), (b'x-ratelimit-reset-tokens', b'392ms'), (b'x-request-id', b'req_8fad32ad11fca1b7a2a842329acf5af3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5ed72abf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,338 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,338 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,338 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,338 - DEBUG - response_closed.started


2024-04-21 11:28:31,339 - DEBUG - response_closed.complete


2024-04-21 11:28:31,341 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,341 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOFrOT0cEkRnOWMZyujpsOcNpS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8nOA24jSBn0OGYzPA95PSB2Q', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=229, total_tokens=234))


2024-04-21 11:28:31,341 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,341 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'782'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4962'), (b'x-ratelimit-remaining-tokens', b'591801'), (b'x-ratelimit-reset-requests', b'453ms'), (b'x-ratelimit-reset-tokens', b'819ms'), (b'x-request-id', b'req_27dc6a06cd384460f351c60fce53c143'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a6d852ad5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,341 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,341 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,341 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,342 - DEBUG - response_closed.started


2024-04-21 11:28:31,342 - DEBUG - response_closed.complete


2024-04-21 11:28:31,344 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,344 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOJBYGrwfVKNtGoRJOQ7MrDG6F', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i1NGoFx3O1Nbk4tamqSNkQX4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=250, total_tokens=255))


2024-04-21 11:28:31,344 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,346 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'596'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4914'), (b'x-ratelimit-remaining-tokens', b'580635'), (b'x-ratelimit-reset-requests', b'1.022s'), (b'x-ratelimit-reset-tokens', b'1.936s'), (b'x-request-id', b'req_c3645b87585f15653dccce35f599a84f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aad76102c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,346 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,346 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,347 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,347 - DEBUG - response_closed.started


2024-04-21 11:28:31,347 - DEBUG - response_closed.complete


2024-04-21 11:28:31,349 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,349 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOKLleoZzP89E0Ltxhw3hqluhV', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_tYatfSpVHzOQmvgZJpSTu1gn', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:31,349 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,372 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'832'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598394'), (b'x-ratelimit-reset-requests', b'85ms'), (b'x-ratelimit-reset-tokens', b'160ms'), (b'x-request-id', b'req_1af145c674876bc91e0bbdf43d634795'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4b8769cf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,373 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,373 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,373 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,373 - DEBUG - response_closed.started


2024-04-21 11:28:31,373 - DEBUG - response_closed.complete


2024-04-21 11:28:31,375 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,376 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOZFOOmvKUjhRBpmTOPf6FhqGd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_lbgM7X0VLewMstOZHCDoweYG', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=250, total_tokens=255))


2024-04-21 11:28:31,376 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,386 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4974'), (b'x-ratelimit-remaining-tokens', b'594384'), (b'x-ratelimit-reset-requests', b'304ms'), (b'x-ratelimit-reset-tokens', b'561ms'), (b'x-request-id', b'req_f83c974704c83ca8e160fef2723468f2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a59652f1a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,386 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,386 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,386 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,386 - DEBUG - response_closed.started


2024-04-21 11:28:31,386 - DEBUG - response_closed.complete


2024-04-21 11:28:31,389 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,389 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOlLvpQ8AKJtpOWm0tW53MoGQ5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_xs9rdfo91apgKu487pwsVZ47', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,390 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,390 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'731'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4942'), (b'x-ratelimit-remaining-tokens', b'587203'), (b'x-ratelimit-reset-requests', b'691ms'), (b'x-ratelimit-reset-tokens', b'1.279s'), (b'x-request-id', b'req_2e71e85d7e940a5342700ae2ca2fa3be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9f8f0920-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,390 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,390 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,390 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,390 - DEBUG - response_closed.started


2024-04-21 11:28:31,390 - DEBUG - response_closed.complete


2024-04-21 11:28:31,393 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,393 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOJrVvRRoFII6iS1jylox1KYRf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_48cnHQHs1JEj3ygF1lzJQy59', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,393 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,396 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4912'), (b'x-ratelimit-remaining-tokens', b'580227'), (b'x-ratelimit-reset-requests', b'1.044s'), (b'x-ratelimit-reset-tokens', b'1.977s'), (b'x-request-id', b'req_91e8c1a2eb9b7f538dafa990517c0410'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aaae07c2f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,396 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,396 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,396 - DEBUG - response_closed.started


2024-04-21 11:28:31,396 - DEBUG - response_closed.complete


2024-04-21 11:28:31,399 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,399 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO0tnE1zxNgbbqAHeihbbiMnhe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uRHBzntr6NHdPxVZRzHp5mG0', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,399 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,399 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'741'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4972'), (b'x-ratelimit-remaining-tokens', b'593928'), (b'x-ratelimit-reset-requests', b'331ms'), (b'x-ratelimit-reset-tokens', b'607ms'), (b'x-request-id', b'req_9e328a7266e856f75c327bd04f4c05ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5aae1015-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,399 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,399 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,399 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,399 - DEBUG - response_closed.started


2024-04-21 11:28:31,399 - DEBUG - response_closed.complete


2024-04-21 11:28:31,402 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,402 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOGxxFqxzfWSVFHAMzrEc76Mvv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_2j3rAWVycbRRks5f77VxgFuj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,403 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,462 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'837'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4911'), (b'x-ratelimit-remaining-tokens', b'580529'), (b'x-ratelimit-reset-requests', b'1.061s'), (b'x-ratelimit-reset-tokens', b'1.947s'), (b'x-request-id', b'req_934eae0655cb76dfad8dd8c9a4059cbd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aaa0c2ebb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,463 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,463 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,463 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,463 - DEBUG - response_closed.started


2024-04-21 11:28:31,463 - DEBUG - response_closed.complete


2024-04-21 11:28:31,467 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,467 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOY8R9Pyj1eL2eRWtVCoQseXlc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_6ge1tpODyIGSlkcy4ab9x885', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=245, total_tokens=250))


2024-04-21 11:28:31,467 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,467 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'784'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4912'), (b'x-ratelimit-remaining-tokens', b'580089'), (b'x-ratelimit-reset-requests', b'1.048s'), (b'x-ratelimit-reset-tokens', b'1.991s'), (b'x-request-id', b'req_db0c6b07dc54725ca7850a3f72f3dfc4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9a9f7c8f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,468 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,468 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,468 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,468 - DEBUG - response_closed.started


2024-04-21 11:28:31,468 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'518'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4970'), (b'x-ratelimit-remaining-tokens', b'593457'), (b'x-ratelimit-reset-requests', b'354ms'), (b'x-ratelimit-reset-tokens', b'654ms'), (b'x-request-id', b'req_d1db0d1541abc0b0174e2946c4e7d633'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5b463110-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,468 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,468 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,468 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,468 - DEBUG - response_closed.started


2024-04-21 11:28:31,468 - DEBUG - response_closed.complete


2024-04-21 11:28:31,472 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,472 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOLnKtRJ4vqHUZ8Q9mqWFFlyXn', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CNeTa65Ids3a6jFYpwW2NkvQ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,473 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,473 - DEBUG - response_closed.complete


2024-04-21 11:28:31,476 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,476 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOk9aPPlF6Csk5emUnrXypOTQI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0TPtdFyCYBq0d88ppPm2fFm6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=270, total_tokens=275))


2024-04-21 11:28:31,477 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,477 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'867'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4938'), (b'x-ratelimit-remaining-tokens', b'586326'), (b'x-ratelimit-reset-requests', b'738ms'), (b'x-ratelimit-reset-tokens', b'1.367s'), (b'x-request-id', b'req_a638b101f6ead0341619fda1119905f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a99087e7d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,477 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,477 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,477 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,477 - DEBUG - response_closed.started


2024-04-21 11:28:31,477 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'884'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'588475'), (b'x-ratelimit-reset-requests', b'618ms'), (b'x-ratelimit-reset-tokens', b'1.152s'), (b'x-request-id', b'req_e7a1472aac70a54d8ffdf40e0323dba0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8c387ca9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,477 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,477 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,478 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,478 - DEBUG - response_closed.started


2024-04-21 11:28:31,478 - DEBUG - response_closed.complete


2024-04-21 11:28:31,481 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,481 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOYvfyMxxeTOJcTb56PzqKcsvm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_V0XLoJLLci90OmlPyDkAGRgk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,481 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,481 - DEBUG - response_closed.complete


2024-04-21 11:28:31,485 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,485 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO932RdJ3SQvN2rvYVTmBbLBXv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kOqiXc3R4MqS7MM5eqekUIm6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,485 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,485 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'864'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4916'), (b'x-ratelimit-remaining-tokens', b'581487'), (b'x-ratelimit-reset-requests', b'1.002s'), (b'x-ratelimit-reset-tokens', b'1.851s'), (b'x-request-id', b'req_3e3f16472ce7e48118991368cf17daf9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9d60532b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,485 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,486 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,486 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,486 - DEBUG - response_closed.started


2024-04-21 11:28:31,486 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'850'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4913'), (b'x-ratelimit-remaining-tokens', b'580674'), (b'x-ratelimit-reset-requests', b'1.037s'), (b'x-ratelimit-reset-tokens', b'1.932s'), (b'x-request-id', b'req_119ec377686fb0100a23a5909bf20cfe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5d6b2f7b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,486 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,486 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,486 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,486 - DEBUG - response_closed.started


2024-04-21 11:28:31,486 - DEBUG - response_closed.complete


2024-04-21 11:28:31,489 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,489 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDO79BKZeSkwbJHN7h5xKZK8SnA', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_xLNG7C60B1723zWm4ROCpyRW', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,490 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,490 - DEBUG - response_closed.complete


2024-04-21 11:28:31,493 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,493 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDONG5PJlivGTz5j4SANIcc9nLF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_siyglMrAXuIGWbyv6vuwWEBz', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,493 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,493 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'874'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4918'), (b'x-ratelimit-remaining-tokens', b'581956'), (b'x-ratelimit-reset-requests', b'977ms'), (b'x-ratelimit-reset-tokens', b'1.804s'), (b'x-request-id', b'req_f44811d45898a94629fb51f03aba1b2a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9bde0fd3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,494 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,494 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,494 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,494 - DEBUG - response_closed.started


2024-04-21 11:28:31,494 - DEBUG - response_closed.complete


2024-04-21 11:28:31,497 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,497 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOHQG6ctco1arbvCz5HOB30buP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CNeTa65Ids3a6jFYpwW2NkvQ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,497 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,504 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'518'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4928'), (b'x-ratelimit-remaining-tokens', b'584052'), (b'x-ratelimit-reset-requests', b'861ms'), (b'x-ratelimit-reset-tokens', b'1.594s'), (b'x-request-id', b'req_fbff0fbe6e9c49a55359c52001a30b7b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9e960fed-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,504 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,504 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,504 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,504 - DEBUG - response_closed.started


2024-04-21 11:28:31,504 - DEBUG - response_closed.complete


2024-04-21 11:28:31,507 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,507 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOy50uY0U4lsJpiqcoAuAKmv2t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_AwRI11IX2U6XQLdUg8QMvOkh', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=251, total_tokens=256))


2024-04-21 11:28:31,507 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,507 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'882'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4916'), (b'x-ratelimit-remaining-tokens', b'581246'), (b'x-ratelimit-reset-requests', b'1.007s'), (b'x-ratelimit-reset-tokens', b'1.875s'), (b'x-request-id', b'req_0802d5597a0edee5c31765e6bb8f2854'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2aa87b78d8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,508 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,508 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,508 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,508 - DEBUG - response_closed.started


2024-04-21 11:28:31,508 - DEBUG - response_closed.complete


2024-04-21 11:28:31,511 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,511 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOjeTTRAq8nWdd0jZRruRU3Vug', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yVrt7Pyi5KOt8EnGFSF085in', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,511 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,556 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'975'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4955'), (b'x-ratelimit-remaining-tokens', b'590026'), (b'x-ratelimit-reset-requests', b'538ms'), (b'x-ratelimit-reset-tokens', b'997ms'), (b'x-request-id', b'req_74ae1afd141b6b010282432230f743e8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7c210fdb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,556 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,556 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,556 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,556 - DEBUG - response_closed.started


2024-04-21 11:28:31,556 - DEBUG - response_closed.complete


2024-04-21 11:28:31,560 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,560 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOQdQZD0TeqnqYTTkCEXvqd3mJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dXHGmD5xkvLXxKivF5eCbLgb', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=255, total_tokens=260))


2024-04-21 11:28:31,560 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,565 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'881'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4949'), (b'x-ratelimit-remaining-tokens', b'588756'), (b'x-ratelimit-reset-requests', b'609ms'), (b'x-ratelimit-reset-tokens', b'1.124s'), (b'x-request-id', b'req_4e77b088601d27be5e69fe11deb4a9e7'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8d197be9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,565 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,565 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,565 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,565 - DEBUG - response_closed.started


2024-04-21 11:28:31,565 - DEBUG - response_closed.complete


2024-04-21 11:28:31,570 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,570 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOB0unwgbMjuienqLpKefrJqg5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_2j3rAWVycbRRks5f77VxgFuj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=247, total_tokens=252))


2024-04-21 11:28:31,570 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,571 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1007'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'597523'), (b'x-ratelimit-reset-requests', b'132ms'), (b'x-ratelimit-reset-tokens', b'247ms'), (b'x-request-id', b'req_d22275dd110ade8c810a02be2c59625b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4d6b2ad5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,571 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,571 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,571 - DEBUG - response_closed.started


2024-04-21 11:28:31,571 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'980'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'588620'), (b'x-ratelimit-reset-requests', b'613ms'), (b'x-ratelimit-reset-tokens', b'1.137s'), (b'x-request-id', b'req_a0af42a0472c2a07ba0bd107f9c2ca52'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7ea82b8c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,571 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,571 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,571 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,571 - DEBUG - response_closed.started


2024-04-21 11:28:31,572 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1018'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'598928'), (b'x-ratelimit-reset-requests', b'69ms'), (b'x-ratelimit-reset-tokens', b'107ms'), (b'x-request-id', b'req_530d978d01d7ab6e21d24468d866c856'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a3b760906-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,572 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,572 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,572 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,572 - DEBUG - response_closed.started


2024-04-21 11:28:31,572 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1024'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4998'), (b'x-ratelimit-remaining-tokens', b'599601'), (b'x-ratelimit-reset-requests', b'21ms'), (b'x-ratelimit-reset-tokens', b'39ms'), (b'x-request-id', b'req_e7712afbd01211b2a5adeaa346e22ac6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a39907e6e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,572 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,572 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,572 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,572 - DEBUG - response_closed.started


2024-04-21 11:28:31,572 - DEBUG - response_closed.complete


2024-04-21 11:28:31,576 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,576 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOqijaEIBEhlq5hkADj7MbIslK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wnEnAtOKHRlrLl0E13k9U3yw', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=300, total_tokens=305))


2024-04-21 11:28:31,577 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,577 - DEBUG - response_closed.complete


2024-04-21 11:28:31,580 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,581 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOzbD7U3mmb8CMtCOv0jqfC18L', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fNRvnZ6rfnfuLeqsltId3CRo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,581 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,581 - DEBUG - response_closed.complete


2024-04-21 11:28:31,584 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,584 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOJN1RGd5T7i7oedYkJ2QSrnOq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eSx6GLzIi9BMbSUT3uA1jMcZ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,584 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,584 - DEBUG - response_closed.complete


2024-04-21 11:28:31,588 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,588 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOWu1WSUrqUGH16vs6EeM0vbLJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_6YfvsbWpZmQ1c4x1vZtTLMgZ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,588 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,588 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1012'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4969'), (b'x-ratelimit-remaining-tokens', b'593305'), (b'x-ratelimit-reset-requests', b'360ms'), (b'x-ratelimit-reset-tokens', b'669ms'), (b'x-request-id', b'req_0b0d0732618fba30fa700e0465cb964c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a582108a6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,589 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,589 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,589 - DEBUG - response_closed.started


2024-04-21 11:28:31,589 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1009'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4971'), (b'x-ratelimit-remaining-tokens', b'593738'), (b'x-ratelimit-reset-requests', b'339ms'), (b'x-ratelimit-reset-tokens', b'626ms'), (b'x-request-id', b'req_4edb6943c91180b3caf62025f02ea12d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a5e412b84-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,589 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,589 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,589 - DEBUG - response_closed.started


2024-04-21 11:28:31,589 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1002'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'591053'), (b'x-ratelimit-reset-requests', b'490ms'), (b'x-ratelimit-reset-tokens', b'894ms'), (b'x-request-id', b'req_deaeb3209b9fcda7825909827ec1c67f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a69a683fd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,589 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,589 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,589 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,589 - DEBUG - response_closed.started


2024-04-21 11:28:31,590 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1031'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'598795'), (b'x-ratelimit-reset-requests', b'64ms'), (b'x-ratelimit-reset-tokens', b'120ms'), (b'x-request-id', b'req_4541e67ef75ef034d634adcbf0d076fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a4fca08f8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,590 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,590 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,590 - DEBUG - response_closed.started


2024-04-21 11:28:31,590 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1004'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'591044'), (b'x-ratelimit-reset-requests', b'482ms'), (b'x-ratelimit-reset-tokens', b'895ms'), (b'x-request-id', b'req_f67e2de06f6b97118da73f649d7d5572'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a79357d71-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,590 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,590 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,590 - DEBUG - response_closed.started


2024-04-21 11:28:31,590 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'989'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4953'), (b'x-ratelimit-remaining-tokens', b'589735'), (b'x-ratelimit-reset-requests', b'558ms'), (b'x-ratelimit-reset-tokens', b'1.026s'), (b'x-request-id', b'req_0b6b86ebef17c84976a37f124f1c1dff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a8a4908ac-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,590 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,590 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,591 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,591 - DEBUG - response_closed.started


2024-04-21 11:28:31,591 - DEBUG - response_closed.complete


2024-04-21 11:28:31,594 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,594 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOecxw1S7HnrXRRxY74x3v3cxK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_LbsUTmIML8FYqSxYXA7WVDjs', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,594 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,594 - DEBUG - response_closed.complete


2024-04-21 11:28:31,597 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,598 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOp9QLS6BGf9wOCZyJJ8ScSkhd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_51sgme7uZMY5gvi9is7gDUBw', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=286, total_tokens=291))


2024-04-21 11:28:31,598 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,598 - DEBUG - response_closed.complete


2024-04-21 11:28:31,601 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,601 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOsFWnrtpB4cT6zKKH8H2s517r', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_RLm2d1Bs354V98JN8ESEw9GF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=248, total_tokens=253))


2024-04-21 11:28:31,601 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,601 - DEBUG - response_closed.complete


2024-04-21 11:28:31,604 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,605 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOsu14Bgc4rw7NXPryxaa9ypu1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_K81Ofc0WbjEhqsBzxmyQeA42', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,605 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,605 - DEBUG - response_closed.complete


2024-04-21 11:28:31,608 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,608 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOEJp3r4cz3Gtxx7Oq2clMppZ3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HvYaEWNjRBylO81qstsLs4v6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=252, total_tokens=257))


2024-04-21 11:28:31,608 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,608 - DEBUG - response_closed.complete


2024-04-21 11:28:31,612 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,612 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOqO6tM0O9J7v9ihIVcFwGBZaz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PWs73fbCtjGE5L7s9AyE1TUP', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,612 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,612 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'998'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4943'), (b'x-ratelimit-remaining-tokens', b'587413'), (b'x-ratelimit-reset-requests', b'680ms'), (b'x-ratelimit-reset-tokens', b'1.258s'), (b'x-request-id', b'req_2099d2221ca3bf0e924900a56d47495d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a99187d76-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,612 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,612 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,612 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,612 - DEBUG - response_closed.started


2024-04-21 11:28:31,612 - DEBUG - response_closed.complete


2024-04-21 11:28:31,616 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,616 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOTbDxWurCv7RW12GpVaZbylq4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YwG1TPehAt9yu1qKidXwbHID', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,616 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,617 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'983'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4956'), (b'x-ratelimit-remaining-tokens', b'590238'), (b'x-ratelimit-reset-requests', b'525ms'), (b'x-ratelimit-reset-tokens', b'976ms'), (b'x-request-id', b'req_f69f32548e790c400e1381e363434ab6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a7a3e0d54-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,617 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,617 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,617 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,617 - DEBUG - response_closed.started


2024-04-21 11:28:31,617 - DEBUG - response_closed.complete


2024-04-21 11:28:31,621 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,621 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOiZRD8J012lgbe5XZx8E10NVM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_RLm2d1Bs354V98JN8ESEw9GF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,621 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,632 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'939'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4933'), (b'x-ratelimit-remaining-tokens', b'585295'), (b'x-ratelimit-reset-requests', b'794ms'), (b'x-ratelimit-reset-tokens', b'1.47s'), (b'x-request-id', b'req_3cd3bdfb57824b893ea049564db7e9c6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9a020ffb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,632 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,632 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,632 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,632 - DEBUG - response_closed.started


2024-04-21 11:28:31,632 - DEBUG - response_closed.complete


2024-04-21 11:28:31,635 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,636 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDONIs0NYrjHmmsLNRrHRwu6hn7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_s61BP3MZOg6tWCXYtau5Q1D1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,636 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,715 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1117'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4931'), (b'x-ratelimit-remaining-tokens', b'584720'), (b'x-ratelimit-reset-requests', b'823ms'), (b'x-ratelimit-reset-tokens', b'1.527s'), (b'x-request-id', b'req_ef0bfd77de2f3b65fb78cbed83080304'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9e692f38-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,715 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,715 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,715 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,715 - DEBUG - response_closed.started


2024-04-21 11:28:31,715 - DEBUG - response_closed.complete


2024-04-21 11:28:31,721 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,721 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOKxxqMh90eKPu1bsdIdAdiALh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OG4Bg8PRFuAxvXfCHrOGy5zB', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:31,721 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:31,840 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:31 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1294'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4989'), (b'x-ratelimit-remaining-tokens', b'597722'), (b'x-ratelimit-reset-requests', b'124ms'), (b'x-ratelimit-reset-tokens', b'227ms'), (b'x-request-id', b'req_83933f13ad5b90b34499e050256f3beb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a48c30fcf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:31,842 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:31,842 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:31,843 - DEBUG - receive_response_body.complete


2024-04-21 11:28:31,843 - DEBUG - response_closed.started


2024-04-21 11:28:31,843 - DEBUG - response_closed.complete


2024-04-21 11:28:31,857 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:31,858 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOs8W1N7bGdA5EzSxMvI2XQAWS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_U9lCe4S2N62KiNTqqBFwX98T', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=253, total_tokens=258))


2024-04-21 11:28:31,859 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:32,025 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1427'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4939'), (b'x-ratelimit-remaining-tokens', b'586677'), (b'x-ratelimit-reset-requests', b'722ms'), (b'x-ratelimit-reset-tokens', b'1.332s'), (b'x-request-id', b'req_2d2698cf2f9605f85c0b3c02b0e7949e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9bf57d0a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:32,026 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:32,026 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:32,027 - DEBUG - receive_response_body.complete


2024-04-21 11:28:32,027 - DEBUG - response_closed.started


2024-04-21 11:28:32,027 - DEBUG - response_closed.complete


2024-04-21 11:28:32,042 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:32,043 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOFnmgr7rfHX1URyhy4ULCcLbG', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_iCnls6VPhNXW7UC3MkQWUbsp', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=281, total_tokens=286))


2024-04-21 11:28:32,044 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:32,639 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1900'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599346'), (b'x-ratelimit-reset-requests', b'37ms'), (b'x-ratelimit-reset-tokens', b'65ms'), (b'x-request-id', b'req_6d0c9a7c1e872884412f068135f83d22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a49557ea1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:32,641 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:32,642 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:32,643 - DEBUG - receive_response_body.complete


2024-04-21 11:28:32,644 - DEBUG - response_closed.started


2024-04-21 11:28:32,645 - DEBUG - response_closed.complete


2024-04-21 11:28:32,665 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:32,667 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOj8ty7WKIHSCACjhEqE4AJM7L', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8OktOoIoWbHObclFNYrTWzFf', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:32,671 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:32,944 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:32 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2188'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4919'), (b'x-ratelimit-remaining-tokens', b'582158'), (b'x-ratelimit-reset-requests', b'966ms'), (b'x-ratelimit-reset-tokens', b'1.784s'), (b'x-request-id', b'req_8331057c139c771196533f732979219b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9ef52a95-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:32,946 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:32,947 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:32,948 - DEBUG - receive_response_body.complete


2024-04-21 11:28:32,949 - DEBUG - response_closed.started


2024-04-21 11:28:32,949 - DEBUG - response_closed.complete


2024-04-21 11:28:32,969 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:32,970 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDOHIIs6aBfBRG0W7pHRnCQ4vGl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3f7keMkwTCMNcBnQfCFxeHR2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724110, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:32,972 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:33,969 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'3379'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4937'), (b'x-ratelimit-remaining-tokens', b'586157'), (b'x-ratelimit-reset-requests', b'746ms'), (b'x-ratelimit-reset-tokens', b'1.384s'), (b'x-request-id', b'req_78dbe735b714284dd944eeb6bc0278d2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f2a9df72ad0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:33,971 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:33,971 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:33,972 - DEBUG - receive_response_body.complete


2024-04-21 11:28:33,973 - DEBUG - response_closed.started


2024-04-21 11:28:33,973 - DEBUG - response_closed.complete


2024-04-21 11:28:33,996 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:33,996 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDPgIpj1MzlmIvRMB7f5J098yQl', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_H60w9A9gmP4rDAoALoO13lx2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724111, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=258, total_tokens=263))


2024-04-21 11:28:33,997 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:34,000 - INFO - Sending messages to the model:
	{'role': 'system', 'content': 'The current primary prompt is not returning enough results. Please provide a new primary prompt that is more general.'}
	{'role': 'user', 'content': 'Current primary prompt: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}


2024-04-21 11:28:34,007 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.MakeNewPrimaryPrompt'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': 'The current primary prompt is not returning enough results. Please provide a new primary prompt that is more general.'}, {'role': 'user', 'content': 'Current primary prompt: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt', 'description': 'Correctly extracted `MakeNewPrimaryPrompt` with all the required parameters with correct types', 'parameters': {'properties': {'primary_prompt': {'description': 'Enter a new primary prompt.', 'title': 'Primary Prompt', 'type': 'string'}}, 'required': ['primary_prompt'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt'}}}


2024-04-21 11:28:34,007 - DEBUG - max_retries: 8


2024-04-21 11:28:34,007 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085e7af0>


2024-04-21 11:28:34,011 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': 'The current primary prompt is not returning enough results. Please provide a new primary prompt that is more general.'}, {'role': 'user', 'content': 'Current primary prompt: Search for tweets discussing the use of Large Language Models (LLMs) for creating, organizing, and managing scalable data trees with O(logn) complexity. Focus on finding content where users are exploring, agreeing with, or understanding the concept of using LLMs to navigate and store data in a metadata-driven tree structure, which is proposed as a solution for large-scale memory in AI systems.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt'}}, 'tools': [{'type': 'function', 'function': {'name': 'MakeNewPrimaryPrompt', 'description': 'Correctly extracted `MakeNewPrimaryPrompt` with all the required parameters with correct types', 'parameters': {'properties': {'primary_prompt': {'description': 'Enter a new primary prompt.', 'title': 'Primary Prompt', 'type': 'string'}}, 'required': ['primary_prompt'], 'type': 'object'}}}]}}


2024-04-21 11:28:34,019 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:34,020 - DEBUG - send_request_headers.complete


2024-04-21 11:28:34,020 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:34,020 - DEBUG - send_request_body.complete


2024-04-21 11:28:34,020 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:35,918 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1651'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599846'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'15ms'), (b'x-request-id', b'req_eed206b70226c2a8b9dd012f28337cb3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f40b8e52b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:35,920 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:35,920 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:35,921 - DEBUG - receive_response_body.complete


2024-04-21 11:28:35,921 - DEBUG - response_closed.started


2024-04-21 11:28:35,922 - DEBUG - response_closed.complete


2024-04-21 11:28:35,938 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:35,940 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDS7QhBXQgjEHITeEwSaQ2CYJfd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Kos5ecBdQjxUoBgo5IPLQRA7', function=Function(arguments='{"primary_prompt":"Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}', name='MakeNewPrimaryPrompt'), type='function')]))], created=1713724114, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=25, prompt_tokens=186, total_tokens=211))


2024-04-21 11:28:35,942 - INFO - Received completion from the model:
primary_prompt='Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'


2024-04-21 11:28:35,946 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:35,950 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:35,950 - DEBUG - max_retries: 8


2024-04-21 11:28:35,950 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085e4d90>


2024-04-21 11:28:35,955 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:35,965 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:35,967 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:35,967 - DEBUG - max_retries: 8


2024-04-21 11:28:35,967 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085e7e80>


2024-04-21 11:28:35,970 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:35,975 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:35,977 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:35,977 - DEBUG - max_retries: 8


2024-04-21 11:28:35,977 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085e6560>


2024-04-21 11:28:35,981 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:35,986 - DEBUG - close.started


2024-04-21 11:28:35,986 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:35,987 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:35,987 - DEBUG - max_retries: 8


2024-04-21 11:28:35,987 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085dbb20>


2024-04-21 11:28:35,990 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:35,995 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:35,997 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:35,997 - DEBUG - max_retries: 8


2024-04-21 11:28:35,997 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085d9ba0>


2024-04-21 11:28:35,999 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,004 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,005 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,005 - DEBUG - max_retries: 8


2024-04-21 11:28:36,005 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085d9240>


2024-04-21 11:28:36,008 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,012 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,013 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,013 - DEBUG - max_retries: 8


2024-04-21 11:28:36,013 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085d9840>


2024-04-21 11:28:36,015 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,020 - DEBUG - close.started


2024-04-21 11:28:36,020 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,020 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,020 - DEBUG - max_retries: 8


2024-04-21 11:28:36,021 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085cf520>


2024-04-21 11:28:36,023 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,027 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \n\nThe next st…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,028 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \n\nThe next st…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,028 - DEBUG - max_retries: 8


2024-04-21 11:28:36,028 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085cea70>


2024-04-21 11:28:36,030 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @adamkhootrader: The first stage of the A.I Revolution was Large Language Models like ChatGPPT, Google Gemini and Meta AI. \n\nThe next st…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,034 - DEBUG - close.started


2024-04-21 11:28:36,034 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,035 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,035 - DEBUG - max_retries: 8


2024-04-21 11:28:36,035 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085cd750>


2024-04-21 11:28:36,059 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,063 - DEBUG - close.started


2024-04-21 11:28:36,063 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @ShardsOfficial 🔗 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let's shape the future together! 🌐🚀 #blockchain\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,064 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @ShardsOfficial 🔗 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let's shape the future together! 🌐🚀 #blockchain\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,064 - DEBUG - max_retries: 8


2024-04-21 11:28:36,064 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103d367d0>


2024-04-21 11:28:36,066 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @ShardsOfficial 🔗 Explore the decentralized future with @shardsofficial! Shards is redefining blockchain scalability and security with its innovative approach. Join the journey towards a more efficient, resilient, and interconnected ecosystem. Let's shape the future together! 🌐🚀 #blockchain\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,069 - DEBUG - close.started


2024-04-21 11:28:36,069 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @NexAcademyx: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 1…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,070 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @NexAcademyx: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 1…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,070 - DEBUG - max_retries: 8


2024-04-21 11:28:36,070 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085cd480>


2024-04-21 11:28:36,072 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @NexAcademyx: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 1…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,075 - DEBUG - close.started


2024-04-21 11:28:36,075 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,075 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,075 - DEBUG - max_retries: 8


2024-04-21 11:28:36,075 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f33dc0>


2024-04-21 11:28:36,077 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,081 - DEBUG - close.started


2024-04-21 11:28:36,081 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,081 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,081 - DEBUG - max_retries: 8


2024-04-21 11:28:36,081 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f339d0>


2024-04-21 11:28:36,083 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,086 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,087 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,087 - DEBUG - max_retries: 8


2024-04-21 11:28:36,087 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f31de0>


2024-04-21 11:28:36,089 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,092 - DEBUG - close.started


2024-04-21 11:28:36,092 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,092 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,092 - DEBUG - max_retries: 8


2024-04-21 11:28:36,092 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085c4c70>


2024-04-21 11:28:36,094 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,098 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,098 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,098 - DEBUG - max_retries: 8


2024-04-21 11:28:36,098 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e5b370>


2024-04-21 11:28:36,100 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,103 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,104 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,104 - DEBUG - max_retries: 8


2024-04-21 11:28:36,104 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e59ae0>


2024-04-21 11:28:36,106 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,109 - DEBUG - close.started


2024-04-21 11:28:36,109 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\nThe differentia…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,109 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\nThe differentia…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,109 - DEBUG - max_retries: 8


2024-04-21 11:28:36,109 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085b6560>


2024-04-21 11:28:36,111 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SPcrypt0: Am I dreaming, or is this reality? The momentum behind $ALPH feels reminiscent of the early days of Ethereum.\nThe differentia…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,114 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: traits/metadata updated soon!!!\n\nlook out for 42069 main characters, overlays\n\nand the super rare golden guns\n\nnice https://t.co/WFON5jZ9CB\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,115 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: traits/metadata updated soon!!!\n\nlook out for 42069 main characters, overlays\n\nand the super rare golden guns\n\nnice https://t.co/WFON5jZ9CB\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,115 - DEBUG - max_retries: 8


2024-04-21 11:28:36,115 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e5ace0>


2024-04-21 11:28:36,117 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: traits/metadata updated soon!!!\n\nlook out for 42069 main characters, overlays\n\nand the super rare golden guns\n\nnice https://t.co/WFON5jZ9CB\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,120 - DEBUG - close.started


2024-04-21 11:28:36,120 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,120 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,120 - DEBUG - max_retries: 8


2024-04-21 11:28:36,120 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085a6170>


2024-04-21 11:28:36,122 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @withmoodxtnt: อัลบั้ม Data storage ของพ้อกสีค้าบ ดีเทลจุกๆ งานอาร์ตสาแก่ใจ ของดีทีป้อปมาก 😭 https://t.co/CaJ7qRAs9C\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,125 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,126 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,126 - DEBUG - max_retries: 8


2024-04-21 11:28:36,126 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085999f0>


2024-04-21 11:28:36,128 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,131 - DEBUG - close.started


2024-04-21 11:28:36,131 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,131 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,131 - DEBUG - max_retries: 8


2024-04-21 11:28:36,131 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108599e10>


2024-04-21 11:28:36,133 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,136 - DEBUG - close.started


2024-04-21 11:28:36,136 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,137 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,137 - DEBUG - max_retries: 8


2024-04-21 11:28:36,137 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085a42b0>


2024-04-21 11:28:36,139 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,141 - DEBUG - close.started


2024-04-21 11:28:36,141 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @LDN_Blockchain Not gonna lie, I'm pretty impressed by the technical details of Jiritsu's Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,142 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @LDN_Blockchain Not gonna lie, I'm pretty impressed by the technical details of Jiritsu's Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,142 - DEBUG - max_retries: 8


2024-04-21 11:28:36,142 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10858e440>


2024-04-21 11:28:36,144 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @LDN_Blockchain Not gonna lie, I'm pretty impressed by the technical details of Jiritsu's Zero-Knowledge Consensus. The blend of blockchain, cryptography and AI verification is really innovative. My main question is around scalability - how will this perform at enterprise scale?\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,147 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,148 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,148 - DEBUG - max_retries: 8


2024-04-21 11:28:36,148 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10858c100>


2024-04-21 11:28:36,150 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,152 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,153 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,153 - DEBUG - max_retries: 8


2024-04-21 11:28:36,153 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085825c0>


2024-04-21 11:28:36,155 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,158 - DEBUG - close.started


2024-04-21 11:28:36,158 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,158 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,158 - DEBUG - max_retries: 8


2024-04-21 11:28:36,158 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e650f0>


2024-04-21 11:28:36,160 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,163 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 100K Tps and infinitely scalability\n@NexaMoney \n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,163 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 100K Tps and infinitely scalability\n@NexaMoney \n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,163 - DEBUG - max_retries: 8


2024-04-21 11:28:36,163 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108582c20>


2024-04-21 11:28:36,165 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Nexa is;\nBetter Security than #Bitcoin\nMore Capacity than #Solana\nand as much programmability as #ethereum\nThat is #Nexa 100K Tps and infinitely scalability\n@NexaMoney \n#MEXC #Binance #gate #bybit https://t.co/Hjrblo6h6B\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,168 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @wardenprotocol: Warden Whitepaper is released\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,169 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @wardenprotocol: Warden Whitepaper is released\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,169 - DEBUG - max_retries: 8


2024-04-21 11:28:36,169 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e78820>


2024-04-21 11:28:36,171 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @wardenprotocol: Warden Whitepaper is released\nModular, secure &amp; incentivized. Warden introduces a new paradigm for blockchain applicati…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,173 - DEBUG - close.started


2024-04-21 11:28:36,174 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,174 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,174 - DEBUG - max_retries: 8


2024-04-21 11:28:36,174 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e78640>


2024-04-21 11:28:36,176 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,179 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,179 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,179 - DEBUG - max_retries: 8


2024-04-21 11:28:36,179 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e79d80>


2024-04-21 11:28:36,181 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: EOS: https://t.co/nTinl1WDEd: https://t.co/nTinl1WDEd is a blockchain platform that aims to provide high scalability and fast transaction processing for decentralized applications. $BAMA | #Bitbama | #R2E.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,184 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @Pawan2001564157 @SenderLabs 282.   "Ethereum\'s scalability solutions: addressing network congestion.   🌐🚧"\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,185 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @Pawan2001564157 @SenderLabs 282.   "Ethereum\'s scalability solutions: addressing network congestion.   🌐🚧"\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,185 - DEBUG - max_retries: 8


2024-04-21 11:28:36,185 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e7ab30>


2024-04-21 11:28:36,187 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @Pawan2001564157 @SenderLabs 282.   "Ethereum\'s scalability solutions: addressing network congestion.   🌐🚧"\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,189 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,190 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,190 - DEBUG - max_retries: 8


2024-04-21 11:28:36,190 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103e7a230>


2024-04-21 11:28:36,192 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,194 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,195 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,195 - DEBUG - max_retries: 8


2024-04-21 11:28:36,195 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10823b820>


2024-04-21 11:28:36,197 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,200 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,200 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,200 - DEBUG - max_retries: 8


2024-04-21 11:28:36,200 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10823b610>


2024-04-21 11:28:36,202 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,205 - DEBUG - close.started


2024-04-21 11:28:36,205 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,205 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,205 - DEBUG - max_retries: 8


2024-04-21 11:28:36,205 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10823a470>


2024-04-21 11:28:36,207 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,210 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,211 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,211 - DEBUG - max_retries: 8


2024-04-21 11:28:36,211 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10820a680>


2024-04-21 11:28:36,212 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,215 - DEBUG - close.started


2024-04-21 11:28:36,215 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,216 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,216 - DEBUG - max_retries: 8


2024-04-21 11:28:36,216 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1082093c0>


2024-04-21 11:28:36,218 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,220 - DEBUG - close.started


2024-04-21 11:28:36,220 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,221 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,221 - DEBUG - max_retries: 8


2024-04-21 11:28:36,221 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108209ab0>


2024-04-21 11:28:36,223 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,225 - DEBUG - close.started


2024-04-21 11:28:36,225 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,226 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,226 - DEBUG - max_retries: 8


2024-04-21 11:28:36,226 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10820b370>


2024-04-21 11:28:36,228 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,230 - DEBUG - close.started


2024-04-21 11:28:36,230 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,231 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,231 - DEBUG - max_retries: 8


2024-04-21 11:28:36,231 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108208310>


2024-04-21 11:28:36,233 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Cookie3_com: 🍪 High Throughput: Faster transaction processing.\n🍪 Lower Fees: Lower transaction costs.\n🍪 Compatibility: Seamless integra…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,235 - DEBUG - close.started


2024-04-21 11:28:36,235 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,236 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,236 - DEBUG - max_retries: 8


2024-04-21 11:28:36,236 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826b1c0>


2024-04-21 11:28:36,238 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Scroll_Bet: By prioritizing user experience, security, and scalability, https://t.co/9mDqf3p3qc aims to revolutionize the online casino…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,240 - DEBUG - close.started


2024-04-21 11:28:36,240 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,241 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,241 - DEBUG - max_retries: 8


2024-04-21 11:28:36,241 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826a170>


2024-04-21 11:28:36,243 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,245 - DEBUG - close.started


2024-04-21 11:28:36,245 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,246 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,246 - DEBUG - max_retries: 8


2024-04-21 11:28:36,246 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826b820>


2024-04-21 11:28:36,248 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,250 - DEBUG - close.started


2024-04-21 11:28:36,250 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,250 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,250 - DEBUG - max_retries: 8


2024-04-21 11:28:36,250 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108577e80>


2024-04-21 11:28:36,252 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,254 - DEBUG - close.started


2024-04-21 11:28:36,255 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,255 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,255 - DEBUG - max_retries: 8


2024-04-21 11:28:36,255 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108577ee0>


2024-04-21 11:28:36,257 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @xallyai: 🌐 Big News on the Horizon! 🚀\n\nWe're thrilled to hint at a groundbreaking partnership with the first modular #blockchain metapr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,259 - DEBUG - close.started


2024-04-21 11:28:36,259 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\n\nLarge language models are real AI that is smarter than 99…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,260 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\n\nLarge language models are real AI that is smarter than 99…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,260 - DEBUG - max_retries: 8


2024-04-21 11:28:36,260 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10826a290>


2024-04-21 11:28:36,262 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @sashayanshin: Chat GPT is going to take all our jobs by the end of the year.\n\nLarge language models are real AI that is smarter than 99…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,264 - DEBUG - close.started


2024-04-21 11:28:36,264 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,264 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,264 - DEBUG - max_retries: 8


2024-04-21 11:28:36,264 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108574eb0>


2024-04-21 11:28:36,266 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @SpectraChain: Post-Bitcoin halving, SpectraChain stands to significantly influence the cryptocurrency landscape by providing critical s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,268 - DEBUG - close.started


2024-04-21 11:28:36,268 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,269 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,269 - DEBUG - max_retries: 8


2024-04-21 11:28:36,269 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108575180>


2024-04-21 11:28:36,271 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,273 - DEBUG - close.started


2024-04-21 11:28:36,273 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @usesendtokens: ⚡️Bitcoin's future is bright!⚡️ Sendtokens integrates with @Photon_L2  by @SatoshiSync!\n\nThis unlocks:\n\nScalability for…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,273 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @usesendtokens: ⚡️Bitcoin's future is bright!⚡️ Sendtokens integrates with @Photon_L2  by @SatoshiSync!\n\nThis unlocks:\n\nScalability for…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,273 - DEBUG - max_retries: 8


2024-04-21 11:28:36,273 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f00ca0>


2024-04-21 11:28:36,276 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @usesendtokens: ⚡️Bitcoin's future is bright!⚡️ Sendtokens integrates with @Photon_L2  by @SatoshiSync!\n\nThis unlocks:\n\nScalability for…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,277 - DEBUG - close.started


2024-04-21 11:28:36,277 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,278 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,278 - DEBUG - max_retries: 8


2024-04-21 11:28:36,278 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f03ca0>


2024-04-21 11:28:36,280 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,282 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,282 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,282 - DEBUG - max_retries: 8


2024-04-21 11:28:36,282 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f014b0>


2024-04-21 11:28:36,284 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: Funding within the program will encompass validators, node operators, service providers, and key entities crucial for the upkeep and expansion of the TON blockchain network, ensuring its resilience and scalability, as outlined in the accompanying thread.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,286 - DEBUG - close.started


2024-04-21 11:28:36,286 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,287 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,287 - DEBUG - max_retries: 8


2024-04-21 11:28:36,287 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f00880>


2024-04-21 11:28:36,289 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,291 - DEBUG - close.started


2024-04-21 11:28:36,291 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @KrystalVil96992 ⚰ ️ ️ 🍉 🌗 9167188853 🦜 ️ 🎍 Who tree structure receive guy guess run.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,291 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @KrystalVil96992 ⚰ ️ ️ 🍉 🌗 9167188853 🦜 ️ 🎍 Who tree structure receive guy guess run.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,291 - DEBUG - max_retries: 8


2024-04-21 11:28:36,291 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f22080>


2024-04-21 11:28:36,293 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @KrystalVil96992 ⚰ ️ ️ 🍉 🌗 9167188853 🦜 ️ 🎍 Who tree structure receive guy guess run.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,295 - DEBUG - close.started


2024-04-21 11:28:36,295 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,296 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,296 - DEBUG - max_retries: 8


2024-04-21 11:28:36,296 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f23c70>


2024-04-21 11:28:36,298 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @palmaierc: 🌴 $PALM Utility Showcase: AI Location Search\n\n📷 Recently we've noticed people using PaLM AI to identify locations based on p…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,299 - DEBUG - close.started


2024-04-21 11:28:36,299 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: 6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. 🔐💡\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,300 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: 6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. 🔐💡\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,300 - DEBUG - max_retries: 8


2024-04-21 11:28:36,300 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f237f0>


2024-04-21 11:28:36,302 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: 6/ At the core, Skate operates within the Execution and Consensus layers of the blockchain stack, offering scalability and trust. 🔐💡\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,303 - DEBUG - close.started


2024-04-21 11:28:36,303 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,304 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,304 - DEBUG - max_retries: 8


2024-04-21 11:28:36,304 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f230a0>


2024-04-21 11:28:36,306 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,307 - DEBUG - close.started


2024-04-21 11:28:36,307 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,308 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,308 - DEBUG - max_retries: 8


2024-04-21 11:28:36,308 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103f22c80>


2024-04-21 11:28:36,310 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,312 - DEBUG - close.started


2024-04-21 11:28:36,312 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,312 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,312 - DEBUG - max_retries: 8


2024-04-21 11:28:36,312 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10856aef0>


2024-04-21 11:28:36,314 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,316 - DEBUG - close.started


2024-04-21 11:28:36,316 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,316 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,316 - DEBUG - max_retries: 8


2024-04-21 11:28:36,316 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10856ad70>


2024-04-21 11:28:36,318 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @vrjar_: metadata refreshed, everything looks ok now ✨\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,320 - DEBUG - close.started


2024-04-21 11:28:36,320 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,320 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,320 - DEBUG - max_retries: 8


2024-04-21 11:28:36,320 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108568850>


2024-04-21 11:28:36,323 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,324 - DEBUG - close.started


2024-04-21 11:28:36,324 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,325 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,325 - DEBUG - max_retries: 8


2024-04-21 11:28:36,325 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108569b40>


2024-04-21 11:28:36,327 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,328 - DEBUG - close.started


2024-04-21 11:28:36,328 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @burkov: I see too many people don’t understand why Meta spends billions to train and then gives away its large language models. They th…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,329 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @burkov: I see too many people don’t understand why Meta spends billions to train and then gives away its large language models. They th…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,329 - DEBUG - max_retries: 8


2024-04-21 11:28:36,329 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108568ca0>


2024-04-21 11:28:36,331 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @burkov: I see too many people don’t understand why Meta spends billions to train and then gives away its large language models. They th…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,332 - DEBUG - close.started


2024-04-21 11:28:36,332 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,333 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,333 - DEBUG - max_retries: 8


2024-04-21 11:28:36,333 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10838b760>


2024-04-21 11:28:36,335 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,336 - DEBUG - close.started


2024-04-21 11:28:36,336 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,336 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,336 - DEBUG - max_retries: 8


2024-04-21 11:28:36,336 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10838a860>


2024-04-21 11:28:36,338 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,340 - DEBUG - close.started


2024-04-21 11:28:36,340 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,340 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,340 - DEBUG - max_retries: 8


2024-04-21 11:28:36,340 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10838b670>


2024-04-21 11:28:36,342 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Sagaxyz__: Infinite horizontal scalability.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,343 - DEBUG - close.started


2024-04-21 11:28:36,343 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,344 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,344 - DEBUG - max_retries: 8


2024-04-21 11:28:36,344 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083f9300>


2024-04-21 11:28:36,346 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,347 - DEBUG - close.started


2024-04-21 11:28:36,347 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,348 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,348 - DEBUG - max_retries: 8


2024-04-21 11:28:36,348 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083f8af0>


2024-04-21 11:28:36,350 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,351 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,352 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,352 - DEBUG - max_retries: 8


2024-04-21 11:28:36,352 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083fbac0>


2024-04-21 11:28:36,354 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Bilal62971019: @SkillfulAI -Skillful AI ensures that its users remain at the cutting edge of technological advancements by leveraging e…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,355 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\n\nHe began with a reality check: "Machine Learning falls s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,355 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\n\nHe began with a reality check: "Machine Learning falls s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,355 - DEBUG - max_retries: 8


2024-04-21 11:28:36,355 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083faef0>


2024-04-21 11:28:36,357 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TheTuringPost: Yann LeCun @ylecun delivered a lecture on Objective-Driven AI.\n\nHe began with a reality check: "Machine Learning falls s…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,358 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,359 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,359 - DEBUG - max_retries: 8


2024-04-21 11:28:36,359 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c13f0>


2024-04-21 11:28:36,361 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,362 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,363 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,363 - DEBUG - max_retries: 8


2024-04-21 11:28:36,363 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c0520>


2024-04-21 11:28:36,365 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,366 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @DaanCrypto "Incredible potentials here! With features focused on scalability and security, this project is set for big things." @TRUMP2024_TOKEN\n#Trump2024Token https://t.co/LQFNowRXUy\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,367 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @DaanCrypto "Incredible potentials here! With features focused on scalability and security, this project is set for big things." @TRUMP2024_TOKEN\n#Trump2024Token https://t.co/LQFNowRXUy\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,367 - DEBUG - max_retries: 8


2024-04-21 11:28:36,367 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c1270>


2024-04-21 11:28:36,369 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @DaanCrypto "Incredible potentials here! With features focused on scalability and security, this project is set for big things." @TRUMP2024_TOKEN\n#Trump2024Token https://t.co/LQFNowRXUy\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,370 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @Lauramaywendel future ai systems. Open AI have two really big cards under it's sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,370 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @Lauramaywendel future ai systems. Open AI have two really big cards under it's sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,370 - DEBUG - max_retries: 8


2024-04-21 11:28:36,370 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083c38b0>


2024-04-21 11:28:36,372 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @Lauramaywendel future ai systems. Open AI have two really big cards under it's sleave, one being Q Star and the other being Sora. If they can create a system that has a much more advanced world understanding, reasoning and the possibility of functioning as a baby AGI, that alone is enough.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,374 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,374 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,374 - DEBUG - max_retries: 8


2024-04-21 11:28:36,374 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10834a7a0>


2024-04-21 11:28:36,376 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,377 - DEBUG - close.started


2024-04-21 11:28:36,377 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,378 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,378 - DEBUG - max_retries: 8


2024-04-21 11:28:36,378 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083485e0>


2024-04-21 11:28:36,380 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,381 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,381 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,381 - DEBUG - max_retries: 8


2024-04-21 11:28:36,381 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083480a0>


2024-04-21 11:28:36,383 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,385 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,385 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,385 - DEBUG - max_retries: 8


2024-04-21 11:28:36,385 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083493c0>


2024-04-21 11:28:36,387 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,388 - DEBUG - close.started


2024-04-21 11:28:36,388 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,389 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,389 - DEBUG - max_retries: 8


2024-04-21 11:28:36,389 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1083484c0>


2024-04-21 11:28:36,391 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,392 - DEBUG - close.started


2024-04-21 11:28:36,392 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,392 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,392 - DEBUG - max_retries: 8


2024-04-21 11:28:36,392 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108365930>


2024-04-21 11:28:36,394 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,396 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,396 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,396 - DEBUG - max_retries: 8


2024-04-21 11:28:36,396 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108367550>


2024-04-21 11:28:36,398 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,399 - DEBUG - close.started


2024-04-21 11:28:36,399 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @jacksonhinklle: 🚨🇮🇱🇺🇸 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,400 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @jacksonhinklle: 🚨🇮🇱🇺🇸 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,400 - DEBUG - max_retries: 8


2024-04-21 11:28:36,400 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x1085465c0>


2024-04-21 11:28:36,402 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @jacksonhinklle: 🚨🇮🇱🇺🇸 META has been accused of leaking user metadata to aid ISRAELI MILITARY TARGETING in GAZA! https://t.co/PFMgCPeLs1\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,403 - DEBUG - close.started


2024-04-21 11:28:36,403 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,404 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,404 - DEBUG - max_retries: 8


2024-04-21 11:28:36,404 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829eb90>


2024-04-21 11:28:36,406 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,407 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,407 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,407 - DEBUG - max_retries: 8


2024-04-21 11:28:36,407 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x108546680>


2024-04-21 11:28:36,409 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,410 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,411 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,411 - DEBUG - max_retries: 8


2024-04-21 11:28:36,411 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829fbb0>


2024-04-21 11:28:36,413 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,414 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,414 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,414 - DEBUG - max_retries: 8


2024-04-21 11:28:36,414 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x10829d120>


2024-04-21 11:28:36,416 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,417 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,418 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,418 - DEBUG - max_retries: 8


2024-04-21 11:28:36,418 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103edd270>


2024-04-21 11:28:36,420 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,421 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \n\n- Scalability \n- interoperability \n- Secure\n- Ma…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,422 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \n\n- Scalability \n- interoperability \n- Secure\n- Ma…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,422 - DEBUG - max_retries: 8


2024-04-21 11:28:36,422 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103edda50>


2024-04-21 11:28:36,424 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @CryptoD40425120: @shahh #SaitaChainBlockchain #LayerZero #SBC24 Your Layer0 Solution \n\n- Scalability \n- interoperability \n- Secure\n- Ma…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,425 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,425 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,425 - DEBUG - max_retries: 8


2024-04-21 11:28:36,425 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103edfc10>


2024-04-21 11:28:36,427 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @TDataScience: Are you (or your organization) thinking of integrating knowledge graphs and LLMs at the enterprise level? @SteveHedden sh…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,428 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,429 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,429 - DEBUG - max_retries: 8


2024-04-21 11:28:36,429 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ede9e0>


2024-04-21 11:28:36,431 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,432 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,432 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,432 - DEBUG - max_retries: 8


2024-04-21 11:28:36,432 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ede7a0>


2024-04-21 11:28:36,434 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,435 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,436 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,436 - DEBUG - max_retries: 8


2024-04-21 11:28:36,436 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed5720>


2024-04-21 11:28:36,438 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,439 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,440 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,440 - DEBUG - max_retries: 8


2024-04-21 11:28:36,440 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed5600>


2024-04-21 11:28:36,442 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: RT @Web3lounge_: Great news for all airdrop seekers! 💥\n\nA promising new project with substantial airdrop potential has appeared. Let's welc…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,443 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,443 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,443 - DEBUG - max_retries: 8


2024-04-21 11:28:36,443 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed46d0>


2024-04-21 11:28:36,445 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Somnia_Network: #Somnia’s L1 and omnichain protocol is bridging fragmented virtual worlds to create a unified, scalable society for mil…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,446 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': "Tweet: @boyney123 I've not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I'd prefer the central project to simply point at each service repo an pull the metadata from there.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}


2024-04-21 11:28:36,447 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @boyney123 I've not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I'd prefer the central project to simply point at each service repo an pull the metadata from there.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,447 - DEBUG - max_retries: 8


2024-04-21 11:28:36,447 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed7e50>


2024-04-21 11:28:36,449 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': "Tweet: @boyney123 I've not looked at it in any depth but my one bug bear is having it all centralised. In my environment, where eachbservive has its own git repo, I'd prefer the central project to simply point at each service repo an pull the metadata from there.\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization."}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,450 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: @ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\nfor Exemple ChatGPT\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,450 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\nfor Exemple ChatGPT\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,450 - DEBUG - max_retries: 8


2024-04-21 11:28:36,450 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103ed7b80>


2024-04-21 11:28:36,452 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: @ahmed_fawzy0000 LLMs==Large Language Models == powerful AI designed to understand our language\nfor Exemple ChatGPT\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,453 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,454 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,454 - DEBUG - max_retries: 8


2024-04-21 11:28:36,454 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103eee4a0>


2024-04-21 11:28:36,456 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,457 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,457 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,457 - DEBUG - max_retries: 8


2024-04-21 11:28:36,457 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103eef130>


2024-04-21 11:28:36,459 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Revolving_Games: Power Status: 100% ️🔋\n\nNexian Gems...\nREFRESH YOUR METADATA.\n\nThe upgrade is complete. Nexian Gems have officially evo…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,460 - INFO - Sending messages to the model:
	{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}
	{'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}


2024-04-21 11:28:36,461 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.filter.ValidateTweet'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}}


2024-04-21 11:28:36,461 - DEBUG - max_retries: 8


2024-04-21 11:28:36,461 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103eee590>


2024-04-21 11:28:36,463 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'system', 'content': "You'll be shown a tweet and also a prompt describing what the user is looking for in tweets. If the tweet is what the user is looking for, set valid to true. If it is not, set valid to false. Respond with 'true' or 'false'."}, {'role': 'user', 'content': 'Tweet: RT @Crypto_OxineEth: Exciting news for all airdrop enthusiasts! 🎉\n\nAn up-and-coming project with great airdrop potential has surfaced. Intr…\n\nFilter: Search for tweets discussing the use of Large Language Models (LLMs) in data management and organization.'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'ValidateTweet'}}, 'tools': [{'type': 'function', 'function': {'name': 'ValidateTweet', 'description': 'Correctly extracted `ValidateTweet` with all the required parameters with correct types', 'parameters': {'properties': {'valid': {'description': 'Whether the user would want this tweet.', 'title': 'Valid', 'type': 'boolean'}}, 'required': ['valid'], 'type': 'object'}}}]}}


2024-04-21 11:28:36,464 - DEBUG - close.started


2024-04-21 11:28:36,464 - DEBUG - close.complete


2024-04-21 11:28:36,464 - DEBUG - close.complete


2024-04-21 11:28:36,464 - DEBUG - close.complete


2024-04-21 11:28:36,464 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,465 - DEBUG - close.started


2024-04-21 11:28:36,465 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.started


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.started


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.started


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.started


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,466 - DEBUG - close.complete


2024-04-21 11:28:36,467 - DEBUG - close.complete


2024-04-21 11:28:36,467 - DEBUG - close.complete


2024-04-21 11:28:36,467 - DEBUG - close.complete


2024-04-21 11:28:36,467 - DEBUG - close.complete


2024-04-21 11:28:36,467 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,467 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,468 - DEBUG - close.complete


2024-04-21 11:28:36,468 - DEBUG - close.started


2024-04-21 11:28:36,468 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,468 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,468 - DEBUG - close.complete


2024-04-21 11:28:36,468 - DEBUG - close.started


2024-04-21 11:28:36,469 - DEBUG - close.started


2024-04-21 11:28:36,469 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,469 - DEBUG - close.complete


2024-04-21 11:28:36,469 - DEBUG - close.started


2024-04-21 11:28:36,470 - DEBUG - close.complete


2024-04-21 11:28:36,471 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,471 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,471 - DEBUG - close.complete


2024-04-21 11:28:36,472 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,472 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,472 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,473 - DEBUG - close.started


2024-04-21 11:28:36,474 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,475 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,475 - DEBUG - close.complete


2024-04-21 11:28:36,476 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,476 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,477 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,478 - DEBUG - close.started


2024-04-21 11:28:36,478 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,478 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,480 - DEBUG - close.complete


2024-04-21 11:28:36,480 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,480 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,480 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,482 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,482 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,482 - DEBUG - close.started


2024-04-21 11:28:36,483 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,483 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,484 - DEBUG - close.complete


2024-04-21 11:28:36,484 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,486 - DEBUG - close.started


2024-04-21 11:28:36,486 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,486 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,488 - DEBUG - close.complete


2024-04-21 11:28:36,488 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,488 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,488 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,490 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,490 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,490 - DEBUG - close.started


2024-04-21 11:28:36,491 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,491 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,492 - DEBUG - close.complete


2024-04-21 11:28:36,492 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,494 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,494 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,494 - DEBUG - close.started


2024-04-21 11:28:36,495 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,495 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,495 - DEBUG - close.complete


2024-04-21 11:28:36,495 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,497 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,497 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,499 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,499 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,499 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,500 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,500 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,502 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,502 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,502 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,504 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,504 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,504 - DEBUG - close.started


2024-04-21 11:28:36,505 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,505 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,506 - DEBUG - close.complete


2024-04-21 11:28:36,506 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,507 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,507 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,508 - DEBUG - close.started


2024-04-21 11:28:36,508 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,508 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,509 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,510 - DEBUG - close.complete


2024-04-21 11:28:36,510 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,510 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,511 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,511 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,511 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,513 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,513 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,514 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,514 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,514 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,515 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,515 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,516 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,516 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,516 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,517 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,517 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,518 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,518 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,518 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,519 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,519 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,520 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,520 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,521 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,522 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,522 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,522 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,522 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,523 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,523 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,523 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,524 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,524 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,524 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,525 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,525 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,526 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,526 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,526 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,527 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,527 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,527 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,527 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,527 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,528 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,528 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,528 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,528 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,528 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,528 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,529 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,529 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,530 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,531 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,531 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,531 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,531 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,532 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,532 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,532 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,532 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,532 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,532 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,533 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,533 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,533 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,533 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,533 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,534 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,534 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,534 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,534 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,534 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,535 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,535 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,535 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,535 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,535 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,536 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,536 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,536 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,536 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,537 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,537 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,537 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,537 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,537 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,538 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,538 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,538 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,538 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,539 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,539 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,539 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,539 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,540 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,540 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,540 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,540 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,541 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,541 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,541 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,541 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,542 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,542 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,542 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,542 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,543 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,543 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,543 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,544 - DEBUG - connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=5.0 socket_options=None


2024-04-21 11:28:36,544 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103ed4d30>


2024-04-21 11:28:36,544 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,545 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085a4160>


2024-04-21 11:28:36,545 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,545 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10823b760>


2024-04-21 11:28:36,545 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,545 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e7a6b0>


2024-04-21 11:28:36,546 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,547 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edfa00>


2024-04-21 11:28:36,547 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,547 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c0dc0>


2024-04-21 11:28:36,547 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,548 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085a6f50>


2024-04-21 11:28:36,548 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,548 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085a4c70>


2024-04-21 11:28:36,548 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,548 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edcf10>


2024-04-21 11:28:36,548 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,552 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515750>


2024-04-21 11:28:36,552 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,555 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec490>


2024-04-21 11:28:36,555 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,555 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eecf40>


2024-04-21 11:28:36,555 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec760>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829d330>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c1bd0>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515ff0>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edc4c0>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083f98d0>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108364f70>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e64970>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,556 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e7bfa0>


2024-04-21 11:28:36,556 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,557 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e64c40>


2024-04-21 11:28:36,557 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,557 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eef010>


2024-04-21 11:28:36,557 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,557 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085825f0>


2024-04-21 11:28:36,557 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,558 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10845be20>


2024-04-21 11:28:36,558 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,558 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10845ba30>


2024-04-21 11:28:36,558 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,558 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10823a290>


2024-04-21 11:28:36,558 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082391e0>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec550>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108459930>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eecc10>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10845bb50>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108459a50>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,559 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108459b70>


2024-04-21 11:28:36,559 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,561 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103c69690>


2024-04-21 11:28:36,561 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,561 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829f1c0>


2024-04-21 11:28:36,562 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,562 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ef5e0>


2024-04-21 11:28:36,562 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,562 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,562 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,562 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,562 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,562 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108269690>


2024-04-21 11:28:36,562 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,562 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f00700>


2024-04-21 11:28:36,562 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,562 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10859b820>


2024-04-21 11:28:36,562 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,563 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10826b6a0>


2024-04-21 11:28:36,563 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,563 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820b970>


2024-04-21 11:28:36,563 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,564 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514250>


2024-04-21 11:28:36,564 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,564 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edf340>


2024-04-21 11:28:36,564 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,564 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,564 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,564 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,564 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,565 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edd000>


2024-04-21 11:28:36,565 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085cc250>


2024-04-21 11:28:36,566 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,566 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e66140>


2024-04-21 11:28:36,566 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edd660>


2024-04-21 11:28:36,566 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,566 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,566 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,567 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,567 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,567 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,567 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,567 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108516b60>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eefdc0>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085161d0>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517250>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,568 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec0a0>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eede10>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108516410>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,568 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108569630>


2024-04-21 11:28:36,568 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,569 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10826b970>


2024-04-21 11:28:36,569 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,570 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fbcd0>


2024-04-21 11:28:36,570 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838b070>


2024-04-21 11:28:36,570 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108269ba0>


2024-04-21 11:28:36,570 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,570 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,570 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,570 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,570 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,570 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,570 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,570 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108547e80>


2024-04-21 11:28:36,570 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084591b0>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eef9d0>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108389a20>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838a050>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec520>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,571 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108366740>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085476a0>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,571 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ecf10>


2024-04-21 11:28:36,571 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,572 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085684f0>


2024-04-21 11:28:36,572 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,572 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108366500>


2024-04-21 11:28:36,572 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,572 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108367f10>


2024-04-21 11:28:36,572 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,573 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,573 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,573 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084edfc0>


2024-04-21 11:28:36,573 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,573 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ec310>


2024-04-21 11:28:36,573 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,573 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fa410>


2024-04-21 11:28:36,573 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,573 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,573 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,573 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108576320>


2024-04-21 11:28:36,573 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,573 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec370>


2024-04-21 11:28:36,573 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,574 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,574 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,574 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,574 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,574 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ed900>


2024-04-21 11:28:36,574 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,574 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108568e80>


2024-04-21 11:28:36,574 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,574 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085b5180>


2024-04-21 11:28:36,574 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,575 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10826a4a0>


2024-04-21 11:28:36,575 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,575 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108268ac0>


2024-04-21 11:28:36,575 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,575 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10823a710>


2024-04-21 11:28:36,576 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,576 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083f8f10>


2024-04-21 11:28:36,576 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108580cd0>


2024-04-21 11:28:36,577 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,577 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,577 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,577 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103edd8d0>


2024-04-21 11:28:36,577 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108367250>


2024-04-21 11:28:36,578 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c3be0>


2024-04-21 11:28:36,578 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108209360>


2024-04-21 11:28:36,578 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,578 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,578 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,578 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,578 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108364400>


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517640>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f21d80>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517430>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,580 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,580 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,580 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eeebf0>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082381f0>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517160>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - connect_tcp.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514cd0>


2024-04-21 11:28:36,580 - DEBUG - start_tls.started ssl_context=<ssl.SSLContext object at 0x102ff3d40> server_hostname='api.openai.com' timeout=5.0


2024-04-21 11:28:36,580 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,580 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,580 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,580 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,580 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,580 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,581 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,581 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,581 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,581 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10858d030>


2024-04-21 11:28:36,581 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c0f40>


2024-04-21 11:28:36,581 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e7a6e0>


2024-04-21 11:28:36,581 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108364520>


2024-04-21 11:28:36,581 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,581 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,581 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,581 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,582 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,582 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,582 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,582 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108209450>


2024-04-21 11:28:36,585 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,585 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,585 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,585 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,585 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,585 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,585 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,585 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,585 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,585 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,585 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103e790f0>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083493f0>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fafb0>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10829c9a0>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10838aaa0>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eded70>


2024-04-21 11:28:36,585 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108576a10>


2024-04-21 11:28:36,586 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103d35180>


2024-04-21 11:28:36,586 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103ede080>


2024-04-21 11:28:36,586 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c36d0>


2024-04-21 11:28:36,588 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,588 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,588 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,588 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,589 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,589 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,589 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103ed6470>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108514340>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f03e50>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108366440>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108238910>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f025c0>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108580f10>


2024-04-21 11:28:36,589 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083fa0e0>


2024-04-21 11:28:36,590 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,590 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,590 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,590 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,591 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,591 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,592 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,592 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f23010>


2024-04-21 11:28:36,592 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108268850>


2024-04-21 11:28:36,592 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082681f0>


2024-04-21 11:28:36,592 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085147c0>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,594 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,594 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,595 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,595 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085151b0>


2024-04-21 11:28:36,595 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c1210>


2024-04-21 11:28:36,595 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c21a0>


2024-04-21 11:28:36,595 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515570>


2024-04-21 11:28:36,595 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108547f10>


2024-04-21 11:28:36,596 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ed4e0>


2024-04-21 11:28:36,596 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1082686a0>


2024-04-21 11:28:36,596 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108516260>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,597 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,597 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,597 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,597 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,597 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,597 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,598 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515300>


2024-04-21 11:28:36,598 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108516f80>


2024-04-21 11:28:36,598 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ef790>


2024-04-21 11:28:36,598 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108269db0>


2024-04-21 11:28:36,599 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,599 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,599 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,599 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,599 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,599 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,599 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,600 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,600 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,600 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,600 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,600 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f219f0>


2024-04-21 11:28:36,600 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108516e60>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,603 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,603 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,604 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,604 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,604 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,604 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,604 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103f214b0>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c0370>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ee080>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10826b850>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c3490>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108581b40>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108208520>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1083c0df0>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085155d0>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10820a1d0>


2024-04-21 11:28:36,604 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108515e10>


2024-04-21 11:28:36,606 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,606 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,606 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,606 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,606 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,606 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,607 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,607 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,607 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,607 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517670>


2024-04-21 11:28:36,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517cd0>


2024-04-21 11:28:36,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x108517190>


2024-04-21 11:28:36,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x103eec610>


2024-04-21 11:28:36,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1085a6bc0>


2024-04-21 11:28:36,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x10834bf70>


2024-04-21 11:28:36,608 - DEBUG - start_tls.complete return_value=<httpcore._backends.anyio.AnyIOStream object at 0x1084ef160>


2024-04-21 11:28:36,608 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,608 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,608 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,608 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,608 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,609 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,609 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,609 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_headers.complete


2024-04-21 11:28:36,610 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:36,610 - DEBUG - send_request_body.complete


2024-04-21 11:28:36,610 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:37,041 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'399'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4998'), (b'x-ratelimit-remaining-tokens', b'599726'), (b'x-ratelimit-reset-requests', b'23ms'), (b'x-ratelimit-reset-tokens', b'27ms'), (b'x-request-id', b'req_16146c0f44b6b19a71596d65629ace49'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f500add2b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,043 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,043 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,044 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,045 - DEBUG - response_closed.started


2024-04-21 11:28:37,045 - DEBUG - response_closed.complete


2024-04-21 11:28:37,046 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,048 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUCicSNHFuJtF4hewM863otrTU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_qQvcdhqwMS7cXf87gQWb5LiX', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,050 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,050 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'350'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'598137'), (b'x-ratelimit-reset-requests', b'142ms'), (b'x-ratelimit-reset-tokens', b'186ms'), (b'x-request-id', b'req_94feeb10525f29d1be42bc6c8141e417'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f506ae22f38-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,051 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,051 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,051 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,051 - DEBUG - response_closed.started


2024-04-21 11:28:37,052 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:36 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4990'), (b'x-ratelimit-remaining-tokens', b'598465'), (b'x-ratelimit-reset-requests', b'116ms'), (b'x-ratelimit-reset-tokens', b'153ms'), (b'x-request-id', b'req_171cd00c1cf4ff0bed76a03729413749'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f506fe92ad0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,052 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,052 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,053 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,053 - DEBUG - response_closed.started


2024-04-21 11:28:37,053 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'405'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4992'), (b'x-ratelimit-remaining-tokens', b'598780'), (b'x-ratelimit-reset-requests', b'91ms'), (b'x-ratelimit-reset-tokens', b'121ms'), (b'x-request-id', b'req_492bababef11e0a8d52e9f2f47ada93f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f504e1708ac-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,053 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,054 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,054 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,054 - DEBUG - response_closed.started


2024-04-21 11:28:37,054 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'364'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597837'), (b'x-ratelimit-reset-requests', b'168ms'), (b'x-ratelimit-reset-tokens', b'216ms'), (b'x-request-id', b'req_797ba58fa1ebf3667c7e8cf12258a529'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5059022a95-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,055 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,055 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,055 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,055 - DEBUG - response_closed.started


2024-04-21 11:28:37,055 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'381'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4986'), (b'x-ratelimit-remaining-tokens', b'597917'), (b'x-ratelimit-reset-requests', b'158ms'), (b'x-ratelimit-reset-tokens', b'208ms'), (b'x-request-id', b'req_f12cbbcbbee537708d7167bc7b7e9dfc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5018ea0906-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,056 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,056 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,056 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,056 - DEBUG - response_closed.started


2024-04-21 11:28:37,056 - DEBUG - response_closed.complete


2024-04-21 11:28:37,057 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,058 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUDeOxloZnvrtLBaMI4LYim5s2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_L1DJIT1v0qdthLTOrlqtnIIa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,058 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,058 - DEBUG - response_closed.complete


2024-04-21 11:28:37,059 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,060 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUnU5AxFQGsC5tS6f39zrK3OcK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_HvCbsJD7pzHndr6cYQHT93X5', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,061 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,061 - DEBUG - response_closed.complete


2024-04-21 11:28:37,061 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,062 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUApVGcGI99UU5JfLz6CBgo9Qi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PnY0WS2b6E0uim0nPwqgwcA9', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=189, total_tokens=194))


2024-04-21 11:28:37,063 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,063 - DEBUG - response_closed.complete


2024-04-21 11:28:37,063 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,064 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUWQROhQL1K6Wk1ZGdXZUynqh8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dhrfgzzYPgNIClEBAEsKL2Be', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,064 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,064 - DEBUG - response_closed.complete


2024-04-21 11:28:37,065 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,065 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUQC7hfj1vPgsDOPWWujrVKDUa', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_wz5Y7bBp0A2TQZbkhc94GTLq', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=192, total_tokens=197))


2024-04-21 11:28:37,066 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,066 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'372'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4978'), (b'x-ratelimit-remaining-tokens', b'596759'), (b'x-ratelimit-reset-requests', b'258ms'), (b'x-ratelimit-reset-tokens', b'324ms'), (b'x-request-id', b'req_22b5ac711170987082e2030a8a05d703'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f509d3208a7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,066 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,066 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,067 - DEBUG - response_closed.started


2024-04-21 11:28:37,067 - DEBUG - response_closed.complete


2024-04-21 11:28:37,067 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,068 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUdQCyIpcse9fYBmKbhprCzM1o', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_oXfuEPYvi8TUUswG1GfZSCEo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,068 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,068 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'347'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4934'), (b'x-ratelimit-remaining-tokens', b'590311'), (b'x-ratelimit-reset-requests', b'787ms'), (b'x-ratelimit-reset-tokens', b'968ms'), (b'x-request-id', b'req_ff4ef5503a9744a27cd7581a610bd624'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ee4c1009-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,069 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,069 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,069 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,069 - DEBUG - response_closed.started


2024-04-21 11:28:37,069 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'376'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4978'), (b'x-ratelimit-remaining-tokens', b'596728'), (b'x-ratelimit-reset-requests', b'254ms'), (b'x-ratelimit-reset-tokens', b'327ms'), (b'x-request-id', b'req_d0b4b367385e369561facb46d49251b3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50bc432f26-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,069 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,069 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,070 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,070 - DEBUG - response_closed.started


2024-04-21 11:28:37,070 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'341'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4951'), (b'x-ratelimit-remaining-tokens', b'592733'), (b'x-ratelimit-reset-requests', b'580ms'), (b'x-ratelimit-reset-tokens', b'726ms'), (b'x-request-id', b'req_13c77f79b06ab44f0513472e2835a2b6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cee15220-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,070 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,070 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,070 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,070 - DEBUG - response_closed.started


2024-04-21 11:28:37,070 - DEBUG - response_closed.complete


2024-04-21 11:28:37,071 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,071 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUOYMwfHcyvzut95snB4Fe2nWM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Gng41twv42UAfIo1icWCApVA', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,071 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,071 - DEBUG - response_closed.complete


2024-04-21 11:28:37,072 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,072 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUXaR7KNwei07oQVtBV38Lu7Uj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PjccJNcSCwVew1XM18KEVri7', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,073 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,073 - DEBUG - response_closed.complete


2024-04-21 11:28:37,073 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,074 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUnR61iAHvYn6if3vB0254rrEf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_dhrfgzzYPgNIClEBAEsKL2Be', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,074 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,074 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'363'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4963'), (b'x-ratelimit-remaining-tokens', b'594620'), (b'x-ratelimit-reset-requests', b'432ms'), (b'x-ratelimit-reset-tokens', b'537ms'), (b'x-request-id', b'req_e5bedce7ac45fb5562a1e88e6ab131bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cc5e2f2d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,074 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,074 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,074 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,074 - DEBUG - response_closed.started


2024-04-21 11:28:37,075 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4986'), (b'x-ratelimit-remaining-tokens', b'597875'), (b'x-ratelimit-reset-requests', b'160ms'), (b'x-ratelimit-reset-tokens', b'212ms'), (b'x-request-id', b'req_d38ef2350f644da19486a93d41f890a1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5099640ffb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,075 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,075 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,075 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,075 - DEBUG - response_closed.started


2024-04-21 11:28:37,075 - DEBUG - response_closed.complete


2024-04-21 11:28:37,076 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,077 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUBXoI0jJ6F76FGnQhBsJfrpAR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ESR5eP493olmA16iarJiQzww', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=242, total_tokens=247))


2024-04-21 11:28:37,077 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,077 - DEBUG - response_closed.complete


2024-04-21 11:28:37,078 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,078 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUX8rgajBzb60Lb0emzGD9B5X2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_L1DJIT1v0qdthLTOrlqtnIIa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,078 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,078 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599838'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'16ms'), (b'x-request-id', b'req_31f42ceaa905d3551d2308851be26d37'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f500f157e6e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,079 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,079 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,079 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,079 - DEBUG - response_closed.started


2024-04-21 11:28:37,079 - DEBUG - response_closed.complete


2024-04-21 11:28:37,080 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,080 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUvl3Sqi2hNKDX5oX65JgD060v', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_6TUNKP3fk1tIokAeyjDls7h6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,080 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,081 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4958'), (b'x-ratelimit-remaining-tokens', b'593665'), (b'x-ratelimit-reset-requests', b'502ms'), (b'x-ratelimit-reset-tokens', b'633ms'), (b'x-request-id', b'req_240801c7993030903768f12256106901'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50caf478d8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,081 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,081 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,081 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,081 - DEBUG - response_closed.started


2024-04-21 11:28:37,081 - DEBUG - response_closed.complete


2024-04-21 11:28:37,082 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,082 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUQScVLlqAXA4WM3bJupJ0ATOH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Ma7oKzoZBDX0Q5cWmFcTyIah', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,082 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,092 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'388'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4946'), (b'x-ratelimit-remaining-tokens', b'592015'), (b'x-ratelimit-reset-requests', b'640ms'), (b'x-ratelimit-reset-tokens', b'798ms'), (b'x-request-id', b'req_f362fafdcbdb76567e98c9f4be135a2a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50db132ee7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,092 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,092 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,093 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,093 - DEBUG - response_closed.started


2024-04-21 11:28:37,093 - DEBUG - response_closed.complete


2024-04-21 11:28:37,094 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,094 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUQNkHpEFVZWws6vwAZz3zMKgr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Jr2YsVosHQwusTyo0AMKeFRH', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,094 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,098 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'383'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4932'), (b'x-ratelimit-remaining-tokens', b'590061'), (b'x-ratelimit-reset-requests', b'808ms'), (b'x-ratelimit-reset-tokens', b'993ms'), (b'x-request-id', b'req_addaef072ea4b69c87506312dae3924e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ef2378e0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,099 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,099 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,099 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,099 - DEBUG - response_closed.started


2024-04-21 11:28:37,099 - DEBUG - response_closed.complete


2024-04-21 11:28:37,100 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,100 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU0algRF0MV0Qjnk2CN22ghAkD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5T1ojJGZqEY7c225H7xvhmMc', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,100 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,101 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'395'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4996'), (b'x-ratelimit-remaining-tokens', b'599491'), (b'x-ratelimit-reset-requests', b'39ms'), (b'x-ratelimit-reset-tokens', b'50ms'), (b'x-request-id', b'req_f3d3223eac779ac83cfd1b5f0cc1a569'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f502e8808a6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,101 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,101 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,101 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,101 - DEBUG - response_closed.started


2024-04-21 11:28:37,101 - DEBUG - response_closed.complete


2024-04-21 11:28:37,102 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,102 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUVOBVCikyFwGaacoQCbDdqDhe', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VkJwn5Ww7ritG85Dec8z6Q25', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=191, total_tokens=196))


2024-04-21 11:28:37,102 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,104 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'397'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4936'), (b'x-ratelimit-remaining-tokens', b'590699'), (b'x-ratelimit-reset-requests', b'757ms'), (b'x-ratelimit-reset-tokens', b'930ms'), (b'x-request-id', b'req_3000ba86a56f0b5f81ebe25c4955fde1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dabf0925-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,104 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,104 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,104 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,105 - DEBUG - response_closed.started


2024-04-21 11:28:37,105 - DEBUG - response_closed.complete


2024-04-21 11:28:37,106 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,106 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU1o2wcgAEPAPul6cpWuM3BeVg', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_NkHNrvgGzgBz1Ui7lBIVifKt', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=187, total_tokens=192))


2024-04-21 11:28:37,106 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,135 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'524'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4995'), (b'x-ratelimit-remaining-tokens', b'599311'), (b'x-ratelimit-reset-requests', b'52ms'), (b'x-ratelimit-reset-tokens', b'68ms'), (b'x-request-id', b'req_73ad7274e17aa3db0293fe9b4c825fea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f503a342b8c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,135 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,135 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,135 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,135 - DEBUG - response_closed.started


2024-04-21 11:28:37,135 - DEBUG - response_closed.complete


2024-04-21 11:28:37,137 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,137 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUQwMdd0KIqmhqa7Nqtrhm9sMD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_GPqIUNHthny7BZIXXqfS7NzB', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=194, total_tokens=199))


2024-04-21 11:28:37,137 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,149 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'436'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4936'), (b'x-ratelimit-remaining-tokens', b'590564'), (b'x-ratelimit-reset-requests', b'764ms'), (b'x-ratelimit-reset-tokens', b'943ms'), (b'x-request-id', b'req_7db7fe8d2e79abfd6df6ac8342af3dcf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ec701029-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,149 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,149 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,149 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,149 - DEBUG - response_closed.started


2024-04-21 11:28:37,149 - DEBUG - response_closed.complete


2024-04-21 11:28:37,151 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,151 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUum0GJxHRJWfu7rMNn0wLydH2', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_re4jiiCPBK97fZCpvXTKzlnS', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=216, total_tokens=221))


2024-04-21 11:28:37,151 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,155 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'560'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599825'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'17ms'), (b'x-request-id', b'req_434dba18b4328909adb8b2f4841b5aac'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f502a837ea1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,155 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,155 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,155 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,155 - DEBUG - response_closed.started


2024-04-21 11:28:37,156 - DEBUG - response_closed.complete


2024-04-21 11:28:37,159 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,160 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU18bfpA7nMLLZU7rWpRfL1BkL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_m5fDUwJXqZmL09mHTWZsrhfD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,160 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,162 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'433'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4925'), (b'x-ratelimit-remaining-tokens', b'589136'), (b'x-ratelimit-reset-requests', b'893ms'), (b'x-ratelimit-reset-tokens', b'1.086s'), (b'x-request-id', b'req_b92b7a49a1491e1a3909bdf0f1b4142a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ebb35227-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,163 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,163 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,163 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,163 - DEBUG - response_closed.started


2024-04-21 11:28:37,163 - DEBUG - response_closed.complete


2024-04-21 11:28:37,166 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,166 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU91SGCIvBeqBSd6czfsU8QAmh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_82cCKlrCoffm9JaDGPPrRlO8', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,167 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,182 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'569'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4998'), (b'x-ratelimit-remaining-tokens', b'599747'), (b'x-ratelimit-reset-requests', b'17ms'), (b'x-ratelimit-reset-tokens', b'25ms'), (b'x-request-id', b'req_6b388c1b5838d7e0e9117358887246d5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50185d2ad5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,183 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,183 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,184 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,184 - DEBUG - response_closed.started


2024-04-21 11:28:37,184 - DEBUG - response_closed.complete


2024-04-21 11:28:37,187 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,188 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU126RGId4jEcLJPnvCBZRpfWK', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_LQrHYrLp7k8SS0IPtkHd4LVk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,189 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,202 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'493'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4939'), (b'x-ratelimit-remaining-tokens', b'591074'), (b'x-ratelimit-reset-requests', b'722ms'), (b'x-ratelimit-reset-tokens', b'892ms'), (b'x-request-id', b'req_30055275ce9cc8ac1031b43282869aad'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50db592b85-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,203 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,203 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,203 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,203 - DEBUG - response_closed.started


2024-04-21 11:28:37,204 - DEBUG - response_closed.complete


2024-04-21 11:28:37,207 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,207 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU4q3J9SZQ7qWe5wEqFiCtZoJj', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_4P2YGA51ML9QuDCpdpIVOtfo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,208 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,210 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'513'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4957'), (b'x-ratelimit-remaining-tokens', b'593600'), (b'x-ratelimit-reset-requests', b'506ms'), (b'x-ratelimit-reset-tokens', b'639ms'), (b'x-request-id', b'req_8ae89672dc2a94acb36d20ef28bd331a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50c9ee28f4-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,211 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,211 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,211 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,212 - DEBUG - response_closed.started


2024-04-21 11:28:37,212 - DEBUG - response_closed.complete


2024-04-21 11:28:37,215 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,216 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUEkAmDSjZ6yI4Mv4yZpbjWlz1', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ksRRJZdz02PY5R17D6G36XcV', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,217 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,217 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'588'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'599137'), (b'x-ratelimit-reset-requests', b'67ms'), (b'x-ratelimit-reset-tokens', b'86ms'), (b'x-request-id', b'req_1caf7930b12a7f31e2854e8c89a3d6b4'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5048877d71-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,218 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,218 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,218 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,218 - DEBUG - response_closed.started


2024-04-21 11:28:37,218 - DEBUG - response_closed.complete


2024-04-21 11:28:37,221 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,222 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUyIocrvYuRD9AfdMLRM6fBqEm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kr03gzJtPwnamYKstJ9EOmMe', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,223 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,223 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'497'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'599052'), (b'x-ratelimit-reset-requests', b'71ms'), (b'x-ratelimit-reset-tokens', b'94ms'), (b'x-request-id', b'req_15f063a31b3061d7e512842a2975c1e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f503e2283fd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,223 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,224 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,224 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,224 - DEBUG - response_closed.started


2024-04-21 11:28:37,224 - DEBUG - response_closed.complete


2024-04-21 11:28:37,227 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,227 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUchRSgaePV4f52EgKlBFWSRiu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_C7R9FgkC37tXCVEHf6Paptgr', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=242, total_tokens=247))


2024-04-21 11:28:37,228 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,240 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'440'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4964'), (b'x-ratelimit-remaining-tokens', b'594660'), (b'x-ratelimit-reset-requests', b'420ms'), (b'x-ratelimit-reset-tokens', b'533ms'), (b'x-request-id', b'req_485332ad63dd9375c837473dcf41b9b1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50c855db6a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,241 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,241 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,241 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,241 - DEBUG - response_closed.started


2024-04-21 11:28:37,241 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'447'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4976'), (b'x-ratelimit-remaining-tokens', b'596391'), (b'x-ratelimit-reset-requests', b'281ms'), (b'x-ratelimit-reset-tokens', b'360ms'), (b'x-request-id', b'req_34185ec63bba61823ab2b7a9cc494a9b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50aa442b9b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,242 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,242 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,242 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,242 - DEBUG - response_closed.started


2024-04-21 11:28:37,242 - DEBUG - response_closed.complete


2024-04-21 11:28:37,245 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,246 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUSPPJ9UUn8xbm2O8qQRnUuyso', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UmdQGGwaHiYS0s6G7i6sjbQD', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,246 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,246 - DEBUG - response_closed.complete


2024-04-21 11:28:37,249 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,250 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU6wrB9kCto2CrCcR70BrucGvd', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VkJwn5Ww7ritG85Dec8z6Q25', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,250 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,259 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'459'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4973'), (b'x-ratelimit-remaining-tokens', b'595987'), (b'x-ratelimit-reset-requests', b'314ms'), (b'x-ratelimit-reset-tokens', b'401ms'), (b'x-request-id', b'req_7b36592a62711a95aef871238404e811'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50bc207eb9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,260 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,260 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,260 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,260 - DEBUG - response_closed.started


2024-04-21 11:28:37,261 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'552'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'593912'), (b'x-ratelimit-reset-requests', b'481ms'), (b'x-ratelimit-reset-tokens', b'608ms'), (b'x-request-id', b'req_d84383a6c75415d66db7b70c50f61d3c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cb1c7d10-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,261 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,261 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,262 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,262 - DEBUG - response_closed.started


2024-04-21 11:28:37,262 - DEBUG - response_closed.complete


2024-04-21 11:28:37,265 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,265 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUE7WfHIN4JSkhQKvfo7ku56Hm', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Y2FX9OeKIVOJ2nuymLkuXaPE', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,266 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,266 - DEBUG - response_closed.complete


2024-04-21 11:28:37,269 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,269 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUq9gokX50zYnqfPSlNk8E8VCW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uDXi0qMoPhzeSkSmjskM5kvA', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,270 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,270 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'441'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4941'), (b'x-ratelimit-remaining-tokens', b'591374'), (b'x-ratelimit-reset-requests', b'696ms'), (b'x-ratelimit-reset-tokens', b'862ms'), (b'x-request-id', b'req_2b96c875f159585950be2d1becb97839'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50d8272f7b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,271 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,271 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,271 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,271 - DEBUG - response_closed.started


2024-04-21 11:28:37,271 - DEBUG - response_closed.complete


2024-04-21 11:28:37,274 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,274 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUIiGIxZ0uPjns90UZXhhor9fJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_O8Un3gudaeNNWisKgNt0Ecse', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=171, total_tokens=176))


2024-04-21 11:28:37,274 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,275 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'454'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4935'), (b'x-ratelimit-remaining-tokens', b'590452'), (b'x-ratelimit-reset-requests', b'775ms'), (b'x-ratelimit-reset-tokens', b'954ms'), (b'x-request-id', b'req_df6cd2734f3f1691c6e5ae1d1bdd3a54'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50e9547d89-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,275 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,275 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,275 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,275 - DEBUG - response_closed.started


2024-04-21 11:28:37,276 - DEBUG - response_closed.complete


2024-04-21 11:28:37,278 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,279 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUhawBGaR8NyES2dfsIkpC8g97', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Y2FX9OeKIVOJ2nuymLkuXaPE', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=171, total_tokens=176))


2024-04-21 11:28:37,279 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,279 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'478'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4924'), (b'x-ratelimit-remaining-tokens', b'588979'), (b'x-ratelimit-reset-requests', b'902ms'), (b'x-ratelimit-reset-tokens', b'1.102s'), (b'x-request-id', b'req_e7e1fb933c20679a748c0bd4b8df812f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eee908a8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,280 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,280 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,280 - DEBUG - response_closed.started


2024-04-21 11:28:37,280 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'511'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4969'), (b'x-ratelimit-remaining-tokens', b'595376'), (b'x-ratelimit-reset-requests', b'365ms'), (b'x-ratelimit-reset-tokens', b'462ms'), (b'x-request-id', b'req_da7d45843f35c74ffd7a342dd2863a13'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50bebb2b94-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,280 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,280 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,280 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,281 - DEBUG - response_closed.started


2024-04-21 11:28:37,281 - DEBUG - response_closed.complete


2024-04-21 11:28:37,283 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,283 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUQQJgseHDHbiHIJwSAuGfHdKN', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_i7UwYONmjEt0IzAvlmdyKDCk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=192, total_tokens=197))


2024-04-21 11:28:37,284 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,284 - DEBUG - response_closed.complete


2024-04-21 11:28:37,286 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,287 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUXbv83A6UjGlz2q1lCTwTXQ8N', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_5MdqvejirSREu3bAbrZyQb9m', function=Function(arguments='{"valid":true}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,287 - INFO - Received completion from the model:
valid=True


2024-04-21 11:28:37,287 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'543'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4988'), (b'x-ratelimit-remaining-tokens', b'598207'), (b'x-ratelimit-reset-requests', b'137ms'), (b'x-ratelimit-reset-tokens', b'179ms'), (b'x-request-id', b'req_3551be6d140d791b894ea35cfda8cb3e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5068b47d76-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,287 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,287 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,288 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,288 - DEBUG - response_closed.started


2024-04-21 11:28:37,288 - DEBUG - response_closed.complete


2024-04-21 11:28:37,290 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,290 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUipxehVxo8ijTsEHK2ylg1vQh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_O8Un3gudaeNNWisKgNt0Ecse', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,291 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,291 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'462'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4944'), (b'x-ratelimit-remaining-tokens', b'591746'), (b'x-ratelimit-reset-requests', b'663ms'), (b'x-ratelimit-reset-tokens', b'825ms'), (b'x-request-id', b'req_badfc96670b3d31ac57ace65147c31ab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dd6152cb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,291 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,291 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,291 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,291 - DEBUG - response_closed.started


2024-04-21 11:28:37,292 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'561'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'598928'), (b'x-ratelimit-reset-requests', b'78ms'), (b'x-ratelimit-reset-tokens', b'107ms'), (b'x-request-id', b'req_f19a167b3c705585e368f0fe6fef5462'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f504c240d54-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,292 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,292 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,292 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,292 - DEBUG - response_closed.started


2024-04-21 11:28:37,292 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'513'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4989'), (b'x-ratelimit-remaining-tokens', b'598344'), (b'x-ratelimit-reset-requests', b'126ms'), (b'x-ratelimit-reset-tokens', b'165ms'), (b'x-request-id', b'req_dae1fe8b9aefc35035110e45c4db9de8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5059240ffb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,292 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,292 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,293 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,293 - DEBUG - response_closed.started


2024-04-21 11:28:37,293 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'463'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4930'), (b'x-ratelimit-remaining-tokens', b'589789'), (b'x-ratelimit-reset-requests', b'831ms'), (b'x-ratelimit-reset-tokens', b'1.021s'), (b'x-request-id', b'req_f5c74bcb4069c4651c9a9daf71e553bc'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ee092f64-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,293 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,293 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,293 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,293 - DEBUG - response_closed.started


2024-04-21 11:28:37,293 - DEBUG - response_closed.complete


2024-04-21 11:28:37,296 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,296 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUIJIVyW2Wtudm2saJZKO6BIwk', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_yQxmicVOLam4FEs25hrYiejh', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,296 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,296 - DEBUG - response_closed.complete


2024-04-21 11:28:37,298 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,299 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUdSrO5IqN0uUgy6byCszqKC4w', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OI5IoSvahis9FH6KB6CKsJ9Z', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=212, total_tokens=217))


2024-04-21 11:28:37,299 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,299 - DEBUG - response_closed.complete


2024-04-21 11:28:37,301 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,301 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUa5F8tarqjVxnlf7Vqn61nuAp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_w6FFUuiYKj5oxaspXwPdr7v6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,302 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,302 - DEBUG - response_closed.complete


2024-04-21 11:28:37,304 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,304 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU6U34q9YqIJEp1WNSCKA78Gmz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0TPtdFyCYBq0d88ppPm2fFm6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,304 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,304 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'646'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4986'), (b'x-ratelimit-remaining-tokens', b'597873'), (b'x-ratelimit-reset-requests', b'167ms'), (b'x-ratelimit-reset-tokens', b'212ms'), (b'x-request-id', b'req_ea04a78c83baaf7f1aef421e2a8364e6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f5048b70fdb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,305 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,305 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,305 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,305 - DEBUG - response_closed.started


2024-04-21 11:28:37,305 - DEBUG - response_closed.complete


2024-04-21 11:28:37,307 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,307 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUl6O021F8lvVBBennDYq4b7M5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_YwG1TPehAt9yu1qKidXwbHID', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,307 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,308 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'510'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'588393'), (b'x-ratelimit-reset-requests', b'945ms'), (b'x-ratelimit-reset-tokens', b'1.16s'), (b'x-request-id', b'req_3b9893be8f9653ffb78b223011cc48f9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eb332aab-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,308 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,308 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,308 - DEBUG - response_closed.started


2024-04-21 11:28:37,308 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'534'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4963'), (b'x-ratelimit-remaining-tokens', b'594495'), (b'x-ratelimit-reset-requests', b'434ms'), (b'x-ratelimit-reset-tokens', b'550ms'), (b'x-request-id', b'req_ea4bbd132c7479bac50307ad224718d5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ced778e5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,308 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,308 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,308 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,309 - DEBUG - response_closed.started


2024-04-21 11:28:37,309 - DEBUG - response_closed.complete


2024-04-21 11:28:37,311 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,311 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUqXavz7sENxdCFVlSA9QMxOA7', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_EsFmWlPieoqqqsbeAkj0lYxa', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,311 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,311 - DEBUG - response_closed.complete


2024-04-21 11:28:37,313 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,313 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUHDUcYXf4k8nGIcVWnmYFQgLL', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_tYatfSpVHzOQmvgZJpSTu1gn', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,314 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,316 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'615'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4981'), (b'x-ratelimit-remaining-tokens', b'597163'), (b'x-ratelimit-reset-requests', b'219ms'), (b'x-ratelimit-reset-tokens', b'283ms'), (b'x-request-id', b'req_c76016252510bfe50868279a04ae00e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50aecc14de-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,316 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,316 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,316 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,316 - DEBUG - response_closed.started


2024-04-21 11:28:37,316 - DEBUG - response_closed.complete


2024-04-21 11:28:37,318 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,319 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUmaSAsxqikkKXqSZsLVpp4KGc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_eSx6GLzIi9BMbSUT3uA1jMcZ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,319 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,319 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'621'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4997'), (b'x-ratelimit-remaining-tokens', b'599627'), (b'x-ratelimit-reset-requests', b'27ms'), (b'x-ratelimit-reset-tokens', b'37ms'), (b'x-request-id', b'req_5d6630be63a5121f5b0d3412e0f4a5eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f502ac70fcf-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,319 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,319 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,319 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,319 - DEBUG - response_closed.started


2024-04-21 11:28:37,319 - DEBUG - response_closed.complete


2024-04-21 11:28:37,321 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,322 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUB3QXmiQYSyhbHFjedxsw0IvJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OmD8QO8xu3QtUzjIgDHh0yZB', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,322 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,322 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'486'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'588547'), (b'x-ratelimit-reset-requests', b'939ms'), (b'x-ratelimit-reset-tokens', b'1.145s'), (b'x-request-id', b'req_af523294825f0d66e05d16d2b673d4a0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ee4a0ceb-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,322 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,322 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,322 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,322 - DEBUG - response_closed.started


2024-04-21 11:28:37,323 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'591'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4938'), (b'x-ratelimit-remaining-tokens', b'590825'), (b'x-ratelimit-reset-requests', b'743ms'), (b'x-ratelimit-reset-tokens', b'917ms'), (b'x-request-id', b'req_6a45a626f35f3836cd3743a73eec6afb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dc331032-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,323 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,323 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,323 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,323 - DEBUG - response_closed.started


2024-04-21 11:28:37,323 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'530'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4943'), (b'x-ratelimit-remaining-tokens', b'591625'), (b'x-ratelimit-reset-requests', b'677ms'), (b'x-ratelimit-reset-tokens', b'837ms'), (b'x-request-id', b'req_2c7e9a0fce492aab39e018bd3d03e78d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dde408f0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,323 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,323 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,323 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,323 - DEBUG - response_closed.started


2024-04-21 11:28:37,323 - DEBUG - response_closed.complete


2024-04-21 11:28:37,326 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,326 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUOJokF6wgJh5fZ9k4oVcrrX5H', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9vD5N8G5p3LGNP9Ta7mmjvKz', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:28:37,326 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,326 - DEBUG - response_closed.complete


2024-04-21 11:28:37,328 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,328 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUvqGz4JaahkqTU7ZlI3ia3YNf', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jHZS5dpEqog7DZ6PJMkH0FGv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,328 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,329 - DEBUG - response_closed.complete


2024-04-21 11:28:37,331 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,331 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUNRPQcWy91zfgktZynpWhL7rU', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_gklmzyli48o8NrPsBTvUR7Uo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,331 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,331 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'633'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597770'), (b'x-ratelimit-reset-requests', b'168ms'), (b'x-ratelimit-reset-tokens', b'222ms'), (b'x-request-id', b'req_68978fb9b140308f2bdc47eb72d34aec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f509d4d312e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,331 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,331 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,331 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,331 - DEBUG - response_closed.started


2024-04-21 11:28:37,332 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'613'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4975'), (b'x-ratelimit-remaining-tokens', b'596195'), (b'x-ratelimit-reset-requests', b'298ms'), (b'x-ratelimit-reset-tokens', b'380ms'), (b'x-request-id', b'req_2fa1722a8b4a57ba1e04506fc882bfdb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50b9810ca3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,332 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,332 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,332 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,332 - DEBUG - response_closed.started


2024-04-21 11:28:37,332 - DEBUG - response_closed.complete


2024-04-21 11:28:37,334 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,334 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUgy7cqM919u85FMl1Abzanktv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0j6NsLwAUINYuJVsbOJJBukF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,334 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,334 - DEBUG - response_closed.complete


2024-04-21 11:28:37,336 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,337 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUA67ZBYtfsgbMwSAwvQupTnmD', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VTmcATYNIbMnQJb26J5NiCeu', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=206, total_tokens=211))


2024-04-21 11:28:37,337 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,337 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'558'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4973'), (b'x-ratelimit-remaining-tokens', b'595986'), (b'x-ratelimit-reset-requests', b'312ms'), (b'x-ratelimit-reset-tokens', b'401ms'), (b'x-request-id', b'req_c101b753a478a3b572db110e74283b0e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50bc742f15-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,337 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,337 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,337 - DEBUG - response_closed.started


2024-04-21 11:28:37,337 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'600'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4965'), (b'x-ratelimit-remaining-tokens', b'594787'), (b'x-ratelimit-reset-requests', b'409ms'), (b'x-ratelimit-reset-tokens', b'521ms'), (b'x-request-id', b'req_f910a1d99e8b09fa9085135d1f0ae97f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50c8d631af-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,337 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,338 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,338 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,338 - DEBUG - response_closed.started


2024-04-21 11:28:37,338 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'639'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599858'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'14ms'), (b'x-request-id', b'req_21343e2e4b1d45b3b04b6e417bd7484b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f500aa008f8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,338 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,338 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,338 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,338 - DEBUG - response_closed.started


2024-04-21 11:28:37,338 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'635'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4981'), (b'x-ratelimit-remaining-tokens', b'597043'), (b'x-ratelimit-reset-requests', b'227ms'), (b'x-ratelimit-reset-tokens', b'295ms'), (b'x-request-id', b'req_cb4df407485c3337d298ba8da93a17c0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50aa5c7ead-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,338 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,338 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,338 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,338 - DEBUG - response_closed.started


2024-04-21 11:28:37,338 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'681'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4993'), (b'x-ratelimit-remaining-tokens', b'598865'), (b'x-ratelimit-reset-requests', b'80ms'), (b'x-ratelimit-reset-tokens', b'113ms'), (b'x-request-id', b'req_3eb94e3c34663304b23f6693002866a8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f505ba57be9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,339 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,339 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,339 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,339 - DEBUG - response_closed.started


2024-04-21 11:28:37,339 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'510'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4929'), (b'x-ratelimit-remaining-tokens', b'589648'), (b'x-ratelimit-reset-requests', b'843ms'), (b'x-ratelimit-reset-tokens', b'1.035s'), (b'x-request-id', b'req_3dbcb113a76d128415c7de9ee4bdd5de'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50e9d12aef-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,339 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,339 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,339 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,339 - DEBUG - response_closed.started


2024-04-21 11:28:37,339 - DEBUG - response_closed.complete


2024-04-21 11:28:37,341 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,341 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUBfBNi6KCWUlKcNQxRukB4nb4', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_QNDXp1bC3HoyUqzvlxhXajka', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,342 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,342 - DEBUG - response_closed.complete


2024-04-21 11:28:37,344 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,344 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUfufv2WiTa3x5IloKzEO0KJZh', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_z4on4XIIvsYTQdPVVmm8rzyl', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=220, total_tokens=225))


2024-04-21 11:28:37,344 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,344 - DEBUG - response_closed.complete


2024-04-21 11:28:37,346 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,346 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUrJhMybVH6DgJ8Er59PImiD8p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OPSgvryV16Y7RkIzUzENY54O', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,346 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,346 - DEBUG - response_closed.complete


2024-04-21 11:28:37,348 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,349 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU8bbHF8tI6Beu5eCjBmMUB5KM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VCtH8kQgjSnDWE0VyGYT59Ey', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,349 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,349 - DEBUG - response_closed.complete


2024-04-21 11:28:37,351 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,351 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDURmUb6yz3W3TljoHTnkQvcpLb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_GzDB04MX9LRKFUbPPOE94nLj', function=Function(arguments='{"valid":true}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,351 - INFO - Received completion from the model:
valid=True


2024-04-21 11:28:37,351 - DEBUG - response_closed.complete


2024-04-21 11:28:37,353 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,354 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU6rHOvgRkrrHqRY1XzrjJ7txI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ytWT2xMfIEdlGCZPaenqIy9d', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,354 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,354 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'623'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4971'), (b'x-ratelimit-remaining-tokens', b'595663'), (b'x-ratelimit-reset-requests', b'340ms'), (b'x-ratelimit-reset-tokens', b'433ms'), (b'x-request-id', b'req_50195287b81f89806f82334d0716b765'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cb767ca9-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,354 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,354 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,354 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,354 - DEBUG - response_closed.started


2024-04-21 11:28:37,354 - DEBUG - response_closed.complete


2024-04-21 11:28:37,356 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,356 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUHceFIUJhIxM5tHI3k4DzDLUZ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kr03gzJtPwnamYKstJ9EOmMe', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,357 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,357 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'588769'), (b'x-ratelimit-reset-requests', b'925ms'), (b'x-ratelimit-reset-tokens', b'1.123s'), (b'x-request-id', b'req_7a40f170fd4ecb6dbb73a6dedca469b6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eae231f7-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,357 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,357 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,357 - DEBUG - response_closed.started


2024-04-21 11:28:37,357 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'639'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4994'), (b'x-ratelimit-remaining-tokens', b'599168'), (b'x-ratelimit-reset-requests', b'68ms'), (b'x-ratelimit-reset-tokens', b'83ms'), (b'x-request-id', b'req_f792654d9a6a9387c2a65d53f6b3191a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f503f4d2b84-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,357 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,357 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,357 - DEBUG - response_closed.started


2024-04-21 11:28:37,357 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'471'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'588423'), (b'x-ratelimit-reset-requests', b'944ms'), (b'x-ratelimit-reset-tokens', b'1.157s'), (b'x-request-id', b'req_9bd636c4369fdfb7adcf17b987008a80'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cbe12ef0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,357 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,358 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,358 - DEBUG - response_closed.started


2024-04-21 11:28:37,358 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'554'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4960'), (b'x-ratelimit-remaining-tokens', b'594148'), (b'x-ratelimit-reset-requests', b'468ms'), (b'x-ratelimit-reset-tokens', b'585ms'), (b'x-request-id', b'req_8698e0e8e360fff44e87c6457cf39fda'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cd322a89-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,358 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,358 - DEBUG - response_closed.started


2024-04-21 11:28:37,358 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'610'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4920'), (b'x-ratelimit-remaining-tokens', b'588363'), (b'x-ratelimit-reset-requests', b'956ms'), (b'x-ratelimit-reset-tokens', b'1.163s'), (b'x-request-id', b'req_697031ce2878f7af47ea5498b88c29be'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ea921013-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,358 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,358 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,358 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,358 - DEBUG - response_closed.started


2024-04-21 11:28:37,358 - DEBUG - response_closed.complete


2024-04-21 11:28:37,360 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,361 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUJT7YfHRn6fVDf83mDXpcFupp', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_OG4Bg8PRFuAxvXfCHrOGy5zB', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,361 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,361 - DEBUG - response_closed.complete


2024-04-21 11:28:37,363 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,363 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUHz8kySkO597WlBD12BHRTd9O', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_s61BP3MZOg6tWCXYtau5Q1D1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=228, total_tokens=233))


2024-04-21 11:28:37,363 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,363 - DEBUG - response_closed.complete


2024-04-21 11:28:37,366 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,366 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUDT1jXbc8uGHDq67msOcwZZ1x', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_fZD8dEmtFRyzEuZL5wbn6lS8', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,366 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,366 - DEBUG - response_closed.complete


2024-04-21 11:28:37,368 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,368 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUJGbmfIWH6vhtQLiS77JN831y', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CmVOQLF0LYMnmrrpRiNIbCkI', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=187, total_tokens=192))


2024-04-21 11:28:37,368 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,368 - DEBUG - response_closed.complete


2024-04-21 11:28:37,371 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,371 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUtsa4lgVNgSyY0d3QXdRwN0P9', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_SaW0k9fr72g2dqt2UaZPzoQm', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=167, total_tokens=172))


2024-04-21 11:28:37,371 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,371 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'508'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4949'), (b'x-ratelimit-remaining-tokens', b'592427'), (b'x-ratelimit-reset-requests', b'605ms'), (b'x-ratelimit-reset-tokens', b'757ms'), (b'x-request-id', b'req_dda2969eaa68810ad51df7bd85af515f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50d85e7bf1-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,371 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,371 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,371 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,371 - DEBUG - response_closed.started


2024-04-21 11:28:37,371 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'472'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4920'), (b'x-ratelimit-remaining-tokens', b'588265'), (b'x-ratelimit-reset-requests', b'955ms'), (b'x-ratelimit-reset-tokens', b'1.173s'), (b'x-request-id', b'req_86030506398410fdef5a9654e829bc9d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50edf90fd0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,372 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,372 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,372 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,372 - DEBUG - response_closed.started


2024-04-21 11:28:37,372 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'643'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4968'), (b'x-ratelimit-remaining-tokens', b'595251'), (b'x-ratelimit-reset-requests', b'375ms'), (b'x-ratelimit-reset-tokens', b'474ms'), (b'x-request-id', b'req_7c65386040d0fd7c1cd8bdeb0fc156f0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ce4c78e6-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,372 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,372 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,372 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,372 - DEBUG - response_closed.started


2024-04-21 11:28:37,372 - DEBUG - response_closed.complete


2024-04-21 11:28:37,374 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,375 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU8bhfCGhqpNdvwjxqbuneeGoQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_L4wFpfn7GJ61H23NIUkva5FO', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=197, total_tokens=202))


2024-04-21 11:28:37,375 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,375 - DEBUG - response_closed.complete


2024-04-21 11:28:37,377 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,377 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUbVFnruYD4ChSNPM29LYqVNcc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_VkJwn5Ww7ritG85Dec8z6Q25', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:28:37,377 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,377 - DEBUG - response_closed.complete


2024-04-21 11:28:37,380 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,380 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU7HrpNAdZVWQd5WfUmrnDetHP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Mk5fimKZefXTPBGyahvS1WX1', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=190, total_tokens=195))


2024-04-21 11:28:37,380 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,380 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'469'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4922'), (b'x-ratelimit-remaining-tokens', b'588560'), (b'x-ratelimit-reset-requests', b'932ms'), (b'x-ratelimit-reset-tokens', b'1.143s'), (b'x-request-id', b'req_d0b90f14d5723aeeb975268826b53a92'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cd1a102d-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,380 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,380 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,380 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,380 - DEBUG - response_closed.started


2024-04-21 11:28:37,381 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'617'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4953'), (b'x-ratelimit-remaining-tokens', b'593006'), (b'x-ratelimit-reset-requests', b'557ms'), (b'x-ratelimit-reset-tokens', b'699ms'), (b'x-request-id', b'req_dd8bc0222ad54c3545cc5754aa9a7635'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50de8c7c3e-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,381 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,381 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,381 - DEBUG - response_closed.started


2024-04-21 11:28:37,381 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'555'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'592297'), (b'x-ratelimit-reset-requests', b'614ms'), (b'x-ratelimit-reset-tokens', b'770ms'), (b'x-request-id', b'req_2964dbfc2e54fc7fea3e170cb66623ce'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dca183fa-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,381 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,381 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,381 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,381 - DEBUG - response_closed.started


2024-04-21 11:28:37,381 - DEBUG - response_closed.complete


2024-04-21 11:28:37,384 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,384 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUriy7DFikSTh3hOhHUjzgNARR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_8QnfxZchuULjzlK8WrGqNmJv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,384 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,384 - DEBUG - response_closed.complete


2024-04-21 11:28:37,386 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,387 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUJbbD6gb8eSp0HScogjlTlpw5', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_siyglMrAXuIGWbyv6vuwWEBz', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=185, total_tokens=190))


2024-04-21 11:28:37,387 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,387 - DEBUG - response_closed.complete


2024-04-21 11:28:37,389 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,389 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU1WeqoYumiHrmYV7kaq0zQm0p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_UHWl2ql1BYFY7lBvtoXlspGh', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=187, total_tokens=192))


2024-04-21 11:28:37,390 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,392 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'675'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4976'), (b'x-ratelimit-remaining-tokens', b'596467'), (b'x-ratelimit-reset-requests', b'276ms'), (b'x-ratelimit-reset-tokens', b'353ms'), (b'x-request-id', b'req_c55c0aa21d4334fc98f77db258affedd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ada12ecc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,392 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,392 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,393 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,393 - DEBUG - response_closed.started


2024-04-21 11:28:37,393 - DEBUG - response_closed.complete


2024-04-21 11:28:37,395 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,395 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUXdEmNqSPrk8ethAnfeOAnB9t', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_0j6NsLwAUINYuJVsbOJJBukF', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=215, total_tokens=220))


2024-04-21 11:28:37,395 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,396 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'578'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4955'), (b'x-ratelimit-remaining-tokens', b'593263'), (b'x-ratelimit-reset-requests', b'538ms'), (b'x-ratelimit-reset-tokens', b'673ms'), (b'x-request-id', b'req_ea59856aea05140239a21db5444b66a9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50d9f37c86-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,396 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,396 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,396 - DEBUG - response_closed.started


2024-04-21 11:28:37,396 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'557'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4974'), (b'x-ratelimit-remaining-tokens', b'596066'), (b'x-ratelimit-reset-requests', b'308ms'), (b'x-ratelimit-reset-tokens', b'393ms'), (b'x-request-id', b'req_ec66f48583a36a354dcf22c95cf04b79'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ba4f312b-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,396 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,396 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,396 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,396 - DEBUG - response_closed.started


2024-04-21 11:28:37,396 - DEBUG - response_closed.complete


2024-04-21 11:28:37,399 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,399 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU8eyU9Hu9InP97twVZpqT9RsM', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ElNxTDlojh9iHZDOHJTu8VQ2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,399 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,399 - DEBUG - response_closed.complete


2024-04-21 11:28:37,402 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,402 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUsx6M6wVbth8dtYTPjMtM8ru0', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_xVmBwTtdCFhUSMba6ZsDVGnL', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,402 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,402 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'559'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'592313'), (b'x-ratelimit-reset-requests', b'618ms'), (b'x-ratelimit-reset-tokens', b'768ms'), (b'x-request-id', b'req_32df471e330df23146dd33faf9b1e256'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50db1752c5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,402 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,402 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,402 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,402 - DEBUG - response_closed.started


2024-04-21 11:28:37,402 - DEBUG - response_closed.complete


2024-04-21 11:28:37,405 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,405 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUHq0YLxrAT52GB0vNQ4NO9nFP', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_otmprEGpfq1ZSzoyC0KkWYmK', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=199, total_tokens=204))


2024-04-21 11:28:37,405 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,405 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'583'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4970'), (b'x-ratelimit-remaining-tokens', b'595472'), (b'x-ratelimit-reset-requests', b'357ms'), (b'x-ratelimit-reset-tokens', b'452ms'), (b'x-request-id', b'req_f7e95a2cfb4a8c86a3a665e82f33e6c3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ba2b7c8f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,406 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,406 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,406 - DEBUG - response_closed.started


2024-04-21 11:28:37,406 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'578'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4954'), (b'x-ratelimit-remaining-tokens', b'593191'), (b'x-ratelimit-reset-requests', b'541ms'), (b'x-ratelimit-reset-tokens', b'680ms'), (b'x-request-id', b'req_a7dc2b8a1b936bf254fed52d125d73b0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50c8420fbe-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,406 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,406 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,406 - DEBUG - response_closed.started


2024-04-21 11:28:37,406 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'661'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4948'), (b'x-ratelimit-remaining-tokens', b'592304'), (b'x-ratelimit-reset-requests', b'615ms'), (b'x-ratelimit-reset-tokens', b'769ms'), (b'x-request-id', b'req_91fb7aae25a21ccd85cd835c8ffb3a8d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50d9af3110-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,406 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,406 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,406 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,406 - DEBUG - response_closed.started


2024-04-21 11:28:37,407 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'603'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4942'), (b'x-ratelimit-remaining-tokens', b'591461'), (b'x-ratelimit-reset-requests', b'687ms'), (b'x-ratelimit-reset-tokens', b'853ms'), (b'x-request-id', b'req_e554ba778299883ed4542c1cdc0f0bbf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50daa97ce3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,407 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,407 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,407 - DEBUG - response_closed.started


2024-04-21 11:28:37,407 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'674'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4974'), (b'x-ratelimit-remaining-tokens', b'595997'), (b'x-ratelimit-reset-requests', b'309ms'), (b'x-ratelimit-reset-tokens', b'400ms'), (b'x-request-id', b'req_3bdf7eae2e07033498a1c7233828ff22'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50bf9508c5-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,407 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,407 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,407 - DEBUG - response_closed.started


2024-04-21 11:28:37,407 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'609'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4937'), (b'x-ratelimit-remaining-tokens', b'590695'), (b'x-ratelimit-reset-requests', b'753ms'), (b'x-ratelimit-reset-tokens', b'930ms'), (b'x-request-id', b'req_1cd6fa9a230a34c332b8896e6c8d7d4b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eebf83fd-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,407 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,407 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,407 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,407 - DEBUG - response_closed.started


2024-04-21 11:28:37,407 - DEBUG - response_closed.complete


2024-04-21 11:28:37,410 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,410 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUSUJNEjNBaTLw39wfYf1f8vwS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pBX0oWNlvMvbOR1eZPZkj5rA', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,410 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,410 - DEBUG - response_closed.complete


2024-04-21 11:28:37,413 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,413 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUmgELoJD4IFTjPfSTiG0VLVvW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_sDU2XrogvRub7h3jFadIj71h', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,413 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,413 - DEBUG - response_closed.complete


2024-04-21 11:28:37,416 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,416 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUsi8RpMuXrQGlQsHf6FtTYVdr', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_LbsUTmIML8FYqSxYXA7WVDjs', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,416 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,416 - DEBUG - response_closed.complete


2024-04-21 11:28:37,419 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,419 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU2ZwHBF3EdbC3bnrE2iaviMKJ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Cs91bTAXn0159CRfN8m5wQSk', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,419 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,420 - DEBUG - response_closed.complete


2024-04-21 11:28:37,422 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,422 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUFIHZhlnnqktXsKikBt19AyDq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_PHRAgxJflWe0gwHxncjvdKYo', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=194, total_tokens=199))


2024-04-21 11:28:37,423 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,423 - DEBUG - response_closed.complete


2024-04-21 11:28:37,425 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,426 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUjY6zri50qUrdFJTONjd0amRx', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pprOY2hQqEyY9JU7dPQlfPYa', function=Function(arguments='{"valid":true}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,426 - INFO - Received completion from the model:
valid=True


2024-04-21 11:28:37,426 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'671'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4932'), (b'x-ratelimit-remaining-tokens', b'590030'), (b'x-ratelimit-reset-requests', b'809ms'), (b'x-ratelimit-reset-tokens', b'996ms'), (b'x-request-id', b'req_5e348d15e5912d4a4b880724923c1975'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50df1d2b60-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,426 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,426 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,426 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,426 - DEBUG - response_closed.started


2024-04-21 11:28:37,426 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'585'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4923'), (b'x-ratelimit-remaining-tokens', b'588739'), (b'x-ratelimit-reset-requests', b'922ms'), (b'x-ratelimit-reset-tokens', b'1.126s'), (b'x-request-id', b'req_f21a8985f2f7d33242503d77febe8b1f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eb2c1019-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,426 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,426 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,426 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,426 - DEBUG - response_closed.started


2024-04-21 11:28:37,427 - DEBUG - response_closed.complete


2024-04-21 11:28:37,429 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,430 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUFlbGEi9uXwf511xd8s4BHZBi', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kr03gzJtPwnamYKstJ9EOmMe', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,430 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,430 - DEBUG - response_closed.complete


2024-04-21 11:28:37,432 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,433 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU2htMPBel2uARVvf4NCJp8Js8', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ElNxTDlojh9iHZDOHJTu8VQ2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=194, total_tokens=199))


2024-04-21 11:28:37,433 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,433 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'596'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4933'), (b'x-ratelimit-remaining-tokens', b'590169'), (b'x-ratelimit-reset-requests', b'800ms'), (b'x-ratelimit-reset-tokens', b'983ms'), (b'x-request-id', b'req_c5abb1dca0990407ff5c7252a0783bea'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ea8a7c71-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,433 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,433 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,433 - DEBUG - response_closed.started


2024-04-21 11:28:37,433 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'600'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4940'), (b'x-ratelimit-remaining-tokens', b'591231'), (b'x-ratelimit-reset-requests', b'708ms'), (b'x-ratelimit-reset-tokens', b'876ms'), (b'x-request-id', b'req_92c521f46482feab4cebeef466ffe947'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dc027c73-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,433 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,433 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,433 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,434 - DEBUG - response_closed.started


2024-04-21 11:28:37,434 - DEBUG - response_closed.complete


2024-04-21 11:28:37,436 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,437 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUgv1RVzAkOxihhbSOkkqvjcUO', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kPmBKFfE7ZTzb65Cf5WrJXyR', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=192, total_tokens=197))


2024-04-21 11:28:37,437 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,437 - DEBUG - response_closed.complete


2024-04-21 11:28:37,440 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,440 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU63BMoj0ZwdA7vRH34L6YCjWb', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CmVOQLF0LYMnmrrpRiNIbCkI', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=195, total_tokens=200))


2024-04-21 11:28:37,440 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,440 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'721'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4954'), (b'x-ratelimit-remaining-tokens', b'593165'), (b'x-ratelimit-reset-requests', b'546ms'), (b'x-ratelimit-reset-tokens', b'683ms'), (b'x-request-id', b'req_80a64be707674d09f4a1404a3734bed8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50dfdb7c7f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,440 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,440 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,440 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,440 - DEBUG - response_closed.started


2024-04-21 11:28:37,441 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'640'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4919'), (b'x-ratelimit-remaining-tokens', b'588102'), (b'x-ratelimit-reset-requests', b'969ms'), (b'x-ratelimit-reset-tokens', b'1.189s'), (b'x-request-id', b'req_393d187825863b59f974f6c56907061c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eece69c2-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,441 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,441 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,441 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,441 - DEBUG - response_closed.started


2024-04-21 11:28:37,441 - DEBUG - response_closed.complete


2024-04-21 11:28:37,444 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,444 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU3NiWPDxIfSJGGs5GdjOmx73H', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jpXotA9t2a7mzzvSp8LnFfzH', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,444 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,444 - DEBUG - response_closed.complete


2024-04-21 11:28:37,447 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,447 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDURwGrOn1nfilclcXHXLYU1M33', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_uM2AQq2JJ6K1wyOZJPqizmT4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,447 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,448 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'592'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4952'), (b'x-ratelimit-remaining-tokens', b'592912'), (b'x-ratelimit-reset-requests', b'565ms'), (b'x-ratelimit-reset-tokens', b'708ms'), (b'x-request-id', b'req_14f985af42b644a0121f5bb61f13806b'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cdb12ae3-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,448 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,448 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,448 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,448 - DEBUG - response_closed.started


2024-04-21 11:28:37,448 - DEBUG - response_closed.complete


2024-04-21 11:28:37,451 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,451 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU9ZzVIeSUsMalldktCm2esLWI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_kk0Sv48U5gFHUpijn6PysefV', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,451 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,451 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'587'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4928'), (b'x-ratelimit-remaining-tokens', b'589531'), (b'x-ratelimit-reset-requests', b'855ms'), (b'x-ratelimit-reset-tokens', b'1.046s'), (b'x-request-id', b'req_061e1e90b2f53a7701c0ef7865c6f2e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50eceb1001-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,451 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,451 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,451 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,451 - DEBUG - response_closed.started


2024-04-21 11:28:37,452 - DEBUG - response_closed.complete


2024-04-21 11:28:37,455 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,455 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU7sgtdfFRqwatacxFMoLkPnXS', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_pGfYT5SMWN7fsdIKyDwWII1R', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=167, total_tokens=172))


2024-04-21 11:28:37,455 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,505 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'785'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4923'), (b'x-ratelimit-remaining-tokens', b'588851'), (b'x-ratelimit-reset-requests', b'913ms'), (b'x-ratelimit-reset-tokens', b'1.114s'), (b'x-request-id', b'req_82829ab87e5661e50ffb2fa7b0de66c5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ef8e2f50-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,505 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,505 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,505 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,505 - DEBUG - response_closed.started


2024-04-21 11:28:37,505 - DEBUG - response_closed.complete


2024-04-21 11:28:37,509 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,509 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUmvW2hm8FEACeCFsv4d7X9mrR', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_BX5F0cNOPrcuNwwszVGYqN6e', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,510 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,519 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'743'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4985'), (b'x-ratelimit-remaining-tokens', b'597667'), (b'x-ratelimit-reset-requests', b'177ms'), (b'x-ratelimit-reset-tokens', b'233ms'), (b'x-request-id', b'req_bec4c57fb3b6fed21baca26965c49bd5'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ae080d20-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,519 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,519 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,520 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,520 - DEBUG - response_closed.started


2024-04-21 11:28:37,520 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'719'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'593953'), (b'x-ratelimit-reset-requests', b'482ms'), (b'x-ratelimit-reset-tokens', b'604ms'), (b'x-request-id', b'req_33a017b9444b0a1bb8bb1496cd62e12c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ce032acc-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,520 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,520 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,520 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,520 - DEBUG - response_closed.started


2024-04-21 11:28:37,520 - DEBUG - response_closed.complete


2024-04-21 11:28:37,524 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,524 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUXfkEEkHzus6hOklgeLclchk6', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_WW5OveqHFNk8kWu2AI90iDUG', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,524 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,525 - DEBUG - response_closed.complete


2024-04-21 11:28:37,528 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,528 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUjKFMQGZAcKKwt1kaDkzkEvxu', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_cgNYpQPMfoq8brQyBawRAnM6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=223, total_tokens=228))


2024-04-21 11:28:37,529 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,529 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'710'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4944'), (b'x-ratelimit-remaining-tokens', b'591746'), (b'x-ratelimit-reset-requests', b'661ms'), (b'x-ratelimit-reset-tokens', b'825ms'), (b'x-request-id', b'req_d09728f05ff6b9c0ca2890ab65b29273'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50d83f2b84-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,529 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,529 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,529 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,529 - DEBUG - response_closed.started


2024-04-21 11:28:37,529 - DEBUG - response_closed.complete


2024-04-21 11:28:37,533 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,533 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU0E4XqOZMQu8mKK3l84Jp3w59', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_khB1Nu19xk2zADe3wyoDMfEt', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,533 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,578 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'759'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4926'), (b'x-ratelimit-remaining-tokens', b'589249'), (b'x-ratelimit-reset-requests', b'879ms'), (b'x-ratelimit-reset-tokens', b'1.075s'), (b'x-request-id', b'req_57a4ec99aec1bf65cc4010d921d13f8c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ea7e2b62-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,578 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,579 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,579 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,579 - DEBUG - response_closed.started


2024-04-21 11:28:37,579 - DEBUG - response_closed.complete


2024-04-21 11:28:37,583 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,584 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDVqh5jq9ayD3ievuJtmbeyVO48', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_g1nCyXoBnDMF1c4mz0o1088F', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724117, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,584 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,591 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'864'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4982'), (b'x-ratelimit-remaining-tokens', b'597291'), (b'x-ratelimit-reset-requests', b'211ms'), (b'x-ratelimit-reset-tokens', b'270ms'), (b'x-request-id', b'req_2537c2aa8bc6c3217a679c45fbb9a5bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50a8012f1c-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,591 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,591 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,592 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,592 - DEBUG - response_closed.started


2024-04-21 11:28:37,592 - DEBUG - response_closed.complete


2024-04-21 11:28:37,596 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,596 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUOW3YHWWBXvn2XdykaGJ4MuZz', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_jHZS5dpEqog7DZ6PJMkH0FGv', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=215, total_tokens=220))


2024-04-21 11:28:37,597 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,622 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'841'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4983'), (b'x-ratelimit-remaining-tokens', b'597388'), (b'x-ratelimit-reset-requests', b'199ms'), (b'x-ratelimit-reset-tokens', b'261ms'), (b'x-request-id', b'req_99b2603b43761a073ebe870c69e3b2f1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50ae9d2f21-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,623 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,623 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,623 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,623 - DEBUG - response_closed.started


2024-04-21 11:28:37,623 - DEBUG - response_closed.complete


2024-04-21 11:28:37,628 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,628 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUxXrIscTf3XEwOO88ixCKMr3p', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_9T2wJwr7hohyvz6sUhjQfFB6', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:28:37,628 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,674 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'878'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4959'), (b'x-ratelimit-remaining-tokens', b'593805'), (b'x-ratelimit-reset-requests', b'490ms'), (b'x-ratelimit-reset-tokens', b'619ms'), (b'x-request-id', b'req_94d7d37c4ab6dc8dd04db6633ca5b3f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cf587c77-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,674 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,674 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,674 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,674 - DEBUG - response_closed.started


2024-04-21 11:28:37,674 - DEBUG - response_closed.complete


2024-04-21 11:28:37,681 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,681 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUEweg23YpfKy3OOwTgS8rKEz3', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_ul7iZxE3lMmnKVC0UuEcZDV4', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,681 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:37,689 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1052'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4990'), (b'x-ratelimit-remaining-tokens', b'598477'), (b'x-ratelimit-reset-requests', b'117ms'), (b'x-ratelimit-reset-tokens', b'152ms'), (b'x-request-id', b'req_abba2447a1c5b2c527b2d7e09b1a668c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f505d3e7d0a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:37,689 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:37,689 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:37,689 - DEBUG - receive_response_body.complete


2024-04-21 11:28:37,689 - DEBUG - response_closed.started


2024-04-21 11:28:37,689 - DEBUG - response_closed.complete


2024-04-21 11:28:37,696 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:37,696 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDVVH1FqymHm2lBktE6MLcTZbEI', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3f7keMkwTCMNcBnQfCFxeHR2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724117, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:37,696 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:38,065 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1212'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4921'), (b'x-ratelimit-remaining-tokens', b'588463'), (b'x-ratelimit-reset-requests', b'946ms'), (b'x-ratelimit-reset-tokens', b'1.153s'), (b'x-request-id', b'req_979168f444041c66a846b788d654c2ff'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50d9f88404-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:38,066 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:38,067 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:38,067 - DEBUG - receive_response_body.complete


2024-04-21 11:28:38,067 - DEBUG - response_closed.started


2024-04-21 11:28:38,068 - DEBUG - response_closed.complete


2024-04-21 11:28:38,082 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:38,084 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUfs11NJ5wxAPyZlpCl8FDn9Xc', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_3f7keMkwTCMNcBnQfCFxeHR2', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=189, total_tokens=194))


2024-04-21 11:28:38,084 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:38,376 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1593'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4979'), (b'x-ratelimit-remaining-tokens', b'596880'), (b'x-ratelimit-reset-requests', b'241ms'), (b'x-ratelimit-reset-tokens', b'311ms'), (b'x-request-id', b'req_2bd0f6d9408dc28c4520039e177c42aa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50bed714de-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:38,377 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:38,378 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:38,378 - DEBUG - receive_response_body.complete


2024-04-21 11:28:38,378 - DEBUG - response_closed.started


2024-04-21 11:28:38,379 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1508'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4923'), (b'x-ratelimit-remaining-tokens', b'588710'), (b'x-ratelimit-reset-requests', b'919ms'), (b'x-ratelimit-reset-tokens', b'1.128s'), (b'x-request-id', b'req_3dad4b228a1258a151733915a179be5f'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50de7d14f0-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:38,379 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:38,380 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:38,382 - DEBUG - receive_response_body.complete


2024-04-21 11:28:38,383 - DEBUG - response_closed.started


2024-04-21 11:28:38,383 - DEBUG - response_closed.complete


2024-04-21 11:28:38,400 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:38,402 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUfOfoE7ddcLuy5bkSF486MCeF', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_Q4FrrbDxJKvfnp8oAG4Zu5Gj', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=193, total_tokens=198))


2024-04-21 11:28:38,403 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:38,403 - DEBUG - response_closed.complete


2024-04-21 11:28:38,417 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:38,417 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUsz4NjZHNC4A57ltI4jHfUkgy', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_CNeTa65Ids3a6jFYpwW2NkvQ', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=5, prompt_tokens=200, total_tokens=205))


2024-04-21 11:28:38,418 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:38,680 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'645'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4967'), (b'x-ratelimit-remaining-tokens', b'595113'), (b'x-ratelimit-reset-requests', b'387ms'), (b'x-ratelimit-reset-tokens', b'488ms'), (b'x-request-id', b'req_b059247ffc8c69a44399a20b2f6862da'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50acc42f0f-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:38,684 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:38,684 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:38,685 - DEBUG - receive_response_body.complete


2024-04-21 11:28:38,685 - DEBUG - response_closed.started


2024-04-21 11:28:38,685 - DEBUG - response_closed.complete


2024-04-21 11:28:38,697 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:38,698 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDU2VPEXqxN2NkJ58DHkDNhU3VH', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_aC2gMgy7Q8rOhfypjVVAFPSA', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_fb84c680ea', usage=CompletionUsage(completion_tokens=5, prompt_tokens=194, total_tokens=199))


2024-04-21 11:28:38,699 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:39,294 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'2472'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4960'), (b'x-ratelimit-remaining-tokens', b'593963'), (b'x-ratelimit-reset-requests', b'478ms'), (b'x-ratelimit-reset-tokens', b'603ms'), (b'x-request-id', b'req_31d4881756848957f634a80e4eecf521'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f50cc3a7cc8-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:39,296 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:39,297 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:39,297 - DEBUG - receive_response_body.complete


2024-04-21 11:28:39,298 - DEBUG - response_closed.started


2024-04-21 11:28:39,298 - DEBUG - response_closed.complete


2024-04-21 11:28:39,312 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:39,314 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDUMxLdu3Itgc3ZGydS8MPYmDiW', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_c0e5BOayxxclsiInWBhKKg0k', function=Function(arguments='{"valid":false}', name='ValidateTweet'), type='function')]))], created=1713724116, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_4fa1855c85', usage=CompletionUsage(completion_tokens=5, prompt_tokens=194, total_tokens=199))


2024-04-21 11:28:39,315 - INFO - Received completion from the model:
valid=False


2024-04-21 11:28:39,319 - INFO - Sending messages to the model:
	{'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}
	{'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}
	{'role': 'user', 'content': 'yes'}


2024-04-21 11:28:39,322 - DEBUG - Instructor Request: mode.value='tool_call', response_model=<class 'x_filter.ai.workflows.guided_convo.Stage4'>, new_kwargs={'model': 'gpt-4-1106-preview', 'messages': [{'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'yes'}], 'temperature': 0.0, 'seed': 69, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}], 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}}


2024-04-21 11:28:39,322 - DEBUG - max_retries: 8


2024-04-21 11:28:39,322 - DEBUG - Retrying, attempt: <tenacity.AttemptManager object at 0x103cd5c60>


2024-04-21 11:28:39,328 - DEBUG - Request options: {'method': 'post', 'url': '/chat/completions', 'files': None, 'json_data': {'messages': [{'role': 'assistant', 'content': "Great! We've successfully gathered all the information we need to move on to the next stage. I'll now generate a search strategy based on the information you've provided. When finished I'll run the filter and schedile it to run as you specified. You can see details in the filter setting object. If you need to make any changes, please let me know there!"}, {'role': 'system', 'content': 'At this stage we want to build a comprehensive "report guide" describing how we will write the report. To give some context, we\'ll have a collection of tweets and we want to know how the user wants the report to be written. If you need to further clarify details about the report guide, ask questions in the \'questions\' field. Otherwise, write the report guide in the \'report_guide\' field. Try to include everything the user talked about and wanted in this guide. The user might ask you to change it, so be ready to make adjustments.'}, {'role': 'user', 'content': 'yes'}], 'model': 'gpt-4-1106-preview', 'seed': 69, 'temperature': 0.0, 'tool_choice': {'type': 'function', 'function': {'name': 'Stage4'}}, 'tools': [{'type': 'function', 'function': {'name': 'Stage4', 'description': 'Correctly extracted `Stage4` with all the required parameters with correct types', 'parameters': {'properties': {'report_guide': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Report Guide'}, 'questions': {'anyOf': [{'type': 'string'}, {'type': 'null'}], 'title': 'Questions'}}, 'required': ['questions', 'report_guide'], 'type': 'object'}}}]}}


2024-04-21 11:28:39,337 - DEBUG - send_request_headers.started request=<Request [b'POST']>


2024-04-21 11:28:39,337 - DEBUG - send_request_headers.complete


2024-04-21 11:28:39,337 - DEBUG - send_request_body.started request=<Request [b'POST']>


2024-04-21 11:28:39,337 - DEBUG - send_request_body.complete


2024-04-21 11:28:39,337 - DEBUG - receive_response_headers.started request=<Request [b'POST']>


2024-04-21 11:28:41,341 - DEBUG - receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Sun, 21 Apr 2024 18:28:41 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'Cache-Control', b'no-cache, must-revalidate'), (b'openai-model', b'gpt-4-1106-preview'), (b'openai-organization', b'user-2rdtlqupt10akenskk7dmi0n'), (b'openai-processing-ms', b'1829'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=15724800; includeSubDomains'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'600000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'599758'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'24ms'), (b'x-request-id', b'req_e82a9d14bd061d2f3ec4c552c74a71fa'), (b'CF-Cache-Status', b'DYNAMIC'), (b'Server', b'cloudflare'), (b'CF-RAY', b'877f6f61f9202b9a-LAX'), (b'Content-Encoding', b'gzip'), (b'alt-svc', b'h3=":443"; ma=86400')])


2024-04-21 11:28:41,343 - INFO - HTTP Request: POST https://api.openai.com/v1/chat/completions "HTTP/1.1 200 OK"


2024-04-21 11:28:41,343 - DEBUG - receive_response_body.started request=<Request [b'POST']>


2024-04-21 11:28:41,344 - DEBUG - receive_response_body.complete


2024-04-21 11:28:41,344 - DEBUG - response_closed.started


2024-04-21 11:28:41,345 - DEBUG - response_closed.complete


2024-04-21 11:28:41,361 - DEBUG - HTTP Request: POST https://api.openai.com/v1/chat/completions "200 OK"


2024-04-21 11:28:41,362 - DEBUG - Instructor Raw Response: ChatCompletion(id='chatcmpl-9GWDXngpUrukhtDcHwN0cJtqtGcBQ', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content=None, role='assistant', function_call=None, tool_calls=[ChatCompletionMessageToolCall(id='call_L4wFpfn7GJ61H23NIUkva5FO', function=Function(arguments='{"report_guide":null,"questions":"Could you please provide more details on how you would like the report to be structured? What specific elements do you want to be included in the report based on the collection of tweets?"}', name='Stage4'), type='function')]))], created=1713724119, model='gpt-4-1106-preview', object='chat.completion', system_fingerprint='fp_94f711dcf6', usage=CompletionUsage(completion_tokens=45, prompt_tokens=277, total_tokens=322))


2024-04-21 11:28:41,363 - INFO - Received completion from the model:
report_guide: None
questions: Could you please provide more details on how you would like the report to be structured? What specific elements do you want to be included in the report based on the collection of tweets?
